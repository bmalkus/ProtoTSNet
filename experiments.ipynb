{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3cc89ae-f713-46da-9f1f-afbcba874ec7",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torcheval.metrics.functional import multiclass_confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from datasets_utils import  ds_get_info, ds_load, TrainTestDS, TSCDataset, DSInfo, ArtificialProtos\n",
    "from autoencoder import PermutingConvAutoencoder, train_autoencoder, RegularConvEncoder\n",
    "from log import create_logger\n",
    "\n",
    "from typing import Dict\n",
    "\n",
    "from train_utils import EarlyStopping\n",
    "\n",
    "from train import EpochType, ProtoTSCoeffs, train_prototsnet, best_stat_saver, get_verbose_logger, BestModelCheckpointer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a94a0a81",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "DATASETS_PATH = Path('datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e99fcd6",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def experiment_setup(experiment_subpath):\n",
    "    experiment_dir = Path.cwd() / 'experiments' / experiment_subpath\n",
    "    os.makedirs(experiment_dir, exist_ok=True)\n",
    "\n",
    "    shutil.copy(src=Path.cwd()/'autoencoder.py', dst=experiment_dir)\n",
    "    shutil.copy(src=Path.cwd()/'datasets_utils.py', dst=experiment_dir)\n",
    "    shutil.copy(src=Path.cwd()/'experiments.ipynb', dst=experiment_dir)\n",
    "    shutil.copy(src=Path.cwd()/'model.py', dst=experiment_dir)\n",
    "    shutil.copy(src=Path.cwd()/'push.py', dst=experiment_dir)\n",
    "    shutil.copy(src=Path.cwd()/'train_utils.py', dst=experiment_dir)\n",
    "    shutil.copy(src=Path.cwd()/'train.py', dst=experiment_dir)\n",
    "    \n",
    "    return experiment_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe2ae440-8b9f-44be-bce2-a9aed146a338",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "pickled_dses_file = './datasets.pickle'\n",
    "if os.path.exists(pickled_dses_file):\n",
    "    with open(pickled_dses_file, 'rb') as f:\n",
    "        all_ds: Dict[str, TrainTestDS] = pickle.load(f)\n",
    "else:\n",
    "    all_ds = ds_load(DATASETS_PATH, list(ds_get_info().keys()))\n",
    "    with open(pickled_dses_file, 'wb') as f:\n",
    "        pickle.dump(all_ds, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e028307-f49b-4806-be0a-67fe6e089559",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"HyperparameterSearch5Fold\"\n",
    "\n",
    "default_params = {\n",
    "    \"coeffs\": ProtoTSCoeffs(crs_ent=1, clst=0, sep=0, l1=1e-3, l1_addon=3e-4),\n",
    "    \"reception\": 0.25,\n",
    "    \"proto_len\": 5,\n",
    "    \"protos_per_class\": 10,\n",
    "    \"proto_features\": 32,\n",
    "    \"features_lr\": 1e-3,\n",
    "    \"push_start_epoch\": 60,\n",
    "    \"num_last_layer_epochs\": 40,\n",
    "}\n",
    "\n",
    "for ds_name, whole_dataset in [(k, v) for k, v in all_ds.items() if k == 'ArticularyWordRecognition']: # all_ds.items():\n",
    "\n",
    "    if ds_name == 'StandWalkJump':\n",
    "        kfold = StratifiedKFold(n_splits=4)\n",
    "    else:\n",
    "        kfold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "    ds_info = ds_get_info(whole_dataset.name)\n",
    "    ds_info.features = whole_dataset.train.X.shape[1]\n",
    "    ds_info.ts_len = whole_dataset.train.X.shape[2]\n",
    "\n",
    "    receptions_to_try = [0.25, 0.5, 0.75, 0.9]\n",
    "    if ds_info.features < 4:\n",
    "        receptions_to_try.remove(0.25)\n",
    "        receptions_to_try.remove(0.75)\n",
    "    elif ds_info.features == 4:\n",
    "        receptions_to_try.remove(0.75)\n",
    "    elif ds_info.features > 500:\n",
    "        receptions_to_try.remove(0.9)\n",
    "\n",
    "    proto_len_factors_to_try = [0.01, 0.1, 0.3, 1]\n",
    "    if ds_info.ts_len < 100:\n",
    "        proto_len_factors_to_try.remove(0.01)\n",
    "\n",
    "    for reception in receptions_to_try:\n",
    "        for proto_len_factor in proto_len_factors_to_try:\n",
    "            for fold_idx, (train_ind, test_ind) in enumerate(\n",
    "                kfold.split(whole_dataset.train.X, whole_dataset.train.y)\n",
    "            ):\n",
    "                ds_info = ds_get_info(whole_dataset.name)\n",
    "                ds_info.features = whole_dataset.train.X.shape[1]\n",
    "                ds_info.ts_len = whole_dataset.train.X.shape[2]\n",
    "\n",
    "                dataset = TrainTestDS(\n",
    "                    ds_name + f\"-fold-{fold_idx}\",\n",
    "                    train=TSCDataset(\n",
    "                        whole_dataset.train.X[train_ind], whole_dataset.train.y[train_ind]\n",
    "                    ),\n",
    "                    val=TSCDataset(\n",
    "                        whole_dataset.train.X[test_ind], whole_dataset.train.y[test_ind]\n",
    "                    ),\n",
    "                    test=TSCDataset(\n",
    "                        whole_dataset.test.X, whole_dataset.test.y\n",
    "                    ),\n",
    "                )\n",
    "\n",
    "                proto_len = max(int(ds_info.ts_len * proto_len_factor), 1)\n",
    "                curr_experiment_dir = experiment_setup(\n",
    "                    f\"{experiment_name}/{whole_dataset.name}/proto-len-{proto_len}/reception-{reception}/fold-{fold_idx}\"\n",
    "                )\n",
    "\n",
    "                log, logclose = create_logger(curr_experiment_dir / \"log.txt\", display=True)\n",
    "\n",
    "                try:\n",
    "                    if os.path.exists(curr_experiment_dir / 'models' / 'last-epoch.pth'):\n",
    "                        print(f\"Skipping training for {dataset.name}, proto len {proto_len}, reception {reception}, already done\")\n",
    "                        continue\n",
    "\n",
    "                    curr_link_path = Path.cwd() / 'experiments' / experiment_name / 'current'\n",
    "                    if os.path.islink(curr_link_path):\n",
    "                        os.unlink(curr_link_path)\n",
    "                    os.symlink(curr_experiment_dir, curr_link_path)\n",
    "                    \n",
    "                    curr_log_link_path = Path.cwd() / 'experiments' / experiment_name / 'curr_log.txt'\n",
    "                    if os.path.islink(curr_log_link_path):\n",
    "                        os.unlink(curr_log_link_path)\n",
    "                    os.symlink(curr_experiment_dir / 'log.txt', curr_log_link_path)\n",
    "                    \n",
    "                    features_lr = default_params[\"features_lr\"]\n",
    "\n",
    "                    protos_per_class = default_params[\"protos_per_class\"]\n",
    "                    proto_features = default_params[\"proto_features\"]\n",
    "                    train_batch_size = 32\n",
    "                    while train_batch_size > len(dataset.train.X) / 2:\n",
    "                        train_batch_size //= 2\n",
    "                    test_batch_size = 128\n",
    "                    coeffs = default_params[\"coeffs\"]\n",
    "                    padding = 'same'\n",
    "\n",
    "                    push_start_epoch = default_params[\"push_start_epoch\"]\n",
    "                    num_warm_epochs = push_start_epoch\n",
    "                    num_last_layer_epochs = default_params[\"num_last_layer_epochs\"]\n",
    "\n",
    "                    early_stopping = EarlyStopping(\n",
    "                        retrieve_stat=\"loss_val\",\n",
    "                        mode=\"min\",\n",
    "                        patience=60,\n",
    "                        wait=push_start_epoch,\n",
    "                    )\n",
    "\n",
    "                    params = {\n",
    "                        \"protos_per_class\": protos_per_class,\n",
    "                        \"proto_features\": proto_features,\n",
    "                        \"proto_len_latent\": proto_len,\n",
    "                        \"features_lr\": features_lr,\n",
    "                        \"num_classes\": ds_info.num_classes,\n",
    "                        \"protos_per_class\": protos_per_class,\n",
    "                        \"coeffs\": coeffs._asdict(),\n",
    "                        \"num_warm_epochs\": num_warm_epochs,\n",
    "                        \"push_start_epoch\": push_start_epoch,\n",
    "                        \"num_last_layer_epochs\": num_last_layer_epochs,\n",
    "                    }\n",
    "                    with open(curr_experiment_dir / \"params.json\", \"w\") as f:\n",
    "                        json.dump(params, f, indent=4)\n",
    "\n",
    "                    log(\n",
    "                        f\"Training for {dataset.name}, proto len {proto_len}, reception {reception}, features_lr {features_lr}, protos per class {protos_per_class}, l1_addon {coeffs.l1_addon}\",\n",
    "                        flush=True,\n",
    "                        display=True\n",
    "                    )\n",
    "                    log(f'Params: {json.dumps(params, indent=4)}')\n",
    "                    \n",
    "                    whole_training_start = time.time()\n",
    "\n",
    "                    log(f'Training encoder', flush=True, display=True)\n",
    "                    autoencoder = PermutingConvAutoencoder(num_features=ds_info.features, latent_features=proto_features, reception_percent=reception, padding=padding)\n",
    "                    train_loader = torch.utils.data.DataLoader(dataset.train, batch_size=train_batch_size, shuffle=True)\n",
    "                    val_loader = torch.utils.data.DataLoader(dataset.val, batch_size=test_batch_size)\n",
    "                    train_autoencoder(autoencoder, train_loader, val_loader, device=device, log=log)\n",
    "                    encoder = autoencoder.encoder\n",
    "\n",
    "                    log(f'Training ProtoTSNet', flush=True, display=True)\n",
    "                    trainer = train_prototsnet(\n",
    "                        dataset,\n",
    "                        curr_experiment_dir,\n",
    "                        device,\n",
    "                        encoder,\n",
    "                        features_lr,\n",
    "                        coeffs,\n",
    "                        protos_per_class,\n",
    "                        proto_features,\n",
    "                        proto_len,\n",
    "                        train_batch_size,\n",
    "                        test_batch_size,\n",
    "                        num_epochs=1000,\n",
    "                        num_warm_epochs=num_warm_epochs,\n",
    "                        push_start_epoch=push_start_epoch,\n",
    "                        push_epochs=range(0, 1000, 20),\n",
    "                        ds_info=ds_info,\n",
    "                        num_last_layer_epochs=num_last_layer_epochs,\n",
    "                        custom_checkpointers=[\n",
    "                            get_verbose_logger(dataset.name),\n",
    "                            best_stat_saver(\n",
    "                                \"loss_val\", curr_experiment_dir / \"min_loss.json\"\n",
    "                            ) if dataset.val is not None else lambda *_: None,\n",
    "                        ],\n",
    "                        early_stopping=early_stopping,\n",
    "                        log=log,\n",
    "                    )\n",
    "\n",
    "                    accu_val = trainer.stats()[\"accu_val\"]\n",
    "                    for i, d in enumerate(accu_val):\n",
    "                        if d[\"epoch_type\"] == \"PUSH\":\n",
    "                            break\n",
    "                    accu_val = accu_val[i:]\n",
    "                    log(\n",
    "                        f'Overall best val accu: {max(s[\"value\"] for s in accu_val)*100:.2f}%, push best: {max(s[\"value\"] for s in trainer.stats()[\"accu_test\"] if s[\"epoch_type\"] in [\"PUSH\", \"LAST_LAYER\"])*100:.2f}%',\n",
    "                        display=True)\n",
    "                    whole_training_end = time.time()\n",
    "                    \n",
    "                    log(f\"Done in {trainer.curr_epoch - 1} epochs, {whole_training_end - whole_training_start:.2f}s\", display=True)\n",
    "                except Exception as e:\n",
    "                    log(f\"Exception ocurred for {ds_name}: {e}\", display=True)\n",
    "                    tb_str = traceback.format_tb(e.__traceback__)\n",
    "                    log('\\n'.join(tb_str), display=True)\n",
    "                finally:\n",
    "                    logclose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "183e9716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for ArticularyWordRecognition, proto len 144, reception 0.25, features_lr 0.001, protos per class 10, l1_addon 3e-05\n",
      "Params: {\n",
      "    \"protos_per_class\": 10,\n",
      "    \"proto_features\": 32,\n",
      "    \"proto_len_latent\": 144,\n",
      "    \"features_lr\": 0.001,\n",
      "    \"num_classes\": 25,\n",
      "    \"coeffs\": {\n",
      "        \"crs_ent\": 1,\n",
      "        \"clst\": 0,\n",
      "        \"sep\": 0,\n",
      "        \"l1\": 0.001,\n",
      "        \"l1_addon\": 3e-05\n",
      "    },\n",
      "    \"num_warm_epochs\": 50,\n",
      "    \"push_start_epoch\": 110,\n",
      "    \"num_last_layer_epochs\": 40,\n",
      "    \"epochs\": 200\n",
      "}\n",
      "Training encoder\n",
      "epoch:   10/300 mse loss: 0.0437\n",
      "epoch:   20/300 mse loss: 0.0360\n",
      "epoch:   30/300 mse loss: 0.0391\n",
      "epoch:   40/300 mse loss: 0.0538\n",
      "epoch:   50/300 mse loss: 0.0527\n",
      "epoch:   60/300 mse loss: 0.0597\n",
      "epoch:   70/300 mse loss: 0.0694\n",
      "epoch:   80/300 mse loss: 0.0751\n",
      "epoch:   90/300 mse loss: 0.0763\n",
      "epoch:  100/300 mse loss: 0.0742\n",
      "epoch:  110/300 mse loss: 0.0753\n",
      "epoch:  120/300 mse loss: 0.0751\n",
      "epoch:  130/300 mse loss: 0.0750\n",
      "epoch:  140/300 mse loss: 0.0729\n",
      "epoch:  150/300 mse loss: 0.0725\n",
      "epoch:  160/300 mse loss: 0.0731\n",
      "epoch:  170/300 mse loss: 0.0724\n",
      "epoch:  180/300 mse loss: 0.0724\n",
      "epoch:  190/300 mse loss: 0.0733\n",
      "epoch:  200/300 mse loss: 0.0740\n",
      "epoch:  210/300 mse loss: 0.0727\n",
      "epoch:  220/300 mse loss: 0.0724\n",
      "epoch:  230/300 mse loss: 0.0726\n",
      "epoch:  240/300 mse loss: 0.0724\n",
      "epoch:  250/300 mse loss: 0.0727\n",
      "epoch:  260/300 mse loss: 0.0729\n",
      "epoch:  270/300 mse loss: 0.0728\n",
      "epoch:  280/300 mse loss: 0.0729\n",
      "epoch:  290/300 mse loss: 0.0731\n",
      "epoch:  300/300 mse loss: 0.0725\n",
      "Training ProtoTSNet\n",
      "Starting training\n",
      "epoch:   1 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 4.00%\n",
      "    train overall loss:       6.224667125278049\n",
      "    train cross_ent loss:     3.2188575797610812\n",
      "    test overall loss:        6.224249521891276\n",
      "    test cross_ent loss:      3.2188666661580405\n",
      "    cluster loss:             3353.149169921875\n",
      "    separation loss:          1112.560302734375\n",
      "    avg separation loss:      1132.5574951171875\n",
      "    l1_addon loss:            179.4165496826172\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04332447052001953\n",
      "    test time:                0.012856483459472656\n",
      "    epoch time:               0.056836843490600586\n",
      "epoch:   2 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 4.00%\n",
      "    train overall loss:       6.2238443692525225\n",
      "    train cross_ent loss:     3.218777126736111\n",
      "    test overall loss:        6.223522822062175\n",
      "    test cross_ent loss:      3.218837340672811\n",
      "    cluster loss:             3355.970703125\n",
      "    separation loss:          1117.9016520182292\n",
      "    avg separation loss:      1154.9610188802083\n",
      "    l1_addon loss:            156.1851043701172\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04211688041687012\n",
      "    test time:                0.012680530548095703\n",
      "    epoch time:               0.05546855926513672\n",
      "epoch:   3 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 5.67%\n",
      "    train overall loss:       6.223086251152886\n",
      "    train cross_ent loss:     3.2186825805240207\n",
      "    test overall loss:        6.222815831502278\n",
      "    test cross_ent loss:      3.218752940495809\n",
      "    cluster loss:             3370.3538411458335\n",
      "    separation loss:          1163.052978515625\n",
      "    avg separation loss:      1210.3892008463542\n",
      "    l1_addon loss:            135.4224853515625\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04210996627807617\n",
      "    test time:                0.02086925506591797\n",
      "    epoch time:               0.06365561485290527\n",
      "epoch:   4 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 22.33%\n",
      "    train overall loss:       6.222389380137126\n",
      "    train cross_ent loss:     3.2185803254445395\n",
      "    test overall loss:        6.222128709157308\n",
      "    test cross_ent loss:      3.2186248302459717\n",
      "    cluster loss:             3379.512451171875\n",
      "    separation loss:          1182.2055257161458\n",
      "    avg separation loss:      1257.8506266276042\n",
      "    l1_addon loss:            116.79396057128906\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04198312759399414\n",
      "    test time:                0.012630462646484375\n",
      "    epoch time:               0.05527329444885254\n",
      "epoch:   5 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 28.33%\n",
      "    train overall loss:       6.221742577022976\n",
      "    train cross_ent loss:     3.2184628115759955\n",
      "    test overall loss:        6.221513271331787\n",
      "    test cross_ent loss:      3.218500773111979\n",
      "    cluster loss:             3380.9479166666665\n",
      "    separation loss:          1179.5697835286458\n",
      "    avg separation loss:      1283.54345703125\n",
      "    l1_addon loss:            100.39991760253906\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04674172401428223\n",
      "    test time:                0.01257634162902832\n",
      "    epoch time:               0.059979915618896484\n",
      "epoch:   6 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       6.221155537499322\n",
      "    train cross_ent loss:     3.2183403174082437\n",
      "    test overall loss:        6.220959345499675\n",
      "    test cross_ent loss:      3.218379338582357\n",
      "    cluster loss:             3370.81591796875\n",
      "    separation loss:          1156.0898030598958\n",
      "    avg separation loss:      1269.0657552083333\n",
      "    l1_addon loss:            85.99406433105469\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.042101144790649414\n",
      "    test time:                0.012596845626831055\n",
      "    epoch time:               0.05536389350891113\n",
      "epoch:   7 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 33.00%\n",
      "    train overall loss:       6.2206250296698675\n",
      "    train cross_ent loss:     3.2182097170088024\n",
      "    test overall loss:        6.220452467600505\n",
      "    test cross_ent loss:      3.2182230949401855\n",
      "    cluster loss:             3350.6962076822915\n",
      "    separation loss:          1109.3580322265625\n",
      "    avg separation loss:      1222.9810791015625\n",
      "    l1_addon loss:            74.30754089355469\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05022859573364258\n",
      "    test time:                0.012571096420288086\n",
      "    epoch time:               0.0634610652923584\n",
      "epoch:   8 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 32.67%\n",
      "    train overall loss:       6.220109038882786\n",
      "    train cross_ent loss:     3.217993550830417\n",
      "    test overall loss:        6.219964663187663\n",
      "    test cross_ent loss:      3.2179764906565347\n",
      "    cluster loss:             3323.0401204427085\n",
      "    separation loss:          1038.9718017578125\n",
      "    avg separation loss:      1162.1583251953125\n",
      "    l1_addon loss:            66.2642822265625\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05059480667114258\n",
      "    test time:                0.01257944107055664\n",
      "    epoch time:               0.06382942199707031\n",
      "epoch:   9 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 34.67%\n",
      "    train overall loss:       6.219567245907253\n",
      "    train cross_ent loss:     3.217655128902859\n",
      "    test overall loss:        6.219422817230225\n",
      "    test cross_ent loss:      3.217588186264038\n",
      "    cluster loss:             3290.1442057291665\n",
      "    separation loss:          955.6154581705729\n",
      "    avg separation loss:      1093.1034342447917\n",
      "    l1_addon loss:            61.140655517578125\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04200339317321777\n",
      "    test time:                0.012586116790771484\n",
      "    epoch time:               0.05525398254394531\n",
      "epoch:  10 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 42.67%\n",
      "    train overall loss:       6.218893157111274\n",
      "    train cross_ent loss:     3.2171010176340737\n",
      "    test overall loss:        6.218763033548991\n",
      "    test cross_ent loss:      3.217017571131388\n",
      "    cluster loss:             3253.5640462239585\n",
      "    separation loss:          864.949462890625\n",
      "    avg separation loss:      1016.1984049479166\n",
      "    l1_addon loss:            58.17588806152344\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04718303680419922\n",
      "    test time:                0.012536048889160156\n",
      "    epoch time:               0.06038069725036621\n",
      "epoch:  11 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 45.67%\n",
      "    train overall loss:       6.218076758914524\n",
      "    train cross_ent loss:     3.2163757748074002\n",
      "    test overall loss:        6.217935721079509\n",
      "    test cross_ent loss:      3.2162970701853433\n",
      "    cluster loss:             3218.0244954427085\n",
      "    separation loss:          780.8973388671875\n",
      "    avg separation loss:      931.5379435221354\n",
      "    l1_addon loss:            54.60871887207031\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04209589958190918\n",
      "    test time:                0.024724245071411133\n",
      "    epoch time:               0.0674901008605957\n",
      "epoch:  12 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 52.00%\n",
      "    train overall loss:       6.216954761081272\n",
      "    train cross_ent loss:     3.2153698338402643\n",
      "    test overall loss:        6.216640631357829\n",
      "    test cross_ent loss:      3.2150877316792807\n",
      "    cluster loss:             3175.4156901041665\n",
      "    separation loss:          673.1948038736979\n",
      "    avg separation loss:      819.5215454101562\n",
      "    l1_addon loss:            51.75518035888672\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04192996025085449\n",
      "    test time:                0.012591123580932617\n",
      "    epoch time:               0.05518007278442383\n",
      "epoch:  13 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 51.33%\n",
      "    train overall loss:       6.215273221333821\n",
      "    train cross_ent loss:     3.2137404017978244\n",
      "    test overall loss:        6.215099493662517\n",
      "    test cross_ent loss:      3.2136386235555015\n",
      "    cluster loss:             3142.0870768229165\n",
      "    separation loss:          591.5652669270834\n",
      "    avg separation loss:      730.4958089192709\n",
      "    l1_addon loss:            48.68622970581055\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05090451240539551\n",
      "    test time:                0.012614965438842773\n",
      "    epoch time:               0.06418132781982422\n",
      "epoch:  14 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 49.00%\n",
      "    train overall loss:       6.213299698299831\n",
      "    train cross_ent loss:     3.2118644184536405\n",
      "    test overall loss:        6.213219165802002\n",
      "    test cross_ent loss:      3.211879332860311\n",
      "    cluster loss:             3119.8868001302085\n",
      "    separation loss:          542.3031005859375\n",
      "    avg separation loss:      673.7176513671875\n",
      "    l1_addon loss:            44.64519500732422\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04202675819396973\n",
      "    test time:                0.012601852416992188\n",
      "    epoch time:               0.055299997329711914\n",
      "epoch:  15 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 49.67%\n",
      "    train overall loss:       6.211111863454183\n",
      "    train cross_ent loss:     3.2097753948635526\n",
      "    test overall loss:        6.210924784342448\n",
      "    test cross_ent loss:      3.209599415461222\n",
      "    cluster loss:             3101.210205078125\n",
      "    separation loss:          497.29932657877606\n",
      "    avg separation loss:      640.6698404947916\n",
      "    l1_addon loss:            44.16820526123047\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04213094711303711\n",
      "    test time:                0.012573003768920898\n",
      "    epoch time:               0.05536651611328125\n",
      "epoch:  16 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 49.33%\n",
      "    train overall loss:       6.208185778723823\n",
      "    train cross_ent loss:     3.206884119245741\n",
      "    test overall loss:        6.2081403732299805\n",
      "    test cross_ent loss:      3.206857760747274\n",
      "    cluster loss:             3086.0042317708335\n",
      "    separation loss:          463.61622111002606\n",
      "    avg separation loss:      609.23828125\n",
      "    l1_addon loss:            42.73947525024414\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.042055606842041016\n",
      "    test time:                0.02193307876586914\n",
      "    epoch time:               0.06464838981628418\n",
      "epoch:  17 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 50.67%\n",
      "    train overall loss:       6.204647858937581\n",
      "    train cross_ent loss:     3.2033655643463135\n",
      "    test overall loss:        6.20441468556722\n",
      "    test cross_ent loss:      3.2031260331471763\n",
      "    cluster loss:             3070.514404296875\n",
      "    separation loss:          425.0093688964844\n",
      "    avg separation loss:      579.9314168294271\n",
      "    l1_addon loss:            42.9407958984375\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04204058647155762\n",
      "    test time:                0.012611150741577148\n",
      "    epoch time:               0.05531764030456543\n",
      "epoch:  18 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 50.33%\n",
      "    train overall loss:       6.199434757232666\n",
      "    train cross_ent loss:     3.198167986339993\n",
      "    test overall loss:        6.199545065561931\n",
      "    test cross_ent loss:      3.198245127995809\n",
      "    cluster loss:             3056.260009765625\n",
      "    separation loss:          389.0026448567708\n",
      "    avg separation loss:      550.9892171223959\n",
      "    l1_addon loss:            43.324676513671875\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04624009132385254\n",
      "    test time:                0.012564420700073242\n",
      "    epoch time:               0.05945634841918945\n",
      "epoch:  19 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 53.00%\n",
      "    train overall loss:       6.191834926605225\n",
      "    train cross_ent loss:     3.19057215584649\n",
      "    test overall loss:        6.192435423533122\n",
      "    test cross_ent loss:      3.191147247950236\n",
      "    cluster loss:             3042.2449544270835\n",
      "    separation loss:          352.6115417480469\n",
      "    avg separation loss:      514.8943583170573\n",
      "    l1_addon loss:            42.93386459350586\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.042253732681274414\n",
      "    test time:                0.012603759765625\n",
      "    epoch time:               0.05552387237548828\n",
      "epoch:  20 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 50.67%\n",
      "    train overall loss:       6.181564119127062\n",
      "    train cross_ent loss:     3.1803242365519204\n",
      "    test overall loss:        6.182769775390625\n",
      "    test cross_ent loss:      3.1815059979756675\n",
      "    cluster loss:             3029.0262858072915\n",
      "    separation loss:          316.87696329752606\n",
      "    avg separation loss:      476.7580261230469\n",
      "    l1_addon loss:            42.115543365478516\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05054330825805664\n",
      "    test time:                0.012561559677124023\n",
      "    epoch time:               0.06375765800476074\n",
      "epoch:  21 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 49.33%\n",
      "    train overall loss:       6.1673041979471845\n",
      "    train cross_ent loss:     3.166073825624254\n",
      "    test overall loss:        6.169250965118408\n",
      "    test cross_ent loss:      3.1680866877237954\n",
      "    cluster loss:             3018.2609049479165\n",
      "    separation loss:          285.3537902832031\n",
      "    avg separation loss:      434.46375528971356\n",
      "    l1_addon loss:            38.79621887207031\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.050650596618652344\n",
      "    test time:                0.012606143951416016\n",
      "    epoch time:               0.06390762329101562\n",
      "epoch:  22 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 54.33%\n",
      "    train overall loss:       6.144390371110704\n",
      "    train cross_ent loss:     3.143200821346707\n",
      "    test overall loss:        6.151458740234375\n",
      "    test cross_ent loss:      3.1502788066864014\n",
      "    cluster loss:             3005.9152018229165\n",
      "    separation loss:          246.8085479736328\n",
      "    avg separation loss:      394.09307861328125\n",
      "    l1_addon loss:            39.32161331176758\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.0420074462890625\n",
      "    test time:                0.012627124786376953\n",
      "    epoch time:               0.055294036865234375\n",
      "epoch:  23 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 61.67%\n",
      "    train overall loss:       6.126202954186334\n",
      "    train cross_ent loss:     3.1250206099616156\n",
      "    test overall loss:        6.135602633158366\n",
      "    test cross_ent loss:      3.13440211613973\n",
      "    cluster loss:             2997.385009765625\n",
      "    separation loss:          219.65233357747397\n",
      "    avg separation loss:      368.8939921061198\n",
      "    l1_addon loss:            40.0029296875\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04206442832946777\n",
      "    test time:                0.012047529220581055\n",
      "    epoch time:               0.0547792911529541\n",
      "epoch:  24 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 62.67%\n",
      "    train overall loss:       6.0984206199646\n",
      "    train cross_ent loss:     3.097251017888387\n",
      "    test overall loss:        6.113652388254802\n",
      "    test cross_ent loss:      3.1125054359436035\n",
      "    cluster loss:             2989.9147135416665\n",
      "    separation loss:          193.61327616373697\n",
      "    avg separation loss:      335.53807576497394\n",
      "    l1_addon loss:            38.22994613647461\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04141569137573242\n",
      "    test time:                0.020038604736328125\n",
      "    epoch time:               0.06211352348327637\n",
      "epoch:  25 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 69.00%\n",
      "    train overall loss:       6.076232327355279\n",
      "    train cross_ent loss:     3.075095944934421\n",
      "    test overall loss:        6.10279115041097\n",
      "    test cross_ent loss:      3.1016085942586265\n",
      "    cluster loss:             2983.751220703125\n",
      "    separation loss:          172.70835876464844\n",
      "    avg separation loss:      321.45229085286456\n",
      "    l1_addon loss:            39.42145538330078\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04108572006225586\n",
      "    test time:                0.012042522430419922\n",
      "    epoch time:               0.053792715072631836\n",
      "epoch:  26 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 68.00%\n",
      "    train overall loss:       6.05069367090861\n",
      "    train cross_ent loss:     3.0495830376942954\n",
      "    test overall loss:        6.079783916473389\n",
      "    test cross_ent loss:      3.0786754290262857\n",
      "    cluster loss:             2978.5064290364585\n",
      "    separation loss:          151.48172505696616\n",
      "    avg separation loss:      286.46229044596356\n",
      "    l1_addon loss:            36.94487380981445\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04611659049987793\n",
      "    test time:                0.01206207275390625\n",
      "    epoch time:               0.058836936950683594\n",
      "epoch:  27 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 67.00%\n",
      "    train overall loss:       6.012519836425781\n",
      "    train cross_ent loss:     3.0114209122127957\n",
      "    test overall loss:        6.065809567769368\n",
      "    test cross_ent loss:      3.0647586981455484\n",
      "    cluster loss:             2974.543701171875\n",
      "    separation loss:          137.22901662190756\n",
      "    avg separation loss:      263.61334228515625\n",
      "    l1_addon loss:            35.020545959472656\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04135441780090332\n",
      "    test time:                0.012058496475219727\n",
      "    epoch time:               0.054071903228759766\n",
      "epoch:  28 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 71.67%\n",
      "    train overall loss:       6.007186677720812\n",
      "    train cross_ent loss:     3.006105581919352\n",
      "    test overall loss:        6.052747885386149\n",
      "    test cross_ent loss:      3.0516833464304605\n",
      "    cluster loss:             2970.76513671875\n",
      "    separation loss:          124.20557403564453\n",
      "    avg separation loss:      256.8369954427083\n",
      "    l1_addon loss:            35.47000503540039\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04558420181274414\n",
      "    test time:                0.012032032012939453\n",
      "    epoch time:               0.05826568603515625\n",
      "epoch:  29 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 72.00%\n",
      "    train overall loss:       5.968882401784261\n",
      "    train cross_ent loss:     2.9678259425693088\n",
      "    test overall loss:        6.041943232218425\n",
      "    test cross_ent loss:      3.040872494379679\n",
      "    cluster loss:             2967.6864420572915\n",
      "    separation loss:          111.15640513102214\n",
      "    avg separation loss:      238.90958658854166\n",
      "    l1_addon loss:            35.67938995361328\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04114198684692383\n",
      "    test time:                0.01910090446472168\n",
      "    epoch time:               0.060901641845703125\n",
      "epoch:  30 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 72.00%\n",
      "    train overall loss:       5.960626443227132\n",
      "    train cross_ent loss:     2.959590752919515\n",
      "    test overall loss:        6.034966627756755\n",
      "    test cross_ent loss:      3.033935546875\n",
      "    cluster loss:             2965.8104654947915\n",
      "    separation loss:          102.75257364908855\n",
      "    avg separation loss:      227.18505350748697\n",
      "    l1_addon loss:            34.36101531982422\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.0410768985748291\n",
      "    test time:                0.012077093124389648\n",
      "    epoch time:               0.05380821228027344\n",
      "epoch:  31 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 74.33%\n",
      "    train overall loss:       5.9273397657606335\n",
      "    train cross_ent loss:     2.9263199965159097\n",
      "    test overall loss:        6.026547114054362\n",
      "    test cross_ent loss:      3.0255316893259683\n",
      "    cluster loss:             2963.8275553385415\n",
      "    separation loss:          94.83170827229817\n",
      "    avg separation loss:      215.74856567382812\n",
      "    l1_addon loss:            33.83384704589844\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.041197776794433594\n",
      "    test time:                0.012058734893798828\n",
      "    epoch time:               0.05391049385070801\n",
      "epoch:  32 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 76.67%\n",
      "    train overall loss:       5.90578646130032\n",
      "    train cross_ent loss:     2.90478417608473\n",
      "    test overall loss:        6.02625830968221\n",
      "    test cross_ent loss:      3.0252261956532798\n",
      "    cluster loss:             2962.40771484375\n",
      "    separation loss:          88.60680898030598\n",
      "    avg separation loss:      216.22869364420572\n",
      "    l1_addon loss:            34.394683837890625\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04115438461303711\n",
      "    test time:                0.012065410614013672\n",
      "    epoch time:               0.053874969482421875\n",
      "epoch:  33 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 75.67%\n",
      "    train overall loss:       5.894039207034641\n",
      "    train cross_ent loss:     2.893043941921658\n",
      "    test overall loss:        6.011949380238851\n",
      "    test cross_ent loss:      3.0109535853068032\n",
      "    cluster loss:             2961.2452799479165\n",
      "    separation loss:          82.86572774251302\n",
      "    avg separation loss:      199.88803100585938\n",
      "    l1_addon loss:            33.187679290771484\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04121804237365723\n",
      "    test time:                0.012037277221679688\n",
      "    epoch time:               0.053919076919555664\n",
      "epoch:  34 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 76.00%\n",
      "    train overall loss:       5.8687693277994795\n",
      "    train cross_ent loss:     2.867789480421278\n",
      "    test overall loss:        6.000322182973226\n",
      "    test cross_ent loss:      2.999367872873942\n",
      "    cluster loss:             2960.3624674479165\n",
      "    separation loss:          80.23688507080078\n",
      "    avg separation loss:      198.84719848632812\n",
      "    l1_addon loss:            31.79738426208496\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.041110992431640625\n",
      "    test time:                0.02043437957763672\n",
      "    epoch time:               0.06220436096191406\n",
      "epoch:  35 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 72.00%\n",
      "    train overall loss:       5.866041342417399\n",
      "    train cross_ent loss:     2.865081310272217\n",
      "    test overall loss:        6.012444972991943\n",
      "    test cross_ent loss:      3.0115320682525635\n",
      "    cluster loss:             2960.5253092447915\n",
      "    separation loss:          78.59439341227214\n",
      "    avg separation loss:      184.85838317871094\n",
      "    l1_addon loss:            30.419048309326172\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.041356563568115234\n",
      "    test time:                0.01213216781616211\n",
      "    epoch time:               0.05415010452270508\n",
      "epoch:  36 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 71.33%\n",
      "    train overall loss:       5.84276819229126\n",
      "    train cross_ent loss:     2.841825352774726\n",
      "    test overall loss:        6.015870571136475\n",
      "    test cross_ent loss:      3.014967203140259\n",
      "    cluster loss:             2960.2650553385415\n",
      "    separation loss:          76.88598378499348\n",
      "    avg separation loss:      185.40253194173178\n",
      "    l1_addon loss:            30.10446548461914\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04117083549499512\n",
      "    test time:                0.01204538345336914\n",
      "    epoch time:               0.05387616157531738\n",
      "epoch:  37 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 72.67%\n",
      "    train overall loss:       5.84262588289049\n",
      "    train cross_ent loss:     2.8416962093777127\n",
      "    test overall loss:        5.997820218404134\n",
      "    test cross_ent loss:      2.996907869974772\n",
      "    cluster loss:             2959.29052734375\n",
      "    separation loss:          71.76372909545898\n",
      "    avg separation loss:      178.52606201171875\n",
      "    l1_addon loss:            30.406654357910156\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04116249084472656\n",
      "    test time:                0.01206064224243164\n",
      "    epoch time:               0.05387306213378906\n",
      "epoch:  38 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 73.33%\n",
      "    train overall loss:       5.830745485093859\n",
      "    train cross_ent loss:     2.829809135860867\n",
      "    test overall loss:        5.988620440165202\n",
      "    test cross_ent loss:      2.9877304236094155\n",
      "    cluster loss:             2959.0328776041665\n",
      "    separation loss:          70.60510762532552\n",
      "    avg separation loss:      177.5059560139974\n",
      "    l1_addon loss:            29.666635513305664\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.045496463775634766\n",
      "    test time:                0.012015819549560547\n",
      "    epoch time:               0.058173179626464844\n",
      "epoch:  39 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 73.33%\n",
      "    train overall loss:       5.8093384636773004\n",
      "    train cross_ent loss:     2.808417320251465\n",
      "    test overall loss:        5.973508834838867\n",
      "    test cross_ent loss:      2.9726199309031167\n",
      "    cluster loss:             2958.3738606770835\n",
      "    separation loss:          67.9941520690918\n",
      "    avg separation loss:      175.3544464111328\n",
      "    l1_addon loss:            29.632495880126953\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04104351997375488\n",
      "    test time:                0.012030839920043945\n",
      "    epoch time:               0.05373072624206543\n",
      "epoch:  40 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 73.67%\n",
      "    train overall loss:       5.784513367546929\n",
      "    train cross_ent loss:     2.7836090193854437\n",
      "    test overall loss:        5.974197069803874\n",
      "    test cross_ent loss:      2.9732774098714194\n",
      "    cluster loss:             2958.3920084635415\n",
      "    separation loss:          67.15527089436848\n",
      "    avg separation loss:      179.18977864583334\n",
      "    l1_addon loss:            30.642589569091797\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04111742973327637\n",
      "    test time:                0.012094497680664062\n",
      "    epoch time:               0.05387282371520996\n",
      "epoch:  41 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 73.67%\n",
      "    train overall loss:       5.762175136142307\n",
      "    train cross_ent loss:     2.761283026801215\n",
      "    test overall loss:        5.962596257527669\n",
      "    test cross_ent loss:      2.9616976579030356\n",
      "    cluster loss:             2958.0245768229165\n",
      "    separation loss:          65.40530649820964\n",
      "    avg separation loss:      175.32394409179688\n",
      "    l1_addon loss:            29.94353485107422\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04109907150268555\n",
      "    test time:                0.012079000473022461\n",
      "    epoch time:               0.05384349822998047\n",
      "epoch:  42 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 72.00%\n",
      "    train overall loss:       5.762865755293104\n",
      "    train cross_ent loss:     2.761976533465915\n",
      "    test overall loss:        5.986278216044108\n",
      "    test cross_ent loss:      2.9853437741597495\n",
      "    cluster loss:             2958.8041178385415\n",
      "    separation loss:          66.33788299560547\n",
      "    avg separation loss:      182.30418904622397\n",
      "    l1_addon loss:            31.12995147705078\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04120802879333496\n",
      "    test time:                0.012074470520019531\n",
      "    epoch time:               0.05393838882446289\n",
      "epoch:  43 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 71.00%\n",
      "    train overall loss:       5.778346538543701\n",
      "    train cross_ent loss:     2.7774643898010254\n",
      "    test overall loss:        5.9718546867370605\n",
      "    test cross_ent loss:      2.9709675312042236\n",
      "    cluster loss:             2958.25\n",
      "    separation loss:          64.54434204101562\n",
      "    avg separation loss:      175.45608520507812\n",
      "    l1_addon loss:            29.564767837524414\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.042635440826416016\n",
      "    test time:                0.01209259033203125\n",
      "    epoch time:               0.055394887924194336\n",
      "epoch:  44 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 71.33%\n",
      "    train overall loss:       5.748550256093343\n",
      "    train cross_ent loss:     2.747691922717624\n",
      "    test overall loss:        5.950454394022624\n",
      "    test cross_ent loss:      2.9496026039123535\n",
      "    cluster loss:             2957.91748046875\n",
      "    separation loss:          62.353458404541016\n",
      "    avg separation loss:      166.13061014811197\n",
      "    l1_addon loss:            28.39450454711914\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04117083549499512\n",
      "    test time:                0.014316558837890625\n",
      "    epoch time:               0.0561375617980957\n",
      "epoch:  45 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 70.33%\n",
      "    train overall loss:       5.705188751220703\n",
      "    train cross_ent loss:     2.704324060016208\n",
      "    test overall loss:        5.9384833971659345\n",
      "    test cross_ent loss:      2.9376529852549234\n",
      "    cluster loss:             2957.6456705729165\n",
      "    separation loss:          61.07493336995443\n",
      "    avg separation loss:      163.97775268554688\n",
      "    l1_addon loss:            27.67966651916504\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.041152000427246094\n",
      "    test time:                0.01205587387084961\n",
      "    epoch time:               0.0538637638092041\n",
      "epoch:  46 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 71.00%\n",
      "    train overall loss:       5.731113380855984\n",
      "    train cross_ent loss:     2.7302610079447427\n",
      "    test overall loss:        5.939011096954346\n",
      "    test cross_ent loss:      2.938175996144613\n",
      "    cluster loss:             2957.4710286458335\n",
      "    separation loss:          59.85150273640951\n",
      "    avg separation loss:      160.36673482259116\n",
      "    l1_addon loss:            27.8333740234375\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.041124820709228516\n",
      "    test time:                0.012143135070800781\n",
      "    epoch time:               0.05391645431518555\n",
      "epoch:  47 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 70.33%\n",
      "    train overall loss:       5.684002664354113\n",
      "    train cross_ent loss:     2.683159351348877\n",
      "    test overall loss:        5.953101793924968\n",
      "    test cross_ent loss:      2.9522317250569663\n",
      "    cluster loss:             2957.9742024739585\n",
      "    separation loss:          60.755296071370445\n",
      "    avg separation loss:      172.10490926106772\n",
      "    l1_addon loss:            28.992841720581055\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.041227102279663086\n",
      "    test time:                0.012051582336425781\n",
      "    epoch time:               0.05393409729003906\n",
      "epoch:  48 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 71.00%\n",
      "    train overall loss:       5.667706065707737\n",
      "    train cross_ent loss:     2.6668687661488852\n",
      "    test overall loss:        5.927987416585286\n",
      "    test cross_ent loss:      2.927168289820353\n",
      "    cluster loss:             2957.41455078125\n",
      "    separation loss:          58.28136444091797\n",
      "    avg separation loss:      161.3744354248047\n",
      "    l1_addon loss:            27.287952423095703\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.041190385818481445\n",
      "    test time:                0.0120849609375\n",
      "    epoch time:               0.05392742156982422\n",
      "epoch:  49 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 68.33%\n",
      "    train overall loss:       5.653067800733778\n",
      "    train cross_ent loss:     2.6522362497117786\n",
      "    test overall loss:        5.93150266011556\n",
      "    test cross_ent loss:      2.930663506189982\n",
      "    cluster loss:             2957.5835774739585\n",
      "    separation loss:          57.47257995605469\n",
      "    avg separation loss:      160.49105326334634\n",
      "    l1_addon loss:            27.952524185180664\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04115748405456543\n",
      "    test time:                0.012040376663208008\n",
      "    epoch time:               0.053854942321777344\n",
      "epoch:  50 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 70.67%\n",
      "    train overall loss:       5.670453813340929\n",
      "    train cross_ent loss:     2.669633838865492\n",
      "    test overall loss:        5.927558898925781\n",
      "    test cross_ent loss:      2.926744302113851\n",
      "    cluster loss:             2957.413818359375\n",
      "    separation loss:          57.748400370279946\n",
      "    avg separation loss:      163.05340067545572\n",
      "    l1_addon loss:            27.153684616088867\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.041159629821777344\n",
      "    test time:                0.012052297592163086\n",
      "    epoch time:               0.05387520790100098\n",
      "epoch:  51 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 69.67%\n",
      "    train overall loss:       5.711333539750841\n",
      "    train cross_ent loss:     2.710521936416626\n",
      "    test overall loss:        5.954419136047363\n",
      "    test cross_ent loss:      2.9536077976226807\n",
      "    cluster loss:             2957.8807779947915\n",
      "    separation loss:          59.053969065348305\n",
      "    avg separation loss:      185.4205780029297\n",
      "    l1_addon loss:            27.035011291503906\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05817699432373047\n",
      "    test time:                0.012105464935302734\n",
      "    epoch time:               0.07098031044006348\n",
      "    joint lr:                 0.0030601000000000087\n",
      "epoch:  52 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 17.33%\n",
      "    train overall loss:       6.135411792331272\n",
      "    train cross_ent loss:     3.134596135881212\n",
      "    test overall loss:        6.217930316925049\n",
      "    test cross_ent loss:      3.217108964920044\n",
      "    cluster loss:             3280.5050455729165\n",
      "    separation loss:          865.2752482096354\n",
      "    avg separation loss:      1426.02197265625\n",
      "    l1_addon loss:            27.372447967529297\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05809640884399414\n",
      "    test time:                0.012153387069702148\n",
      "    epoch time:               0.07099533081054688\n",
      "    joint lr:                 0.005960997999999999\n",
      "epoch:  53 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 20.00%\n",
      "    train overall loss:       6.20112238989936\n",
      "    train cross_ent loss:     3.2002862294514975\n",
      "    test overall loss:        6.217694123586019\n",
      "    test cross_ent loss:      3.216844320297241\n",
      "    cluster loss:             3251.7696126302085\n",
      "    separation loss:          747.3872884114584\n",
      "    avg separation loss:      1338.76220703125\n",
      "    l1_addon loss:            28.329086303710938\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05837130546569824\n",
      "    test time:                0.012163877487182617\n",
      "    epoch time:               0.07131099700927734\n",
      "    joint lr:                 0.008803582030000007\n",
      "epoch:  54 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 33.67%\n",
      "    train overall loss:       6.202013969421387\n",
      "    train cross_ent loss:     3.201164139641656\n",
      "    test overall loss:        6.213132381439209\n",
      "    test cross_ent loss:      3.2122915585835776\n",
      "    cluster loss:             3090.7526041666665\n",
      "    separation loss:          351.78394571940106\n",
      "    avg separation loss:      696.6819458007812\n",
      "    l1_addon loss:            28.0230770111084\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.0583033561706543\n",
      "    test time:                0.012150287628173828\n",
      "    epoch time:               0.07123661041259766\n",
      "    joint lr:                 0.011588728279599995\n",
      "epoch:  55 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 59.33%\n",
      "    train overall loss:       6.178750991821289\n",
      "    train cross_ent loss:     3.1779319180382624\n",
      "    test overall loss:        6.151041030883789\n",
      "    test cross_ent loss:      3.150252024332682\n",
      "    cluster loss:             2977.0185546875\n",
      "    separation loss:          103.76160176595052\n",
      "    avg separation loss:      273.03990173339844\n",
      "    l1_addon loss:            26.28419303894043\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058249473571777344\n",
      "    test time:                0.012176752090454102\n",
      "    epoch time:               0.07119512557983398\n",
      "    joint lr:                 0.014317301246005004\n",
      "epoch:  56 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 35.67%\n",
      "    train overall loss:       5.94672950108846\n",
      "    train cross_ent loss:     2.9458912478552923\n",
      "    test overall loss:        6.177453517913818\n",
      "    test cross_ent loss:      3.1766266028086343\n",
      "    cluster loss:             2994.4190266927085\n",
      "    separation loss:          117.94369125366211\n",
      "    avg separation loss:      429.19378662109375\n",
      "    l1_addon loss:            27.55705451965332\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058167457580566406\n",
      "    test time:                0.012162923812866211\n",
      "    epoch time:               0.07104611396789551\n",
      "    joint lr:                 0.016990153880253933\n",
      "epoch:  57 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 48.33%\n",
      "    train overall loss:       5.86247083875868\n",
      "    train cross_ent loss:     2.8615913656022816\n",
      "    test overall loss:        6.171924591064453\n",
      "    test cross_ent loss:      3.1710598468780518\n",
      "    cluster loss:             2990.6605631510415\n",
      "    separation loss:          107.16940307617188\n",
      "    avg separation loss:      347.95558675130206\n",
      "    l1_addon loss:            28.81952667236328\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05853986740112305\n",
      "    test time:                0.012077808380126953\n",
      "    epoch time:               0.07132959365844727\n",
      "    joint lr:                 0.019608127731693303\n",
      "epoch:  58 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 35.67%\n",
      "    train overall loss:       5.68574137157864\n",
      "    train cross_ent loss:     2.6847805182139077\n",
      "    test overall loss:        6.20618470509847\n",
      "    test cross_ent loss:      3.2051382064819336\n",
      "    cluster loss:             3039.810546875\n",
      "    separation loss:          174.07342783610025\n",
      "    avg separation loss:      588.5863647460938\n",
      "    l1_addon loss:            34.864986419677734\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05817985534667969\n",
      "    test time:                0.012119770050048828\n",
      "    epoch time:               0.07104063034057617\n",
      "    joint lr:                 0.02217205309071584\n",
      "epoch:  59 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 56.33%\n",
      "    train overall loss:       5.587420675489637\n",
      "    train cross_ent loss:     2.5863835546705456\n",
      "    test overall loss:        6.077719370524089\n",
      "    test cross_ent loss:      3.0767245292663574\n",
      "    cluster loss:             2966.635009765625\n",
      "    separation loss:          55.92880884806315\n",
      "    avg separation loss:      203.60462443033853\n",
      "    l1_addon loss:            33.148887634277344\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05813336372375488\n",
      "    test time:                0.012092113494873047\n",
      "    epoch time:               0.07098913192749023\n",
      "    joint lr:                 0.024682749129784777\n",
      "epoch:  60 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 53.33%\n",
      "    train overall loss:       5.599332862430149\n",
      "    train cross_ent loss:     2.598244163725111\n",
      "    test overall loss:        5.921575387318929\n",
      "    test cross_ent loss:      2.9204713503519693\n",
      "    cluster loss:             2959.28857421875\n",
      "    separation loss:          42.21254793802897\n",
      "    avg separation loss:      149.80074055989584\n",
      "    l1_addon loss:            36.78811264038086\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.0585932731628418\n",
      "    test time:                0.01219630241394043\n",
      "    epoch time:               0.07152199745178223\n",
      "    joint lr:                 0.027141024042763244\n",
      "epoch:  61 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 51.67%\n",
      "    train overall loss:       5.687553776635064\n",
      "    train cross_ent loss:     2.6863536834716797\n",
      "    test overall loss:        5.929527918497722\n",
      "    test cross_ent loss:      2.9283037185668945\n",
      "    cluster loss:             2957.2766927083335\n",
      "    separation loss:          40.37822278340658\n",
      "    avg separation loss:      123.77145894368489\n",
      "    l1_addon loss:            40.794219970703125\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058301448822021484\n",
      "    test time:                0.012094497680664062\n",
      "    epoch time:               0.07119417190551758\n",
      "    joint lr:                 0.025532083112218835\n",
      "epoch:  62 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 55.00%\n",
      "    train overall loss:       5.566369798448351\n",
      "    train cross_ent loss:     2.565134048461914\n",
      "    test overall loss:        5.969330310821533\n",
      "    test cross_ent loss:      2.9680248896280923\n",
      "    cluster loss:             2958.3265787760415\n",
      "    separation loss:          42.57194391886393\n",
      "    avg separation loss:      120.09514872233073\n",
      "    l1_addon loss:            43.51043701171875\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05860638618469238\n",
      "    test time:                0.012143611907958984\n",
      "    epoch time:               0.07151198387145996\n",
      "    joint lr:                 0.023952616897881036\n",
      "epoch:  63 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 66.00%\n",
      "    train overall loss:       5.2996392250061035\n",
      "    train cross_ent loss:     2.2983573542700872\n",
      "    test overall loss:        5.355183919270833\n",
      "    test cross_ent loss:      2.3538846174875894\n",
      "    cluster loss:             2952.50341796875\n",
      "    separation loss:          23.24440574645996\n",
      "    avg separation loss:      65.66124725341797\n",
      "    l1_addon loss:            43.28984832763672\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058269500732421875\n",
      "    test time:                0.012175321578979492\n",
      "    epoch time:               0.07116413116455078\n",
      "    joint lr:                 0.022402196799518763\n",
      "epoch:  64 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 60.33%\n",
      "    train overall loss:       5.177669949001736\n",
      "    train cross_ent loss:     2.1763474543889365\n",
      "    test overall loss:        5.387681166330974\n",
      "    test cross_ent loss:      2.386326233545939\n",
      "    cluster loss:             2952.3777669270835\n",
      "    separation loss:          21.172314325968426\n",
      "    avg separation loss:      58.83778381347656\n",
      "    l1_addon loss:            45.153385162353516\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05886054039001465\n",
      "    test time:                0.012195825576782227\n",
      "    epoch time:               0.07184910774230957\n",
      "    joint lr:                 0.02088039984143395\n",
      "epoch:  65 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 65.00%\n",
      "    train overall loss:       5.00632741716173\n",
      "    train cross_ent loss:     2.0049587753083973\n",
      "    test overall loss:        5.161690711975098\n",
      "    test cross_ent loss:      2.160330057144165\n",
      "    cluster loss:             2951.64697265625\n",
      "    separation loss:          18.23915386199951\n",
      "    avg separation loss:      56.58639399210612\n",
      "    l1_addon loss:            45.351226806640625\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05844449996948242\n",
      "    test time:                0.012160539627075195\n",
      "    epoch time:               0.07138204574584961\n",
      "    joint lr:                 0.01938680860283089\n",
      "epoch:  66 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 67.33%\n",
      "    train overall loss:       4.879935370551215\n",
      "    train cross_ent loss:     1.8785394695070055\n",
      "    test overall loss:        4.834628105163574\n",
      "    test cross_ent loss:      1.8332515954971313\n",
      "    cluster loss:             2951.30859375\n",
      "    separation loss:          15.160839716593424\n",
      "    avg separation loss:      43.488171895345054\n",
      "    l1_addon loss:            45.869258880615234\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05841875076293945\n",
      "    test time:                0.012152433395385742\n",
      "    epoch time:               0.0712735652923584\n",
      "    joint lr:                 0.017921011149015745\n",
      "epoch:  67 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 74.33%\n",
      "    train overall loss:       4.840320852067736\n",
      "    train cross_ent loss:     1.8389046589533489\n",
      "    test overall loss:        4.702597935994466\n",
      "    test cross_ent loss:      1.7011934916178386\n",
      "    cluster loss:             2951.1087239583335\n",
      "    separation loss:          13.714940071105957\n",
      "    avg separation loss:      37.59624989827474\n",
      "    l1_addon loss:            46.80549621582031\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05824780464172363\n",
      "    test time:                0.012193918228149414\n",
      "    epoch time:               0.07118558883666992\n",
      "    joint lr:                 0.016482600963416614\n",
      "epoch:  68 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 67.33%\n",
      "    train overall loss:       4.867922729916042\n",
      "    train cross_ent loss:     1.8664916621314154\n",
      "    test overall loss:        5.256666819254558\n",
      "    test cross_ent loss:      2.255190849304199\n",
      "    cluster loss:             2952.2801920572915\n",
      "    separation loss:          17.02713743845622\n",
      "    avg separation loss:      41.497912089029946\n",
      "    l1_addon loss:            49.18871307373047\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058257102966308594\n",
      "    test time:                0.012148618698120117\n",
      "    epoch time:               0.0711672306060791\n",
      "    joint lr:                 0.015071176880414561\n",
      "epoch:  69 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 68.67%\n",
      "    train overall loss:       4.752298884921604\n",
      "    train cross_ent loss:     1.7508843474917941\n",
      "    test overall loss:        4.6033854484558105\n",
      "    test cross_ent loss:      1.6020147800445557\n",
      "    cluster loss:             2951.554931640625\n",
      "    separation loss:          13.508116722106934\n",
      "    avg separation loss:      34.036556243896484\n",
      "    l1_addon loss:            45.685813903808594\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.059653282165527344\n",
      "    test time:                0.01321101188659668\n",
      "    epoch time:               0.07358646392822266\n",
      "    joint lr:                 0.01368634301897622\n",
      "epoch:  70 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 70.33%\n",
      "    train overall loss:       4.405734221140544\n",
      "    train cross_ent loss:     1.4043229553434584\n",
      "    test overall loss:        4.429275989532471\n",
      "    test cross_ent loss:      1.427850365638733\n",
      "    cluster loss:             2951.002685546875\n",
      "    separation loss:          11.411855061848959\n",
      "    avg separation loss:      31.184887568155926\n",
      "    l1_addon loss:            47.506568908691406\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.061470746994018555\n",
      "    test time:                0.01272273063659668\n",
      "    epoch time:               0.0749518871307373\n",
      "    joint lr:                 0.012327708717078603\n",
      "epoch:  71 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 76.67%\n",
      "    train overall loss:       4.278351253933376\n",
      "    train cross_ent loss:     1.276931299103631\n",
      "    test overall loss:        4.298290411631267\n",
      "    test cross_ent loss:      1.296831488609314\n",
      "    cluster loss:             2950.951171875\n",
      "    separation loss:          11.362343152364096\n",
      "    avg separation loss:      29.03441556294759\n",
      "    l1_addon loss:            48.62458801269531\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06169533729553223\n",
      "    test time:                0.012652873992919922\n",
      "    epoch time:               0.0750575065612793\n",
      "    joint lr:                 0.01099488846691703\n",
      "epoch:  72 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 75.33%\n",
      "    train overall loss:       4.048288106918335\n",
      "    train cross_ent loss:     1.0468518733978271\n",
      "    test overall loss:        4.116547743479411\n",
      "    test cross_ent loss:      1.1151260733604431\n",
      "    cluster loss:             2950.836181640625\n",
      "    separation loss:          9.702794075012207\n",
      "    avg separation loss:      24.793917973836262\n",
      "    l1_addon loss:            47.378623962402344\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06079697608947754\n",
      "    test time:                0.012701988220214844\n",
      "    epoch time:               0.0742638111114502\n",
      "    joint lr:                 0.009687501850886984\n",
      "epoch:  73 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 83.00%\n",
      "    train overall loss:       4.014702479044597\n",
      "    train cross_ent loss:     1.013266881306966\n",
      "    test overall loss:        3.8782873153686523\n",
      "    test cross_ent loss:      0.8768343726793925\n",
      "    cluster loss:             2950.5966796875\n",
      "    separation loss:          8.681029796600342\n",
      "    avg separation loss:      22.46734619140625\n",
      "    l1_addon loss:            48.423484802246094\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06138277053833008\n",
      "    test time:                0.012693166732788086\n",
      "    epoch time:               0.07479405403137207\n",
      "    joint lr:                 0.008405173478330853\n",
      "epoch:  74 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 85.00%\n",
      "    train overall loss:       3.884385585784912\n",
      "    train cross_ent loss:     0.882945371998681\n",
      "    test overall loss:        3.859715700149536\n",
      "    test cross_ent loss:      0.8582985003789266\n",
      "    cluster loss:             2950.5099283854165\n",
      "    separation loss:          7.901289304097493\n",
      "    avg separation loss:      19.88309605916341\n",
      "    l1_addon loss:            47.226951599121094\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06142544746398926\n",
      "    test time:                0.012640237808227539\n",
      "    epoch time:               0.07478737831115723\n",
      "    joint lr:                 0.007147532923040749\n",
      "epoch:  75 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 89.67%\n",
      "    train overall loss:       3.666312959459093\n",
      "    train cross_ent loss:     0.6648727589183383\n",
      "    test overall loss:        3.5509347120920816\n",
      "    test cross_ent loss:      0.5494870146115621\n",
      "    cluster loss:             2950.27978515625\n",
      "    separation loss:          7.0358460744222\n",
      "    avg separation loss:      17.456960678100586\n",
      "    l1_addon loss:            48.25067138671875\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06130266189575195\n",
      "    test time:                0.012767791748046875\n",
      "    epoch time:               0.0748147964477539\n",
      "    joint lr:                 0.005914214661508615\n",
      "epoch:  76 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 93.67%\n",
      "    train overall loss:       3.5380733013153076\n",
      "    train cross_ent loss:     0.5366349187162187\n",
      "    test overall loss:        3.4860451221466064\n",
      "    test cross_ent loss:      0.4846198757489522\n",
      "    cluster loss:             2950.236083984375\n",
      "    separation loss:          6.533723672231038\n",
      "    avg separation loss:      16.022160530090332\n",
      "    l1_addon loss:            47.50288772583008\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06146740913391113\n",
      "    test time:                0.012732505798339844\n",
      "    epoch time:               0.07493877410888672\n",
      "    joint lr:                 0.004704858011914826\n",
      "epoch:  77 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 92.67%\n",
      "    train overall loss:       3.461747090021769\n",
      "    train cross_ent loss:     0.4603160205814574\n",
      "    test overall loss:        3.4179275035858154\n",
      "    test cross_ent loss:      0.4165046066045761\n",
      "    cluster loss:             2950.2066243489585\n",
      "    separation loss:          6.0006818771362305\n",
      "    avg separation loss:      14.37049643198649\n",
      "    l1_addon loss:            47.42247772216797\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06092500686645508\n",
      "    test time:                0.01264190673828125\n",
      "    epoch time:               0.07427740097045898\n",
      "    joint lr:                 0.0035191070738467612\n",
      "epoch:  78 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 90.33%\n",
      "    train overall loss:       3.3298238118489585\n",
      "    train cross_ent loss:     0.3283911728196674\n",
      "    test overall loss:        3.4545411268870034\n",
      "    test cross_ent loss:      0.4531184285879135\n",
      "    cluster loss:             2950.19775390625\n",
      "    separation loss:          5.926213105519612\n",
      "    avg separation loss:      13.866679191589355\n",
      "    l1_addon loss:            47.410491943359375\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06097817420959473\n",
      "    test time:                0.013204574584960938\n",
      "    epoch time:               0.0748898983001709\n",
      "    joint lr:                 0.00235661066873886\n",
      "epoch:  79 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       3.2479491233825684\n",
      "    train cross_ent loss:     0.24651888095670277\n",
      "    test overall loss:        3.2979026635487876\n",
      "    test cross_ent loss:      0.29646433393160504\n",
      "    cluster loss:             2950.1184895833335\n",
      "    separation loss:          5.529745101928711\n",
      "    avg separation loss:      12.985597610473633\n",
      "    l1_addon loss:            47.941009521484375\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06109738349914551\n",
      "    test time:                0.012663841247558594\n",
      "    epoch time:               0.0745077133178711\n",
      "    joint lr:                 0.001217022281025732\n",
      "epoch:  80 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 91.67%\n",
      "    train overall loss:       3.1769415537516275\n",
      "    train cross_ent loss:     0.1755002381073104\n",
      "    test overall loss:        3.2704078356424966\n",
      "    test cross_ent loss:      0.2689734796682994\n",
      "    cluster loss:             2950.093994140625\n",
      "    separation loss:          5.343259334564209\n",
      "    avg separation loss:      12.24247678120931\n",
      "    l1_addon loss:            47.803306579589844\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06160283088684082\n",
      "    test time:                0.012650728225708008\n",
      "    epoch time:               0.07498812675476074\n",
      "    joint lr:                 0.0001\n",
      "epoch:  81 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 92.33%\n",
      "    train overall loss:       3.136018991470337\n",
      "    train cross_ent loss:     0.13458489461077583\n",
      "    test overall loss:        3.267194986343384\n",
      "    test cross_ent loss:      0.26576127111911774\n",
      "    cluster loss:             2950.0921223958335\n",
      "    separation loss:          5.3393575350443525\n",
      "    avg separation loss:      12.202091217041016\n",
      "    l1_addon loss:            47.776763916015625\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.060697317123413086\n",
      "    test time:                0.012727975845336914\n",
      "    epoch time:               0.07416176795959473\n",
      "    joint lr:                 0.00228958707526664\n",
      "epoch:  82 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       3.170153194003635\n",
      "    train cross_ent loss:     0.16872518757979074\n",
      "    test overall loss:        3.271139065424601\n",
      "    test cross_ent loss:      0.26969878375530243\n",
      "    cluster loss:             2950.106201171875\n",
      "    separation loss:          5.333946228027344\n",
      "    avg separation loss:      12.142705599466959\n",
      "    l1_addon loss:            47.99995040893555\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06107354164123535\n",
      "    test time:                0.012679338455200195\n",
      "    epoch time:               0.07447409629821777\n",
      "    joint lr:                 0.004435382409027948\n",
      "epoch:  83 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 94.00%\n",
      "    train overall loss:       3.142017232047187\n",
      "    train cross_ent loss:     0.14059040654036734\n",
      "    test overall loss:        3.2885608673095703\n",
      "    test cross_ent loss:      0.287125622232755\n",
      "    cluster loss:             2950.149169921875\n",
      "    separation loss:          5.085010051727295\n",
      "    avg separation loss:      11.180986404418945\n",
      "    l1_addon loss:            47.832130432128906\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.0612483024597168\n",
      "    test time:                0.012626171112060547\n",
      "    epoch time:               0.074615478515625\n",
      "    joint lr:                 0.006538042877406532\n",
      "epoch:  84 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       3.3041272163391113\n",
      "    train cross_ent loss:     0.3026973042223189\n",
      "    test overall loss:        3.3758886655171714\n",
      "    test cross_ent loss:      0.37448659042517346\n",
      "    cluster loss:             2950.1732584635415\n",
      "    separation loss:          5.149943669637044\n",
      "    avg separation loss:      11.246219317118326\n",
      "    l1_addon loss:            46.72859191894531\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.061144351959228516\n",
      "    test time:                0.012711048126220703\n",
      "    epoch time:               0.07457613945007324\n",
      "    joint lr:                 0.008598216598176611\n",
      "epoch:  85 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 85.67%\n",
      "    train overall loss:       3.5710498491923013\n",
      "    train cross_ent loss:     0.5696337189939287\n",
      "    test overall loss:        3.9843791325887046\n",
      "    test cross_ent loss:      0.9829991261164347\n",
      "    cluster loss:             2950.4589029947915\n",
      "    separation loss:          6.3558669090271\n",
      "    avg separation loss:      12.921778678894043\n",
      "    l1_addon loss:            45.993255615234375\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06383061408996582\n",
      "    test time:                0.012651920318603516\n",
      "    epoch time:               0.07723689079284668\n",
      "    joint lr:                 0.010616543040243577\n",
      "epoch:  86 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 90.67%\n",
      "    train overall loss:       3.8355204264322915\n",
      "    train cross_ent loss:     0.8341065545876821\n",
      "    test overall loss:        3.6399522622426352\n",
      "    test cross_ent loss:      0.6385153631369272\n",
      "    cluster loss:             2950.2897135416665\n",
      "    separation loss:          6.527446905771892\n",
      "    avg separation loss:      14.082341829935709\n",
      "    l1_addon loss:            47.89147186279297\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06085777282714844\n",
      "    test time:                0.012669086456298828\n",
      "    epoch time:               0.07422971725463867\n",
      "    joint lr:                 0.012593653131809358\n",
      "epoch:  87 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 86.00%\n",
      "    train overall loss:       3.823750204510159\n",
      "    train cross_ent loss:     0.822328014506234\n",
      "    test overall loss:        4.0770134925842285\n",
      "    test cross_ent loss:      1.075589934984843\n",
      "    cluster loss:             2950.5037434895835\n",
      "    separation loss:          7.659056345621745\n",
      "    avg separation loss:      17.795323689778645\n",
      "    l1_addon loss:            47.44872283935547\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06170368194580078\n",
      "    test time:                0.012658357620239258\n",
      "    epoch time:               0.07509446144104004\n",
      "    joint lr:                 0.014530169367239798\n",
      "epoch:  88 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       4.154513862397936\n",
      "    train cross_ent loss:     1.1530858476956685\n",
      "    test overall loss:        4.1578718821207685\n",
      "    test cross_ent loss:      1.1564897894859314\n",
      "    cluster loss:             2950.681396484375\n",
      "    separation loss:          8.040948232014975\n",
      "    avg separation loss:      17.571134567260742\n",
      "    l1_addon loss:            46.05949020385742\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06187558174133301\n",
      "    test time:                0.01267552375793457\n",
      "    epoch time:               0.07526206970214844\n",
      "    joint lr:                 0.01642670591264845\n",
      "epoch:  89 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 84.67%\n",
      "    train overall loss:       3.9993805355495877\n",
      "    train cross_ent loss:     0.9979540705680847\n",
      "    test overall loss:        4.001261870066325\n",
      "    test cross_ent loss:      0.9998730818430582\n",
      "    cluster loss:             2950.6128743489585\n",
      "    separation loss:          8.021750291188559\n",
      "    avg separation loss:      18.35750961303711\n",
      "    l1_addon loss:            46.28443145751953\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06114363670349121\n",
      "    test time:                0.14792895317077637\n",
      "    epoch time:               0.20982575416564941\n",
      "    joint lr:                 0.018283868710212207\n",
      "epoch:  90 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 88.00%\n",
      "    train overall loss:       4.062405268351237\n",
      "    train cross_ent loss:     1.0609775649176703\n",
      "    test overall loss:        4.058463970820109\n",
      "    test cross_ent loss:      1.0570351481437683\n",
      "    cluster loss:             2950.8690592447915\n",
      "    separation loss:          9.20885435740153\n",
      "    avg separation loss:      20.095977783203125\n",
      "    l1_addon loss:            47.61314392089844\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.0616605281829834\n",
      "    test time:                0.012738704681396484\n",
      "    epoch time:               0.07516646385192871\n",
      "    joint lr:                 0.020102255581233422\n",
      "epoch:  91 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 77.33%\n",
      "    train overall loss:       4.268607828352186\n",
      "    train cross_ent loss:     1.2671713762813144\n",
      "    test overall loss:        4.556910673777263\n",
      "    test cross_ent loss:      1.5555285612742107\n",
      "    cluster loss:             2951.797607421875\n",
      "    separation loss:          11.09169896443685\n",
      "    avg separation loss:      22.989884694417317\n",
      "    l1_addon loss:            46.055152893066406\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06090068817138672\n",
      "    test time:                0.012674570083618164\n",
      "    epoch time:               0.07431626319885254\n",
      "    joint lr:                 0.018912121374150048\n",
      "epoch:  92 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 70.33%\n",
      "    train overall loss:       4.599938074747722\n",
      "    train cross_ent loss:     1.5985036161210802\n",
      "    test overall loss:        4.6961774826049805\n",
      "    test cross_ent loss:      1.694713791211446\n",
      "    cluster loss:             2952.29638671875\n",
      "    separation loss:          13.656715393066406\n",
      "    avg separation loss:      27.939676920572918\n",
      "    l1_addon loss:            48.77584457397461\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.060962677001953125\n",
      "    test time:                0.012660026550292969\n",
      "    epoch time:               0.07433843612670898\n",
      "    joint lr:                 0.017743789625650205\n",
      "epoch:  93 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 74.00%\n",
      "    train overall loss:       4.408141877916124\n",
      "    train cross_ent loss:     1.4066823720932007\n",
      "    test overall loss:        4.4869278271993\n",
      "    test cross_ent loss:      1.4854798714319866\n",
      "    cluster loss:             2952.25146484375\n",
      "    separation loss:          13.272438685099283\n",
      "    avg separation loss:      27.444005966186523\n",
      "    l1_addon loss:            48.26319122314453\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.061721086502075195\n",
      "    test time:                0.012717962265014648\n",
      "    epoch time:               0.07518124580383301\n",
      "    joint lr:                 0.01659694329998293\n",
      "epoch:  94 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 81.00%\n",
      "    train overall loss:       4.515276802910699\n",
      "    train cross_ent loss:     1.5138219727410211\n",
      "    test overall loss:        4.382459958394368\n",
      "    test cross_ent loss:      1.3809938430786133\n",
      "    cluster loss:             2952.3484700520835\n",
      "    separation loss:          13.260305086771647\n",
      "    avg separation loss:      26.601694742838543\n",
      "    l1_addon loss:            48.85716247558594\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.0614924430847168\n",
      "    test time:                0.012714147567749023\n",
      "    epoch time:               0.0749201774597168\n",
      "    joint lr:                 0.01547126952186645\n",
      "epoch:  95 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 76.33%\n",
      "    train overall loss:       4.2487185266282825\n",
      "    train cross_ent loss:     1.2472605639033847\n",
      "    test overall loss:        4.3276190757751465\n",
      "    test cross_ent loss:      1.3261629343032837\n",
      "    cluster loss:             2952.407470703125\n",
      "    separation loss:          13.295266469319662\n",
      "    avg separation loss:      26.30983543395996\n",
      "    l1_addon loss:            48.52970886230469\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06152081489562988\n",
      "    test time:                0.012688875198364258\n",
      "    epoch time:               0.0749354362487793\n",
      "    joint lr:                 0.014366459524982304\n",
      "epoch:  96 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 71.00%\n",
      "    train overall loss:       4.262082762188381\n",
      "    train cross_ent loss:     1.2606167329682245\n",
      "    test overall loss:        4.55921745300293\n",
      "    test cross_ent loss:      1.5577686627705891\n",
      "    cluster loss:             2952.4745279947915\n",
      "    separation loss:          13.210337320963541\n",
      "    avg separation loss:      25.539079030354817\n",
      "    l1_addon loss:            48.288177490234375\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.060933828353881836\n",
      "    test time:                0.013657093048095703\n",
      "    epoch time:               0.0753777027130127\n",
      "    joint lr:                 0.013282208601083652\n",
      "epoch:  97 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 76.67%\n",
      "    train overall loss:       4.306017610761854\n",
      "    train cross_ent loss:     1.3045533895492554\n",
      "    test overall loss:        4.316183725992839\n",
      "    test cross_ent loss:      1.3147210677464802\n",
      "    cluster loss:             2952.3162434895835\n",
      "    separation loss:          12.825189272562662\n",
      "    avg separation loss:      24.993168512980144\n",
      "    l1_addon loss:            48.74661636352539\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.060953378677368164\n",
      "    test time:                0.012924432754516602\n",
      "    epoch time:               0.07465624809265137\n",
      "    joint lr:                 0.012218216049710476\n",
      "epoch:  98 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 76.33%\n",
      "    train overall loss:       4.148811075422499\n",
      "    train cross_ent loss:     1.1473448144065008\n",
      "    test overall loss:        4.388587633768718\n",
      "    test cross_ent loss:      1.387088656425476\n",
      "    cluster loss:             2952.34423828125\n",
      "    separation loss:          13.08501116434733\n",
      "    avg separation loss:      25.118277231852215\n",
      "    l1_addon loss:            49.95195007324219\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06031036376953125\n",
      "    test time:                0.012757539749145508\n",
      "    epoch time:               0.0738532543182373\n",
      "    joint lr:                 0.011174185128504639\n",
      "epoch:  99 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 79.00%\n",
      "    train overall loss:       4.0928981569078235\n",
      "    train cross_ent loss:     1.0914210379123688\n",
      "    test overall loss:        4.257052898406982\n",
      "    test cross_ent loss:      1.2556225458780925\n",
      "    cluster loss:             2952.2233072916665\n",
      "    separation loss:          11.99868361155192\n",
      "    avg separation loss:      22.77232615152995\n",
      "    l1_addon loss:            47.675682067871094\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06143617630004883\n",
      "    test time:                0.012670278549194336\n",
      "    epoch time:               0.07486534118652344\n",
      "    joint lr:                 0.010149823004117963\n",
      "epoch: 100 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 86.33%\n",
      "    train overall loss:       3.8659609423743353\n",
      "    train cross_ent loss:     0.8644999663035074\n",
      "    test overall loss:        3.7740821838378906\n",
      "    test cross_ent loss:      0.7726154526074728\n",
      "    cluster loss:             2951.8865559895835\n",
      "    separation loss:          11.319857279459635\n",
      "    avg separation loss:      21.473242441813152\n",
      "    l1_addon loss:            48.88730239868164\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06089162826538086\n",
      "    test time:                0.012689828872680664\n",
      "    epoch time:               0.07430005073547363\n",
      "    joint lr:                 0.009144840703706159\n",
      "epoch: 101 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 87.00%\n",
      "    train overall loss:       3.6624090671539307\n",
      "    train cross_ent loss:     0.660952220360438\n",
      "    test overall loss:        3.709340810775757\n",
      "    test cross_ent loss:      0.707875669002533\n",
      "    cluster loss:             2951.7255045572915\n",
      "    separation loss:          10.680099487304688\n",
      "    avg separation loss:      20.183244069417317\n",
      "    l1_addon loss:            48.8319206237793\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06075477600097656\n",
      "    test time:                0.012676239013671875\n",
      "    epoch time:               0.07415270805358887\n",
      "    joint lr:                 0.008158953067002189\n",
      "epoch: 102 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       3.6437209447224936\n",
      "    train cross_ent loss:     0.6422722008493211\n",
      "    test overall loss:        3.6640360355377197\n",
      "    test cross_ent loss:      0.6625718871752421\n",
      "    cluster loss:             2951.6383463541665\n",
      "    separation loss:          10.086251576741537\n",
      "    avg separation loss:      18.700860341389973\n",
      "    l1_addon loss:            48.79368591308594\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06160283088684082\n",
      "    test time:                0.012803792953491211\n",
      "    epoch time:               0.07516670227050781\n",
      "    joint lr:                 0.0071918786989619305\n",
      "epoch: 103 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 91.33%\n",
      "    train overall loss:       3.4671193493737116\n",
      "    train cross_ent loss:     0.46567778786023456\n",
      "    test overall loss:        3.469381093978882\n",
      "    test cross_ent loss:      0.4679484963417053\n",
      "    cluster loss:             2951.4417317708335\n",
      "    separation loss:          9.382260958353678\n",
      "    avg separation loss:      17.475177764892578\n",
      "    l1_addon loss:            47.7503662109375\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06083369255065918\n",
      "    test time:                0.012717485427856445\n",
      "    epoch time:               0.0743098258972168\n",
      "    joint lr:                 0.006243339922975775\n",
      "epoch: 104 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 93.67%\n",
      "    train overall loss:       3.351457887225681\n",
      "    train cross_ent loss:     0.350023337536388\n",
      "    test overall loss:        3.514362017313639\n",
      "    test cross_ent loss:      0.5129522979259491\n",
      "    cluster loss:             2951.4693196614585\n",
      "    separation loss:          9.201491355895996\n",
      "    avg separation loss:      16.50484339396159\n",
      "    l1_addon loss:            46.986419677734375\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.061341047286987305\n",
      "    test time:                0.012652873992919922\n",
      "    epoch time:               0.07473874092102051\n",
      "    joint lr:                 0.005313062734639446\n",
      "epoch: 105 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       3.2716436651017933\n",
      "    train cross_ent loss:     0.2702101518710454\n",
      "    test overall loss:        3.3295876185099282\n",
      "    test cross_ent loss:      0.3281652132670085\n",
      "    cluster loss:             2951.3484700520835\n",
      "    separation loss:          8.743104616800943\n",
      "    avg separation loss:      15.53596305847168\n",
      "    l1_addon loss:            47.40339279174805\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06130647659301758\n",
      "    test time:                0.012668371200561523\n",
      "    epoch time:               0.07470822334289551\n",
      "    joint lr:                 0.004400776756077547\n",
      "epoch: 106 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       3.1681980556911893\n",
      "    train cross_ent loss:     0.16676524778207144\n",
      "    test overall loss:        3.2404640515645347\n",
      "    test cross_ent loss:      0.23902732133865356\n",
      "    cluster loss:             2951.2757161458335\n",
      "    separation loss:          8.48868195215861\n",
      "    avg separation loss:      15.105521202087402\n",
      "    l1_addon loss:            47.87953186035156\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06112313270568848\n",
      "    test time:                0.012688636779785156\n",
      "    epoch time:               0.07458639144897461\n",
      "    joint lr:                 0.0035062151908134102\n",
      "epoch: 107 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       3.118947638405694\n",
      "    train cross_ent loss:     0.11752081807288858\n",
      "    test overall loss:        3.224935452143351\n",
      "    test cross_ent loss:      0.22350351264079413\n",
      "    cluster loss:             2951.300537109375\n",
      "    separation loss:          8.315109888712565\n",
      "    avg separation loss:      14.350201606750488\n",
      "    l1_addon loss:            47.72075653076172\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06094622611999512\n",
      "    test time:                0.012643575668334961\n",
      "    epoch time:               0.07431960105895996\n",
      "    joint lr:                 0.0026291147791789593\n",
      "epoch: 108 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       3.0843649175431995\n",
      "    train cross_ent loss:     0.08293348799149196\n",
      "    test overall loss:        3.1878703435262046\n",
      "    test cross_ent loss:      0.1864438901344935\n",
      "    cluster loss:             2951.2506510416665\n",
      "    separation loss:          8.221785386403402\n",
      "    avg separation loss:      14.270981152852377\n",
      "    l1_addon loss:            47.54185485839844\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.060924530029296875\n",
      "    test time:                0.012760400772094727\n",
      "    epoch time:               0.07444310188293457\n",
      "    joint lr:                 0.001769215754258106\n",
      "epoch: 109 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       3.07224178314209\n",
      "    train cross_ent loss:     0.07081617911656697\n",
      "    test overall loss:        3.1828511555989585\n",
      "    test cross_ent loss:      0.18142733722925186\n",
      "    cluster loss:             2951.2693684895835\n",
      "    separation loss:          8.158708254496256\n",
      "    avg separation loss:      13.94964853922526\n",
      "    l1_addon loss:            47.45336151123047\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06152653694152832\n",
      "    test time:                0.012688398361206055\n",
      "    epoch time:               0.07495236396789551\n",
      "    joint lr:                 0.0009262617983577627\n",
      "epoch: 110 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       3.048871729109022\n",
      "    train cross_ent loss:     0.0474458115382327\n",
      "    test overall loss:        3.1798532803853354\n",
      "    test cross_ent loss:      0.17842589567104974\n",
      "    cluster loss:             2951.2550455729165\n",
      "    separation loss:          8.107594013214111\n",
      "    avg separation loss:      13.871757825215658\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.061615705490112305\n",
      "    test time:                0.012672662734985352\n",
      "    epoch time:               0.07501339912414551\n",
      "    joint lr:                 0.0001\n",
      "epoch: 110 (PUSH) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       3.048871729109022\n",
      "    train cross_ent loss:     0.0474458115382327\n",
      "    test overall loss:        3.1839025020599365\n",
      "    test cross_ent loss:      0.18247505463659763\n",
      "    cluster loss:             2949.3111165364585\n",
      "    separation loss:          2.5620195865631104\n",
      "    avg separation loss:      7.202435811360677\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.061615705490112305\n",
      "    test time:                0.012864351272583008\n",
      "    epoch time:               0.35463571548461914\n",
      "epoch: 110 (1/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       3.0631026956770153\n",
      "    train cross_ent loss:     0.06387082621869114\n",
      "    test overall loss:        3.17854897181193\n",
      "    test cross_ent loss:      0.1819054534037908\n",
      "    cluster loss:             2949.3118489583335\n",
      "    separation loss:          2.5693881511688232\n",
      "    avg separation loss:      7.209911187489827\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  2995.21630859375\n",
      "    train time:               0.02488422393798828\n",
      "    test time:                0.012623071670532227\n",
      "    epoch time:               0.03803133964538574\n",
      "    last layer lr:            0.0007599999999999978\n",
      "epoch: 110 (2/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       3.0456628269619412\n",
      "    train cross_ent loss:     0.0644003012114101\n",
      "    test overall loss:        3.143312454223633\n",
      "    test cross_ent loss:      0.1812595333904028\n",
      "    cluster loss:             2949.3120930989585\n",
      "    separation loss:          2.5714441935221353\n",
      "    avg separation loss:      7.2245987256368\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  2960.62548828125\n",
      "    train time:               0.024198055267333984\n",
      "    test time:                0.01259613037109375\n",
      "    epoch time:               0.0373082160949707\n",
      "    last layer lr:            0.0014200000000000013\n",
      "epoch: 110 (3/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       2.99251291486952\n",
      "    train cross_ent loss:     0.059441752110918365\n",
      "    test overall loss:        3.0788137118021646\n",
      "    test cross_ent loss:      0.18182607740163803\n",
      "    cluster loss:             2949.3123372395835\n",
      "    separation loss:          2.569838603337606\n",
      "    avg separation loss:      7.232180913289388\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  2895.560302734375\n",
      "    train time:               0.024140357971191406\n",
      "    test time:                0.012578487396240234\n",
      "    epoch time:               0.03723454475402832\n",
      "    last layer lr:            0.0020799999999999985\n",
      "epoch: 110 (4/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       2.9229217105441623\n",
      "    train cross_ent loss:     0.06850525033142832\n",
      "    test overall loss:        2.9845330715179443\n",
      "    test cross_ent loss:      0.18285608726243177\n",
      "    cluster loss:             2949.3128255208335\n",
      "    separation loss:          2.5729668935139975\n",
      "    avg separation loss:      7.241304715474446\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  2800.249755859375\n",
      "    train time:               0.024224281311035156\n",
      "    test time:                0.012570858001708984\n",
      "    epoch time:               0.03730511665344238\n",
      "    last layer lr:            0.0027400000000000024\n",
      "epoch: 110 (5/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       2.8166028923458524\n",
      "    train cross_ent loss:     0.07004141559203465\n",
      "    test overall loss:        2.8630486329396567\n",
      "    test cross_ent loss:      0.18520429730415344\n",
      "    cluster loss:             2949.312255859375\n",
      "    separation loss:          2.5720554987589517\n",
      "    avg separation loss:      7.238011360168457\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  2676.4169921875\n",
      "    train time:               0.024538516998291016\n",
      "    test time:                0.012599706649780273\n",
      "    epoch time:               0.03765416145324707\n",
      "    last layer lr:            0.0034\n",
      "epoch: 110 (6/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       2.675631470150418\n",
      "    train cross_ent loss:     0.06558442239960034\n",
      "    test overall loss:        2.7117416063944497\n",
      "    test cross_ent loss:      0.1862695012241602\n",
      "    cluster loss:             2949.3114420572915\n",
      "    separation loss:          2.568032662073771\n",
      "    avg separation loss:      7.223543167114258\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  2524.044921875\n",
      "    train time:               0.024156570434570312\n",
      "    test time:                0.012586593627929688\n",
      "    epoch time:               0.0372617244720459\n",
      "    last layer lr:            0.004059999999999998\n",
      "epoch: 110 (7/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       2.515857776006063\n",
      "    train cross_ent loss:     0.07157423843940099\n",
      "    test overall loss:        2.535317341486613\n",
      "    test cross_ent loss:      0.19220325785378614\n",
      "    cluster loss:             2949.3116048177085\n",
      "    separation loss:          2.5700105826059976\n",
      "    avg separation loss:      7.227034409840901\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  2341.686767578125\n",
      "    train time:               0.024385929107666016\n",
      "    test time:                0.012598514556884766\n",
      "    epoch time:               0.03749513626098633\n",
      "    last layer lr:            0.004720000000000002\n",
      "epoch: 110 (8/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       2.320803589291043\n",
      "    train cross_ent loss:     0.07152603240683675\n",
      "    test overall loss:        2.334418217341105\n",
      "    test cross_ent loss:      0.20258941501379013\n",
      "    cluster loss:             2949.3115234375\n",
      "    separation loss:          2.5676713784535727\n",
      "    avg separation loss:      7.219037373860677\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  2130.401611328125\n",
      "    train time:               0.025676250457763672\n",
      "    test time:                0.013434648513793945\n",
      "    epoch time:               0.039670705795288086\n",
      "    last layer lr:            0.005379999999999999\n",
      "epoch: 110 (9/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       2.1060375372568765\n",
      "    train cross_ent loss:     0.08099465693036716\n",
      "    test overall loss:        2.1118451356887817\n",
      "    test cross_ent loss:      0.22095176205039024\n",
      "    cluster loss:             2949.3119303385415\n",
      "    separation loss:          2.570150454839071\n",
      "    avg separation loss:      7.243768850962321\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  1889.466064453125\n",
      "    train time:               0.024608135223388672\n",
      "    test time:                0.012631654739379883\n",
      "    epoch time:               0.03776264190673828\n",
      "    last layer lr:            0.006040000000000003\n",
      "epoch: 110 (10/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       1.8552169137530856\n",
      "    train cross_ent loss:     0.08405690402206448\n",
      "    test overall loss:        1.8575520515441895\n",
      "    test cross_ent loss:      0.2353500003616015\n",
      "    cluster loss:             2949.3121744791665\n",
      "    separation loss:          2.567604939142863\n",
      "    avg separation loss:      7.2436238924662275\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  1620.774658203125\n",
      "    train time:               0.024309635162353516\n",
      "    test time:                0.012687444686889648\n",
      "    epoch time:               0.03752398490905762\n",
      "    last layer lr:            0.0067\n",
      "epoch: 110 (11/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       1.5894340806537204\n",
      "    train cross_ent loss:     0.0950836261941327\n",
      "    test overall loss:        1.581182599067688\n",
      "    test cross_ent loss:      0.24844596286614737\n",
      "    cluster loss:             2949.312255859375\n",
      "    separation loss:          2.5720274448394775\n",
      "    avg separation loss:      7.2550638516743975\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  1331.3092041015625\n",
      "    train time:               0.024377822875976562\n",
      "    test time:                0.012608766555786133\n",
      "    epoch time:               0.037502288818359375\n",
      "    last layer lr:            0.0073599999999999985\n",
      "epoch: 110 (12/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       1.293078343073527\n",
      "    train cross_ent loss:     0.1045955042872164\n",
      "    test overall loss:        1.284041961034139\n",
      "    test cross_ent loss:      0.27349838614463806\n",
      "    cluster loss:             2949.3121744791665\n",
      "    separation loss:          2.5796863238016763\n",
      "    avg separation loss:      7.247969150543213\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  1009.1162109375\n",
      "    train time:               0.024188995361328125\n",
      "    test time:                0.012645959854125977\n",
      "    epoch time:               0.03735017776489258\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 110 (13/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.9788504706488715\n",
      "    train cross_ent loss:     0.12052212572760052\n",
      "    test overall loss:        0.9665772517522176\n",
      "    test cross_ent loss:      0.29696526875098544\n",
      "    cluster loss:             2949.3119303385415\n",
      "    separation loss:          2.5744415918986\n",
      "    avg separation loss:      7.240217844645183\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  668.1846923828125\n",
      "    train time:               0.024367094039916992\n",
      "    test time:                0.012633323669433594\n",
      "    epoch time:               0.03754234313964844\n",
      "    last layer lr:            0.008679999999999998\n",
      "epoch: 110 (14/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       0.6366446051332686\n",
      "    train cross_ent loss:     0.12524550966918468\n",
      "    test overall loss:        0.6244451602300009\n",
      "    test cross_ent loss:      0.30279658486445743\n",
      "    cluster loss:             2949.3120930989585\n",
      "    separation loss:          2.5734174251556396\n",
      "    avg separation loss:      7.236502329508464\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  320.22125244140625\n",
      "    train time:               0.02299809455871582\n",
      "    test time:                0.0120697021484375\n",
      "    epoch time:               0.03554391860961914\n",
      "    last layer lr:            0.009340000000000003\n",
      "epoch: 110 (15/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.35226454337437946\n",
      "    train cross_ent loss:     0.128427614354425\n",
      "    test overall loss:        0.43435023228327435\n",
      "    test cross_ent loss:      0.2929871728022893\n",
      "    cluster loss:             2949.3123372395835\n",
      "    separation loss:          2.575399160385132\n",
      "    avg separation loss:      7.249831835428874\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  139.93577575683594\n",
      "    train time:               0.022943496704101562\n",
      "    test time:                0.012079954147338867\n",
      "    epoch time:               0.03550004959106445\n",
      "    last layer lr:            0.01\n",
      "epoch: 110 (16/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 94.67%\n",
      "    train overall loss:       0.21601157718234593\n",
      "    train cross_ent loss:     0.10317063248819774\n",
      "    test overall loss:        0.3542066216468811\n",
      "    test cross_ent loss:      0.26722756028175354\n",
      "    cluster loss:             2949.3121744791665\n",
      "    separation loss:          2.57366943359375\n",
      "    avg separation loss:      7.245420614878337\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  85.5517578125\n",
      "    train time:               0.02293562889099121\n",
      "    test time:                0.012055158615112305\n",
      "    epoch time:               0.03546786308288574\n",
      "    last layer lr:            0.009604000000000001\n",
      "epoch: 110 (17/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.1756722256541252\n",
      "    train cross_ent loss:     0.10534429012073411\n",
      "    test overall loss:        0.28610077997048694\n",
      "    test cross_ent loss:      0.23233437786499658\n",
      "    cluster loss:             2949.3118489583335\n",
      "    separation loss:          2.5749701658884683\n",
      "    avg separation loss:      7.217265923817952\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  52.339111328125\n",
      "    train time:               0.023245811462402344\n",
      "    test time:                0.012047052383422852\n",
      "    epoch time:               0.03577566146850586\n",
      "    last layer lr:            0.009208\n",
      "epoch: 110 (18/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.13871162840061718\n",
      "    train cross_ent loss:     0.08736485118667285\n",
      "    test overall loss:        0.25713762640953064\n",
      "    test cross_ent loss:      0.21851765861113867\n",
      "    cluster loss:             2949.3121744791665\n",
      "    separation loss:          2.571265776952108\n",
      "    avg separation loss:      7.230585098266602\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  37.19267654418945\n",
      "    train time:               0.022968053817749023\n",
      "    test time:                0.012057065963745117\n",
      "    epoch time:               0.03550910949707031\n",
      "    last layer lr:            0.008812\n",
      "epoch: 110 (19/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.11498479048411052\n",
      "    train cross_ent loss:     0.0789143414133125\n",
      "    test overall loss:        0.2498066375652949\n",
      "    test cross_ent loss:      0.2195525641242663\n",
      "    cluster loss:             2949.3125\n",
      "    separation loss:          2.574960390726725\n",
      "    avg separation loss:      7.236592928568522\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  28.8267822265625\n",
      "    train time:               0.022914409637451172\n",
      "    test time:                0.012120723724365234\n",
      "    epoch time:               0.035543203353881836\n",
      "    last layer lr:            0.008415999999999998\n",
      "epoch: 110 (20/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.1036470921503173\n",
      "    train cross_ent loss:     0.07709806288282077\n",
      "    test overall loss:        0.22824595868587494\n",
      "    test cross_ent loss:      0.20699982345104218\n",
      "    cluster loss:             2949.3124186197915\n",
      "    separation loss:          2.5765008131663003\n",
      "    avg separation loss:      7.260857582092285\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  19.818843841552734\n",
      "    train time:               0.025026559829711914\n",
      "    test time:                0.012087821960449219\n",
      "    epoch time:               0.03759121894836426\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 110 (21/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       0.09435500618484285\n",
      "    train cross_ent loss:     0.07467737359305222\n",
      "    test overall loss:        0.22244962801535925\n",
      "    test cross_ent loss:      0.205213725566864\n",
      "    cluster loss:             2949.311767578125\n",
      "    separation loss:          2.5705131689707437\n",
      "    avg separation loss:      7.229029019673665\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  15.808605194091797\n",
      "    train time:               0.0229794979095459\n",
      "    test time:                0.012049198150634766\n",
      "    epoch time:               0.03551197052001953\n",
      "    last layer lr:            0.007624000000000002\n",
      "epoch: 110 (22/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       0.07793526599804561\n",
      "    train cross_ent loss:     0.06001798270477189\n",
      "    test overall loss:        0.21585637082656225\n",
      "    test cross_ent loss:      0.19977030033866564\n",
      "    cluster loss:             2949.3116861979165\n",
      "    separation loss:          2.568251371383667\n",
      "    avg separation loss:      7.233171780904134\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  14.658777236938477\n",
      "    train time:               0.022928714752197266\n",
      "    test time:                0.012089729309082031\n",
      "    epoch time:               0.03550219535827637\n",
      "    last layer lr:            0.007228000000000001\n",
      "epoch: 110 (23/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.08242964330646727\n",
      "    train cross_ent loss:     0.06736084839536084\n",
      "    test overall loss:        0.20979217688242593\n",
      "    test cross_ent loss:      0.19544960061709085\n",
      "    cluster loss:             2949.3115234375\n",
      "    separation loss:          2.5699474016825357\n",
      "    avg separation loss:      7.22727092107137\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  12.915284156799316\n",
      "    train time:               0.022924184799194336\n",
      "    test time:                0.012074708938598633\n",
      "    epoch time:               0.03548288345336914\n",
      "    last layer lr:            0.006832000000000001\n",
      "epoch: 110 (24/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.06964853033423424\n",
      "    train cross_ent loss:     0.05566157214343548\n",
      "    test overall loss:        0.2068576216697693\n",
      "    test cross_ent loss:      0.1948117936650912\n",
      "    cluster loss:             2949.312255859375\n",
      "    separation loss:          2.5733796755472818\n",
      "    avg separation loss:      7.235011736551921\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  10.618532180786133\n",
      "    train time:               0.023133277893066406\n",
      "    test time:                0.01207113265991211\n",
      "    epoch time:               0.03568243980407715\n",
      "    last layer lr:            0.006436\n",
      "epoch: 110 (25/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.06301655661728647\n",
      "    train cross_ent loss:     0.05183268938627508\n",
      "    test overall loss:        0.20191763589779535\n",
      "    test cross_ent loss:      0.19195120533307394\n",
      "    cluster loss:             2949.3116861979165\n",
      "    separation loss:          2.5684948762257895\n",
      "    avg separation loss:      7.231741905212402\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  8.539133071899414\n",
      "    train time:               0.0233919620513916\n",
      "    test time:                0.012060165405273438\n",
      "    epoch time:               0.035971641540527344\n",
      "    last layer lr:            0.00604\n",
      "epoch: 110 (26/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.06377359831498729\n",
      "    train cross_ent loss:     0.054037402073542275\n",
      "    test overall loss:        0.2003952426215013\n",
      "    test cross_ent loss:      0.19119354585806528\n",
      "    cluster loss:             2949.312255859375\n",
      "    separation loss:          2.5748738447825112\n",
      "    avg separation loss:      7.243419011433919\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  7.774402141571045\n",
      "    train time:               0.022959470748901367\n",
      "    test time:                0.012089252471923828\n",
      "    epoch time:               0.03552436828613281\n",
      "    last layer lr:            0.005644000000000002\n",
      "epoch: 110 (27/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.07273276419275337\n",
      "    train cross_ent loss:     0.06366599061422878\n",
      "    test overall loss:        0.19776356716950735\n",
      "    test cross_ent loss:      0.18854696055253348\n",
      "    cluster loss:             2949.3118489583335\n",
      "    separation loss:          2.5687149365743003\n",
      "    avg separation loss:      7.22026522954305\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  7.789314270019531\n",
      "    train time:               0.022980690002441406\n",
      "    test time:                0.012061834335327148\n",
      "    epoch time:               0.03552103042602539\n",
      "    last layer lr:            0.005248\n",
      "epoch: 110 (28/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.06669787565867107\n",
      "    train cross_ent loss:     0.05715962851213084\n",
      "    test overall loss:        0.19579698393742243\n",
      "    test cross_ent loss:      0.18605655059218407\n",
      "    cluster loss:             2949.3118489583335\n",
      "    separation loss:          2.5710606575012207\n",
      "    avg separation loss:      7.241049289703369\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  8.313138961791992\n",
      "    train time:               0.023072004318237305\n",
      "    test time:                0.01207590103149414\n",
      "    epoch time:               0.03562498092651367\n",
      "    last layer lr:            0.004852000000000001\n",
      "epoch: 110 (29/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.06937212290035354\n",
      "    train cross_ent loss:     0.060417246280444994\n",
      "    test overall loss:        0.192363440990448\n",
      "    test cross_ent loss:      0.18419301385680834\n",
      "    cluster loss:             2949.31201171875\n",
      "    separation loss:          2.565711736679077\n",
      "    avg separation loss:      7.23031743367513\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  6.74313497543335\n",
      "    train time:               0.02322530746459961\n",
      "    test time:                0.012109756469726562\n",
      "    epoch time:               0.03582048416137695\n",
      "    last layer lr:            0.004455999999999999\n",
      "epoch: 110 (30/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.0809082103272279\n",
      "    train cross_ent loss:     0.07233691857092911\n",
      "    test overall loss:        0.1898228886226813\n",
      "    test cross_ent loss:      0.18187184756000838\n",
      "    cluster loss:             2949.3125813802085\n",
      "    separation loss:          2.5692872206370034\n",
      "    avg separation loss:      7.247615655263265\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  6.523744583129883\n",
      "    train time:               0.0230867862701416\n",
      "    test time:                0.012139320373535156\n",
      "    epoch time:               0.035700082778930664\n",
      "    last layer lr:            0.004060000000000001\n",
      "epoch: 110 (31/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.06310386210680008\n",
      "    train cross_ent loss:     0.054521420763598546\n",
      "    test overall loss:        0.18820761268337569\n",
      "    test cross_ent loss:      0.18036285787820816\n",
      "    cluster loss:             2949.3118489583335\n",
      "    separation loss:          2.573000113169352\n",
      "    avg separation loss:      7.2535858154296875\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  6.4174652099609375\n",
      "    train time:               0.0226898193359375\n",
      "    test time:                0.012042760848999023\n",
      "    epoch time:               0.0352017879486084\n",
      "    last layer lr:            0.0036640000000000015\n",
      "epoch: 110 (32/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.06035448217557536\n",
      "    train cross_ent loss:     0.053167468764715724\n",
      "    test overall loss:        0.18711068977912268\n",
      "    test cross_ent loss:      0.18035515770316124\n",
      "    cluster loss:             2949.3119303385415\n",
      "    separation loss:          2.567595879236857\n",
      "    avg separation loss:      7.23700475692749\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  5.328239440917969\n",
      "    train time:               0.02267932891845703\n",
      "    test time:                0.01205587387084961\n",
      "    epoch time:               0.03521227836608887\n",
      "    last layer lr:            0.0032679999999999996\n",
      "epoch: 110 (33/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.056402967828843326\n",
      "    train cross_ent loss:     0.05001350388758712\n",
      "    test overall loss:        0.18528077006340027\n",
      "    test cross_ent loss:      0.1794657607873281\n",
      "    cluster loss:             2949.3119303385415\n",
      "    separation loss:          2.568700631459554\n",
      "    avg separation loss:      7.227305889129639\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  4.387720108032227\n",
      "    train time:               0.022802352905273438\n",
      "    test time:                0.012076139450073242\n",
      "    epoch time:               0.03535103797912598\n",
      "    last layer lr:            0.002872000000000001\n",
      "epoch: 110 (34/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.06500555005752379\n",
      "    train cross_ent loss:     0.059358110547893576\n",
      "    test overall loss:        0.18562988564372063\n",
      "    test cross_ent loss:      0.1803757150967916\n",
      "    cluster loss:             2949.3131510416665\n",
      "    separation loss:          2.575470209121704\n",
      "    avg separation loss:      7.252744674682617\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  3.8268747329711914\n",
      "    train time:               0.02266097068786621\n",
      "    test time:                0.012061119079589844\n",
      "    epoch time:               0.0351865291595459\n",
      "    last layer lr:            0.0024759999999999986\n",
      "epoch: 110 (35/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.05971517268982199\n",
      "    train cross_ent loss:     0.05416685032347838\n",
      "    test overall loss:        0.1842320536573728\n",
      "    test cross_ent loss:      0.17926223824421564\n",
      "    cluster loss:             2949.3125\n",
      "    separation loss:          2.5700854460398355\n",
      "    avg separation loss:      7.224647839864095\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  3.5425267219543457\n",
      "    train time:               0.022581100463867188\n",
      "    test time:                0.012046098709106445\n",
      "    epoch time:               0.03509402275085449\n",
      "    last layer lr:            0.0020800000000000003\n",
      "epoch: 110 (36/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.0501253642141819\n",
      "    train cross_ent loss:     0.04525771064476834\n",
      "    test overall loss:        0.1824346569677194\n",
      "    test cross_ent loss:      0.17788159723083177\n",
      "    cluster loss:             2949.3121744791665\n",
      "    separation loss:          2.5715222358703613\n",
      "    avg separation loss:      7.247270107269287\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  3.1257715225219727\n",
      "    train time:               0.02264714241027832\n",
      "    test time:                0.01207876205444336\n",
      "    epoch time:               0.03519296646118164\n",
      "    last layer lr:            0.0016840000000000017\n",
      "epoch: 110 (37/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.051952715342243515\n",
      "    train cross_ent loss:     0.04779731875492467\n",
      "    test overall loss:        0.18137083823482195\n",
      "    test cross_ent loss:      0.1774845557908217\n",
      "    cluster loss:             2949.3120930989585\n",
      "    separation loss:          2.57226832707723\n",
      "    avg separation loss:      7.230596542358398\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  2.4589881896972656\n",
      "    train time:               0.022678375244140625\n",
      "    test time:                0.01202249526977539\n",
      "    epoch time:               0.03516840934753418\n",
      "    last layer lr:            0.0012879999999999994\n",
      "epoch: 110 (38/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.05499137255052725\n",
      "    train cross_ent loss:     0.051223031969534025\n",
      "    test overall loss:        0.1803301696976026\n",
      "    test cross_ent loss:      0.1766286020477613\n",
      "    cluster loss:             2949.3121744791665\n",
      "    separation loss:          2.576709191004435\n",
      "    avg separation loss:      7.261782010396321\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  2.274272918701172\n",
      "    train time:               0.022673845291137695\n",
      "    test time:                0.01204824447631836\n",
      "    epoch time:               0.03519487380981445\n",
      "    last layer lr:            0.0008920000000000009\n",
      "epoch: 110 (39/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.04933032662504249\n",
      "    train cross_ent loss:     0.045976038401325546\n",
      "    test overall loss:        0.18031338974833488\n",
      "    test cross_ent loss:      0.177339448283116\n",
      "    cluster loss:             2949.3133138020835\n",
      "    separation loss:          2.573614756266276\n",
      "    avg separation loss:      7.245062828063965\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  1.5466437339782715\n",
      "    train time:               0.022630691528320312\n",
      "    test time:                0.012086629867553711\n",
      "    epoch time:               0.03519105911254883\n",
      "    last layer lr:            0.0004959999999999986\n",
      "epoch: 110 (40/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.06218478083610535\n",
      "    train cross_ent loss:     0.0594430917667018\n",
      "    test overall loss:        0.17971613506476083\n",
      "    test cross_ent loss:      0.17714053019881248\n",
      "    cluster loss:             2949.3130696614585\n",
      "    separation loss:          2.5802605152130127\n",
      "    avg separation loss:      7.234177430470784\n",
      "    l1_addon loss:            47.576416015625\n",
      "    l1 loss:                  1.1483111381530762\n",
      "    train time:               0.02274799346923828\n",
      "    test time:                0.012092351913452148\n",
      "    epoch time:               0.035308122634887695\n",
      "    last layer lr:            0.0001\n",
      "epoch: 111 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.04835797535876433\n",
      "    train cross_ent loss:     0.04578244292901622\n",
      "    test overall loss:        0.17814364160100618\n",
      "    test cross_ent loss:      0.1755681335926056\n",
      "    cluster loss:             2949.3116861979165\n",
      "    separation loss:          2.568688233693441\n",
      "    avg separation loss:      7.236199537913005\n",
      "    l1_addon loss:            47.573143005371094\n",
      "    l1 loss:                  1.1483111381530762\n",
      "    train time:               0.05702352523803711\n",
      "    test time:                0.012211322784423828\n",
      "    epoch time:               0.07041287422180176\n",
      "    joint lr:                 0.0017196383771408863\n",
      "epoch: 112 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.050037017506029874\n",
      "    train cross_ent loss:     0.04746004162977139\n",
      "    test overall loss:        0.15786668409903845\n",
      "    test cross_ent loss:      0.15529176717003187\n",
      "    cluster loss:             2949.2978515625\n",
      "    separation loss:          2.5436596870422363\n",
      "    avg separation loss:      7.089023907979329\n",
      "    l1_addon loss:            47.5533447265625\n",
      "    l1 loss:                  1.1483111381530762\n",
      "    train time:               0.05885791778564453\n",
      "    test time:                0.012640237808227539\n",
      "    epoch time:               0.07227873802185059\n",
      "    joint lr:                 0.0033068839867389757\n",
      "epoch: 113 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.05458950665262011\n",
      "    train cross_ent loss:     0.05202081840899256\n",
      "    test overall loss:        0.21043983598550162\n",
      "    test cross_ent loss:      0.20785587032636008\n",
      "    cluster loss:             2949.3336588541665\n",
      "    separation loss:          2.6242761611938477\n",
      "    avg separation loss:      7.071749051411946\n",
      "    l1_addon loss:            47.85490417480469\n",
      "    l1 loss:                  1.1483111381530762\n",
      "    train time:               0.05920886993408203\n",
      "    test time:                0.012643575668334961\n",
      "    epoch time:               0.07265615463256836\n",
      "    joint lr:                 0.0048622227203073696\n",
      "epoch: 114 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.037571678765945964\n",
      "    train cross_ent loss:     0.03500183599276675\n",
      "    test overall loss:        0.1538732796907425\n",
      "    test cross_ent loss:      0.15131577787299952\n",
      "    cluster loss:             2949.3240559895835\n",
      "    separation loss:          2.6168972651163735\n",
      "    avg separation loss:      7.030158996582031\n",
      "    l1_addon loss:            46.97310256958008\n",
      "    l1 loss:                  1.1483111381530762\n",
      "    train time:               0.05918145179748535\n",
      "    test time:                0.012662887573242188\n",
      "    epoch time:               0.07258772850036621\n",
      "    joint lr:                 0.00638613399080572\n",
      "epoch: 115 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 98.00%\n",
      "    train overall loss:       0.05118889816933208\n",
      "    train cross_ent loss:     0.048619276326563626\n",
      "    test overall loss:        0.14294400190313658\n",
      "    test cross_ent loss:      0.14037751530607542\n",
      "    cluster loss:             2949.3446451822915\n",
      "    separation loss:          2.655379056930542\n",
      "    avg separation loss:      7.148180325826009\n",
      "    l1_addon loss:            47.27259063720703\n",
      "    l1 loss:                  1.1483111381530762\n",
      "    train time:               0.05896949768066406\n",
      "    test time:                0.012622594833374023\n",
      "    epoch time:               0.0723729133605957\n",
      "    joint lr:                 0.007879090813622073\n",
      "epoch: 116 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.043824179822372064\n",
      "    train cross_ent loss:     0.041256864451699786\n",
      "    test overall loss:        0.1447072128454844\n",
      "    test cross_ent loss:      0.14213956519961357\n",
      "    cluster loss:             2949.344970703125\n",
      "    separation loss:          2.5308738549550376\n",
      "    avg separation loss:      6.541240374247233\n",
      "    l1_addon loss:            47.311195373535156\n",
      "    l1 loss:                  1.1483111381530762\n",
      "    train time:               0.05897641181945801\n",
      "    test time:                0.012644290924072266\n",
      "    epoch time:               0.07242226600646973\n",
      "    joint lr:                 0.009341559886583039\n",
      "epoch: 117 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.05970547731137938\n",
      "    train cross_ent loss:     0.057140425158043705\n",
      "    test overall loss:        0.2086996758977572\n",
      "    test cross_ent loss:      0.20616023987531662\n",
      "    cluster loss:             2949.4239908854165\n",
      "    separation loss:          2.6651466687520347\n",
      "    avg separation loss:      6.708598772684733\n",
      "    l1_addon loss:            46.37092590332031\n",
      "    l1 loss:                  1.1483111381530762\n",
      "    train time:               0.05910181999206543\n",
      "    test time:                0.012650489807128906\n",
      "    epoch time:               0.07251667976379395\n",
      "    joint lr:                 0.010774001669003403\n",
      "epoch: 118 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.23732065678470665\n",
      "    train cross_ent loss:     0.2347536931435267\n",
      "    test overall loss:        0.4784955382347107\n",
      "    test cross_ent loss:      0.4759087562561035\n",
      "    cluster loss:             2949.6022135416665\n",
      "    separation loss:          3.543003479639689\n",
      "    avg separation loss:      8.022393385569254\n",
      "    l1_addon loss:            47.94928741455078\n",
      "    l1 loss:                  1.1483111381530762\n",
      "    train time:               0.058948516845703125\n",
      "    test time:                0.012659788131713867\n",
      "    epoch time:               0.07234978675842285\n",
      "    joint lr:                 0.012176870459786701\n",
      "epoch: 119 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 94.00%\n",
      "    train overall loss:       0.5399546043740379\n",
      "    train cross_ent loss:     0.5373937471045388\n",
      "    test overall loss:        0.6813029050827026\n",
      "    test cross_ent loss:      0.6787282824516296\n",
      "    cluster loss:             2949.8197428385415\n",
      "    separation loss:          4.394562164942424\n",
      "    avg separation loss:      10.12178866068522\n",
      "    l1_addon loss:            47.54480743408203\n",
      "    l1 loss:                  1.1483111381530762\n",
      "    train time:               0.058989524841308594\n",
      "    test time:                0.012672901153564453\n",
      "    epoch time:               0.07243895530700684\n",
      "    joint lr:                 0.013550614474587434\n",
      "epoch: 120 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 86.33%\n",
      "    train overall loss:       0.784898062547048\n",
      "    train cross_ent loss:     0.7823342978954315\n",
      "    test overall loss:        0.861748198668162\n",
      "    test cross_ent loss:      0.8591978351275126\n",
      "    cluster loss:             2950.1180013020835\n",
      "    separation loss:          6.081313451131185\n",
      "    avg separation loss:      13.493351300557455\n",
      "    l1_addon loss:            46.73686218261719\n",
      "    l1 loss:                  1.1483111381530762\n",
      "    train time:               0.05914306640625\n",
      "    test time:                0.012634754180908203\n",
      "    epoch time:               0.07257342338562012\n",
      "    joint lr:                 0.014895675922046181\n",
      "epoch: 121 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 86.00%\n",
      "    train overall loss:       1.1415386133723788\n",
      "    train cross_ent loss:     1.1389545136027865\n",
      "    test overall loss:        1.4409892956415813\n",
      "    test cross_ent loss:      1.4383786122004192\n",
      "    cluster loss:             2950.8262532552085\n",
      "    separation loss:          8.718331654866537\n",
      "    avg separation loss:      18.55731964111328\n",
      "    l1_addon loss:            48.743019104003906\n",
      "    l1 loss:                  1.1483111381530762\n",
      "    train time:               0.05889177322387695\n",
      "    test time:                0.012659788131713867\n",
      "    epoch time:               0.07234406471252441\n",
      "    joint lr:                 0.014015333204684437\n",
      "epoch: 122 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 92.33%\n",
      "    train overall loss:       1.137712472014957\n",
      "    train cross_ent loss:     1.13513003455268\n",
      "    test overall loss:        0.8660056591033936\n",
      "    test cross_ent loss:      0.8634084860483805\n",
      "    cluster loss:             2950.7183430989585\n",
      "    separation loss:          8.719749609629313\n",
      "    avg separation loss:      18.42039616902669\n",
      "    l1_addon loss:            48.29658889770508\n",
      "    l1 loss:                  1.1483111381530762\n",
      "    train time:               0.05914568901062012\n",
      "    test time:                0.012751340866088867\n",
      "    epoch time:               0.07268500328063965\n",
      "    joint lr:                 0.01315111777407772\n",
      "epoch: 123 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 94.00%\n",
      "    train overall loss:       0.8405457999971178\n",
      "    train cross_ent loss:     0.8379414743847318\n",
      "    test overall loss:        0.6930708686510721\n",
      "    test cross_ent loss:      0.6904740730921427\n",
      "    cluster loss:             2950.706787109375\n",
      "    separation loss:          8.334553877512613\n",
      "    avg separation loss:      17.580631891886394\n",
      "    l1_addon loss:            48.282997131347656\n",
      "    l1 loss:                  1.1483111381530762\n",
      "    train time:               0.05893659591674805\n",
      "    test time:                0.012675762176513672\n",
      "    epoch time:               0.07239937782287598\n",
      "    joint lr:                 0.012302795118762673\n",
      "epoch: 124 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.6197950707541572\n",
      "    train cross_ent loss:     0.617184579372406\n",
      "    test overall loss:        0.6026001373926798\n",
      "    test cross_ent loss:      0.5999812185764313\n",
      "    cluster loss:             2950.71630859375\n",
      "    separation loss:          7.788969039916992\n",
      "    avg separation loss:      15.911203066507975\n",
      "    l1_addon loss:            49.020694732666016\n",
      "    l1 loss:                  1.1483111381530762\n",
      "    train time:               0.05883336067199707\n",
      "    test time:                0.012681245803833008\n",
      "    epoch time:               0.07230925559997559\n",
      "    joint lr:                 0.011470133804776505\n",
      "epoch: 125 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 91.00%\n",
      "    train overall loss:       0.47927340865135193\n",
      "    train cross_ent loss:     0.4766602747970157\n",
      "    test overall loss:        0.6419782340526581\n",
      "    test cross_ent loss:      0.6393770178159078\n",
      "    cluster loss:             2950.705322265625\n",
      "    separation loss:          7.149807612101237\n",
      "    avg separation loss:      13.748686154683432\n",
      "    l1_addon loss:            48.430870056152344\n",
      "    l1 loss:                  1.1483111381530762\n",
      "    train time:               0.05935263633728027\n",
      "    test time:                0.012662887573242188\n",
      "    epoch time:               0.072845458984375\n",
      "    joint lr:                 0.010652905437558197\n",
      "epoch: 126 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.4584873186217414\n",
      "    train cross_ent loss:     0.4558754182524151\n",
      "    test overall loss:        0.4582127432028453\n",
      "    test cross_ent loss:      0.4555906554063161\n",
      "    cluster loss:             2950.6471354166665\n",
      "    separation loss:          6.678982734680176\n",
      "    avg separation loss:      12.85033925374349\n",
      "    l1_addon loss:            49.12689208984375\n",
      "    l1 loss:                  1.1483111381530762\n",
      "    train time:               0.05902814865112305\n",
      "    test time:                0.012643814086914062\n",
      "    epoch time:               0.07247781753540039\n",
      "    joint lr:                 0.009850884624303774\n",
      "epoch: 127 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 94.33%\n",
      "    train overall loss:       0.343020757039388\n",
      "    train cross_ent loss:     0.34041215313805473\n",
      "    test overall loss:        0.3116135249535243\n",
      "    test cross_ent loss:      0.3090071628491084\n",
      "    cluster loss:             2950.553466796875\n",
      "    separation loss:          6.29438050587972\n",
      "    avg separation loss:      12.16681702931722\n",
      "    l1_addon loss:            48.60173034667969\n",
      "    l1 loss:                  1.1483111381530762\n",
      "    train time:               0.058939218521118164\n",
      "    test time:                0.012639522552490234\n",
      "    epoch time:               0.07236146926879883\n",
      "    joint lr:                 0.00906384893677068\n",
      "epoch: 128 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.22291406326823765\n",
      "    train cross_ent loss:     0.22030899259779188\n",
      "    test overall loss:        0.28042655686537427\n",
      "    test cross_ent loss:      0.2778223107258479\n",
      "    cluster loss:             2950.568603515625\n",
      "    separation loss:          6.004241784413655\n",
      "    avg separation loss:      11.26730473836263\n",
      "    l1_addon loss:            48.53090286254883\n",
      "    l1 loss:                  1.1483111381530762\n",
      "    train time:               0.05914187431335449\n",
      "    test time:                0.012660980224609375\n",
      "    epoch time:               0.07257556915283203\n",
      "    joint lr:                 0.00829157887452582\n",
      "epoch: 129 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.20094017518891227\n",
      "    train cross_ent loss:     0.1983372535970476\n",
      "    test overall loss:        0.21914162238438925\n",
      "    test cross_ent loss:      0.2165416975816091\n",
      "    cluster loss:             2950.5431315104165\n",
      "    separation loss:          5.835515817006429\n",
      "    avg separation loss:      10.525137265523275\n",
      "    l1_addon loss:            48.38700866699219\n",
      "    l1 loss:                  1.1483111381530762\n",
      "    train time:               0.059006690979003906\n",
      "    test time:                0.012633085250854492\n",
      "    epoch time:               0.07242584228515625\n",
      "    joint lr:                 0.007533857828632187\n",
      "epoch: 130 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 94.67%\n",
      "    train overall loss:       0.1617907774117258\n",
      "    train cross_ent loss:     0.1591949901647038\n",
      "    test overall loss:        0.31599117318789166\n",
      "    test cross_ent loss:      0.31338632603486377\n",
      "    cluster loss:             2950.5847981770835\n",
      "    separation loss:          5.925002257029216\n",
      "    avg separation loss:      10.59391180674235\n",
      "    l1_addon loss:            48.551422119140625\n",
      "    l1 loss:                  1.1483111381530762\n",
      "    train time:               0.05883288383483887\n",
      "    test time:                0.012644290924072266\n",
      "    epoch time:               0.07227134704589844\n",
      "    joint lr:                 0.00679047204576897\n",
      "epoch: 131 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.29986123823457295\n",
      "    train cross_ent loss:     0.2972634981075923\n",
      "    test overall loss:        0.3701266447703044\n",
      "    test cross_ent loss:      0.36752376953760785\n",
      "    cluster loss:             2950.5799153645835\n",
      "    separation loss:          5.889241854349772\n",
      "    avg separation loss:      10.570595105489096\n",
      "    l1_addon loss:            48.48583221435547\n",
      "    l1 loss:                  1.1483111381530762\n",
      "    train time:               0.05885624885559082\n",
      "    test time:                0.012698888778686523\n",
      "    epoch time:               0.07234740257263184\n",
      "    joint lr:                 0.006061210592780146\n",
      "epoch: 132 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 94.00%\n",
      "    train overall loss:       0.3852328641547097\n",
      "    train cross_ent loss:     0.3826531627111965\n",
      "    test overall loss:        0.2712997794151306\n",
      "    test cross_ent loss:      0.26872119307518005\n",
      "    cluster loss:             2950.4747721354165\n",
      "    separation loss:          5.780838330586751\n",
      "    avg separation loss:      10.544130007425943\n",
      "    l1_addon loss:            47.675689697265625\n",
      "    l1 loss:                  1.1483111381530762\n",
      "    train time:               0.05919480323791504\n",
      "    test time:                0.012655496597290039\n",
      "    epoch time:               0.07262825965881348\n",
      "    joint lr:                 0.005345865321646531\n",
      "epoch: 133 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.2033732450670666\n",
      "    train cross_ent loss:     0.20080027480920157\n",
      "    test overall loss:        0.3639371593793233\n",
      "    test cross_ent loss:      0.3613516589005788\n",
      "    cluster loss:             2950.5020345052085\n",
      "    separation loss:          5.7113823890686035\n",
      "    avg separation loss:      10.499270757039389\n",
      "    l1_addon loss:            47.90636444091797\n",
      "    l1 loss:                  1.1483111381530762\n",
      "    train time:               0.058963775634765625\n",
      "    test time:                0.012730121612548828\n",
      "    epoch time:               0.07247424125671387\n",
      "    joint lr:                 0.00464423083487631\n",
      "epoch: 134 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.1234571606748634\n",
      "    train cross_ent loss:     0.12088083600004514\n",
      "    test overall loss:        0.21918576210737228\n",
      "    test cross_ent loss:      0.21659401307503381\n",
      "    cluster loss:             2950.4247233072915\n",
      "    separation loss:          5.651750246683757\n",
      "    avg separation loss:      10.50462277730306\n",
      "    l1_addon loss:            48.11439895629883\n",
      "    l1 loss:                  1.1483111381530762\n",
      "    train time:               0.059026479721069336\n",
      "    test time:                0.012671232223510742\n",
      "    epoch time:               0.07249593734741211\n",
      "    joint lr:                 0.003956104451309328\n",
      "epoch: 135 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.07482377646697892\n",
      "    train cross_ent loss:     0.0722448689242204\n",
      "    test overall loss:        0.16938269138336182\n",
      "    test cross_ent loss:      0.16681605577468872\n",
      "    cluster loss:             2950.3795572916665\n",
      "    separation loss:          5.314265886942546\n",
      "    avg separation loss:      9.745825131734213\n",
      "    l1_addon loss:            47.27742004394531\n",
      "    l1 loss:                  1.1483111381530762\n",
      "    train time:               0.05901050567626953\n",
      "    test time:                0.012626409530639648\n",
      "    epoch time:               0.07241511344909668\n",
      "    joint lr:                 0.0032812861723301896\n",
      "epoch: 136 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.043637941798402205\n",
      "    train cross_ent loss:     0.04106087413512998\n",
      "    test overall loss:        0.14791241536537805\n",
      "    test cross_ent loss:      0.1453257699807485\n",
      "    cluster loss:             2950.3663736979165\n",
      "    separation loss:          5.243569850921631\n",
      "    avg separation loss:      9.572039286295572\n",
      "    l1_addon loss:            47.944313049316406\n",
      "    l1 loss:                  1.1483111381530762\n",
      "    train time:               0.05878186225891113\n",
      "    test time:                0.012636661529541016\n",
      "    epoch time:               0.07220292091369629\n",
      "    joint lr:                 0.0026195786484855114\n",
      "epoch: 137 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.029123803186747763\n",
      "    train cross_ent loss:     0.02654699029193984\n",
      "    test overall loss:        0.13614304860432944\n",
      "    test cross_ent loss:      0.13357608765363693\n",
      "    cluster loss:             2950.3423665364585\n",
      "    separation loss:          5.13666566212972\n",
      "    avg separation loss:      9.370573997497559\n",
      "    l1_addon loss:            47.28817367553711\n",
      "    l1 loss:                  1.1483111381530762\n",
      "    train time:               0.05879330635070801\n",
      "    test time:                0.012636423110961914\n",
      "    epoch time:               0.07223820686340332\n",
      "    joint lr:                 0.0019707871465004943\n",
      "epoch: 138 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.021217371233635478\n",
      "    train cross_ent loss:     0.018645749272157747\n",
      "    test overall loss:        0.12587949261069298\n",
      "    test cross_ent loss:      0.12330222129821777\n",
      "    cluster loss:             2950.3326009114585\n",
      "    separation loss:          5.09323263168335\n",
      "    avg separation loss:      9.22516663869222\n",
      "    l1_addon loss:            47.63187026977539\n",
      "    l1 loss:                  1.1483111381530762\n",
      "    train time:               0.05887174606323242\n",
      "    test time:                0.012685298919677734\n",
      "    epoch time:               0.07234835624694824\n",
      "    joint lr:                 0.0013347195166903292\n",
      "epoch: 139 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.01703656826996141\n",
      "    train cross_ent loss:     0.014458857528451417\n",
      "    test overall loss:        0.122975904494524\n",
      "    test cross_ent loss:      0.12039786825577418\n",
      "    cluster loss:             2950.3282877604165\n",
      "    separation loss:          5.06414794921875\n",
      "    avg separation loss:      9.15552043914795\n",
      "    l1_addon loss:            47.657623291015625\n",
      "    l1 loss:                  1.1483111381530762\n",
      "    train time:               0.05861639976501465\n",
      "    test time:                0.012172937393188477\n",
      "    epoch time:               0.07158112525939941\n",
      "    joint lr:                 0.0007111861607617089\n",
      "epoch: 140 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.011312395437724061\n",
      "    train cross_ent loss:     0.00873421753446261\n",
      "    test overall loss:        0.12061744680007298\n",
      "    test cross_ent loss:      0.11803966884811719\n",
      "    cluster loss:             2950.3267415364585\n",
      "    separation loss:          5.0506265958150225\n",
      "    avg separation loss:      9.134543418884277\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  1.1483111381530762\n",
      "    train time:               0.05810546875\n",
      "    test time:                0.012623310089111328\n",
      "    epoch time:               0.07153487205505371\n",
      "    joint lr:                 0.0001\n",
      "epoch: 140 (PUSH) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.011312395437724061\n",
      "    train cross_ent loss:     0.00873421753446261\n",
      "    test overall loss:        0.15390449513991675\n",
      "    test cross_ent loss:      0.1513267159461975\n",
      "    cluster loss:             2949.2945149739585\n",
      "    separation loss:          2.3732195297876992\n",
      "    avg separation loss:      6.045755545298259\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  1.1483111381530762\n",
      "    train time:               0.05810546875\n",
      "    test time:                0.01286935806274414\n",
      "    epoch time:               0.39333033561706543\n",
      "epoch: 140 (1/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.03644600215678414\n",
      "    train cross_ent loss:     0.03405516387687789\n",
      "    test overall loss:        0.153641356776158\n",
      "    test cross_ent loss:      0.15144681992630163\n",
      "    cluster loss:             2949.2945963541665\n",
      "    separation loss:          2.3756361405054727\n",
      "    avg separation loss:      6.059390862782796\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  0.7650699019432068\n",
      "    train time:               0.02438974380493164\n",
      "    test time:                0.012610912322998047\n",
      "    epoch time:               0.03757214546203613\n",
      "    last layer lr:            0.0007599999999999978\n",
      "epoch: 140 (2/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.03561204858124256\n",
      "    train cross_ent loss:     0.032640416330347456\n",
      "    test overall loss:        0.15415658801794052\n",
      "    test cross_ent loss:      0.15116381210585436\n",
      "    cluster loss:             2949.29443359375\n",
      "    separation loss:          2.373142719268799\n",
      "    avg separation loss:      6.052347977956136\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  1.5633082389831543\n",
      "    train time:               0.02392125129699707\n",
      "    test time:                0.012621879577636719\n",
      "    epoch time:               0.0370488166809082\n",
      "    last layer lr:            0.0014199999999999955\n",
      "epoch: 140 (3/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.034536794345411986\n",
      "    train cross_ent loss:     0.031301133127676115\n",
      "    test overall loss:        0.15370728075504303\n",
      "    test cross_ent loss:      0.15040407019356886\n",
      "    cluster loss:             2949.29443359375\n",
      "    separation loss:          2.3757514556248984\n",
      "    avg separation loss:      6.0571333567301435\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  1.873740553855896\n",
      "    train time:               0.023840904235839844\n",
      "    test time:                0.012768268585205078\n",
      "    epoch time:               0.037127017974853516\n",
      "    last layer lr:            0.0020800000000000046\n",
      "epoch: 140 (4/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.040016373412476644\n",
      "    train cross_ent loss:     0.036312861988941826\n",
      "    test overall loss:        0.1526065319776535\n",
      "    test cross_ent loss:      0.14863489692409834\n",
      "    cluster loss:             2949.2945963541665\n",
      "    separation loss:          2.371905048688253\n",
      "    avg separation loss:      6.048219362894694\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  2.542172431945801\n",
      "    train time:               0.024125337600708008\n",
      "    test time:                0.012600183486938477\n",
      "    epoch time:               0.037229061126708984\n",
      "    last layer lr:            0.0027400000000000024\n",
      "epoch: 140 (5/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.037749170429176755\n",
      "    train cross_ent loss:     0.03326796078019672\n",
      "    test overall loss:        0.15309744576613107\n",
      "    test cross_ent loss:      0.14798064095278582\n",
      "    cluster loss:             2949.2950032552085\n",
      "    separation loss:          2.3773028453191123\n",
      "    avg separation loss:      6.062204043070476\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  3.6873440742492676\n",
      "    train time:               0.0239255428314209\n",
      "    test time:                0.012581348419189453\n",
      "    epoch time:               0.037011146545410156\n",
      "    last layer lr:            0.0034\n",
      "epoch: 140 (6/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.03337862052851253\n",
      "    train cross_ent loss:     0.02822303016566568\n",
      "    test overall loss:        0.15270957226554552\n",
      "    test cross_ent loss:      0.1477170748015245\n",
      "    cluster loss:             2949.2948404947915\n",
      "    separation loss:          2.3792657454808555\n",
      "    avg separation loss:      6.0672760009765625\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  3.5630321502685547\n",
      "    train time:               0.023755550384521484\n",
      "    test time:                0.012567281723022461\n",
      "    epoch time:               0.036821842193603516\n",
      "    last layer lr:            0.004059999999999998\n",
      "epoch: 140 (7/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.031883202493190765\n",
      "    train cross_ent loss:     0.026524804015126493\n",
      "    test overall loss:        0.15115095674991608\n",
      "    test cross_ent loss:      0.14557160871724287\n",
      "    cluster loss:             2949.2945149739585\n",
      "    separation loss:          2.3787481784820557\n",
      "    avg separation loss:      6.068680604298909\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  4.14987850189209\n",
      "    train time:               0.023735523223876953\n",
      "    test time:                0.012571573257446289\n",
      "    epoch time:               0.03680825233459473\n",
      "    last layer lr:            0.004719999999999996\n",
      "epoch: 140 (8/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.03877894663148456\n",
      "    train cross_ent loss:     0.032906020888023906\n",
      "    test overall loss:        0.14991390208403269\n",
      "    test cross_ent loss:      0.14380958303809166\n",
      "    cluster loss:             2949.2945963541665\n",
      "    separation loss:          2.3775821129480996\n",
      "    avg separation loss:      6.066622098286946\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  4.674854278564453\n",
      "    train time:               0.02374267578125\n",
      "    test time:                0.012573003768920898\n",
      "    epoch time:               0.03681302070617676\n",
      "    last layer lr:            0.0053800000000000054\n",
      "epoch: 140 (9/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.03239862093081077\n",
      "    train cross_ent loss:     0.025893992071764335\n",
      "    test overall loss:        0.14972946296135584\n",
      "    test cross_ent loss:      0.14350240491330624\n",
      "    cluster loss:             2949.294677734375\n",
      "    separation loss:          2.378582159678141\n",
      "    avg separation loss:      6.068108240763347\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  4.797592639923096\n",
      "    train time:               0.02390885353088379\n",
      "    test time:                0.012577056884765625\n",
      "    epoch time:               0.036989688873291016\n",
      "    last layer lr:            0.006040000000000003\n",
      "epoch: 140 (10/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.029822864569723606\n",
      "    train cross_ent loss:     0.023253284963882632\n",
      "    test overall loss:        0.1501158078511556\n",
      "    test cross_ent loss:      0.14331615716218948\n",
      "    cluster loss:             2949.2950032552085\n",
      "    separation loss:          2.3759994506835938\n",
      "    avg separation loss:      6.046115239461263\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  5.370182991027832\n",
      "    train time:               0.023708581924438477\n",
      "    test time:                0.012571573257446289\n",
      "    epoch time:               0.03677845001220703\n",
      "    last layer lr:            0.0067\n",
      "epoch: 140 (11/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.030918316294749577\n",
      "    train cross_ent loss:     0.023988588092227776\n",
      "    test overall loss:        0.1487473485370477\n",
      "    test cross_ent loss:      0.14169291717310747\n",
      "    cluster loss:             2949.2950846354165\n",
      "    separation loss:          2.378871202468872\n",
      "    avg separation loss:      6.058057149251302\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  5.624966144561768\n",
      "    train time:               0.023759841918945312\n",
      "    test time:                0.012597322463989258\n",
      "    epoch time:               0.03685784339904785\n",
      "    last layer lr:            0.0073599999999999985\n",
      "epoch: 140 (12/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 94.67%\n",
      "    train overall loss:       0.03239344546778335\n",
      "    train cross_ent loss:     0.025039041104416054\n",
      "    test overall loss:        0.14946208894252777\n",
      "    test cross_ent loss:      0.1413725931197405\n",
      "    cluster loss:             2949.2948404947915\n",
      "    separation loss:          2.376858870188395\n",
      "    avg separation loss:      6.047057628631592\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  6.660032272338867\n",
      "    train time:               0.024170875549316406\n",
      "    test time:                0.012618303298950195\n",
      "    epoch time:               0.03729248046875\n",
      "    last layer lr:            0.008019999999999994\n",
      "epoch: 140 (13/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.0354100006322066\n",
      "    train cross_ent loss:     0.027188458997342322\n",
      "    test overall loss:        0.14976692075530687\n",
      "    test cross_ent loss:      0.14142312171558538\n",
      "    cluster loss:             2949.29541015625\n",
      "    separation loss:          2.3782520294189453\n",
      "    avg separation loss:      6.049203713734944\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  6.914333343505859\n",
      "    train time:               0.02393651008605957\n",
      "    test time:                0.012574911117553711\n",
      "    epoch time:               0.03701353073120117\n",
      "    last layer lr:            0.008680000000000005\n",
      "epoch: 140 (14/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.03166932985186577\n",
      "    train cross_ent loss:     0.02287283632904291\n",
      "    test overall loss:        0.14858389149109522\n",
      "    test cross_ent loss:      0.1399720056603352\n",
      "    cluster loss:             2949.2954915364585\n",
      "    separation loss:          2.3757826487223306\n",
      "    avg separation loss:      6.0380533536275225\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  7.182419300079346\n",
      "    train time:               0.02368450164794922\n",
      "    test time:                0.012629985809326172\n",
      "    epoch time:               0.03681349754333496\n",
      "    last layer lr:            0.009340000000000003\n",
      "epoch: 140 (15/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.02890348682800929\n",
      "    train cross_ent loss:     0.019785415691634018\n",
      "    test overall loss:        0.1477908119559288\n",
      "    test cross_ent loss:      0.13874522844950357\n",
      "    cluster loss:             2949.2948404947915\n",
      "    separation loss:          2.377672036488851\n",
      "    avg separation loss:      6.045671780904134\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  7.616116523742676\n",
      "    train time:               0.023732900619506836\n",
      "    test time:                0.012568473815917969\n",
      "    epoch time:               0.03680086135864258\n",
      "    last layer lr:            0.01\n",
      "epoch: 140 (16/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       0.02980409065882365\n",
      "    train cross_ent loss:     0.020822873442537256\n",
      "    test overall loss:        0.14680289352933565\n",
      "    test cross_ent loss:      0.13760890749593577\n",
      "    cluster loss:             2949.294921875\n",
      "    separation loss:          2.37908927599589\n",
      "    avg separation loss:      6.054832458496094\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  7.764523506164551\n",
      "    train time:               0.024110078811645508\n",
      "    test time:                0.01258087158203125\n",
      "    epoch time:               0.03719139099121094\n",
      "    last layer lr:            0.009604000000000001\n",
      "epoch: 140 (17/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.03220877630843057\n",
      "    train cross_ent loss:     0.022995735415154032\n",
      "    test overall loss:        0.14449429884552956\n",
      "    test cross_ent loss:      0.13524964824318886\n",
      "    cluster loss:             2949.2947591145835\n",
      "    separation loss:          2.376241604487101\n",
      "    avg separation loss:      6.062008698781331\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  7.815189361572266\n",
      "    train time:               0.023753643035888672\n",
      "    test time:                0.012545108795166016\n",
      "    epoch time:               0.036800384521484375\n",
      "    last layer lr:            0.009208000000000003\n",
      "epoch: 140 (18/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.033313900232315063\n",
      "    train cross_ent loss:     0.024252765915460057\n",
      "    test overall loss:        0.14463486274083456\n",
      "    test cross_ent loss:      0.13523518294095993\n",
      "    cluster loss:             2949.294677734375\n",
      "    separation loss:          2.3723543087641397\n",
      "    avg separation loss:      6.048653920491536\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  7.970212936401367\n",
      "    train time:               0.02378988265991211\n",
      "    test time:                0.01257944107055664\n",
      "    epoch time:               0.03686690330505371\n",
      "    last layer lr:            0.008811999999999997\n",
      "epoch: 140 (19/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.028464261028501723\n",
      "    train cross_ent loss:     0.018882789856029883\n",
      "    test overall loss:        0.14274254565437636\n",
      "    test cross_ent loss:      0.1338001824915409\n",
      "    cluster loss:             2949.2948404947915\n",
      "    separation loss:          2.373817801475525\n",
      "    avg separation loss:      6.041280905405681\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  7.5128984451293945\n",
      "    train time:               0.023754358291625977\n",
      "    test time:                0.012586355209350586\n",
      "    epoch time:               0.036849021911621094\n",
      "    last layer lr:            0.008415999999999998\n",
      "epoch: 140 (20/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.029337463693486318\n",
      "    train cross_ent loss:     0.02037277879814307\n",
      "    test overall loss:        0.14114117622375488\n",
      "    test cross_ent loss:      0.1321718730032444\n",
      "    cluster loss:             2949.2950032552085\n",
      "    separation loss:          2.3771920998891196\n",
      "    avg separation loss:      6.055908997853597\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  7.539832592010498\n",
      "    train time:               0.023927688598632812\n",
      "    test time:                0.012589216232299805\n",
      "    epoch time:               0.037018537521362305\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 140 (21/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.02655354400889741\n",
      "    train cross_ent loss:     0.017802084071768656\n",
      "    test overall loss:        0.1408993328611056\n",
      "    test cross_ent loss:      0.13214828819036484\n",
      "    cluster loss:             2949.2945963541665\n",
      "    separation loss:          2.377623120943705\n",
      "    avg separation loss:      6.061728000640869\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  7.321573734283447\n",
      "    train time:               0.024295330047607422\n",
      "    test time:                0.012765645980834961\n",
      "    epoch time:               0.03757190704345703\n",
      "    last layer lr:            0.007624000000000002\n",
      "epoch: 140 (22/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.032497999568780266\n",
      "    train cross_ent loss:     0.024088532560401492\n",
      "    test overall loss:        0.13987712810436884\n",
      "    test cross_ent loss:      0.13122390707333884\n",
      "    cluster loss:             2949.2947591145835\n",
      "    separation loss:          2.376722057660421\n",
      "    avg separation loss:      6.049717744191487\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  7.223756790161133\n",
      "    train time:               0.02410578727722168\n",
      "    test time:                0.012772321701049805\n",
      "    epoch time:               0.03738856315612793\n",
      "    last layer lr:            0.0072280000000000035\n",
      "epoch: 140 (23/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.025855826834837597\n",
      "    train cross_ent loss:     0.017155590053233836\n",
      "    test overall loss:        0.13870887955029806\n",
      "    test cross_ent loss:      0.13070529202620187\n",
      "    cluster loss:             2949.2947591145835\n",
      "    separation loss:          2.377841909726461\n",
      "    avg separation loss:      6.0560784339904785\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  6.5741167068481445\n",
      "    train time:               0.02408289909362793\n",
      "    test time:                0.012892007827758789\n",
      "    epoch time:               0.0374908447265625\n",
      "    last layer lr:            0.006831999999999998\n",
      "epoch: 140 (24/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.023050578518046275\n",
      "    train cross_ent loss:     0.015475979592237208\n",
      "    test overall loss:        0.13765654837091765\n",
      "    test cross_ent loss:      0.13032391232748827\n",
      "    cluster loss:             2949.2945149739585\n",
      "    separation loss:          2.374821146329244\n",
      "    avg separation loss:      6.0583146413167315\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  5.903168678283691\n",
      "    train time:               0.02320575714111328\n",
      "    test time:                0.012286663055419922\n",
      "    epoch time:               0.035962581634521484\n",
      "    last layer lr:            0.006436\n",
      "epoch: 140 (25/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.026396494462258287\n",
      "    train cross_ent loss:     0.0193227877219518\n",
      "    test overall loss:        0.1357879638671875\n",
      "    test cross_ent loss:      0.12891760716835657\n",
      "    cluster loss:             2949.2948404947915\n",
      "    separation loss:          2.378669341405233\n",
      "    avg separation loss:      6.052002747853597\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  5.440890312194824\n",
      "    train time:               0.022936344146728516\n",
      "    test time:                0.012313365936279297\n",
      "    epoch time:               0.03571629524230957\n",
      "    last layer lr:            0.00604\n",
      "epoch: 140 (26/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.021778056398034096\n",
      "    train cross_ent loss:     0.015015904610562656\n",
      "    test overall loss:        0.13406572366754213\n",
      "    test cross_ent loss:      0.12772327226897082\n",
      "    cluster loss:             2949.294921875\n",
      "    separation loss:          2.3791674375534058\n",
      "    avg separation loss:      6.052857240041097\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  4.912981986999512\n",
      "    train time:               0.02298593521118164\n",
      "    test time:                0.012300729751586914\n",
      "    epoch time:               0.03575468063354492\n",
      "    last layer lr:            0.005644000000000002\n",
      "epoch: 140 (27/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.021943292166623805\n",
      "    train cross_ent loss:     0.01580526612492071\n",
      "    test overall loss:        0.13262671853105226\n",
      "    test cross_ent loss:      0.12659030531843504\n",
      "    cluster loss:             2949.294921875\n",
      "    separation loss:          2.37793759504954\n",
      "    avg separation loss:      6.055741628011067\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  4.606945514678955\n",
      "    train time:               0.023350238800048828\n",
      "    test time:                0.012300729751586914\n",
      "    epoch time:               0.036118268966674805\n",
      "    last layer lr:            0.005248000000000003\n",
      "epoch: 140 (28/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.020546731642550893\n",
      "    train cross_ent loss:     0.014848966332566407\n",
      "    test overall loss:        0.13288784275452295\n",
      "    test cross_ent loss:      0.12735262823601565\n",
      "    cluster loss:             2949.2947591145835\n",
      "    separation loss:          2.381138801574707\n",
      "    avg separation loss:      6.064233620961507\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  4.105752468109131\n",
      "    train time:               0.023070335388183594\n",
      "    test time:                0.01231241226196289\n",
      "    epoch time:               0.03585243225097656\n",
      "    last layer lr:            0.004851999999999998\n",
      "epoch: 140 (29/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.02154739884038766\n",
      "    train cross_ent loss:     0.016183444919685524\n",
      "    test overall loss:        0.132682333389918\n",
      "    test cross_ent loss:      0.12737388598422208\n",
      "    cluster loss:             2949.294921875\n",
      "    separation loss:          2.3826797803243003\n",
      "    avg separation loss:      6.074540297190349\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  3.8789801597595215\n",
      "    train time:               0.023013830184936523\n",
      "    test time:                0.012308120727539062\n",
      "    epoch time:               0.03578948974609375\n",
      "    last layer lr:            0.004455999999999999\n",
      "epoch: 140 (30/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.01957291706154744\n",
      "    train cross_ent loss:     0.014454747912370496\n",
      "    test overall loss:        0.13064231599370638\n",
      "    test cross_ent loss:      0.12568842557569346\n",
      "    cluster loss:             2949.2950846354165\n",
      "    separation loss:          2.379289229710897\n",
      "    avg separation loss:      6.067374070485433\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  3.5244274139404297\n",
      "    train time:               0.023102283477783203\n",
      "    test time:                0.012328863143920898\n",
      "    epoch time:               0.03589677810668945\n",
      "    last layer lr:            0.004060000000000001\n",
      "epoch: 140 (31/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.01809622295614746\n",
      "    train cross_ent loss:     0.013269420402745405\n",
      "    test overall loss:        0.13082657878597578\n",
      "    test cross_ent loss:      0.1260714257756869\n",
      "    cluster loss:             2949.2950032552085\n",
      "    separation loss:          2.3768568436304727\n",
      "    avg separation loss:      6.053297519683838\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  3.3256897926330566\n",
      "    train time:               0.02356410026550293\n",
      "    test time:                0.012339591979980469\n",
      "    epoch time:               0.036370277404785156\n",
      "    last layer lr:            0.0036640000000000015\n",
      "epoch: 140 (32/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.019449698014391795\n",
      "    train cross_ent loss:     0.014961622810612122\n",
      "    test overall loss:        0.13046662136912346\n",
      "    test cross_ent loss:      0.1259783816834291\n",
      "    cluster loss:             2949.294921875\n",
      "    separation loss:          2.3769649664560952\n",
      "    avg separation loss:      6.060923894246419\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  3.0587692260742188\n",
      "    train time:               0.023245811462402344\n",
      "    test time:                0.012352466583251953\n",
      "    epoch time:               0.03607487678527832\n",
      "    last layer lr:            0.003268000000000003\n",
      "epoch: 140 (33/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.021274608973827627\n",
      "    train cross_ent loss:     0.016933208279725578\n",
      "    test overall loss:        0.12954207013050714\n",
      "    test cross_ent loss:      0.12525424857934317\n",
      "    cluster loss:             2949.2950846354165\n",
      "    separation loss:          2.377989649772644\n",
      "    avg separation loss:      6.055154164632161\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  2.858354091644287\n",
      "    train time:               0.023108959197998047\n",
      "    test time:                0.01233530044555664\n",
      "    epoch time:               0.03590726852416992\n",
      "    last layer lr:            0.002871999999999997\n",
      "epoch: 140 (34/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.01747668907046318\n",
      "    train cross_ent loss:     0.013501695771184232\n",
      "    test overall loss:        0.1295554426809152\n",
      "    test cross_ent loss:      0.12571422134836516\n",
      "    cluster loss:             2949.2945963541665\n",
      "    separation loss:          2.3745749394098916\n",
      "    avg separation loss:      6.053844769795735\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  2.411759614944458\n",
      "    train time:               0.0230405330657959\n",
      "    test time:                0.012332439422607422\n",
      "    epoch time:               0.03584003448486328\n",
      "    last layer lr:            0.0024759999999999986\n",
      "epoch: 140 (35/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.018333759158849716\n",
      "    train cross_ent loss:     0.014629278435475297\n",
      "    test overall loss:        0.12926791608333588\n",
      "    test cross_ent loss:      0.1257588304579258\n",
      "    cluster loss:             2949.29443359375\n",
      "    separation loss:          2.375685731569926\n",
      "    avg separation loss:      6.060925006866455\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  2.0796151161193848\n",
      "    train time:               0.023403406143188477\n",
      "    test time:                0.012330770492553711\n",
      "    epoch time:               0.036200523376464844\n",
      "    last layer lr:            0.0020800000000000003\n",
      "epoch: 140 (36/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.020505448285904195\n",
      "    train cross_ent loss:     0.017219401844259765\n",
      "    test overall loss:        0.1281549334526062\n",
      "    test cross_ent loss:      0.12489341634015243\n",
      "    cluster loss:             2949.2948404947915\n",
      "    separation loss:          2.373278776804606\n",
      "    avg separation loss:      6.066666920979817\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  1.832047700881958\n",
      "    train time:               0.023174285888671875\n",
      "    test time:                0.012410640716552734\n",
      "    epoch time:               0.03605294227600098\n",
      "    last layer lr:            0.0016840000000000017\n",
      "epoch: 140 (37/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.016630237715111837\n",
      "    train cross_ent loss:     0.013509938182930151\n",
      "    test overall loss:        0.1281459480524063\n",
      "    test cross_ent loss:      0.1252040732651949\n",
      "    cluster loss:             2949.2947591145835\n",
      "    separation loss:          2.3750502268473306\n",
      "    avg separation loss:      6.055384476979573\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  1.5124077796936035\n",
      "    train time:               0.023174524307250977\n",
      "    test time:                0.012398719787597656\n",
      "    epoch time:               0.0360407829284668\n",
      "    last layer lr:            0.001288000000000003\n",
      "epoch: 140 (38/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.017584136894179717\n",
      "    train cross_ent loss:     0.014823741538243162\n",
      "    test overall loss:        0.1280650794506073\n",
      "    test cross_ent loss:      0.12542052815357843\n",
      "    cluster loss:             2949.2952473958335\n",
      "    separation loss:          2.376412828763326\n",
      "    avg separation loss:      6.05534553527832\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  1.2150856256484985\n",
      "    train time:               0.025703907012939453\n",
      "    test time:                0.01429891586303711\n",
      "    epoch time:               0.04066038131713867\n",
      "    last layer lr:            0.0008919999999999973\n",
      "epoch: 140 (39/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.015799234724707074\n",
      "    train cross_ent loss:     0.013336653200288614\n",
      "    test overall loss:        0.12815382579962412\n",
      "    test cross_ent loss:      0.12582198716700077\n",
      "    cluster loss:             2949.294677734375\n",
      "    separation loss:          2.3750606775283813\n",
      "    avg separation loss:      6.048066775004069\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  0.9023769497871399\n",
      "    train time:               0.030740737915039062\n",
      "    test time:                0.014346122741699219\n",
      "    epoch time:               0.04578733444213867\n",
      "    last layer lr:            0.0004959999999999986\n",
      "epoch: 140 (40/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.014054644852876663\n",
      "    train cross_ent loss:     0.011958039624409543\n",
      "    test overall loss:        0.12668240442872047\n",
      "    test cross_ent loss:      0.12472308054566383\n",
      "    cluster loss:             2949.2950846354165\n",
      "    separation loss:          2.379857579867045\n",
      "    avg separation loss:      6.066383997599284\n",
      "    l1_addon loss:            47.64873123168945\n",
      "    l1 loss:                  0.5298618674278259\n",
      "    train time:               0.023589134216308594\n",
      "    test time:                0.012466669082641602\n",
      "    epoch time:               0.03655290603637695\n",
      "    last layer lr:            0.0001\n",
      "epoch: 141 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.01817765376634068\n",
      "    train cross_ent loss:     0.016218437088860407\n",
      "    test overall loss:        0.12514925686021647\n",
      "    test cross_ent loss:      0.12319022851685683\n",
      "    cluster loss:             2949.2942708333335\n",
      "    separation loss:          2.3731765747070312\n",
      "    avg separation loss:      6.064130465189616\n",
      "    l1_addon loss:            47.63909149169922\n",
      "    l1 loss:                  0.5298618674278259\n",
      "    train time:               0.06094861030578613\n",
      "    test time:                0.012408018112182617\n",
      "    epoch time:               0.07453656196594238\n",
      "    joint lr:                 0.001298047112325102\n",
      "epoch: 142 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.01441894161204497\n",
      "    train cross_ent loss:     0.012461237143725157\n",
      "    test overall loss:        0.1264807010690371\n",
      "    test cross_ent loss:      0.1245236974209547\n",
      "    cluster loss:             2949.28857421875\n",
      "    separation loss:          2.3553620974222818\n",
      "    avg separation loss:      5.9839019775390625\n",
      "    l1_addon loss:            47.57170486450195\n",
      "    l1 loss:                  0.5298618674278259\n",
      "    train time:               0.06060481071472168\n",
      "    test time:                0.012969732284545898\n",
      "    epoch time:               0.07458901405334473\n",
      "    joint lr:                 0.002472133282403701\n",
      "epoch: 143 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.008969954008029567\n",
      "    train cross_ent loss:     0.007013476596006917\n",
      "    test overall loss:        0.11767687586446603\n",
      "    test cross_ent loss:      0.11572025964657466\n",
      "    cluster loss:             2949.281982421875\n",
      "    separation loss:          2.324409008026123\n",
      "    avg separation loss:      5.883555253346761\n",
      "    l1_addon loss:            47.55878448486328\n",
      "    l1 loss:                  0.5298618674278259\n",
      "    train time:               0.05920696258544922\n",
      "    test time:                0.012697219848632812\n",
      "    epoch time:               0.0727081298828125\n",
      "    joint lr:                 0.0036226179243694966\n",
      "epoch: 144 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.006122013890287942\n",
      "    train cross_ent loss:     0.004163551532352964\n",
      "    test overall loss:        0.10827387062211831\n",
      "    test cross_ent loss:      0.10631579688439767\n",
      "    cluster loss:             2949.279052734375\n",
      "    separation loss:          2.3089747428894043\n",
      "    avg separation loss:      5.852604230244954\n",
      "    l1_addon loss:            47.6071662902832\n",
      "    l1 loss:                  0.5298618674278259\n",
      "    train time:               0.05888652801513672\n",
      "    test time:                0.012650489807128906\n",
      "    epoch time:               0.07230401039123535\n",
      "    joint lr:                 0.004749855660167736\n",
      "epoch: 145 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.004628325760778453\n",
      "    train cross_ent loss:     0.002673928677621815\n",
      "    test overall loss:        0.10168495588004589\n",
      "    test cross_ent loss:      0.09973309468477964\n",
      "    cluster loss:             2949.275390625\n",
      "    separation loss:          2.2945163249969482\n",
      "    avg separation loss:      5.847309589385986\n",
      "    l1_addon loss:            47.399898529052734\n",
      "    l1 loss:                  0.5298618674278259\n",
      "    train time:               0.05890703201293945\n",
      "    test time:                0.012652397155761719\n",
      "    epoch time:               0.07236766815185547\n",
      "    joint lr:                 0.005854196379457574\n",
      "epoch: 146 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.0051837943287359346\n",
      "    train cross_ent loss:     0.0032297485870205695\n",
      "    test overall loss:        0.09693131161232789\n",
      "    test cross_ent loss:      0.09497453086078167\n",
      "    cluster loss:             2949.2779134114585\n",
      "    separation loss:          2.290828267733256\n",
      "    avg separation loss:      5.845465660095215\n",
      "    l1_addon loss:            47.564048767089844\n",
      "    l1 loss:                  0.5298618674278259\n",
      "    train time:               0.05875802040100098\n",
      "    test time:                0.01264500617980957\n",
      "    epoch time:               0.07220101356506348\n",
      "    joint lr:                 0.006935985298795627\n",
      "epoch: 147 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.004153773654252291\n",
      "    train cross_ent loss:     0.00219588336120877\n",
      "    test overall loss:        0.10106839487950008\n",
      "    test cross_ent loss:      0.09911230516930421\n",
      "    cluster loss:             2949.2788899739585\n",
      "    separation loss:          2.2868640422821045\n",
      "    avg separation loss:      5.790001233418782\n",
      "    l1_addon loss:            47.54092788696289\n",
      "    l1 loss:                  0.5298618674278259\n",
      "    train time:               0.059027671813964844\n",
      "    test time:                0.012704610824584961\n",
      "    epoch time:               0.07254743576049805\n",
      "    joint lr:                 0.007995563020108943\n",
      "epoch: 148 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.003741759289469984\n",
      "    train cross_ent loss:     0.0017907531809113505\n",
      "    test overall loss:        0.10026765738924344\n",
      "    test cross_ent loss:      0.09832004209359486\n",
      "    cluster loss:             2949.2765299479165\n",
      "    separation loss:          2.2523920138676963\n",
      "    avg separation loss:      5.713351726531982\n",
      "    l1_addon loss:            47.25847625732422\n",
      "    l1 loss:                  0.5298618674278259\n",
      "    train time:               0.05878734588623047\n",
      "    test time:                0.012642621994018555\n",
      "    epoch time:               0.0722503662109375\n",
      "    joint lr:                 0.009033265588466115\n",
      "epoch: 149 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.00359403347182605\n",
      "    train cross_ent loss:     0.0016453872926326261\n",
      "    test overall loss:        0.09991407487541437\n",
      "    test cross_ent loss:      0.09796298295259476\n",
      "    cluster loss:             2949.2737630208335\n",
      "    separation loss:          2.241852323214213\n",
      "    avg separation loss:      5.676557540893555\n",
      "    l1_addon loss:            47.37439727783203\n",
      "    l1 loss:                  0.5298618674278259\n",
      "    train time:               0.058624267578125\n",
      "    test time:                0.01217341423034668\n",
      "    epoch time:               0.07154488563537598\n",
      "    joint lr:                 0.010049424549154131\n",
      "epoch: 150 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.0034592579532828596\n",
      "    train cross_ent loss:     0.001510237350076851\n",
      "    test overall loss:        0.09592458202193181\n",
      "    test cross_ent loss:      0.09398030738035838\n",
      "    cluster loss:             2949.2740071614585\n",
      "    separation loss:          2.2263640562693277\n",
      "    avg separation loss:      5.6193052927653\n",
      "    l1_addon loss:            47.14714050292969\n",
      "    l1 loss:                  0.5298618674278259\n",
      "    train time:               0.05811572074890137\n",
      "    test time:                0.012151479721069336\n",
      "    epoch time:               0.07102656364440918\n",
      "    joint lr:                 0.011044367004069541\n",
      "epoch: 151 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.0033840660212768447\n",
      "    train cross_ent loss:     0.0014391164036674632\n",
      "    test overall loss:        0.08840266987681389\n",
      "    test cross_ent loss:      0.08645496889948845\n",
      "    cluster loss:             2949.2711588541665\n",
      "    separation loss:          2.206571102142334\n",
      "    avg separation loss:      5.585062026977539\n",
      "    l1_addon loss:            47.26130676269531\n",
      "    l1 loss:                  0.5298618674278259\n",
      "    train time:               0.058228254318237305\n",
      "    test time:                0.012125015258789062\n",
      "    epoch time:               0.07110023498535156\n",
      "    joint lr:                 0.010393177167327405\n",
      "epoch: 152 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.00398620849268304\n",
      "    train cross_ent loss:     0.0020402990566152665\n",
      "    test overall loss:        0.08597728547950585\n",
      "    test cross_ent loss:      0.08403066669901212\n",
      "    cluster loss:             2949.2730305989585\n",
      "    separation loss:          2.22465443611145\n",
      "    avg separation loss:      5.649378935496013\n",
      "    l1_addon loss:            47.225364685058594\n",
      "    l1 loss:                  0.5298618674278259\n",
      "    train time:               0.05971026420593262\n",
      "    test time:                0.01244497299194336\n",
      "    epoch time:               0.07284045219421387\n",
      "    joint lr:                 0.009753916690619703\n",
      "epoch: 153 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.0041938590196271735\n",
      "    train cross_ent loss:     0.0022460916144255963\n",
      "    test overall loss:        0.08783445786684752\n",
      "    test cross_ent loss:      0.08588980262478192\n",
      "    cluster loss:             2949.2723795572915\n",
      "    separation loss:          2.2052195072174072\n",
      "    avg separation loss:      5.57990026473999\n",
      "    l1_addon loss:            47.159881591796875\n",
      "    l1 loss:                  0.5298618674278259\n",
      "    train time:               0.06018424034118652\n",
      "    test time:                0.012156486511230469\n",
      "    epoch time:               0.07301759719848633\n",
      "    joint lr:                 0.009126412105729424\n",
      "epoch: 154 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.003561319602239463\n",
      "    train cross_ent loss:     0.0016196180885243746\n",
      "    test overall loss:        0.09650543394188087\n",
      "    test cross_ent loss:      0.09456574575354655\n",
      "    cluster loss:             2949.273193359375\n",
      "    separation loss:          2.2007924715677896\n",
      "    avg separation loss:      5.546110312143962\n",
      "    l1_addon loss:            46.99422836303711\n",
      "    l1 loss:                  0.5298618674278259\n",
      "    train time:               0.059893131256103516\n",
      "    test time:                0.012168407440185547\n",
      "    epoch time:               0.0727684497833252\n",
      "    joint lr:                 0.008510492220867888\n",
      "epoch: 155 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.0032948526915990645\n",
      "    train cross_ent loss:     0.0013539637244927387\n",
      "    test overall loss:        0.09319499569634597\n",
      "    test cross_ent loss:      0.09125298168510199\n",
      "    cluster loss:             2949.273193359375\n",
      "    separation loss:          2.1867898305257163\n",
      "    avg separation loss:      5.518189271291097\n",
      "    l1_addon loss:            47.07184600830078\n",
      "    l1 loss:                  0.5298618674278259\n",
      "    train time:               0.05999302864074707\n",
      "    test time:                0.012195587158203125\n",
      "    epoch time:               0.07288479804992676\n",
      "    joint lr:                 0.00790598809249301\n",
      "epoch: 156 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.0029937042854726315\n",
      "    train cross_ent loss:     0.0010511753433901402\n",
      "    test overall loss:        0.08811188551286857\n",
      "    test cross_ent loss:      0.08617064636200666\n",
      "    cluster loss:             2949.2728678385415\n",
      "    separation loss:          2.1713308095932007\n",
      "    avg separation loss:      5.485160191853841\n",
      "    l1_addon loss:            47.045997619628906\n",
      "    l1 loss:                  0.5298618674278259\n",
      "    train time:               0.06006503105163574\n",
      "    test time:                0.012156009674072266\n",
      "    epoch time:               0.07290816307067871\n",
      "    joint lr:                 0.007312732997463544\n",
      "epoch: 157 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.0028330115084018973\n",
      "    train cross_ent loss:     0.0008943248928214113\n",
      "    test overall loss:        0.08752863574773073\n",
      "    test cross_ent loss:      0.08559244840095441\n",
      "    cluster loss:             2949.2705078125\n",
      "    separation loss:          2.156705141067505\n",
      "    avg separation loss:      5.449560801188151\n",
      "    l1_addon loss:            46.87759017944336\n",
      "    l1 loss:                  0.5298618674278259\n",
      "    train time:               0.06073451042175293\n",
      "    test time:                0.01217341423034668\n",
      "    epoch time:               0.07363581657409668\n",
      "    joint lr:                 0.006730562405525418\n",
      "epoch: 158 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.006937467777687643\n",
      "    train cross_ent loss:     0.0049990531762078814\n",
      "    test overall loss:        0.08914807842423518\n",
      "    test cross_ent loss:      0.08721119600037734\n",
      "    cluster loss:             2949.2709147135415\n",
      "    separation loss:          2.1652552684148154\n",
      "    avg separation loss:      5.442525227864583\n",
      "    l1_addon loss:            46.900672912597656\n",
      "    l1 loss:                  0.5298618674278259\n",
      "    train time:               0.0598146915435791\n",
      "    test time:                0.012270689010620117\n",
      "    epoch time:               0.07278561592102051\n",
      "    joint lr:                 0.006159313952126306\n",
      "epoch: 159 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.0051634790531049175\n",
      "    train cross_ent loss:     0.00323144899125004\n",
      "    test overall loss:        0.09352428838610649\n",
      "    test cross_ent loss:      0.09158880108346541\n",
      "    cluster loss:             2949.2897135416665\n",
      "    separation loss:          2.179571747779846\n",
      "    avg separation loss:      5.445770740509033\n",
      "    l1_addon loss:            46.85430145263672\n",
      "    l1 loss:                  0.5298618674278259\n",
      "    train time:               0.06044197082519531\n",
      "    test time:                0.012182235717773438\n",
      "    epoch time:               0.07334065437316895\n",
      "    joint lr:                 0.005598827411554625\n",
      "epoch: 160 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.004620435699406598\n",
      "    train cross_ent loss:     0.002680046377160276\n",
      "    test overall loss:        0.09636408214767773\n",
      "    test cross_ent loss:      0.09442013253768285\n",
      "    cluster loss:             2949.299072265625\n",
      "    separation loss:          2.2101739645004272\n",
      "    avg separation loss:      5.4863942464192705\n",
      "    l1_addon loss:            47.136253356933594\n",
      "    l1 loss:                  0.5298618674278259\n",
      "    train time:               0.05983901023864746\n",
      "    test time:                0.012129068374633789\n",
      "    epoch time:               0.07265591621398926\n",
      "    joint lr:                 0.005048944670399165\n",
      "epoch: 161 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.005108952237707045\n",
      "    train cross_ent loss:     0.00316777074476704\n",
      "    test overall loss:        0.10104077961295843\n",
      "    test cross_ent loss:      0.09910385776311159\n",
      "    cluster loss:             2949.2974446614585\n",
      "    separation loss:          2.1921192407608032\n",
      "    avg separation loss:      5.425257682800293\n",
      "    l1_addon loss:            46.90211868286133\n",
      "    l1 loss:                  0.5298618674278259\n",
      "    train time:               0.06002926826477051\n",
      "    test time:                0.01213836669921875\n",
      "    epoch time:               0.07285022735595703\n",
      "    joint lr:                 0.004509509701325646\n",
      "epoch: 162 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.004469248129882746\n",
      "    train cross_ent loss:     0.0025357595748371547\n",
      "    test overall loss:        0.09201513106624286\n",
      "    test cross_ent loss:      0.09008333552628756\n",
      "    cluster loss:             2949.2978515625\n",
      "    separation loss:          2.1725951433181763\n",
      "    avg separation loss:      5.415308157602946\n",
      "    l1_addon loss:            46.73121643066406\n",
      "    l1 loss:                  0.5298618674278259\n",
      "    train time:               0.06035614013671875\n",
      "    test time:                0.012192487716674805\n",
      "    epoch time:               0.07324862480163574\n",
      "    joint lr:                 0.00398036853716657\n",
      "epoch: 163 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.003087325668376353\n",
      "    train cross_ent loss:     0.001154744011324106\n",
      "    test overall loss:        0.08936177007853985\n",
      "    test cross_ent loss:      0.08742775768041611\n",
      "    cluster loss:             2949.2928059895835\n",
      "    separation loss:          2.1637038787206015\n",
      "    avg separation loss:      5.3815484046936035\n",
      "    l1_addon loss:            46.80514907836914\n",
      "    l1 loss:                  0.5298618674278259\n",
      "    train time:               0.05998873710632324\n",
      "    test time:                0.01218867301940918\n",
      "    epoch time:               0.07288670539855957\n",
      "    joint lr:                 0.0034613692453205423\n",
      "epoch: 164 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.002649253130786949\n",
      "    train cross_ent loss:     0.0007139273673399455\n",
      "    test overall loss:        0.08634147668878238\n",
      "    test cross_ent loss:      0.08440530424316724\n",
      "    cluster loss:             2949.2908528645835\n",
      "    separation loss:          2.1603028774261475\n",
      "    avg separation loss:      5.378558158874512\n",
      "    l1_addon loss:            46.877113342285156\n",
      "    l1 loss:                  0.5298618674278259\n",
      "    train time:               0.059893131256103516\n",
      "    test time:                0.01226496696472168\n",
      "    epoch time:               0.07284855842590332\n",
      "    joint lr:                 0.002952361902457719\n",
      "epoch: 165 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.0026121515677207047\n",
      "    train cross_ent loss:     0.000675923517620605\n",
      "    test overall loss:        0.08564030720541875\n",
      "    test cross_ent loss:      0.08370431481550138\n",
      "    cluster loss:             2949.2889811197915\n",
      "    separation loss:          2.1598008473714194\n",
      "    avg separation loss:      5.374878724416097\n",
      "    l1_addon loss:            46.871002197265625\n",
      "    l1 loss:                  0.5298618674278259\n",
      "    train time:               0.0599207878112793\n",
      "    test time:                0.012262344360351562\n",
      "    epoch time:               0.07290077209472656\n",
      "    joint lr:                 0.0024531985695276076\n",
      "epoch: 166 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.0034230018500238657\n",
      "    train cross_ent loss:     0.001487419507207556\n",
      "    test overall loss:        0.08359707208971183\n",
      "    test cross_ent loss:      0.08166304665307204\n",
      "    cluster loss:             2949.2896321614585\n",
      "    separation loss:          2.1476922035217285\n",
      "    avg separation loss:      5.366273244222005\n",
      "    l1_addon loss:            46.805458068847656\n",
      "    l1 loss:                  0.5298618674278259\n",
      "    train time:               0.05998539924621582\n",
      "    test time:                0.01219940185546875\n",
      "    epoch time:               0.07287740707397461\n",
      "    joint lr:                 0.001963733267065865\n",
      "epoch: 167 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.0025445734564628866\n",
      "    train cross_ent loss:     0.0006113344861660153\n",
      "    test overall loss:        0.08522836895038684\n",
      "    test cross_ent loss:      0.08329569920897484\n",
      "    cluster loss:             2949.2880859375\n",
      "    separation loss:          2.144211729367574\n",
      "    avg separation loss:      5.346240997314453\n",
      "    l1_addon loss:            46.76026916503906\n",
      "    l1 loss:                  0.5298618674278259\n",
      "    train time:               0.06023001670837402\n",
      "    test time:                0.012147665023803711\n",
      "    epoch time:               0.07302975654602051\n",
      "    joint lr:                 0.001483821950796405\n",
      "epoch: 168 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.0026025761746697957\n",
      "    train cross_ent loss:     0.0006701250191933165\n",
      "    test overall loss:        0.08496399192760389\n",
      "    test cross_ent loss:      0.08303177263587713\n",
      "    cluster loss:             2949.2875162760415\n",
      "    separation loss:          2.1448152462641397\n",
      "    avg separation loss:      5.350991884867351\n",
      "    l1_addon loss:            46.745277404785156\n",
      "    l1 loss:                  0.5298618674278259\n",
      "    train time:               0.06028866767883301\n",
      "    test time:                0.012158870697021484\n",
      "    epoch time:               0.07316327095031738\n",
      "    joint lr:                 0.0010133224875256274\n",
      "epoch: 169 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.0030229484093272025\n",
      "    train cross_ent loss:     0.0010906831400158505\n",
      "    test overall loss:        0.08550945607324441\n",
      "    test cross_ent loss:      0.08357718742142121\n",
      "    cluster loss:             2949.287353515625\n",
      "    separation loss:          2.1431784629821777\n",
      "    avg separation loss:      5.337337811787923\n",
      "    l1_addon loss:            46.747005462646484\n",
      "    l1 loss:                  0.5298618674278259\n",
      "    train time:               0.06000709533691406\n",
      "    test time:                0.01222681999206543\n",
      "    epoch time:               0.07297945022583008\n",
      "    joint lr:                 0.0005520946313251855\n",
      "epoch: 170 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.0025174698999358546\n",
      "    train cross_ent loss:     0.0005853734102048394\n",
      "    test overall loss:        0.08478207016984622\n",
      "    test cross_ent loss:      0.08285011133799951\n",
      "    cluster loss:             2949.2867024739585\n",
      "    separation loss:          2.145220160484314\n",
      "    avg separation loss:      5.349712371826172\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  0.5298618674278259\n",
      "    train time:               0.06001591682434082\n",
      "    test time:                0.012274503707885742\n",
      "    epoch time:               0.07300972938537598\n",
      "    joint lr:                 0.0001\n",
      "epoch: 170 (PUSH) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.0025174698999358546\n",
      "    train cross_ent loss:     0.0005853734102048394\n",
      "    test overall loss:        0.11301314892868201\n",
      "    test cross_ent loss:      0.11108119537432988\n",
      "    cluster loss:             2949.2874348958335\n",
      "    separation loss:          2.101783275604248\n",
      "    avg separation loss:      5.315110206604004\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  0.5298618674278259\n",
      "    train time:               0.06001591682434082\n",
      "    test time:                0.012455224990844727\n",
      "    epoch time:               0.38654112815856934\n",
      "epoch: 170 (1/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.010257965600531962\n",
      "    train cross_ent loss:     0.008508156752213836\n",
      "    test overall loss:        0.11345594003796577\n",
      "    test cross_ent loss:      0.11182290377716224\n",
      "    cluster loss:             2949.2876790364585\n",
      "    separation loss:          2.1012683312098184\n",
      "    avg separation loss:      5.30718453725179\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  0.23094284534454346\n",
      "    train time:               0.02367091178894043\n",
      "    test time:                0.012150287628173828\n",
      "    epoch time:               0.036301374435424805\n",
      "    last layer lr:            0.0007599999999999978\n",
      "epoch: 170 (2/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.011778083319465319\n",
      "    train cross_ent loss:     0.00961353094317019\n",
      "    test overall loss:        0.11362250211338203\n",
      "    test cross_ent loss:      0.11142997195323308\n",
      "    cluster loss:             2949.2877604166665\n",
      "    separation loss:          2.0995476245880127\n",
      "    avg separation loss:      5.313542207082112\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  0.7904375791549683\n",
      "    train time:               0.023336410522460938\n",
      "    test time:                0.01208949089050293\n",
      "    epoch time:               0.0359034538269043\n",
      "    last layer lr:            0.0014199999999999955\n",
      "epoch: 170 (3/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.010692641449471315\n",
      "    train cross_ent loss:     0.008278743933058448\n",
      "    test overall loss:        0.11349538465340932\n",
      "    test cross_ent loss:      0.11104503770669301\n",
      "    cluster loss:             2949.2876790364585\n",
      "    separation loss:          2.0995879968007407\n",
      "    avg separation loss:      5.312167962392171\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  1.0482490062713623\n",
      "    train time:               0.02317953109741211\n",
      "    test time:                0.012151479721069336\n",
      "    epoch time:               0.03580832481384277\n",
      "    last layer lr:            0.0020800000000000046\n",
      "epoch: 170 (4/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.011789406908469068\n",
      "    train cross_ent loss:     0.009030914244552454\n",
      "    test overall loss:        0.11341026177008946\n",
      "    test cross_ent loss:      0.11028100301822026\n",
      "    cluster loss:             2949.287841796875\n",
      "    separation loss:          2.1039011081059775\n",
      "    avg separation loss:      5.322345574696858\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  1.7271595001220703\n",
      "    train time:               0.023631811141967773\n",
      "    test time:                0.012338876724243164\n",
      "    epoch time:               0.03649020195007324\n",
      "    last layer lr:            0.0027400000000000024\n",
      "epoch: 170 (5/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.011174391437735822\n",
      "    train cross_ent loss:     0.007865077143328058\n",
      "    test overall loss:        0.112621429686745\n",
      "    test cross_ent loss:      0.10935315613945325\n",
      "    cluster loss:             2949.287841796875\n",
      "    separation loss:          2.1013659636179605\n",
      "    avg separation loss:      5.325472990671794\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  1.8661789894104004\n",
      "    train time:               0.02305436134338379\n",
      "    test time:                0.012146949768066406\n",
      "    epoch time:               0.03570151329040527\n",
      "    last layer lr:            0.0034\n",
      "epoch: 170 (6/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.01433511750979556\n",
      "    train cross_ent loss:     0.01074955721075336\n",
      "    test overall loss:        0.1132592565069596\n",
      "    test cross_ent loss:      0.10955355999370416\n",
      "    cluster loss:             2949.28759765625\n",
      "    separation loss:          2.104981263478597\n",
      "    avg separation loss:      5.323413054148356\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  2.3035995960235596\n",
      "    train time:               0.023116350173950195\n",
      "    test time:                0.012065887451171875\n",
      "    epoch time:               0.03565645217895508\n",
      "    last layer lr:            0.004059999999999998\n",
      "epoch: 170 (7/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.01138277119025588\n",
      "    train cross_ent loss:     0.007355055616547664\n",
      "    test overall loss:        0.11339136647681396\n",
      "    test cross_ent loss:      0.10931317135691643\n",
      "    cluster loss:             2949.2875162760415\n",
      "    separation loss:          2.1043907403945923\n",
      "    avg separation loss:      5.32601801554362\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  2.6760969161987305\n",
      "    train time:               0.023106098175048828\n",
      "    test time:                0.012107372283935547\n",
      "    epoch time:               0.03569388389587402\n",
      "    last layer lr:            0.004719999999999996\n",
      "epoch: 170 (8/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.014606562443077564\n",
      "    train cross_ent loss:     0.00999898488064193\n",
      "    test overall loss:        0.11459651837746303\n",
      "    test cross_ent loss:      0.10958972635368507\n",
      "    cluster loss:             2949.2877604166665\n",
      "    separation loss:          2.100258549054464\n",
      "    avg separation loss:      5.30915101369222\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  3.6046977043151855\n",
      "    train time:               0.023155689239501953\n",
      "    test time:                0.012071371078491211\n",
      "    epoch time:               0.03570103645324707\n",
      "    last layer lr:            0.0053800000000000054\n",
      "epoch: 170 (9/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.013266945723444223\n",
      "    train cross_ent loss:     0.00789451671557294\n",
      "    test overall loss:        0.11403657495975494\n",
      "    test cross_ent loss:      0.10862919439872105\n",
      "    cluster loss:             2949.287353515625\n",
      "    separation loss:          2.1020737091700235\n",
      "    avg separation loss:      5.307651360829671\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  4.005285739898682\n",
      "    train time:               0.022981882095336914\n",
      "    test time:                0.01212000846862793\n",
      "    epoch time:               0.035576581954956055\n",
      "    last layer lr:            0.006040000000000003\n",
      "epoch: 170 (10/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.012956479357348548\n",
      "    train cross_ent loss:     0.007349665509536862\n",
      "    test overall loss:        0.11508953136702378\n",
      "    test cross_ent loss:      0.1093297718713681\n",
      "    cluster loss:             2949.2876790364585\n",
      "    separation loss:          2.1027143001556396\n",
      "    avg separation loss:      5.30504035949707\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  4.357658386230469\n",
      "    train time:               0.0232393741607666\n",
      "    test time:                0.012090682983398438\n",
      "    epoch time:               0.035830020904541016\n",
      "    last layer lr:            0.0067\n",
      "epoch: 170 (11/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.013633572910394933\n",
      "    train cross_ent loss:     0.0075002881284389235\n",
      "    test overall loss:        0.11411628561715285\n",
      "    test cross_ent loss:      0.10789427533745766\n",
      "    cluster loss:             2949.2876790364585\n",
      "    separation loss:          2.1025509039560952\n",
      "    avg separation loss:      5.319809118906657\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  4.819912910461426\n",
      "    train time:               0.024243831634521484\n",
      "    test time:                0.012153863906860352\n",
      "    epoch time:               0.03687262535095215\n",
      "    last layer lr:            0.0073599999999999985\n",
      "epoch: 170 (12/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.013235132520397505\n",
      "    train cross_ent loss:     0.0068016709604611\n",
      "    test overall loss:        0.11502219239870708\n",
      "    test cross_ent loss:      0.10855228391786416\n",
      "    cluster loss:             2949.2877604166665\n",
      "    separation loss:          2.101819157600403\n",
      "    avg separation loss:      5.3064961433410645\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  5.067816257476807\n",
      "    train time:               0.023175954818725586\n",
      "    test time:                0.012178897857666016\n",
      "    epoch time:               0.03582954406738281\n",
      "    last layer lr:            0.008019999999999994\n",
      "epoch: 170 (13/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.013075705410705673\n",
      "    train cross_ent loss:     0.006272631412785914\n",
      "    test overall loss:        0.11404119494060676\n",
      "    test cross_ent loss:      0.10716034596165021\n",
      "    cluster loss:             2949.28759765625\n",
      "    separation loss:          2.1009278694788613\n",
      "    avg separation loss:      5.310463587443034\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  5.4787492752075195\n",
      "    train time:               0.023072242736816406\n",
      "    test time:                0.012102603912353516\n",
      "    epoch time:               0.03565216064453125\n",
      "    last layer lr:            0.008680000000000005\n",
      "epoch: 170 (14/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.014704309817817476\n",
      "    train cross_ent loss:     0.007348227237040798\n",
      "    test overall loss:        0.11460766692956288\n",
      "    test cross_ent loss:      0.10686826954285304\n",
      "    cluster loss:             2949.2876790364585\n",
      "    separation loss:          2.0990697542826333\n",
      "    avg separation loss:      5.307706197102864\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  6.337303161621094\n",
      "    train time:               0.0230710506439209\n",
      "    test time:                0.012070894241333008\n",
      "    epoch time:               0.03561544418334961\n",
      "    last layer lr:            0.009340000000000003\n",
      "epoch: 170 (15/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.014575486795769798\n",
      "    train cross_ent loss:     0.006720783240679238\n",
      "    test overall loss:        0.11556660135587056\n",
      "    test cross_ent loss:      0.10768825250367324\n",
      "    cluster loss:             2949.28759765625\n",
      "    separation loss:          2.1009421745936074\n",
      "    avg separation loss:      5.307122866312663\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  6.476251602172852\n",
      "    train time:               0.0231320858001709\n",
      "    test time:                0.012198686599731445\n",
      "    epoch time:               0.03583812713623047\n",
      "    last layer lr:            0.01\n",
      "epoch: 170 (16/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.01494295998579926\n",
      "    train cross_ent loss:     0.006774378914592994\n",
      "    test overall loss:        0.11588725199302037\n",
      "    test cross_ent loss:      0.10764844343066216\n",
      "    cluster loss:             2949.28759765625\n",
      "    separation loss:          2.102962334950765\n",
      "    avg separation loss:      5.308218479156494\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  6.8367109298706055\n",
      "    train time:               0.02344989776611328\n",
      "    test time:                0.012153863906860352\n",
      "    epoch time:               0.036084651947021484\n",
      "    last layer lr:            0.009604000000000001\n",
      "epoch: 170 (17/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.018343144199914403\n",
      "    train cross_ent loss:     0.010065997278110849\n",
      "    test overall loss:        0.1186480453858773\n",
      "    test cross_ent loss:      0.10969156585633755\n",
      "    cluster loss:             2949.2877604166665\n",
      "    separation loss:          2.0997136433919272\n",
      "    avg separation loss:      5.29504410425822\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  7.554385185241699\n",
      "    train time:               0.022989511489868164\n",
      "    test time:                0.012130975723266602\n",
      "    epoch time:               0.03560161590576172\n",
      "    last layer lr:            0.009208000000000003\n",
      "epoch: 170 (18/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.01682555696202649\n",
      "    train cross_ent loss:     0.007975681477950679\n",
      "    test overall loss:        0.1173874909679095\n",
      "    test cross_ent loss:      0.10864987907310326\n",
      "    cluster loss:             2949.2876790364585\n",
      "    separation loss:          2.0989291270573935\n",
      "    avg separation loss:      5.293745835622151\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  7.335519790649414\n",
      "    train time:               0.023234844207763672\n",
      "    test time:                0.012096643447875977\n",
      "    epoch time:               0.035805702209472656\n",
      "    last layer lr:            0.008811999999999997\n",
      "epoch: 170 (19/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.015396319950620333\n",
      "    train cross_ent loss:     0.007138938125636842\n",
      "    test overall loss:        0.11633994181950887\n",
      "    test cross_ent loss:      0.10832710657268763\n",
      "    cluster loss:             2949.28759765625\n",
      "    separation loss:          2.1056504249572754\n",
      "    avg separation loss:      5.321455478668213\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  6.610743522644043\n",
      "    train time:               0.023152828216552734\n",
      "    test time:                0.012223958969116211\n",
      "    epoch time:               0.03586697578430176\n",
      "    last layer lr:            0.008415999999999998\n",
      "epoch: 170 (20/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.014275012537837029\n",
      "    train cross_ent loss:     0.00651175345087217\n",
      "    test overall loss:        0.11508475119868915\n",
      "    test cross_ent loss:      0.10755425381163757\n",
      "    cluster loss:             2949.287841796875\n",
      "    separation loss:          2.104743560155233\n",
      "    avg separation loss:      5.321557680765788\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  6.128401756286621\n",
      "    train time:               0.023718595504760742\n",
      "    test time:                0.012576103210449219\n",
      "    epoch time:               0.03678607940673828\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 170 (21/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.013343075497282876\n",
      "    train cross_ent loss:     0.005944996761778991\n",
      "    test overall loss:        0.11549854464828968\n",
      "    test cross_ent loss:      0.10805153908828895\n",
      "    cluster loss:             2949.2881673177085\n",
      "    separation loss:          2.102201263109843\n",
      "    avg separation loss:      5.3094987869262695\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  6.04490852355957\n",
      "    train time:               0.023691415786743164\n",
      "    test time:                0.016032695770263672\n",
      "    epoch time:               0.0402224063873291\n",
      "    last layer lr:            0.007624000000000002\n",
      "epoch: 170 (22/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.01495531408323182\n",
      "    train cross_ent loss:     0.007740616022298734\n",
      "    test overall loss:        0.1132415880759557\n",
      "    test cross_ent loss:      0.10603852880497773\n",
      "    cluster loss:             2949.287841796875\n",
      "    separation loss:          2.1030319929122925\n",
      "    avg separation loss:      5.327341238657634\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  5.80096435546875\n",
      "    train time:               0.024109840393066406\n",
      "    test time:                0.01244664192199707\n",
      "    epoch time:               0.03703641891479492\n",
      "    last layer lr:            0.0072280000000000035\n",
      "epoch: 170 (23/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.014942566760712199\n",
      "    train cross_ent loss:     0.00802203081548214\n",
      "    test overall loss:        0.11344920781751473\n",
      "    test cross_ent loss:      0.10659443400800228\n",
      "    cluster loss:             2949.2879231770835\n",
      "    separation loss:          2.0993464390436807\n",
      "    avg separation loss:      5.309914906819661\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  5.452676773071289\n",
      "    train time:               0.024875402450561523\n",
      "    test time:                0.012931585311889648\n",
      "    epoch time:               0.038317203521728516\n",
      "    last layer lr:            0.006831999999999998\n",
      "epoch: 170 (24/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.014239659325944053\n",
      "    train cross_ent loss:     0.007772486217113005\n",
      "    test overall loss:        0.11303221496442954\n",
      "    test cross_ent loss:      0.10625786458452542\n",
      "    cluster loss:             2949.288330078125\n",
      "    separation loss:          2.1013100147247314\n",
      "    avg separation loss:      5.312707424163818\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  5.372250556945801\n",
      "    train time:               0.02576899528503418\n",
      "    test time:                0.013115882873535156\n",
      "    epoch time:               0.03950238227844238\n",
      "    last layer lr:            0.006436\n",
      "epoch: 170 (25/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.013307618805103831\n",
      "    train cross_ent loss:     0.0065666732585264575\n",
      "    test overall loss:        0.11236957957347234\n",
      "    test cross_ent loss:      0.10599340312182903\n",
      "    cluster loss:             2949.2876790364585\n",
      "    separation loss:          2.0992474953333535\n",
      "    avg separation loss:      5.308267275492351\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  4.974076747894287\n",
      "    train time:               0.025966644287109375\n",
      "    test time:                0.013082265853881836\n",
      "    epoch time:               0.0396265983581543\n",
      "    last layer lr:            0.00604\n",
      "epoch: 170 (26/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.013063182640406821\n",
      "    train cross_ent loss:     0.006950306395689647\n",
      "    test overall loss:        0.11265910230576992\n",
      "    test cross_ent loss:      0.10679015796631575\n",
      "    cluster loss:             2949.2879231770835\n",
      "    separation loss:          2.104677160580953\n",
      "    avg separation loss:      5.309699694315593\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  4.466851234436035\n",
      "    train time:               0.02486896514892578\n",
      "    test time:                0.012954950332641602\n",
      "    epoch time:               0.03833889961242676\n",
      "    last layer lr:            0.005644000000000002\n",
      "epoch: 170 (27/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.014832544864879714\n",
      "    train cross_ent loss:     0.009058908585252034\n",
      "    test overall loss:        0.11313821002840996\n",
      "    test cross_ent loss:      0.10693655628710985\n",
      "    cluster loss:             2949.2879231770835\n",
      "    separation loss:          2.1059962113698325\n",
      "    avg separation loss:      5.3200812339782715\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  4.799553871154785\n",
      "    train time:               0.024962425231933594\n",
      "    test time:                0.012908935546875\n",
      "    epoch time:               0.03838396072387695\n",
      "    last layer lr:            0.005248000000000003\n",
      "epoch: 170 (28/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.011241043141732613\n",
      "    train cross_ent loss:     0.005490307851384084\n",
      "    test overall loss:        0.11151227727532387\n",
      "    test cross_ent loss:      0.10593836195766926\n",
      "    cluster loss:             2949.2879231770835\n",
      "    separation loss:          2.1020021041234336\n",
      "    avg separation loss:      5.3050916989644366\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  4.171820640563965\n",
      "    train time:               0.02512645721435547\n",
      "    test time:                0.012909173965454102\n",
      "    epoch time:               0.03855013847351074\n",
      "    last layer lr:            0.004851999999999998\n",
      "epoch: 170 (29/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.014442454609606001\n",
      "    train cross_ent loss:     0.00917463418510225\n",
      "    test overall loss:        0.11010099574923515\n",
      "    test cross_ent loss:      0.10463763152559598\n",
      "    cluster loss:             2949.288330078125\n",
      "    separation loss:          2.096787214279175\n",
      "    avg separation loss:      5.304225921630859\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  4.061270713806152\n",
      "    train time:               0.024945974349975586\n",
      "    test time:                0.012915611267089844\n",
      "    epoch time:               0.03837418556213379\n",
      "    last layer lr:            0.004455999999999999\n",
      "epoch: 170 (30/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.009707417339086533\n",
      "    train cross_ent loss:     0.004310468496340845\n",
      "    test overall loss:        0.11040268527964751\n",
      "    test cross_ent loss:      0.10537300693492095\n",
      "    cluster loss:             2949.2881673177085\n",
      "    separation loss:          2.0983874797821045\n",
      "    avg separation loss:      5.309409459431966\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  3.627580165863037\n",
      "    train time:               0.024936199188232422\n",
      "    test time:                0.012921333312988281\n",
      "    epoch time:               0.038367509841918945\n",
      "    last layer lr:            0.004060000000000001\n",
      "epoch: 170 (31/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.009241174285610517\n",
      "    train cross_ent loss:     0.004512197907186217\n",
      "    test overall loss:        0.11007374214629333\n",
      "    test cross_ent loss:      0.10556636347124974\n",
      "    cluster loss:             2949.287841796875\n",
      "    separation loss:          2.100580175717672\n",
      "    avg separation loss:      5.3228081067403155\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  3.1052818298339844\n",
      "    train time:               0.025490760803222656\n",
      "    test time:                0.013020753860473633\n",
      "    epoch time:               0.03903007507324219\n",
      "    last layer lr:            0.0036640000000000015\n",
      "epoch: 170 (32/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.008694452337092824\n",
      "    train cross_ent loss:     0.004448205982852314\n",
      "    test overall loss:        0.11020246272285779\n",
      "    test cross_ent loss:      0.10613088185588519\n",
      "    cluster loss:             2949.2874348958335\n",
      "    separation loss:          2.101827621459961\n",
      "    avg separation loss:      5.3129903475443525\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  2.6694862842559814\n",
      "    train time:               0.0249021053314209\n",
      "    test time:                0.01290440559387207\n",
      "    epoch time:               0.038316965103149414\n",
      "    last layer lr:            0.003268000000000003\n",
      "epoch: 170 (33/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.010063561921318373\n",
      "    train cross_ent loss:     0.00616081648816665\n",
      "    test overall loss:        0.10998814987639587\n",
      "    test cross_ent loss:      0.1061512775098284\n",
      "    cluster loss:             2949.28759765625\n",
      "    separation loss:          2.1032273372014365\n",
      "    avg separation loss:      5.316214084625244\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  2.43477725982666\n",
      "    train time:               0.025069475173950195\n",
      "    test time:                0.012920379638671875\n",
      "    epoch time:               0.03850102424621582\n",
      "    last layer lr:            0.002871999999999997\n",
      "epoch: 170 (34/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.00806954021876057\n",
      "    train cross_ent loss:     0.004432782996445894\n",
      "    test overall loss:        0.11018981784582138\n",
      "    test cross_ent loss:      0.10664559000482161\n",
      "    cluster loss:             2949.2876790364585\n",
      "    separation loss:          2.1027657190958657\n",
      "    avg separation loss:      5.3048882484436035\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  2.14213228225708\n",
      "    train time:               0.025050878524780273\n",
      "    test time:                0.012923479080200195\n",
      "    epoch time:               0.03849005699157715\n",
      "    last layer lr:            0.0024759999999999986\n",
      "epoch: 170 (35/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.010135490343802504\n",
      "    train cross_ent loss:     0.006760608534225159\n",
      "    test overall loss:        0.10885465393463771\n",
      "    test cross_ent loss:      0.10551220364868641\n",
      "    cluster loss:             2949.2875162760415\n",
      "    separation loss:          2.101278066635132\n",
      "    avg separation loss:      5.311128616333008\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  1.9403529167175293\n",
      "    train time:               0.024883747100830078\n",
      "    test time:                0.012951374053955078\n",
      "    epoch time:               0.0383450984954834\n",
      "    last layer lr:            0.0020800000000000003\n",
      "epoch: 170 (36/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.009020706535213523\n",
      "    train cross_ent loss:     0.005784158801866902\n",
      "    test overall loss:        0.10756854278345902\n",
      "    test cross_ent loss:      0.10445960983633995\n",
      "    cluster loss:             2949.2877604166665\n",
      "    separation loss:          2.100986440976461\n",
      "    avg separation loss:      5.31790018081665\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  1.7068324089050293\n",
      "    train time:               0.025087833404541016\n",
      "    test time:                0.012924671173095703\n",
      "    epoch time:               0.038526296615600586\n",
      "    last layer lr:            0.0016840000000000017\n",
      "epoch: 170 (37/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.006839465763833787\n",
      "    train cross_ent loss:     0.003952065741436349\n",
      "    test overall loss:        0.10759805329144001\n",
      "    test cross_ent loss:      0.10486524024357398\n",
      "    cluster loss:             2949.2874348958335\n",
      "    separation loss:          2.1022136211395264\n",
      "    avg separation loss:      5.317250410715739\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  1.330713152885437\n",
      "    train time:               0.02505970001220703\n",
      "    test time:                0.01295781135559082\n",
      "    epoch time:               0.038550376892089844\n",
      "    last layer lr:            0.001288000000000003\n",
      "epoch: 170 (38/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.009290644278128942\n",
      "    train cross_ent loss:     0.0067336045516033964\n",
      "    test overall loss:        0.1066998237123092\n",
      "    test cross_ent loss:      0.10421672184020281\n",
      "    cluster loss:             2949.2879231770835\n",
      "    separation loss:          2.097562630971273\n",
      "    avg separation loss:      5.311549345652263\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  1.0810070037841797\n",
      "    train time:               0.024919509887695312\n",
      "    test time:                0.012946844100952148\n",
      "    epoch time:               0.038378238677978516\n",
      "    last layer lr:            0.0008919999999999973\n",
      "epoch: 170 (39/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.008656290049354235\n",
      "    train cross_ent loss:     0.006331036462345057\n",
      "    test overall loss:        0.10726027997831504\n",
      "    test cross_ent loss:      0.10504111057768266\n",
      "    cluster loss:             2949.2875162760415\n",
      "    separation loss:          2.098827600479126\n",
      "    avg separation loss:      5.3121538162231445\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  0.817068338394165\n",
      "    train time:               0.025062084197998047\n",
      "    test time:                0.012926101684570312\n",
      "    epoch time:               0.03850054740905762\n",
      "    last layer lr:            0.0004959999999999986\n",
      "epoch: 170 (40/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.0079744728282094\n",
      "    train cross_ent loss:     0.005951725489770372\n",
      "    test overall loss:        0.10693584755063057\n",
      "    test cross_ent loss:      0.10504181869328022\n",
      "    cluster loss:             2949.287841796875\n",
      "    separation loss:          2.101063291231791\n",
      "    avg separation loss:      5.326345284779866\n",
      "    l1_addon loss:            46.73664093017578\n",
      "    l1 loss:                  0.491934210062027\n",
      "    train time:               0.024977684020996094\n",
      "    test time:                0.012922048568725586\n",
      "    epoch time:               0.03841114044189453\n",
      "    last layer lr:            0.0001\n",
      "epoch: 171 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.00786425918340683\n",
      "    train cross_ent loss:     0.005970218736264441\n",
      "    test overall loss:        0.10689313088854153\n",
      "    test cross_ent loss:      0.10499910327295463\n",
      "    cluster loss:             2949.2875162760415\n",
      "    separation loss:          2.098347783088684\n",
      "    avg separation loss:      5.305042743682861\n",
      "    l1_addon loss:            46.73653030395508\n",
      "    l1 loss:                  0.491934210062027\n",
      "    train time:               0.06315279006958008\n",
      "    test time:                0.012943029403686523\n",
      "    epoch time:               0.0768897533416748\n",
      "    joint lr:                 0.0009861958963236286\n",
      "epoch: 172 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.007234576675626967\n",
      "    train cross_ent loss:     0.00534052365562982\n",
      "    test overall loss:        0.10632409900426865\n",
      "    test cross_ent loss:      0.10443014620492856\n",
      "    cluster loss:             2949.2837727864585\n",
      "    separation loss:          2.093643307685852\n",
      "    avg separation loss:      5.2783487637837725\n",
      "    l1_addon loss:            46.73398971557617\n",
      "    l1 loss:                  0.491934210062027\n",
      "    train time:               0.06098437309265137\n",
      "    test time:                0.012819051742553711\n",
      "    epoch time:               0.07457494735717773\n",
      "    joint lr:                 0.001854667874720785\n",
      "epoch: 173 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.007074249597887198\n",
      "    train cross_ent loss:     0.005180556637545426\n",
      "    test overall loss:        0.10140573947379987\n",
      "    test cross_ent loss:      0.09951209835708141\n",
      "    cluster loss:             2949.2802734375\n",
      "    separation loss:          2.0916577180226645\n",
      "    avg separation loss:      5.306377569834392\n",
      "    l1_addon loss:            46.723670959472656\n",
      "    l1 loss:                  0.491934210062027\n",
      "    train time:               0.06152486801147461\n",
      "    test time:                0.012644290924072266\n",
      "    epoch time:               0.07489562034606934\n",
      "    joint lr:                 0.0027056817939603655\n",
      "epoch: 174 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.005179424175164766\n",
      "    train cross_ent loss:     0.0032865721214976576\n",
      "    test overall loss:        0.1022755466401577\n",
      "    test cross_ent loss:      0.10038412548601627\n",
      "    cluster loss:             2949.2784016927085\n",
      "    separation loss:          2.0842806895573935\n",
      "    avg separation loss:      5.302191416422526\n",
      "    l1_addon loss:            46.64970397949219\n",
      "    l1 loss:                  0.491934210062027\n",
      "    train time:               0.061251163482666016\n",
      "    test time:                0.01264643669128418\n",
      "    epoch time:               0.07463455200195312\n",
      "    joint lr:                 0.003539499968027705\n",
      "epoch: 175 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.005879148168282377\n",
      "    train cross_ent loss:     0.003991322992886934\n",
      "    test overall loss:        0.10172878640393417\n",
      "    test cross_ent loss:      0.09984016635765632\n",
      "    cluster loss:             2949.27685546875\n",
      "    separation loss:          2.077172636985779\n",
      "    avg separation loss:      5.218499183654785\n",
      "    l1_addon loss:            46.55635452270508\n",
      "    l1 loss:                  0.491934210062027\n",
      "    train time:               0.061156511306762695\n",
      "    test time:                0.012673616409301758\n",
      "    epoch time:               0.07456302642822266\n",
      "    joint lr:                 0.00435638121043428\n",
      "epoch: 176 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       0.005723092679141296\n",
      "    train cross_ent loss:     0.003829921130090952\n",
      "    test overall loss:        0.1066327141597867\n",
      "    test cross_ent loss:      0.10473947692662477\n",
      "    cluster loss:             2949.2769368489585\n",
      "    separation loss:          2.0873985290527344\n",
      "    avg separation loss:      5.209245999654134\n",
      "    l1_addon loss:            46.710105895996094\n",
      "    l1 loss:                  0.491934210062027\n",
      "    train time:               0.061736106872558594\n",
      "    test time:                0.012658357620239258\n",
      "    epoch time:               0.07509875297546387\n",
      "    joint lr:                 0.00515658087799592\n",
      "epoch: 177 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.0058568599116471075\n",
      "    train cross_ent loss:     0.003972339152824134\n",
      "    test overall loss:        0.09744765764723222\n",
      "    test cross_ent loss:      0.09556295443326235\n",
      "    cluster loss:             2949.2854817708335\n",
      "    separation loss:          2.105586051940918\n",
      "    avg separation loss:      5.269865194956462\n",
      "    l1_addon loss:            46.425682067871094\n",
      "    l1 loss:                  0.491934210062027\n",
      "    train time:               0.06125664710998535\n",
      "    test time:                0.012699604034423828\n",
      "    epoch time:               0.0747075080871582\n",
      "    joint lr:                 0.005940350914085284\n",
      "epoch: 178 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.004596120212227106\n",
      "    train cross_ent loss:     0.002701889167332815\n",
      "    test overall loss:        0.1069327878455321\n",
      "    test cross_ent loss:      0.10503541988631089\n",
      "    cluster loss:             2949.3092447916665\n",
      "    separation loss:          2.1536264022191367\n",
      "    avg separation loss:      5.297152996063232\n",
      "    l1_addon loss:            46.847999572753906\n",
      "    l1 loss:                  0.491934210062027\n",
      "    train time:               0.06163311004638672\n",
      "    test time:                0.012640714645385742\n",
      "    epoch time:               0.07501816749572754\n",
      "    joint lr:                 0.00670793989136506\n",
      "epoch: 179 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.005683778267767694\n",
      "    train cross_ent loss:     0.003793183520125846\n",
      "    test overall loss:        0.11005588403592508\n",
      "    test cross_ent loss:      0.10817531247933705\n",
      "    cluster loss:             2949.2998046875\n",
      "    separation loss:          2.133994181950887\n",
      "    avg separation loss:      5.2361321449279785\n",
      "    l1_addon loss:            46.287933349609375\n",
      "    l1 loss:                  0.491934210062027\n",
      "    train time:               0.05991768836975098\n",
      "    test time:                0.012700796127319336\n",
      "    epoch time:               0.07337045669555664\n",
      "    joint lr:                 0.007459593054007833\n",
      "epoch: 180 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.016360943464355335\n",
      "    train cross_ent loss:     0.01447867114135685\n",
      "    test overall loss:        0.12814841543634733\n",
      "    test cross_ent loss:      0.12624220053354898\n",
      "    cluster loss:             2949.3722330729165\n",
      "    separation loss:          2.372794429461161\n",
      "    avg separation loss:      5.671728769938151\n",
      "    l1_addon loss:            47.14259338378906\n",
      "    l1 loss:                  0.491934210062027\n",
      "    train time:               0.06191372871398926\n",
      "    test time:                0.012679338455200195\n",
      "    epoch time:               0.07533502578735352\n",
      "    joint lr:                 0.008195552359408614\n",
      "epoch: 181 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.017831762579994068\n",
      "    train cross_ent loss:     0.01594688117297159\n",
      "    test overall loss:        0.10171037788192432\n",
      "    test cross_ent loss:      0.0998233857875069\n",
      "    cluster loss:             2949.3775227864585\n",
      "    separation loss:          2.5526525179545083\n",
      "    avg separation loss:      5.977497895558675\n",
      "    l1_addon loss:            46.5018310546875\n",
      "    l1 loss:                  0.491934210062027\n",
      "    train time:               0.06315350532531738\n",
      "    test time:                0.012529373168945312\n",
      "    epoch time:               0.07645392417907715\n",
      "    joint lr:                 0.007713866994023813\n",
      "epoch: 182 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.013008366701089673\n",
      "    train cross_ent loss:     0.011120284053807458\n",
      "    test overall loss:        0.10839662080009778\n",
      "    test cross_ent loss:      0.1065271186331908\n",
      "    cluster loss:             2949.4259440104165\n",
      "    separation loss:          2.605189005533854\n",
      "    avg separation loss:      5.905081113179524\n",
      "    l1_addon loss:            45.91908264160156\n",
      "    l1 loss:                  0.491934210062027\n",
      "    train time:               0.06129145622253418\n",
      "    test time:                0.012639284133911133\n",
      "    epoch time:               0.07466006278991699\n",
      "    joint lr:                 0.007241005780710745\n",
      "epoch: 183 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.018869879862500563\n",
      "    train cross_ent loss:     0.016997251711371873\n",
      "    test overall loss:        0.10621793754398823\n",
      "    test cross_ent loss:      0.10433630676319201\n",
      "    cluster loss:             2949.4267578125\n",
      "    separation loss:          2.595382293065389\n",
      "    avg separation loss:      6.011038939158122\n",
      "    l1_addon loss:            46.323326110839844\n",
      "    l1 loss:                  0.491934210062027\n",
      "    train time:               0.061539411544799805\n",
      "    test time:                0.012730836868286133\n",
      "    epoch time:               0.07501029968261719\n",
      "    joint lr:                 0.006776840404964548\n",
      "epoch: 184 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.0214902659257253\n",
      "    train cross_ent loss:     0.019608034105557535\n",
      "    test overall loss:        0.11366752162575722\n",
      "    test cross_ent loss:      0.1117905688782533\n",
      "    cluster loss:             2949.4375\n",
      "    separation loss:          2.6161778767903647\n",
      "    avg separation loss:      6.136417865753174\n",
      "    l1_addon loss:            46.16741943359375\n",
      "    l1 loss:                  0.491934210062027\n",
      "    train time:               0.06149482727050781\n",
      "    test time:                0.012962818145751953\n",
      "    epoch time:               0.07522058486938477\n",
      "    joint lr:                 0.006321244236155204\n",
      "epoch: 185 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.00922700009929637\n",
      "    train cross_ent loss:     0.0073459102358255125\n",
      "    test overall loss:        0.09622028407951196\n",
      "    test cross_ent loss:      0.09434199271102746\n",
      "    cluster loss:             2949.4254557291665\n",
      "    separation loss:          2.591792424519857\n",
      "    avg separation loss:      6.033164024353027\n",
      "    l1_addon loss:            46.21189880371094\n",
      "    l1 loss:                  0.491934210062027\n",
      "    train time:               0.06104850769042969\n",
      "    test time:                0.012679338455200195\n",
      "    epoch time:               0.07445907592773438\n",
      "    joint lr:                 0.00587409230668155\n",
      "epoch: 186 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.006677559369968044\n",
      "    train cross_ent loss:     0.004801807828092326\n",
      "    test overall loss:        0.09008261561393738\n",
      "    test cross_ent loss:      0.0882078545788924\n",
      "    cluster loss:             2949.4163411458335\n",
      "    separation loss:          2.5596121152242026\n",
      "    avg separation loss:      5.911599636077881\n",
      "    l1_addon loss:            46.09435272216797\n",
      "    l1 loss:                  0.491934210062027\n",
      "    train time:               0.06155109405517578\n",
      "    test time:                0.012678146362304688\n",
      "    epoch time:               0.074951171875\n",
      "    joint lr:                 0.0054352612913737535\n",
      "epoch: 187 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.007766529296835263\n",
      "    train cross_ent loss:     0.0058916342936249245\n",
      "    test overall loss:        0.09207417163997889\n",
      "    test cross_ent loss:      0.09020754819115002\n",
      "    cluster loss:             2949.4082845052085\n",
      "    separation loss:          2.5374578634897866\n",
      "    avg separation loss:      5.873330275217692\n",
      "    l1_addon loss:            45.822975158691406\n",
      "    l1 loss:                  0.491934210062027\n",
      "    train time:               0.06120157241821289\n",
      "    test time:                0.012660980224609375\n",
      "    epoch time:               0.07455611228942871\n",
      "    joint lr:                 0.005004629487141445\n",
      "epoch: 188 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.008951625243450204\n",
      "    train cross_ent loss:     0.007090833051026695\n",
      "    test overall loss:        0.11387738461295764\n",
      "    test cross_ent loss:      0.11200389048705499\n",
      "    cluster loss:             2949.4019368489585\n",
      "    separation loss:          2.537770907084147\n",
      "    avg separation loss:      5.888501803080241\n",
      "    l1_addon loss:            46.05206298828125\n",
      "    l1 loss:                  0.491934210062027\n",
      "    train time:               0.06155133247375488\n",
      "    test time:                0.012650012969970703\n",
      "    epoch time:               0.07490134239196777\n",
      "    joint lr:                 0.004582076792864645\n",
      "epoch: 189 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.010679739449794093\n",
      "    train cross_ent loss:     0.008798271456422905\n",
      "    test overall loss:        0.09262558290114005\n",
      "    test cross_ent loss:      0.09075411626448233\n",
      "    cluster loss:             2949.3988444010415\n",
      "    separation loss:          2.497644027074178\n",
      "    avg separation loss:      5.827367623647054\n",
      "    l1_addon loss:            45.984413146972656\n",
      "    l1 loss:                  0.491934210062027\n",
      "    train time:               0.06173849105834961\n",
      "    test time:                0.012617826461791992\n",
      "    epoch time:               0.07505226135253906\n",
      "    joint lr:                 0.004167484689524657\n",
      "epoch: 190 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 98.00%\n",
      "    train overall loss:       0.014539940903584162\n",
      "    train cross_ent loss:     0.012683196717666255\n",
      "    test overall loss:        0.09042017720639706\n",
      "    test cross_ent loss:      0.08856515710552533\n",
      "    cluster loss:             2949.410400390625\n",
      "    separation loss:          2.5114336808522544\n",
      "    avg separation loss:      5.767165025075276\n",
      "    l1_addon loss:            45.436256408691406\n",
      "    l1 loss:                  0.491934210062027\n",
      "    train time:               0.06131935119628906\n",
      "    test time:                0.012650489807128906\n",
      "    epoch time:               0.07471489906311035\n",
      "    joint lr:                 0.003760736220572192\n",
      "epoch: 191 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.005121172509259648\n",
      "    train cross_ent loss:     0.003257392362381021\n",
      "    test overall loss:        0.09575266142686208\n",
      "    test cross_ent loss:      0.09388135808209579\n",
      "    cluster loss:             2949.40283203125\n",
      "    separation loss:          2.4660443464914956\n",
      "    avg separation loss:      5.712413946787517\n",
      "    l1_addon loss:            45.9790153503418\n",
      "    l1 loss:                  0.491934210062027\n",
      "    train time:               0.0615847110748291\n",
      "    test time:                0.012665748596191406\n",
      "    epoch time:               0.07499074935913086\n",
      "    joint lr:                 0.0033617159725298235\n",
      "epoch: 192 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.004989943441210521\n",
      "    train cross_ent loss:     0.0031177768380277688\n",
      "    test overall loss:        0.09334654950847228\n",
      "    test cross_ent loss:      0.09147511205325524\n",
      "    cluster loss:             2949.4005533854165\n",
      "    separation loss:          2.460252046585083\n",
      "    avg separation loss:      5.693986892700195\n",
      "    l1_addon loss:            45.98350524902344\n",
      "    l1 loss:                  0.491934210062027\n",
      "    train time:               0.061821699142456055\n",
      "    test time:                0.012642383575439453\n",
      "    epoch time:               0.07520842552185059\n",
      "    joint lr:                 0.002970310055826246\n",
      "epoch: 193 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.004306164311452044\n",
      "    train cross_ent loss:     0.0024361545220017433\n",
      "    test overall loss:        0.08875522141655286\n",
      "    test cross_ent loss:      0.08688704731563728\n",
      "    cluster loss:             2949.39208984375\n",
      "    separation loss:          2.442483822504679\n",
      "    avg separation loss:      5.66303284962972\n",
      "    l1_addon loss:            45.87471008300781\n",
      "    l1 loss:                  0.491934210062027\n",
      "    train time:               0.06122922897338867\n",
      "    test time:                0.012620210647583008\n",
      "    epoch time:               0.07462239265441895\n",
      "    joint lr:                 0.0025864060858594865\n",
      "epoch: 194 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 98.00%\n",
      "    train overall loss:       0.0038415776669151252\n",
      "    train cross_ent loss:     0.001975089719053358\n",
      "    test overall loss:        0.08338055325051148\n",
      "    test cross_ent loss:      0.08151622395962477\n",
      "    cluster loss:             2949.3902994791665\n",
      "    separation loss:          2.4242774645487466\n",
      "    avg separation loss:      5.621354420979817\n",
      "    l1_addon loss:            45.74652862548828\n",
      "    l1 loss:                  0.491934210062027\n",
      "    train time:               0.06170535087585449\n",
      "    test time:                0.01273036003112793\n",
      "    epoch time:               0.07513809204101562\n",
      "    joint lr:                 0.00220989316428648\n",
      "epoch: 195 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 98.00%\n",
      "    train overall loss:       0.003108932688418362\n",
      "    train cross_ent loss:     0.0012446701358486381\n",
      "    test overall loss:        0.08063893144329388\n",
      "    test cross_ent loss:      0.07877440036584933\n",
      "    cluster loss:             2949.3881022135415\n",
      "    separation loss:          2.413194179534912\n",
      "    avg separation loss:      5.612499554951985\n",
      "    l1_addon loss:            45.7533073425293\n",
      "    l1 loss:                  0.491934210062027\n",
      "    train time:               0.06173443794250488\n",
      "    test time:                0.012650012969970703\n",
      "    epoch time:               0.07511448860168457\n",
      "    joint lr:                 0.0018406618605363474\n",
      "epoch: 196 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 98.33%\n",
      "    train overall loss:       0.003467600689166122\n",
      "    train cross_ent loss:     0.001601851632585749\n",
      "    test overall loss:        0.07950795566042264\n",
      "    test cross_ent loss:      0.07764095130066077\n",
      "    cluster loss:             2949.3883463541665\n",
      "    separation loss:          2.410660982131958\n",
      "    avg separation loss:      5.619848410288493\n",
      "    l1_addon loss:            45.83570861816406\n",
      "    l1 loss:                  0.491934210062027\n",
      "    train time:               0.061290740966796875\n",
      "    test time:                0.012674570083618164\n",
      "    epoch time:               0.07471704483032227\n",
      "    joint lr:                 0.001478604193544789\n",
      "epoch: 197 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 98.33%\n",
      "    train overall loss:       0.0028397239641182953\n",
      "    train cross_ent loss:     0.0009729435065916429\n",
      "    test overall loss:        0.08024310941497485\n",
      "    test cross_ent loss:      0.07837633478144805\n",
      "    cluster loss:             2949.3866373697915\n",
      "    separation loss:          2.4086341857910156\n",
      "    avg separation loss:      5.610240459442139\n",
      "    l1_addon loss:            45.82813262939453\n",
      "    l1 loss:                  0.491934210062027\n",
      "    train time:               0.06161141395568848\n",
      "    test time:                0.012618303298950195\n",
      "    epoch time:               0.0749216079711914\n",
      "    joint lr:                 0.0011236136137069992\n",
      "epoch: 198 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 98.00%\n",
      "    train overall loss:       0.002620257954630587\n",
      "    train cross_ent loss:     0.0007534733514249739\n",
      "    test overall loss:        0.08082604718705018\n",
      "    test cross_ent loss:      0.0789593926941355\n",
      "    cluster loss:             2949.3846028645835\n",
      "    separation loss:          2.403717597325643\n",
      "    avg separation loss:      5.594569206237793\n",
      "    l1_addon loss:            45.824073791503906\n",
      "    l1 loss:                  0.491934210062027\n",
      "    train time:               0.06124258041381836\n",
      "    test time:                0.012675762176513672\n",
      "    epoch time:               0.07465457916259766\n",
      "    joint lr:                 0.0007755849850466195\n",
      "epoch: 199 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.0031989371507532066\n",
      "    train cross_ent loss:     0.0013326116572392897\n",
      "    test overall loss:        0.08089145769675572\n",
      "    test cross_ent loss:      0.07902544333289067\n",
      "    cluster loss:             2949.3828938802085\n",
      "    separation loss:          2.406113386154175\n",
      "    avg separation loss:      5.601375420888265\n",
      "    l1_addon loss:            45.802757263183594\n",
      "    l1 loss:                  0.491934210062027\n",
      "    train time:               0.06051445007324219\n",
      "    test time:                0.012671470642089844\n",
      "    epoch time:               0.07391905784606934\n",
      "    joint lr:                 0.0004344145675980766\n",
      "epoch: 200 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 98.00%\n",
      "    train overall loss:       0.0026314699918859536\n",
      "    train cross_ent loss:     0.0007655552213287188\n",
      "    test overall loss:        0.07932104667027791\n",
      "    test cross_ent loss:      0.07745516688252489\n",
      "    cluster loss:             2949.3837890625\n",
      "    separation loss:          2.401590585708618\n",
      "    avg separation loss:      5.60290543238322\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  0.491934210062027\n",
      "    train time:               0.06127667427062988\n",
      "    test time:                0.013507604598999023\n",
      "    epoch time:               0.07567143440246582\n",
      "    joint lr:                 0.0001\n",
      "epoch: 200 (PUSH) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.0026314699918859536\n",
      "    train cross_ent loss:     0.0007655552213287188\n",
      "    test overall loss:        0.10442345154782136\n",
      "    test cross_ent loss:      0.10255757191528876\n",
      "    cluster loss:             2949.2876790364585\n",
      "    separation loss:          2.0496192375818887\n",
      "    avg separation loss:      5.150289217631022\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  0.491934210062027\n",
      "    train time:               0.06127667427062988\n",
      "    test time:                0.012825965881347656\n",
      "    epoch time:               0.3908247947692871\n",
      "epoch: 200 (1/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.008475230385859808\n",
      "    train cross_ent loss:     0.006784060581897696\n",
      "    test overall loss:        0.10502827074378729\n",
      "    test cross_ent loss:      0.10342990979552269\n",
      "    cluster loss:             2949.2888997395835\n",
      "    separation loss:          2.0520593325297036\n",
      "    avg separation loss:      5.1543935139973955\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  0.2244185507297516\n",
      "    train time:               0.025056838989257812\n",
      "    test time:                0.012603521347045898\n",
      "    epoch time:               0.038179874420166016\n",
      "    last layer lr:            0.0007600000000000095\n",
      "epoch: 200 (2/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.007233827012694544\n",
      "    train cross_ent loss:     0.0052050922014233135\n",
      "    test overall loss:        0.10570843797177076\n",
      "    test cross_ent loss:      0.1036873950312535\n",
      "    cluster loss:             2949.2881673177085\n",
      "    separation loss:          2.048472762107849\n",
      "    avg separation loss:      5.144074598948161\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  0.6470921635627747\n",
      "    train time:               0.024738073348999023\n",
      "    test time:                0.01260685920715332\n",
      "    epoch time:               0.03786301612854004\n",
      "    last layer lr:            0.0014199999999999955\n",
      "epoch: 200 (3/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.007066668787350257\n",
      "    train cross_ent loss:     0.004749675488306416\n",
      "    test overall loss:        0.10589533454428117\n",
      "    test cross_ent loss:      0.10353312982867162\n",
      "    cluster loss:             2949.2884114583335\n",
      "    separation loss:          2.0485567251841226\n",
      "    avg separation loss:      5.138546625773112\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  0.9882531762123108\n",
      "    train time:               0.024766921997070312\n",
      "    test time:                0.012901067733764648\n",
      "    epoch time:               0.038184165954589844\n",
      "    last layer lr:            0.0020800000000000046\n",
      "epoch: 200 (4/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.008176025313635668\n",
      "    train cross_ent loss:     0.005540592052663366\n",
      "    test overall loss:        0.10674833785742521\n",
      "    test cross_ent loss:      0.10389600414782763\n",
      "    cluster loss:             2949.2882486979165\n",
      "    separation loss:          2.0479180415471396\n",
      "    avg separation loss:      5.125454266866048\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  1.478381872177124\n",
      "    train time:               0.024884700775146484\n",
      "    test time:                0.012667655944824219\n",
      "    epoch time:               0.038068294525146484\n",
      "    last layer lr:            0.0027399999999999907\n",
      "epoch: 200 (5/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.007504162223388751\n",
      "    train cross_ent loss:     0.004274794896547165\n",
      "    test overall loss:        0.10530445165932178\n",
      "    test cross_ent loss:      0.10203361790627241\n",
      "    cluster loss:             2949.2879231770835\n",
      "    separation loss:          2.047512491544088\n",
      "    avg separation loss:      5.129276116689046\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  1.8968839645385742\n",
      "    train time:               0.02447676658630371\n",
      "    test time:                0.01261448860168457\n",
      "    epoch time:               0.037604570388793945\n",
      "    last layer lr:            0.0034\n",
      "epoch: 200 (6/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.009340015033053027\n",
      "    train cross_ent loss:     0.005774589300724781\n",
      "    test overall loss:        0.10597873385995626\n",
      "    test cross_ent loss:      0.10210821808626254\n",
      "    cluster loss:             2949.28857421875\n",
      "    separation loss:          2.047611435254415\n",
      "    avg separation loss:      5.131243387858073\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  2.496565818786621\n",
      "    train time:               0.024263381958007812\n",
      "    test time:                0.012864828109741211\n",
      "    epoch time:               0.03764510154724121\n",
      "    last layer lr:            0.00406000000000001\n",
      "epoch: 200 (7/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.008352784336441092\n",
      "    train cross_ent loss:     0.004316526180547144\n",
      "    test overall loss:        0.10543684661388397\n",
      "    test cross_ent loss:      0.10137663750598828\n",
      "    cluster loss:             2949.2880859375\n",
      "    separation loss:          2.0466479063034058\n",
      "    avg separation loss:      5.124228477478027\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  2.6862621307373047\n",
      "    train time:               0.024386882781982422\n",
      "    test time:                0.012607574462890625\n",
      "    epoch time:               0.03750920295715332\n",
      "    last layer lr:            0.004719999999999996\n",
      "epoch: 200 (8/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.0084630794202288\n",
      "    train cross_ent loss:     0.004069276464482148\n",
      "    test overall loss:        0.10584390442818403\n",
      "    test cross_ent loss:      0.10133625753223896\n",
      "    cluster loss:             2949.2884928385415\n",
      "    separation loss:          2.049981196721395\n",
      "    avg separation loss:      5.129509290059407\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  3.1337013244628906\n",
      "    train time:               0.02425670623779297\n",
      "    test time:                0.012618064880371094\n",
      "    epoch time:               0.03739023208618164\n",
      "    last layer lr:            0.0053800000000000054\n",
      "epoch: 200 (9/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.01732168470819791\n",
      "    train cross_ent loss:     0.012501200350622335\n",
      "    test overall loss:        0.10721538588404655\n",
      "    test cross_ent loss:      0.10060432211806376\n",
      "    cluster loss:             2949.2884114583335\n",
      "    separation loss:          2.052578250567118\n",
      "    avg separation loss:      5.125552972157796\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  5.237114906311035\n",
      "    train time:               0.02425408363342285\n",
      "    test time:                0.012807130813598633\n",
      "    epoch time:               0.037578582763671875\n",
      "    last layer lr:            0.0060399999999999916\n",
      "epoch: 200 (10/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.014338828830255402\n",
      "    train cross_ent loss:     0.004853876255866554\n",
      "    test overall loss:        0.11064872580269973\n",
      "    test cross_ent loss:      0.10103307881702979\n",
      "    cluster loss:             2949.2880045572915\n",
      "    separation loss:          2.051279385884603\n",
      "    avg separation loss:      5.136953512827556\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  8.241703033447266\n",
      "    train time:               0.02345418930053711\n",
      "    test time:                0.012081384658813477\n",
      "    epoch time:               0.03602027893066406\n",
      "    last layer lr:            0.0067\n",
      "epoch: 200 (11/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.014469857431120343\n",
      "    train cross_ent loss:     0.005737649380332894\n",
      "    test overall loss:        0.105402372777462\n",
      "    test cross_ent loss:      0.09742964028070371\n",
      "    cluster loss:             2949.2880859375\n",
      "    separation loss:          2.0518783728281655\n",
      "    avg separation loss:      5.129787445068359\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  6.598784446716309\n",
      "    train time:               0.022947311401367188\n",
      "    test time:                0.012064218521118164\n",
      "    epoch time:               0.03548932075500488\n",
      "    last layer lr:            0.007360000000000011\n",
      "epoch: 200 (12/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.012183996745281749\n",
      "    train cross_ent loss:     0.004426347324624658\n",
      "    test overall loss:        0.104054086531202\n",
      "    test cross_ent loss:      0.09701597193876903\n",
      "    cluster loss:             2949.2884928385415\n",
      "    separation loss:          2.052718162536621\n",
      "    avg separation loss:      5.1345295906066895\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  5.664163112640381\n",
      "    train time:               0.023085594177246094\n",
      "    test time:                0.01234889030456543\n",
      "    epoch time:               0.035916805267333984\n",
      "    last layer lr:            0.008019999999999994\n",
      "epoch: 200 (13/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.012053201492461894\n",
      "    train cross_ent loss:     0.004687453749486142\n",
      "    test overall loss:        0.10153847684462865\n",
      "    test cross_ent loss:      0.09439980455984671\n",
      "    cluster loss:             2949.2890625\n",
      "    separation loss:          2.052393317222595\n",
      "    avg separation loss:      5.136615753173828\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  5.7647294998168945\n",
      "    train time:               0.02323174476623535\n",
      "    test time:                0.012065649032592773\n",
      "    epoch time:               0.03577852249145508\n",
      "    last layer lr:            0.008680000000000005\n",
      "epoch: 200 (14/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.012036287329263158\n",
      "    train cross_ent loss:     0.004566437176739176\n",
      "    test overall loss:        0.10177206558485825\n",
      "    test cross_ent loss:      0.09426028685023387\n",
      "    cluster loss:             2949.2887369791665\n",
      "    separation loss:          2.0506752332051597\n",
      "    avg separation loss:      5.128489176432292\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  6.137828826904297\n",
      "    train time:               0.02294754981994629\n",
      "    test time:                0.012058019638061523\n",
      "    epoch time:               0.03549027442932129\n",
      "    last layer lr:            0.00933999999999999\n",
      "epoch: 200 (15/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.011031051269835897\n",
      "    train cross_ent loss:     0.0032272847731494242\n",
      "    test overall loss:        0.10059380593399207\n",
      "    test cross_ent loss:      0.0928100785240531\n",
      "    cluster loss:             2949.2881673177085\n",
      "    separation loss:          2.0494466622670493\n",
      "    avg separation loss:      5.136733849843343\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  6.409782409667969\n",
      "    train time:               0.022957563400268555\n",
      "    test time:                0.012158632278442383\n",
      "    epoch time:               0.03559303283691406\n",
      "    last layer lr:            0.01\n",
      "epoch: 200 (16/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.012035357765853405\n",
      "    train cross_ent loss:     0.0038760235507248175\n",
      "    test overall loss:        0.10080372355878353\n",
      "    test cross_ent loss:      0.09257971371213596\n",
      "    cluster loss:             2949.288330078125\n",
      "    separation loss:          2.052249471346537\n",
      "    avg separation loss:      5.152291774749756\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  6.8500590324401855\n",
      "    train time:               0.023897409439086914\n",
      "    test time:                0.012394189834594727\n",
      "    epoch time:               0.03677511215209961\n",
      "    last layer lr:            0.009603999999999994\n",
      "epoch: 200 (17/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 98.33%\n",
      "    train overall loss:       0.011670772089726396\n",
      "    train cross_ent loss:     0.0034720039628963503\n",
      "    test overall loss:        0.0996680265913407\n",
      "    test cross_ent loss:      0.0915098466599981\n",
      "    cluster loss:             2949.2880045572915\n",
      "    separation loss:          2.0480541388193765\n",
      "    avg separation loss:      5.144192377726237\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  6.784236431121826\n",
      "    train time:               0.023633480072021484\n",
      "    test time:                0.012397289276123047\n",
      "    epoch time:               0.03650927543640137\n",
      "    last layer lr:            0.009208000000000003\n",
      "epoch: 200 (18/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 98.00%\n",
      "    train overall loss:       0.012045297875172563\n",
      "    train cross_ent loss:     0.00401134315567712\n",
      "    test overall loss:        0.09873990031580131\n",
      "    test cross_ent loss:      0.09043961297720671\n",
      "    cluster loss:             2949.287841796875\n",
      "    separation loss:          2.046337366104126\n",
      "    avg separation loss:      5.145979245503743\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  6.926341533660889\n",
      "    train time:               0.02370166778564453\n",
      "    test time:                0.012769460678100586\n",
      "    epoch time:               0.03695106506347656\n",
      "    last layer lr:            0.008811999999999997\n",
      "epoch: 200 (19/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 98.33%\n",
      "    train overall loss:       0.011553820843497912\n",
      "    train cross_ent loss:     0.0034115810800964632\n",
      "    test overall loss:        0.0984802848349015\n",
      "    test cross_ent loss:      0.090746003203094\n",
      "    cluster loss:             2949.2884928385415\n",
      "    separation loss:          2.048002004623413\n",
      "    avg separation loss:      5.147179126739502\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  6.360335350036621\n",
      "    train time:               0.023861408233642578\n",
      "    test time:                0.012413740158081055\n",
      "    epoch time:               0.036750078201293945\n",
      "    last layer lr:            0.008416000000000005\n",
      "epoch: 200 (20/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 98.33%\n",
      "    train overall loss:       0.011243930293454064\n",
      "    train cross_ent loss:     0.00366707902867347\n",
      "    test overall loss:        0.09710055962204933\n",
      "    test cross_ent loss:      0.08964456990361214\n",
      "    cluster loss:             2949.2880045572915\n",
      "    separation loss:          2.0482800801595054\n",
      "    avg separation loss:      5.156720320383708\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  6.082040786743164\n",
      "    train time:               0.023381471633911133\n",
      "    test time:                0.01239776611328125\n",
      "    epoch time:               0.03625082969665527\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 200 (21/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 98.33%\n",
      "    train overall loss:       0.010856774842573537\n",
      "    train cross_ent loss:     0.003654187920296358\n",
      "    test overall loss:        0.09637877593437831\n",
      "    test cross_ent loss:      0.0892870103319486\n",
      "    cluster loss:             2949.2884928385415\n",
      "    separation loss:          2.049714287122091\n",
      "    avg separation loss:      5.158937136332194\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  5.7178192138671875\n",
      "    train time:               0.023430585861206055\n",
      "    test time:                0.012424945831298828\n",
      "    epoch time:               0.036329030990600586\n",
      "    last layer lr:            0.007623999999999995\n",
      "epoch: 200 (22/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.01127486251708534\n",
      "    train cross_ent loss:     0.004369667252629167\n",
      "    test overall loss:        0.09676825441420078\n",
      "    test cross_ent loss:      0.08976752652476232\n",
      "    cluster loss:             2949.2882486979165\n",
      "    separation loss:          2.0506563584009805\n",
      "    avg separation loss:      5.150625705718994\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  5.626776695251465\n",
      "    train time:               0.023517608642578125\n",
      "    test time:                0.012378692626953125\n",
      "    epoch time:               0.03636622428894043\n",
      "    last layer lr:            0.0072280000000000035\n",
      "epoch: 200 (23/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.010563482323454486\n",
      "    train cross_ent loss:     0.003890513468326794\n",
      "    test overall loss:        0.0971888592466712\n",
      "    test cross_ent loss:      0.09059657187511523\n",
      "    cluster loss:             2949.2881673177085\n",
      "    separation loss:          2.0538652737935386\n",
      "    avg separation loss:      5.149080594380696\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  5.218337535858154\n",
      "    train time:               0.02335500717163086\n",
      "    test time:                0.012406349182128906\n",
      "    epoch time:               0.03623175621032715\n",
      "    last layer lr:            0.006831999999999998\n",
      "epoch: 200 (24/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.010876246934963597\n",
      "    train cross_ent loss:     0.004478130774158571\n",
      "    test overall loss:        0.09662698612858851\n",
      "    test cross_ent loss:      0.09023500109712283\n",
      "    cluster loss:             2949.28857421875\n",
      "    separation loss:          2.053705851236979\n",
      "    avg separation loss:      5.140738328297933\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  5.018033027648926\n",
      "    train time:               0.02339768409729004\n",
      "    test time:                0.012432575225830078\n",
      "    epoch time:               0.03630638122558594\n",
      "    last layer lr:            0.006436000000000007\n",
      "epoch: 200 (25/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.0118006132543087\n",
      "    train cross_ent loss:     0.005565817855919401\n",
      "    test overall loss:        0.09594331278155248\n",
      "    test cross_ent loss:      0.0897571820144852\n",
      "    cluster loss:             2949.288818359375\n",
      "    separation loss:          2.0514766375223794\n",
      "    avg separation loss:      5.146526336669922\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  4.8121819496154785\n",
      "    train time:               0.023441314697265625\n",
      "    test time:                0.012404680252075195\n",
      "    epoch time:               0.036318063735961914\n",
      "    last layer lr:            0.00604\n",
      "epoch: 200 (26/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.009012866454819838\n",
      "    train cross_ent loss:     0.0030541789148830706\n",
      "    test overall loss:        0.0949404425919056\n",
      "    test cross_ent loss:      0.08918225392699242\n",
      "    cluster loss:             2949.2884114583335\n",
      "    separation loss:          2.0513028701146445\n",
      "    avg separation loss:      5.139182726542155\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  4.384240627288818\n",
      "    train time:               0.023339033126831055\n",
      "    test time:                0.012452363967895508\n",
      "    epoch time:               0.03626513481140137\n",
      "    last layer lr:            0.0056439999999999945\n",
      "epoch: 200 (27/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.009913336537364457\n",
      "    train cross_ent loss:     0.004279249981563125\n",
      "    test overall loss:        0.09456502925604582\n",
      "    test cross_ent loss:      0.0889705481628577\n",
      "    cluster loss:             2949.2881673177085\n",
      "    separation loss:          2.0479408899943032\n",
      "    avg separation loss:      5.144694805145264\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  4.220534324645996\n",
      "    train time:               0.023384571075439453\n",
      "    test time:                0.012491464614868164\n",
      "    epoch time:               0.036347389221191406\n",
      "    last layer lr:            0.005248000000000003\n",
      "epoch: 200 (28/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.008351389163484177\n",
      "    train cross_ent loss:     0.0030299725347302025\n",
      "    test overall loss:        0.09410636406391859\n",
      "    test cross_ent loss:      0.0889325567210714\n",
      "    cluster loss:             2949.2880859375\n",
      "    separation loss:          2.0518835385640464\n",
      "    avg separation loss:      5.152356147766113\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  3.7998623847961426\n",
      "    train time:               0.023572206497192383\n",
      "    test time:                0.012428045272827148\n",
      "    epoch time:               0.03647756576538086\n",
      "    last layer lr:            0.004851999999999998\n",
      "epoch: 200 (29/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.008044971515321069\n",
      "    train cross_ent loss:     0.003094780161821594\n",
      "    test overall loss:        0.09276832484950621\n",
      "    test cross_ent loss:      0.0879404665902257\n",
      "    cluster loss:             2949.288330078125\n",
      "    separation loss:          2.0483354330062866\n",
      "    avg separation loss:      5.141456127166748\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  3.453913450241089\n",
      "    train time:               0.023416519165039062\n",
      "    test time:                0.012404203414916992\n",
      "    epoch time:               0.03629660606384277\n",
      "    last layer lr:            0.004456000000000006\n",
      "epoch: 200 (30/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.007828211980975337\n",
      "    train cross_ent loss:     0.0031218764229884576\n",
      "    test overall loss:        0.0920965156207482\n",
      "    test cross_ent loss:      0.08751676635195811\n",
      "    cluster loss:             2949.2884114583335\n",
      "    separation loss:          2.0508601665496826\n",
      "    avg separation loss:      5.140136241912842\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  3.2058019638061523\n",
      "    train time:               0.023408174514770508\n",
      "    test time:                0.012440919876098633\n",
      "    epoch time:               0.036319732666015625\n",
      "    last layer lr:            0.004060000000000001\n",
      "epoch: 200 (31/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.009018398666133484\n",
      "    train cross_ent loss:     0.004493124162157376\n",
      "    test overall loss:        0.09172596751401822\n",
      "    test cross_ent loss:      0.08734375952432553\n",
      "    cluster loss:             2949.2884114583335\n",
      "    separation loss:          2.0497865279515586\n",
      "    avg separation loss:      5.144410928090413\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  3.0082602500915527\n",
      "    train time:               0.023395538330078125\n",
      "    test time:                0.012387752532958984\n",
      "    epoch time:               0.036255598068237305\n",
      "    last layer lr:            0.0036639999999999945\n",
      "epoch: 200 (32/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.00688135696368085\n",
      "    train cross_ent loss:     0.0026704075409927303\n",
      "    test overall loss:        0.0915786549448967\n",
      "    test cross_ent loss:      0.0875862759227554\n",
      "    cluster loss:             2949.28857421875\n",
      "    separation loss:          2.0505522092183432\n",
      "    avg separation loss:      5.136267185211182\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  2.61843204498291\n",
      "    train time:               0.023389339447021484\n",
      "    test time:                0.012416601181030273\n",
      "    epoch time:               0.03630185127258301\n",
      "    last layer lr:            0.003268000000000003\n",
      "epoch: 200 (33/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.006735596805810928\n",
      "    train cross_ent loss:     0.0028616406101112566\n",
      "    test overall loss:        0.09141180509080489\n",
      "    test cross_ent loss:      0.08758180883402626\n",
      "    cluster loss:             2949.287841796875\n",
      "    separation loss:          2.05092720190684\n",
      "    avg separation loss:      5.141842365264893\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  2.456047534942627\n",
      "    train time:               0.02341318130493164\n",
      "    test time:                0.012809514999389648\n",
      "    epoch time:               0.03670001029968262\n",
      "    last layer lr:            0.002871999999999997\n",
      "epoch: 200 (34/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.0072076293225917555\n",
      "    train cross_ent loss:     0.003577393440840145\n",
      "    test overall loss:        0.09109004586935043\n",
      "    test cross_ent loss:      0.08756221489359935\n",
      "    cluster loss:             2949.2884114583335\n",
      "    separation loss:          2.051105539004008\n",
      "    avg separation loss:      5.134002526601155\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  2.1538825035095215\n",
      "    train time:               0.023500442504882812\n",
      "    test time:                0.012386083602905273\n",
      "    epoch time:               0.03636932373046875\n",
      "    last layer lr:            0.0024760000000000055\n",
      "epoch: 200 (35/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.007016710730062591\n",
      "    train cross_ent loss:     0.0037008956973699648\n",
      "    test overall loss:        0.09078897008051474\n",
      "    test cross_ent loss:      0.08755061930666368\n",
      "    cluster loss:             2949.2877604166665\n",
      "    separation loss:          2.048299551010132\n",
      "    avg separation loss:      5.126139163970947\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  1.8644044399261475\n",
      "    train time:               0.02602076530456543\n",
      "    test time:                0.013297796249389648\n",
      "    epoch time:               0.03987622261047363\n",
      "    last layer lr:            0.0020800000000000003\n",
      "epoch: 200 (36/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.006366300034440226\n",
      "    train cross_ent loss:     0.00330224779382762\n",
      "    test overall loss:        0.09103959488372008\n",
      "    test cross_ent loss:      0.08804480374480288\n",
      "    cluster loss:             2949.2880045572915\n",
      "    separation loss:          2.0472038984298706\n",
      "    avg separation loss:      5.121310551961263\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  1.6208447217941284\n",
      "    train time:               0.02500462532043457\n",
      "    test time:                0.012959480285644531\n",
      "    epoch time:               0.03848457336425781\n",
      "    last layer lr:            0.0016839999999999945\n",
      "epoch: 200 (37/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.005443167614026202\n",
      "    train cross_ent loss:     0.0026571182016697195\n",
      "    test overall loss:        0.09048872844626506\n",
      "    test cross_ent loss:      0.08781681209802628\n",
      "    cluster loss:             2949.2881673177085\n",
      "    separation loss:          2.0478230317433677\n",
      "    avg separation loss:      5.131793975830078\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  1.2979695796966553\n",
      "    train time:               0.02509284019470215\n",
      "    test time:                0.013064146041870117\n",
      "    epoch time:               0.038681745529174805\n",
      "    last layer lr:            0.001288000000000003\n",
      "epoch: 200 (38/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 98.00%\n",
      "    train overall loss:       0.006093089623997609\n",
      "    train cross_ent loss:     0.0035829354310408235\n",
      "    test overall loss:        0.08910454933842023\n",
      "    test cross_ent loss:      0.08669661544263363\n",
      "    cluster loss:             2949.28857421875\n",
      "    separation loss:          2.05120841662089\n",
      "    avg separation loss:      5.154640515645345\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  1.0339847803115845\n",
      "    train time:               0.025408267974853516\n",
      "    test time:                0.01294255256652832\n",
      "    epoch time:               0.03887581825256348\n",
      "    last layer lr:            0.0008919999999999973\n",
      "epoch: 200 (39/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.004847587034520175\n",
      "    train cross_ent loss:     0.0026164992143296534\n",
      "    test overall loss:        0.08922436460852623\n",
      "    test cross_ent loss:      0.08708762718985479\n",
      "    cluster loss:             2949.2880859375\n",
      "    separation loss:          2.052569111188253\n",
      "    avg separation loss:      5.151018778483073\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  0.7627905607223511\n",
      "    train time:               0.025740861892700195\n",
      "    test time:                0.012951850891113281\n",
      "    epoch time:               0.03922152519226074\n",
      "    last layer lr:            0.0004960000000000057\n",
      "epoch: 200 (40/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.005773099501513773\n",
      "    train cross_ent loss:     0.0038266131757862037\n",
      "    test overall loss:        0.08983286966880162\n",
      "    test cross_ent loss:      0.08798443557073672\n",
      "    cluster loss:             2949.288818359375\n",
      "    separation loss:          2.0529688199361167\n",
      "    avg separation loss:      5.130539576212565\n",
      "    l1_addon loss:            45.79825973510742\n",
      "    l1 loss:                  0.4744885265827179\n",
      "    train time:               0.025697708129882812\n",
      "    test time:                0.012930870056152344\n",
      "    epoch time:               0.03914594650268555\n",
      "    last layer lr:            0.0001\n",
      "Finished training in 31.07 seconds\n",
      "Last epoch test accu: 97.67%\n",
      "Done in 200 epochs, 42.27s\n",
      "Training for ArticularyWordRecognition, proto len 144, reception 0.25, features_lr 0.001, protos per class 10, l1_addon 3e-05\n",
      "Params: {\n",
      "    \"protos_per_class\": 10,\n",
      "    \"proto_features\": 32,\n",
      "    \"proto_len_latent\": 144,\n",
      "    \"features_lr\": 0.001,\n",
      "    \"num_classes\": 25,\n",
      "    \"coeffs\": {\n",
      "        \"crs_ent\": 1,\n",
      "        \"clst\": 0,\n",
      "        \"sep\": 0,\n",
      "        \"l1\": 0.001,\n",
      "        \"l1_addon\": 3e-05\n",
      "    },\n",
      "    \"num_warm_epochs\": 50,\n",
      "    \"push_start_epoch\": 110,\n",
      "    \"num_last_layer_epochs\": 40,\n",
      "    \"epochs\": 200\n",
      "}\n",
      "Training encoder\n",
      "epoch:   10/300 mse loss: 0.0409\n",
      "epoch:   20/300 mse loss: 0.0307\n",
      "epoch:   30/300 mse loss: 0.0347\n",
      "epoch:   40/300 mse loss: 0.0474\n",
      "epoch:   50/300 mse loss: 0.0520\n",
      "epoch:   60/300 mse loss: 0.0603\n",
      "epoch:   70/300 mse loss: 0.0611\n",
      "epoch:   80/300 mse loss: 0.0662\n",
      "epoch:   90/300 mse loss: 0.0739\n",
      "epoch:  100/300 mse loss: 0.0769\n",
      "epoch:  110/300 mse loss: 0.0757\n",
      "epoch:  120/300 mse loss: 0.0757\n",
      "epoch:  130/300 mse loss: 0.0769\n",
      "epoch:  140/300 mse loss: 0.0756\n",
      "epoch:  150/300 mse loss: 0.0758\n",
      "epoch:  160/300 mse loss: 0.0763\n",
      "epoch:  170/300 mse loss: 0.0753\n",
      "epoch:  180/300 mse loss: 0.0745\n",
      "epoch:  190/300 mse loss: 0.0760\n",
      "epoch:  200/300 mse loss: 0.0754\n",
      "epoch:  210/300 mse loss: 0.0748\n",
      "epoch:  220/300 mse loss: 0.0747\n",
      "epoch:  230/300 mse loss: 0.0743\n",
      "epoch:  240/300 mse loss: 0.0742\n",
      "epoch:  250/300 mse loss: 0.0747\n",
      "epoch:  260/300 mse loss: 0.0748\n",
      "epoch:  270/300 mse loss: 0.0750\n",
      "epoch:  280/300 mse loss: 0.0749\n",
      "epoch:  290/300 mse loss: 0.0747\n",
      "epoch:  300/300 mse loss: 0.0747\n",
      "Training ProtoTSNet\n",
      "Starting training\n",
      "epoch:   1 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 6.33%\n",
      "    train overall loss:       6.224549293518066\n",
      "    train cross_ent loss:     3.218854930665758\n",
      "    test overall loss:        6.224115530649821\n",
      "    test cross_ent loss:      3.218851407368978\n",
      "    cluster loss:             3415.3412272135415\n",
      "    separation loss:          1286.0068766276042\n",
      "    avg separation loss:      1305.83740234375\n",
      "    l1_addon loss:            175.46670532226562\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04309558868408203\n",
      "    test time:                0.012879610061645508\n",
      "    epoch time:               0.05661821365356445\n",
      "epoch:   2 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 6.33%\n",
      "    train overall loss:       6.223688019646539\n",
      "    train cross_ent loss:     3.2187455230289035\n",
      "    test overall loss:        6.2233710289001465\n",
      "    test cross_ent loss:      3.2188207308451333\n",
      "    cluster loss:             3408.46875\n",
      "    separation loss:          1264.1571451822917\n",
      "    avg separation loss:      1297.1629638671875\n",
      "    l1_addon loss:            151.6636199951172\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05228877067565918\n",
      "    test time:                0.012626409530639648\n",
      "    epoch time:               0.06557059288024902\n",
      "epoch:   3 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 8.33%\n",
      "    train overall loss:       6.22287983364529\n",
      "    train cross_ent loss:     3.2186212804582386\n",
      "    test overall loss:        6.222657362620036\n",
      "    test cross_ent loss:      3.2187489668528237\n",
      "    cluster loss:             3395.6962890625\n",
      "    separation loss:          1233.86669921875\n",
      "    avg separation loss:      1274.6340738932292\n",
      "    l1_addon loss:            130.26597595214844\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04219818115234375\n",
      "    test time:                0.012614250183105469\n",
      "    epoch time:               0.055472612380981445\n",
      "epoch:   4 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 17.33%\n",
      "    train overall loss:       6.2221677038404675\n",
      "    train cross_ent loss:     3.2185162703196206\n",
      "    test overall loss:        6.221965154012044\n",
      "    test cross_ent loss:      3.2186211744944253\n",
      "    cluster loss:             3380.44384765625\n",
      "    separation loss:          1200.8887125651042\n",
      "    avg separation loss:      1248.1363118489583\n",
      "    l1_addon loss:            111.46060943603516\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.048920392990112305\n",
      "    test time:                0.012614011764526367\n",
      "    epoch time:               0.06219649314880371\n",
      "epoch:   5 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 24.33%\n",
      "    train overall loss:       6.22150993347168\n",
      "    train cross_ent loss:     3.2183867030673556\n",
      "    test overall loss:        6.221323013305664\n",
      "    test cross_ent loss:      3.218461831410726\n",
      "    cluster loss:             3365.0369466145835\n",
      "    separation loss:          1162.9759521484375\n",
      "    avg separation loss:      1228.8365478515625\n",
      "    l1_addon loss:            95.36409759521484\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04231071472167969\n",
      "    test time:                0.024250268936157227\n",
      "    epoch time:               0.06722736358642578\n",
      "epoch:   6 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 32.33%\n",
      "    train overall loss:       6.220926761627197\n",
      "    train cross_ent loss:     3.218250274658203\n",
      "    test overall loss:        6.220747470855713\n",
      "    test cross_ent loss:      3.218282461166382\n",
      "    cluster loss:             3346.1878255208335\n",
      "    separation loss:          1111.7039388020833\n",
      "    avg separation loss:      1199.3146565755208\n",
      "    l1_addon loss:            82.15327453613281\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04206418991088867\n",
      "    test time:                0.012648582458496094\n",
      "    epoch time:               0.05537271499633789\n",
      "epoch:   7 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 37.67%\n",
      "    train overall loss:       6.220392386118571\n",
      "    train cross_ent loss:     3.218065367804633\n",
      "    test overall loss:        6.22019640604655\n",
      "    test cross_ent loss:      3.2180240154266357\n",
      "    cluster loss:             3319.8872884114585\n",
      "    separation loss:          1039.8235270182292\n",
      "    avg separation loss:      1147.3401692708333\n",
      "    l1_addon loss:            72.39929962158203\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04617142677307129\n",
      "    test time:                0.01259613037109375\n",
      "    epoch time:               0.05942821502685547\n",
      "epoch:   8 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 45.00%\n",
      "    train overall loss:       6.219818698035346\n",
      "    train cross_ent loss:     3.2177411715189614\n",
      "    test overall loss:        6.219629128774007\n",
      "    test cross_ent loss:      3.2176437377929688\n",
      "    cluster loss:             3287.2708333333335\n",
      "    separation loss:          958.5705973307291\n",
      "    avg separation loss:      1080.1763509114583\n",
      "    l1_addon loss:            66.16334533691406\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.042404890060424805\n",
      "    test time:                0.012627363204956055\n",
      "    epoch time:               0.055692434310913086\n",
      "epoch:   9 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 54.33%\n",
      "    train overall loss:       6.2191847165425616\n",
      "    train cross_ent loss:     3.2172372341156006\n",
      "    test overall loss:        6.218954245249431\n",
      "    test cross_ent loss:      3.217048088709513\n",
      "    cluster loss:             3249.8548177083335\n",
      "    separation loss:          863.6654459635416\n",
      "    avg separation loss:      1004.5240275065104\n",
      "    l1_addon loss:            63.531028747558594\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05353212356567383\n",
      "    test time:                0.012587547302246094\n",
      "    epoch time:               0.0667877197265625\n",
      "epoch:  10 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 59.33%\n",
      "    train overall loss:       6.218362967173259\n",
      "    train cross_ent loss:     3.216495407952203\n",
      "    test overall loss:        6.2180501619974775\n",
      "    test cross_ent loss:      3.2162416776021323\n",
      "    cluster loss:             3211.0902506510415\n",
      "    separation loss:          764.8340250651041\n",
      "    avg separation loss:      914.2690226236979\n",
      "    l1_addon loss:            60.27066421508789\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.0422663688659668\n",
      "    test time:                0.019154071807861328\n",
      "    epoch time:               0.0620877742767334\n",
      "epoch:  11 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 62.67%\n",
      "    train overall loss:       6.2172962294684515\n",
      "    train cross_ent loss:     3.215549495485094\n",
      "    test overall loss:        6.2168474197387695\n",
      "    test cross_ent loss:      3.2151730060577393\n",
      "    cluster loss:             3175.553466796875\n",
      "    separation loss:          679.892822265625\n",
      "    avg separation loss:      817.1248168945312\n",
      "    l1_addon loss:            55.811737060546875\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.042113304138183594\n",
      "    test time:                0.012590169906616211\n",
      "    epoch time:               0.05536079406738281\n",
      "epoch:  12 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 62.33%\n",
      "    train overall loss:       6.215817557440864\n",
      "    train cross_ent loss:     3.2141946951548257\n",
      "    test overall loss:        6.215343475341797\n",
      "    test cross_ent loss:      3.213787873586019\n",
      "    cluster loss:             3145.8085123697915\n",
      "    separation loss:          607.8873697916666\n",
      "    avg separation loss:      735.9902750651041\n",
      "    l1_addon loss:            51.85514831542969\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05018281936645508\n",
      "    test time:                0.012615442276000977\n",
      "    epoch time:               0.0634615421295166\n",
      "epoch:  13 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 57.67%\n",
      "    train overall loss:       6.2141511175367565\n",
      "    train cross_ent loss:     3.2126392788357205\n",
      "    test overall loss:        6.213694890340169\n",
      "    test cross_ent loss:      3.2122828165690103\n",
      "    cluster loss:             3125.9087727864585\n",
      "    separation loss:          564.7031453450521\n",
      "    avg separation loss:      677.8623046875\n",
      "    l1_addon loss:            47.063636779785156\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04207968711853027\n",
      "    test time:                0.012702465057373047\n",
      "    epoch time:               0.05544281005859375\n",
      "epoch:  14 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 61.67%\n",
      "    train overall loss:       6.212261570824517\n",
      "    train cross_ent loss:     3.2108466890123157\n",
      "    test overall loss:        6.2116020520528155\n",
      "    test cross_ent loss:      3.2101735273996987\n",
      "    cluster loss:             3106.8958333333335\n",
      "    separation loss:          512.9527384440104\n",
      "    avg separation loss:      645.36669921875\n",
      "    l1_addon loss:            47.61006164550781\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.046282052993774414\n",
      "    test time:                0.012602806091308594\n",
      "    epoch time:               0.05954623222351074\n",
      "epoch:  15 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 58.33%\n",
      "    train overall loss:       6.209800826178657\n",
      "    train cross_ent loss:     3.20842711130778\n",
      "    test overall loss:        6.208772341410319\n",
      "    test cross_ent loss:      3.207408825556437\n",
      "    cluster loss:             3091.0601399739585\n",
      "    separation loss:          478.8030497233073\n",
      "    avg separation loss:      609.0431518554688\n",
      "    l1_addon loss:            45.44972229003906\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04204225540161133\n",
      "    test time:                0.01676011085510254\n",
      "    epoch time:               0.059482574462890625\n",
      "epoch:  16 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 56.67%\n",
      "    train overall loss:       6.206883271535237\n",
      "    train cross_ent loss:     3.205551995171441\n",
      "    test overall loss:        6.2052435874938965\n",
      "    test cross_ent loss:      3.203925609588623\n",
      "    cluster loss:             3076.151611328125\n",
      "    separation loss:          445.03880818684894\n",
      "    avg separation loss:      569.4968872070312\n",
      "    l1_addon loss:            43.90887451171875\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04202675819396973\n",
      "    test time:                0.012600183486938477\n",
      "    epoch time:               0.05529212951660156\n",
      "epoch:  17 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 55.33%\n",
      "    train overall loss:       6.202590253618029\n",
      "    train cross_ent loss:     3.201266050338745\n",
      "    test overall loss:        6.200808048248291\n",
      "    test cross_ent loss:      3.199535290400187\n",
      "    cluster loss:             3062.4478352864585\n",
      "    separation loss:          412.97791544596356\n",
      "    avg separation loss:      536.1056315104166\n",
      "    l1_addon loss:            42.41490173339844\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.0502469539642334\n",
      "    test time:                0.012603998184204102\n",
      "    epoch time:               0.06351876258850098\n",
      "epoch:  18 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 54.67%\n",
      "    train overall loss:       6.197084691789415\n",
      "    train cross_ent loss:     3.195779906378852\n",
      "    test overall loss:        6.194392363230388\n",
      "    test cross_ent loss:      3.1931108633677163\n",
      "    cluster loss:             3048.6366373697915\n",
      "    separation loss:          377.0773417154948\n",
      "    avg separation loss:      506.3260091145833\n",
      "    l1_addon loss:            42.706268310546875\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04204916954040527\n",
      "    test time:                0.020753860473632812\n",
      "    epoch time:               0.06345891952514648\n",
      "epoch:  19 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 58.00%\n",
      "    train overall loss:       6.189198440975613\n",
      "    train cross_ent loss:     3.187913868162367\n",
      "    test overall loss:        6.185504754384358\n",
      "    test cross_ent loss:      3.184187968571981\n",
      "    cluster loss:             3035.0336100260415\n",
      "    separation loss:          336.7340596516927\n",
      "    avg separation loss:      471.71734619140625\n",
      "    l1_addon loss:            43.87797927856445\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04198098182678223\n",
      "    test time:                0.012614727020263672\n",
      "    epoch time:               0.05525779724121094\n",
      "epoch:  20 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 56.00%\n",
      "    train overall loss:       6.177216423882379\n",
      "    train cross_ent loss:     3.1759339968363443\n",
      "    test overall loss:        6.17155122756958\n",
      "    test cross_ent loss:      3.1702800591786704\n",
      "    cluster loss:             3023.1175944010415\n",
      "    separation loss:          302.80579630533856\n",
      "    avg separation loss:      431.0576578776042\n",
      "    l1_addon loss:            42.3524169921875\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.048305511474609375\n",
      "    test time:                0.012569189071655273\n",
      "    epoch time:               0.061537742614746094\n",
      "epoch:  21 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 55.33%\n",
      "    train overall loss:       6.159833908081055\n",
      "    train cross_ent loss:     3.158580329683092\n",
      "    test overall loss:        6.154516537984212\n",
      "    test cross_ent loss:      3.153277556101481\n",
      "    cluster loss:             3012.5382486979165\n",
      "    separation loss:          269.29433186848956\n",
      "    avg separation loss:      391.8185729980469\n",
      "    l1_addon loss:            41.288944244384766\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.042172908782958984\n",
      "    test time:                0.012628555297851562\n",
      "    epoch time:               0.05546116828918457\n",
      "epoch:  22 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 57.33%\n",
      "    train overall loss:       6.139701260460748\n",
      "    train cross_ent loss:     3.1384721861945257\n",
      "    test overall loss:        6.136115392049153\n",
      "    test cross_ent loss:      3.1348820527394614\n",
      "    cluster loss:             3003.7322591145835\n",
      "    separation loss:          237.1468302408854\n",
      "    avg separation loss:      354.46531168619794\n",
      "    l1_addon loss:            41.09654235839844\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.050131797790527344\n",
      "    test time:                0.012627124786376953\n",
      "    epoch time:               0.06341958045959473\n",
      "epoch:  23 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 62.33%\n",
      "    train overall loss:       6.112732516394721\n",
      "    train cross_ent loss:     3.1115200519561768\n",
      "    test overall loss:        6.115815957387288\n",
      "    test cross_ent loss:      3.1145772139231362\n",
      "    cluster loss:             2995.2828776041665\n",
      "    separation loss:          209.09512329101562\n",
      "    avg separation loss:      327.29090372721356\n",
      "    l1_addon loss:            41.283546447753906\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04783272743225098\n",
      "    test time:                0.012585639953613281\n",
      "    epoch time:               0.06107807159423828\n",
      "epoch:  24 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 63.00%\n",
      "    train overall loss:       6.08860100640191\n",
      "    train cross_ent loss:     3.0874102115631104\n",
      "    test overall loss:        6.093134880065918\n",
      "    test cross_ent loss:      3.0919485886891684\n",
      "    cluster loss:             2989.2105305989585\n",
      "    separation loss:          187.58866373697916\n",
      "    avg separation loss:      298.13641357421875\n",
      "    l1_addon loss:            39.53575897216797\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04211068153381348\n",
      "    test time:                0.012671709060668945\n",
      "    epoch time:               0.05543708801269531\n",
      "epoch:  25 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 62.33%\n",
      "    train overall loss:       6.067144129011366\n",
      "    train cross_ent loss:     3.0659801165262857\n",
      "    test overall loss:        6.076008001963298\n",
      "    test cross_ent loss:      3.074885924657186\n",
      "    cluster loss:             2984.2715657552085\n",
      "    separation loss:          169.64632161458334\n",
      "    avg separation loss:      270.1671447753906\n",
      "    l1_addon loss:            37.395999908447266\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04979658126831055\n",
      "    test time:                0.012578010559082031\n",
      "    epoch time:               0.06304693222045898\n",
      "epoch:  26 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 63.00%\n",
      "    train overall loss:       6.0423880153232155\n",
      "    train cross_ent loss:     3.041246387693617\n",
      "    test overall loss:        6.065672874450684\n",
      "    test cross_ent loss:      3.064579804738363\n",
      "    cluster loss:             2980.0987141927085\n",
      "    separation loss:          155.11988830566406\n",
      "    avg separation loss:      252.8177744547526\n",
      "    l1_addon loss:            36.42894744873047\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04208827018737793\n",
      "    test time:                0.016306161880493164\n",
      "    epoch time:               0.05905413627624512\n",
      "epoch:  27 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 63.67%\n",
      "    train overall loss:       6.0228623814053\n",
      "    train cross_ent loss:     3.0217443307240806\n",
      "    test overall loss:        6.046924432118733\n",
      "    test cross_ent loss:      3.0458346207936606\n",
      "    cluster loss:             2975.70751953125\n",
      "    separation loss:          137.76007843017578\n",
      "    avg separation loss:      231.57625834147134\n",
      "    l1_addon loss:            36.31606674194336\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.041974544525146484\n",
      "    test time:                0.012616872787475586\n",
      "    epoch time:               0.05525088310241699\n",
      "epoch:  28 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 68.67%\n",
      "    train overall loss:       6.003771199120416\n",
      "    train cross_ent loss:     3.002662022908529\n",
      "    test overall loss:        6.04974889755249\n",
      "    test cross_ent loss:      3.048635164896647\n",
      "    cluster loss:             2972.992919921875\n",
      "    separation loss:          123.95754496256511\n",
      "    avg separation loss:      216.97247823079428\n",
      "    l1_addon loss:            37.11307907104492\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04380679130554199\n",
      "    test time:                0.012610673904418945\n",
      "    epoch time:               0.057077646255493164\n",
      "epoch:  29 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 70.00%\n",
      "    train overall loss:       5.983114613427056\n",
      "    train cross_ent loss:     2.982018126381768\n",
      "    test overall loss:        6.03927755355835\n",
      "    test cross_ent loss:      3.038191556930542\n",
      "    cluster loss:             2970.1813151041665\n",
      "    separation loss:          113.21862030029297\n",
      "    avg separation loss:      201.53198750813803\n",
      "    l1_addon loss:            36.18880081176758\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04223775863647461\n",
      "    test time:                0.012632608413696289\n",
      "    epoch time:               0.05552387237548828\n",
      "epoch:  30 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 73.33%\n",
      "    train overall loss:       5.963221973843044\n",
      "    train cross_ent loss:     2.9621451960669622\n",
      "    test overall loss:        6.022250652313232\n",
      "    test cross_ent loss:      3.021166960398356\n",
      "    cluster loss:             2967.5562337239585\n",
      "    separation loss:          102.74585469563802\n",
      "    avg separation loss:      188.78386942545572\n",
      "    l1_addon loss:            36.11506652832031\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04910540580749512\n",
      "    test time:                0.012591838836669922\n",
      "    epoch time:               0.062346696853637695\n",
      "epoch:  31 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 75.00%\n",
      "    train overall loss:       5.947748872968885\n",
      "    train cross_ent loss:     2.946684810850355\n",
      "    test overall loss:        6.012535095214844\n",
      "    test cross_ent loss:      3.0114553769429526\n",
      "    cluster loss:             2965.61962890625\n",
      "    separation loss:          92.77323659261067\n",
      "    avg separation loss:      177.6640421549479\n",
      "    l1_addon loss:            35.9898796081543\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.042057037353515625\n",
      "    test time:                0.012624502182006836\n",
      "    epoch time:               0.05533885955810547\n",
      "epoch:  32 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 73.67%\n",
      "    train overall loss:       5.9254416359795465\n",
      "    train cross_ent loss:     2.9243941836886935\n",
      "    test overall loss:        6.007426420847575\n",
      "    test cross_ent loss:      3.00638477007548\n",
      "    cluster loss:             2964.253662109375\n",
      "    separation loss:          87.27580006917317\n",
      "    avg separation loss:      167.96977742513022\n",
      "    l1_addon loss:            34.71338653564453\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04211878776550293\n",
      "    test time:                0.012607336044311523\n",
      "    epoch time:               0.0553898811340332\n",
      "epoch:  33 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 73.67%\n",
      "    train overall loss:       5.905366208818224\n",
      "    train cross_ent loss:     2.904322624206543\n",
      "    test overall loss:        5.994138081868489\n",
      "    test cross_ent loss:      2.993119398752848\n",
      "    cluster loss:             2962.8496907552085\n",
      "    separation loss:          81.50548553466797\n",
      "    avg separation loss:      157.74712117513022\n",
      "    l1_addon loss:            33.95592498779297\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04641318321228027\n",
      "    test time:                0.012605905532836914\n",
      "    epoch time:               0.0596768856048584\n",
      "epoch:  34 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 72.33%\n",
      "    train overall loss:       5.886690563625759\n",
      "    train cross_ent loss:     2.8856669531928167\n",
      "    test overall loss:        5.9850748380025225\n",
      "    test cross_ent loss:      2.984081427256266\n",
      "    cluster loss:             2961.7045084635415\n",
      "    separation loss:          76.84875996907552\n",
      "    avg separation loss:      150.11927286783853\n",
      "    l1_addon loss:            33.108802795410156\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.042047739028930664\n",
      "    test time:                0.020601749420166016\n",
      "    epoch time:               0.06330490112304688\n",
      "epoch:  35 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 77.33%\n",
      "    train overall loss:       5.872485372755262\n",
      "    train cross_ent loss:     2.871479776170519\n",
      "    test overall loss:        6.007542769114177\n",
      "    test cross_ent loss:      3.0064924558003745\n",
      "    cluster loss:             2961.3263346354165\n",
      "    separation loss:          69.94503529866536\n",
      "    avg separation loss:      146.90780639648438\n",
      "    l1_addon loss:            35.00148391723633\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.0419764518737793\n",
      "    test time:                0.012702226638793945\n",
      "    epoch time:               0.05533194541931152\n",
      "epoch:  36 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 78.33%\n",
      "    train overall loss:       5.864028771718343\n",
      "    train cross_ent loss:     2.8630184067620172\n",
      "    test overall loss:        5.982988516489665\n",
      "    test cross_ent loss:      2.981975873311361\n",
      "    cluster loss:             2960.2936197916665\n",
      "    separation loss:          67.85111745198567\n",
      "    avg separation loss:      141.9385782877604\n",
      "    l1_addon loss:            33.74460220336914\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.042342185974121094\n",
      "    test time:                0.012606143951416016\n",
      "    epoch time:               0.055606842041015625\n",
      "epoch:  37 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 78.00%\n",
      "    train overall loss:       5.861500846015082\n",
      "    train cross_ent loss:     2.8605130513509116\n",
      "    test overall loss:        5.988048553466797\n",
      "    test cross_ent loss:      2.9870667457580566\n",
      "    cluster loss:             2960.717041015625\n",
      "    separation loss:          69.19882456461589\n",
      "    avg separation loss:      140.03148905436197\n",
      "    l1_addon loss:            32.712791442871094\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04231858253479004\n",
      "    test time:                0.012603521347045898\n",
      "    epoch time:               0.055574893951416016\n",
      "epoch:  38 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 75.33%\n",
      "    train overall loss:       5.84624899758233\n",
      "    train cross_ent loss:     2.8452709250979953\n",
      "    test overall loss:        5.971602439880371\n",
      "    test cross_ent loss:      2.970662275950114\n",
      "    cluster loss:             2959.9864908854165\n",
      "    separation loss:          66.93343861897786\n",
      "    avg separation loss:      134.17394510904947\n",
      "    l1_addon loss:            31.334630966186523\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04378509521484375\n",
      "    test time:                0.012601852416992188\n",
      "    epoch time:               0.057039499282836914\n",
      "epoch:  39 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 76.00%\n",
      "    train overall loss:       5.823379304673937\n",
      "    train cross_ent loss:     2.8224191665649414\n",
      "    test overall loss:        5.965779622395833\n",
      "    test cross_ent loss:      2.964837630589803\n",
      "    cluster loss:             2959.6619466145835\n",
      "    separation loss:          64.68538157145183\n",
      "    avg separation loss:      130.98473358154297\n",
      "    l1_addon loss:            31.38385772705078\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04201078414916992\n",
      "    test time:                0.012621164321899414\n",
      "    epoch time:               0.05527067184448242\n",
      "epoch:  40 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 77.33%\n",
      "    train overall loss:       5.795090145534939\n",
      "    train cross_ent loss:     2.794128656387329\n",
      "    test overall loss:        5.960608005523682\n",
      "    test cross_ent loss:      2.9596598943074546\n",
      "    cluster loss:             2959.396484375\n",
      "    separation loss:          62.039947509765625\n",
      "    avg separation loss:      128.89096323649088\n",
      "    l1_addon loss:            31.603830337524414\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04224038124084473\n",
      "    test time:                0.012599945068359375\n",
      "    epoch time:               0.05549478530883789\n",
      "epoch:  41 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 76.67%\n",
      "    train overall loss:       5.789380179511176\n",
      "    train cross_ent loss:     2.7884274853600397\n",
      "    test overall loss:        5.957889874776204\n",
      "    test cross_ent loss:      2.9569541613260903\n",
      "    cluster loss:             2959.2676595052085\n",
      "    separation loss:          60.65014139811198\n",
      "    avg separation loss:      125.2018814086914\n",
      "    l1_addon loss:            31.18392562866211\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04601573944091797\n",
      "    test time:                0.012693643569946289\n",
      "    epoch time:               0.05938005447387695\n",
      "epoch:  42 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 78.67%\n",
      "    train overall loss:       5.787049187554254\n",
      "    train cross_ent loss:     2.7861065334743924\n",
      "    test overall loss:        5.97297477722168\n",
      "    test cross_ent loss:      2.9719932874043784\n",
      "    cluster loss:             2959.1106770833335\n",
      "    separation loss:          58.36107889811198\n",
      "    avg separation loss:      126.86245727539062\n",
      "    l1_addon loss:            32.71175765991211\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.041959285736083984\n",
      "    test time:                0.016689300537109375\n",
      "    epoch time:               0.05929231643676758\n",
      "epoch:  43 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 77.67%\n",
      "    train overall loss:       5.75509770711263\n",
      "    train cross_ent loss:     2.7541654904683432\n",
      "    test overall loss:        5.963147799173991\n",
      "    test cross_ent loss:      2.9621810913085938\n",
      "    cluster loss:             2958.8282877604165\n",
      "    separation loss:          56.67428334554037\n",
      "    avg separation loss:      123.23212432861328\n",
      "    l1_addon loss:            32.220008850097656\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04198455810546875\n",
      "    test time:                0.012624263763427734\n",
      "    epoch time:               0.05525803565979004\n",
      "epoch:  44 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 74.00%\n",
      "    train overall loss:       5.7709479331970215\n",
      "    train cross_ent loss:     2.7700075573391385\n",
      "    test overall loss:        5.947164535522461\n",
      "    test cross_ent loss:      2.946261246999105\n",
      "    cluster loss:             2959.0496419270835\n",
      "    separation loss:          58.1685536702474\n",
      "    avg separation loss:      120.52176411946614\n",
      "    l1_addon loss:            30.097816467285156\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.042479753494262695\n",
      "    test time:                0.012595415115356445\n",
      "    epoch time:               0.05573129653930664\n",
      "epoch:  45 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 72.00%\n",
      "    train overall loss:       5.767760753631592\n",
      "    train cross_ent loss:     2.766844537523058\n",
      "    test overall loss:        5.954050381978353\n",
      "    test cross_ent loss:      2.9531761010487876\n",
      "    cluster loss:             2959.256591796875\n",
      "    separation loss:          58.63275909423828\n",
      "    avg separation loss:      118.68685150146484\n",
      "    l1_addon loss:            29.127166748046875\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04243588447570801\n",
      "    test time:                0.01260685920715332\n",
      "    epoch time:               0.05570268630981445\n",
      "epoch:  46 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 77.33%\n",
      "    train overall loss:       5.7446280055575905\n",
      "    train cross_ent loss:     2.7437235249413385\n",
      "    test overall loss:        5.935037612915039\n",
      "    test cross_ent loss:      2.934105555216471\n",
      "    cluster loss:             2958.3784993489585\n",
      "    separation loss:          54.84767405192057\n",
      "    avg separation loss:      119.45502217610677\n",
      "    l1_addon loss:            31.055767059326172\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04205441474914551\n",
      "    test time:                0.012686491012573242\n",
      "    epoch time:               0.055388689041137695\n",
      "epoch:  47 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 74.33%\n",
      "    train overall loss:       5.7122483253479\n",
      "    train cross_ent loss:     2.711335129208035\n",
      "    test overall loss:        5.929163297017415\n",
      "    test cross_ent loss:      2.9282737572987876\n",
      "    cluster loss:             2958.2576497395835\n",
      "    separation loss:          54.5935173034668\n",
      "    avg separation loss:      115.9525655110677\n",
      "    l1_addon loss:            29.636871337890625\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.050466060638427734\n",
      "    test time:                0.012603044509887695\n",
      "    epoch time:               0.06373357772827148\n",
      "epoch:  48 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 74.00%\n",
      "    train overall loss:       5.719549867841932\n",
      "    train cross_ent loss:     2.718636221355862\n",
      "    test overall loss:        5.9161176681518555\n",
      "    test cross_ent loss:      2.915230909983317\n",
      "    cluster loss:             2958.053955078125\n",
      "    separation loss:          53.9086545308431\n",
      "    avg separation loss:      115.27684783935547\n",
      "    l1_addon loss:            29.544294357299805\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04207491874694824\n",
      "    test time:                0.012596607208251953\n",
      "    epoch time:               0.05532264709472656\n",
      "epoch:  49 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 75.00%\n",
      "    train overall loss:       5.711046006944445\n",
      "    train cross_ent loss:     2.7101606527964273\n",
      "    test overall loss:        5.923266092936198\n",
      "    test cross_ent loss:      2.9223743279774985\n",
      "    cluster loss:             2958.0718587239585\n",
      "    separation loss:          52.85660298665365\n",
      "    avg separation loss:      113.30795796712239\n",
      "    l1_addon loss:            29.721267700195312\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04353499412536621\n",
      "    test time:                0.013029336929321289\n",
      "    epoch time:               0.0572357177734375\n",
      "epoch:  50 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 73.67%\n",
      "    train overall loss:       5.673701816134983\n",
      "    train cross_ent loss:     2.672810263103909\n",
      "    test overall loss:        5.907604058583577\n",
      "    test cross_ent loss:      2.906727393468221\n",
      "    cluster loss:             2957.776611328125\n",
      "    separation loss:          52.080254872639976\n",
      "    avg separation loss:      111.39722188313802\n",
      "    l1_addon loss:            29.21653938293457\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04823422431945801\n",
      "    test time:                0.012689590454101562\n",
      "    epoch time:               0.061593055725097656\n",
      "epoch:  51 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 71.00%\n",
      "    train overall loss:       5.695299943288167\n",
      "    train cross_ent loss:     2.694418430328369\n",
      "    test overall loss:        5.927755514780681\n",
      "    test cross_ent loss:      2.9268736839294434\n",
      "    cluster loss:             2958.23486328125\n",
      "    separation loss:          55.146252950032554\n",
      "    avg separation loss:      115.08291371663411\n",
      "    l1_addon loss:            29.38746452331543\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.061420440673828125\n",
      "    test time:                0.012944698333740234\n",
      "    epoch time:               0.07509469985961914\n",
      "    joint lr:                 0.0030601000000000087\n",
      "epoch:  52 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 15.33%\n",
      "    train overall loss:       6.11118221282959\n",
      "    train cross_ent loss:     3.1103370984395347\n",
      "    test overall loss:        6.218966801961263\n",
      "    test cross_ent loss:      3.2181595961252847\n",
      "    cluster loss:             3192.1090494791665\n",
      "    separation loss:          476.10247802734375\n",
      "    avg separation loss:      885.7829996744791\n",
      "    l1_addon loss:            26.901012420654297\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06095767021179199\n",
      "    test time:                0.012658834457397461\n",
      "    epoch time:               0.07429790496826172\n",
      "    joint lr:                 0.005960997999999999\n",
      "epoch:  53 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 34.67%\n",
      "    train overall loss:       5.989403088887532\n",
      "    train cross_ent loss:     2.9885978433820934\n",
      "    test overall loss:        6.189417044321696\n",
      "    test cross_ent loss:      3.1885271072387695\n",
      "    cluster loss:             2991.6555989583335\n",
      "    separation loss:          98.78885396321614\n",
      "    avg separation loss:      286.838134765625\n",
      "    l1_addon loss:            29.661848068237305\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06125235557556152\n",
      "    test time:                0.012652158737182617\n",
      "    epoch time:               0.07461285591125488\n",
      "    joint lr:                 0.008803582030000007\n",
      "epoch:  54 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 47.67%\n",
      "    train overall loss:       5.760356320275201\n",
      "    train cross_ent loss:     2.7595129542880588\n",
      "    test overall loss:        6.109995047251384\n",
      "    test cross_ent loss:      3.109170834223429\n",
      "    cluster loss:             2967.35009765625\n",
      "    separation loss:          57.57315317789713\n",
      "    avg separation loss:      164.19541931152344\n",
      "    l1_addon loss:            27.462032318115234\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06120657920837402\n",
      "    test time:                0.012664556503295898\n",
      "    epoch time:               0.07458949089050293\n",
      "    joint lr:                 0.011588728279599995\n",
      "epoch:  55 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 59.67%\n",
      "    train overall loss:       5.6697168880038795\n",
      "    train cross_ent loss:     2.6688826349046497\n",
      "    test overall loss:        6.067803382873535\n",
      "    test cross_ent loss:      3.0669676462809243\n",
      "    cluster loss:             2961.7093098958335\n",
      "    separation loss:          50.96790059407552\n",
      "    avg separation loss:      147.60928344726562\n",
      "    l1_addon loss:            27.85492706298828\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06100130081176758\n",
      "    test time:                0.012669563293457031\n",
      "    epoch time:               0.07439994812011719\n",
      "    joint lr:                 0.014317301246005004\n",
      "epoch:  56 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 58.00%\n",
      "    train overall loss:       5.400994247860378\n",
      "    train cross_ent loss:     2.4001466698116727\n",
      "    test overall loss:        5.971652984619141\n",
      "    test cross_ent loss:      2.970784902572632\n",
      "    cluster loss:             2957.8824055989585\n",
      "    separation loss:          36.184393564860024\n",
      "    avg separation loss:      101.85558064778645\n",
      "    l1_addon loss:            28.92998504638672\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06085968017578125\n",
      "    test time:                0.012498617172241211\n",
      "    epoch time:               0.07404017448425293\n",
      "    joint lr:                 0.016990153880253933\n",
      "epoch:  57 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 52.00%\n",
      "    train overall loss:       5.4030190043979225\n",
      "    train cross_ent loss:     2.4021344979604087\n",
      "    test overall loss:        5.870617389678955\n",
      "    test cross_ent loss:      2.869694471359253\n",
      "    cluster loss:             2956.722900390625\n",
      "    separation loss:          29.443016052246094\n",
      "    avg separation loss:      93.92694600423177\n",
      "    l1_addon loss:            30.761871337890625\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058806419372558594\n",
      "    test time:                0.012207508087158203\n",
      "    epoch time:               0.0718083381652832\n",
      "    joint lr:                 0.019608127731693303\n",
      "epoch:  58 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 76.33%\n",
      "    train overall loss:       5.196972052256267\n",
      "    train cross_ent loss:     2.196016139454312\n",
      "    test overall loss:        5.32554833094279\n",
      "    test cross_ent loss:      2.3245559533437095\n",
      "    cluster loss:             2952.0485026041665\n",
      "    separation loss:          19.76187578837077\n",
      "    avg separation loss:      62.24347941080729\n",
      "    l1_addon loss:            33.07086181640625\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05895400047302246\n",
      "    test time:                0.012785196304321289\n",
      "    epoch time:               0.0725245475769043\n",
      "    joint lr:                 0.02217205309071584\n",
      "epoch:  59 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 67.67%\n",
      "    train overall loss:       5.180850187937419\n",
      "    train cross_ent loss:     2.17982280254364\n",
      "    test overall loss:        5.353448708852132\n",
      "    test cross_ent loss:      2.3524118264516196\n",
      "    cluster loss:             2952.3515625\n",
      "    separation loss:          21.271114985148113\n",
      "    avg separation loss:      60.25707117716471\n",
      "    l1_addon loss:            34.55797576904297\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05865836143493652\n",
      "    test time:                0.012111186981201172\n",
      "    epoch time:               0.07153844833374023\n",
      "    joint lr:                 0.024682749129784777\n",
      "epoch:  60 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 65.67%\n",
      "    train overall loss:       5.243917147318522\n",
      "    train cross_ent loss:     2.242829362551371\n",
      "    test overall loss:        5.399767239888509\n",
      "    test cross_ent loss:      2.398703654607137\n",
      "    cluster loss:             2952.673583984375\n",
      "    separation loss:          20.69327227274577\n",
      "    avg separation loss:      63.75811004638672\n",
      "    l1_addon loss:            35.44621276855469\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05825448036193848\n",
      "    test time:                0.012683629989624023\n",
      "    epoch time:               0.07209205627441406\n",
      "    joint lr:                 0.027141024042763244\n",
      "epoch:  61 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 71.00%\n",
      "    train overall loss:       5.076262368096246\n",
      "    train cross_ent loss:     2.075135654873318\n",
      "    test overall loss:        4.99873161315918\n",
      "    test cross_ent loss:      1.9976032972335815\n",
      "    cluster loss:             2951.6127115885415\n",
      "    separation loss:          17.582692464192707\n",
      "    avg separation loss:      55.24761454264323\n",
      "    l1_addon loss:            37.61358642578125\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058516502380371094\n",
      "    test time:                0.012646913528442383\n",
      "    epoch time:               0.07224702835083008\n",
      "    joint lr:                 0.025532083112218835\n",
      "epoch:  62 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 70.00%\n",
      "    train overall loss:       5.004163371192084\n",
      "    train cross_ent loss:     2.002996484438578\n",
      "    test overall loss:        5.186044375101726\n",
      "    test cross_ent loss:      2.1848889191945395\n",
      "    cluster loss:             2951.760498046875\n",
      "    separation loss:          17.963581720987957\n",
      "    avg separation loss:      58.132790883382164\n",
      "    l1_addon loss:            38.50957489013672\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058500051498413086\n",
      "    test time:                0.012651205062866211\n",
      "    epoch time:               0.07217288017272949\n",
      "    joint lr:                 0.023952616897881036\n",
      "epoch:  63 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 70.00%\n",
      "    train overall loss:       4.869902928670247\n",
      "    train cross_ent loss:     1.8687203460269504\n",
      "    test overall loss:        5.190175215403239\n",
      "    test cross_ent loss:      2.188973069190979\n",
      "    cluster loss:             2952.0889485677085\n",
      "    separation loss:          17.382877985636394\n",
      "    avg separation loss:      53.70261255900065\n",
      "    l1_addon loss:            40.07275390625\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05816245079040527\n",
      "    test time:                0.01263427734375\n",
      "    epoch time:               0.07195711135864258\n",
      "    joint lr:                 0.022402196799518763\n",
      "epoch:  64 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 74.67%\n",
      "    train overall loss:       4.911118189493815\n",
      "    train cross_ent loss:     1.909899459944831\n",
      "    test overall loss:        4.582067171732585\n",
      "    test cross_ent loss:      1.5808629592259724\n",
      "    cluster loss:             2951.259033203125\n",
      "    separation loss:          14.774380048116049\n",
      "    avg separation loss:      45.269161224365234\n",
      "    l1_addon loss:            40.13144302368164\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058377742767333984\n",
      "    test time:                0.012678146362304688\n",
      "    epoch time:               0.0721902847290039\n",
      "    joint lr:                 0.02088039984143395\n",
      "epoch:  65 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 80.00%\n",
      "    train overall loss:       4.810852421654595\n",
      "    train cross_ent loss:     1.8096094528834026\n",
      "    test overall loss:        4.2529598871866865\n",
      "    test cross_ent loss:      1.2517260313034058\n",
      "    cluster loss:             2950.8113606770835\n",
      "    separation loss:          13.279290199279785\n",
      "    avg separation loss:      41.04226811726888\n",
      "    l1_addon loss:            41.1193733215332\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058161258697509766\n",
      "    test time:                0.012639045715332031\n",
      "    epoch time:               0.07191324234008789\n",
      "    joint lr:                 0.01938680860283089\n",
      "epoch:  66 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 59.67%\n",
      "    train overall loss:       4.900110138787164\n",
      "    train cross_ent loss:     1.8988600307040744\n",
      "    test overall loss:        5.256787935892741\n",
      "    test cross_ent loss:      2.255465865135193\n",
      "    cluster loss:             2952.7329915364585\n",
      "    separation loss:          17.43517303466797\n",
      "    avg separation loss:      51.689432779947914\n",
      "    l1_addon loss:            44.057037353515625\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05723977088928223\n",
      "    test time:                0.012153148651123047\n",
      "    epoch time:               0.07054877281188965\n",
      "    joint lr:                 0.017921011149015745\n",
      "epoch:  67 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 63.67%\n",
      "    train overall loss:       4.929669221242269\n",
      "    train cross_ent loss:     1.9284124771753948\n",
      "    test overall loss:        4.964628219604492\n",
      "    test cross_ent loss:      1.9633381764094036\n",
      "    cluster loss:             2952.07666015625\n",
      "    separation loss:          16.452853838602703\n",
      "    avg separation loss:      48.492628733317055\n",
      "    l1_addon loss:            42.98810577392578\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.057053565979003906\n",
      "    test time:                0.012219667434692383\n",
      "    epoch time:               0.07043886184692383\n",
      "    joint lr:                 0.016482600963416614\n",
      "epoch:  68 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 76.67%\n",
      "    train overall loss:       4.559503290388319\n",
      "    train cross_ent loss:     1.5582598050435383\n",
      "    test overall loss:        4.557721296946208\n",
      "    test cross_ent loss:      1.5564420223236084\n",
      "    cluster loss:             2951.0299479166665\n",
      "    separation loss:          13.627949714660645\n",
      "    avg separation loss:      39.59903462727865\n",
      "    l1_addon loss:            42.622413635253906\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.057077884674072266\n",
      "    test time:                0.01207876205444336\n",
      "    epoch time:               0.0703279972076416\n",
      "    joint lr:                 0.015071176880414561\n",
      "epoch:  69 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 77.67%\n",
      "    train overall loss:       4.351088417900933\n",
      "    train cross_ent loss:     1.349837475352817\n",
      "    test overall loss:        4.268137137095134\n",
      "    test cross_ent loss:      1.2669099569320679\n",
      "    cluster loss:             2950.700927734375\n",
      "    separation loss:          11.626006444295248\n",
      "    avg separation loss:      32.0882765452067\n",
      "    l1_addon loss:            40.89331817626953\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05745863914489746\n",
      "    test time:                0.012116193771362305\n",
      "    epoch time:               0.0707695484161377\n",
      "    joint lr:                 0.01368634301897622\n",
      "epoch:  70 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 80.00%\n",
      "    train overall loss:       4.20148507754008\n",
      "    train cross_ent loss:     1.2002293202612135\n",
      "    test overall loss:        3.9187546571095786\n",
      "    test cross_ent loss:      0.9175015489260355\n",
      "    cluster loss:             2950.11572265625\n",
      "    separation loss:          9.207046031951904\n",
      "    avg separation loss:      28.7801996866862\n",
      "    l1_addon loss:            41.760032653808594\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.057006120681762695\n",
      "    test time:                0.012127399444580078\n",
      "    epoch time:               0.07032251358032227\n",
      "    joint lr:                 0.012327708717078603\n",
      "epoch:  71 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 82.00%\n",
      "    train overall loss:       4.041072474585639\n",
      "    train cross_ent loss:     1.0398181345727708\n",
      "    test overall loss:        3.9365690549214682\n",
      "    test cross_ent loss:      0.9353186190128326\n",
      "    cluster loss:             2950.1617024739585\n",
      "    separation loss:          8.749970277150473\n",
      "    avg separation loss:      27.6944522857666\n",
      "    l1_addon loss:            41.6787109375\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05690360069274902\n",
      "    test time:                0.012122869491577148\n",
      "    epoch time:               0.07023739814758301\n",
      "    joint lr:                 0.01099488846691703\n",
      "epoch:  72 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       3.8112503157721624\n",
      "    train cross_ent loss:     0.8099947505527072\n",
      "    test overall loss:        3.755276679992676\n",
      "    test cross_ent loss:      0.754030446211497\n",
      "    cluster loss:             2949.8778483072915\n",
      "    separation loss:          7.183011372884114\n",
      "    avg separation loss:      23.85594113667806\n",
      "    l1_addon loss:            41.53636169433594\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05690503120422363\n",
      "    test time:                0.012112855911254883\n",
      "    epoch time:               0.07019996643066406\n",
      "    joint lr:                 0.009687501850886984\n",
      "epoch:  73 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 87.00%\n",
      "    train overall loss:       3.933437797758314\n",
      "    train cross_ent loss:     0.9321820073657565\n",
      "    test overall loss:        4.1809877554575605\n",
      "    test cross_ent loss:      1.1796823342641194\n",
      "    cluster loss:             2950.3333333333335\n",
      "    separation loss:          7.855433305104573\n",
      "    avg separation loss:      23.1807804107666\n",
      "    l1_addon loss:            43.49810791015625\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05709123611450195\n",
      "    test time:                0.012104034423828125\n",
      "    epoch time:               0.0703585147857666\n",
      "    joint lr:                 0.008405173478330853\n",
      "epoch:  74 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       3.7209483782450357\n",
      "    train cross_ent loss:     0.7196905513604482\n",
      "    test overall loss:        3.5952889919281006\n",
      "    test cross_ent loss:      0.5940470447142919\n",
      "    cluster loss:             2949.795654296875\n",
      "    separation loss:          6.479849338531494\n",
      "    avg separation loss:      18.104434331258137\n",
      "    l1_addon loss:            41.38863754272461\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05692887306213379\n",
      "    test time:                0.012127876281738281\n",
      "    epoch time:               0.07021117210388184\n",
      "    joint lr:                 0.007147532923040749\n",
      "epoch:  75 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 90.00%\n",
      "    train overall loss:       3.647663699256049\n",
      "    train cross_ent loss:     0.6464117897881402\n",
      "    test overall loss:        3.5214949448903403\n",
      "    test cross_ent loss:      0.5202535018324852\n",
      "    cluster loss:             2949.7188313802085\n",
      "    separation loss:          6.053752263387044\n",
      "    avg separation loss:      17.92277463277181\n",
      "    l1_addon loss:            41.37145233154297\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05689740180969238\n",
      "    test time:                0.012118101119995117\n",
      "    epoch time:               0.07016110420227051\n",
      "    joint lr:                 0.005914214661508615\n",
      "epoch:  76 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 91.33%\n",
      "    train overall loss:       3.47810697555542\n",
      "    train cross_ent loss:     0.4768563442760044\n",
      "    test overall loss:        3.417314132054647\n",
      "    test cross_ent loss:      0.41607793668905896\n",
      "    cluster loss:             2949.6381022135415\n",
      "    separation loss:          5.479764461517334\n",
      "    avg separation loss:      16.64255968729655\n",
      "    l1_addon loss:            41.19776916503906\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.056970834732055664\n",
      "    test time:                0.012152671813964844\n",
      "    epoch time:               0.07028841972351074\n",
      "    joint lr:                 0.004704858011914826\n",
      "epoch:  77 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       3.355511426925659\n",
      "    train cross_ent loss:     0.3542592144674725\n",
      "    test overall loss:        3.3473676840464273\n",
      "    test cross_ent loss:      0.3461122040947278\n",
      "    cluster loss:             2949.5699055989585\n",
      "    separation loss:          4.818780183792114\n",
      "    avg separation loss:      13.547590255737305\n",
      "    l1_addon loss:            41.83988952636719\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05686068534851074\n",
      "    test time:                0.012115001678466797\n",
      "    epoch time:               0.07017016410827637\n",
      "    joint lr:                 0.0035191070738467612\n",
      "epoch:  78 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 93.00%\n",
      "    train overall loss:       3.311936961279975\n",
      "    train cross_ent loss:     0.3106865841481421\n",
      "    test overall loss:        3.3183873494466147\n",
      "    test cross_ent loss:      0.31713400532801944\n",
      "    cluster loss:             2949.51318359375\n",
      "    separation loss:          4.736961285273234\n",
      "    avg separation loss:      14.086897214253744\n",
      "    l1_addon loss:            41.77048873901367\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05688977241516113\n",
      "    test time:                0.012191534042358398\n",
      "    epoch time:               0.07025814056396484\n",
      "    joint lr:                 0.00235661066873886\n",
      "epoch:  79 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 94.67%\n",
      "    train overall loss:       3.221750921673245\n",
      "    train cross_ent loss:     0.2205006256699562\n",
      "    test overall loss:        3.246853748957316\n",
      "    test cross_ent loss:      0.24559940894444784\n",
      "    cluster loss:             2949.4949544270835\n",
      "    separation loss:          4.347458600997925\n",
      "    avg separation loss:      12.308380444844564\n",
      "    l1_addon loss:            41.80424118041992\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05714082717895508\n",
      "    test time:                0.01210331916809082\n",
      "    epoch time:               0.07041645050048828\n",
      "    joint lr:                 0.001217022281025732\n",
      "epoch:  80 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       3.1595671706729465\n",
      "    train cross_ent loss:     0.15831779398851925\n",
      "    test overall loss:        3.222702900568644\n",
      "    test cross_ent loss:      0.2214536021153132\n",
      "    cluster loss:             2949.46826171875\n",
      "    separation loss:          4.3429514567057295\n",
      "    avg separation loss:      12.719014485677084\n",
      "    l1_addon loss:            41.6387939453125\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.056963205337524414\n",
      "    test time:                0.012089014053344727\n",
      "    epoch time:               0.07023191452026367\n",
      "    joint lr:                 0.0001\n",
      "epoch:  81 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       3.1424089272816977\n",
      "    train cross_ent loss:     0.1411589350965288\n",
      "    test overall loss:        3.2179914315541587\n",
      "    test cross_ent loss:      0.21674117570122084\n",
      "    cluster loss:             2949.4632161458335\n",
      "    separation loss:          4.301597833633423\n",
      "    avg separation loss:      12.616530100504557\n",
      "    l1_addon loss:            41.671142578125\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05696535110473633\n",
      "    test time:                0.012140512466430664\n",
      "    epoch time:               0.07028007507324219\n",
      "    joint lr:                 0.00228958707526664\n",
      "epoch:  82 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 94.33%\n",
      "    train overall loss:       3.143781370586819\n",
      "    train cross_ent loss:     0.14253116047216785\n",
      "    test overall loss:        3.236947456995646\n",
      "    test cross_ent loss:      0.2356876196960608\n",
      "    cluster loss:             2949.4689127604165\n",
      "    separation loss:          4.056916872660319\n",
      "    avg separation loss:      11.638167381286621\n",
      "    l1_addon loss:            41.98909378051758\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.0571439266204834\n",
      "    test time:                0.012105941772460938\n",
      "    epoch time:               0.07041764259338379\n",
      "    joint lr:                 0.004435382409027948\n",
      "epoch:  83 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 94.67%\n",
      "    train overall loss:       3.1948035028245716\n",
      "    train cross_ent loss:     0.19355228977898756\n",
      "    test overall loss:        3.234794775644938\n",
      "    test cross_ent loss:      0.23352968071897826\n",
      "    cluster loss:             2949.4532877604165\n",
      "    separation loss:          3.892712354660034\n",
      "    avg separation loss:      11.198796590169271\n",
      "    l1_addon loss:            42.16419219970703\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05714678764343262\n",
      "    test time:                0.01209878921508789\n",
      "    epoch time:               0.07040715217590332\n",
      "    joint lr:                 0.006538042877406532\n",
      "epoch:  84 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 94.33%\n",
      "    train overall loss:       3.270185867945353\n",
      "    train cross_ent loss:     0.26893244228429264\n",
      "    test overall loss:        3.38407039642334\n",
      "    test cross_ent loss:      0.3828265021244685\n",
      "    cluster loss:             2949.5277506510415\n",
      "    separation loss:          3.946576992670695\n",
      "    avg separation loss:      11.65442975362142\n",
      "    l1_addon loss:            41.45600891113281\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.057250261306762695\n",
      "    test time:                0.012140035629272461\n",
      "    epoch time:               0.07057905197143555\n",
      "    joint lr:                 0.008598216598176611\n",
      "epoch:  85 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 91.33%\n",
      "    train overall loss:       3.498825947443644\n",
      "    train cross_ent loss:     0.497591045167711\n",
      "    test overall loss:        3.5083115895589194\n",
      "    test cross_ent loss:      0.5070670942465464\n",
      "    cluster loss:             2949.6004231770835\n",
      "    separation loss:          4.0285398960113525\n",
      "    avg separation loss:      11.31131680806478\n",
      "    l1_addon loss:            41.47795104980469\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.057290077209472656\n",
      "    test time:                0.012142181396484375\n",
      "    epoch time:               0.07059574127197266\n",
      "    joint lr:                 0.010616543040243577\n",
      "epoch:  86 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 88.00%\n",
      "    train overall loss:       3.7876122527652316\n",
      "    train cross_ent loss:     0.7863718668619791\n",
      "    test overall loss:        3.7669714291890464\n",
      "    test cross_ent loss:      0.7657588620980581\n",
      "    cluster loss:             2949.914306640625\n",
      "    separation loss:          5.4793375333150225\n",
      "    avg separation loss:      13.884881655375162\n",
      "    l1_addon loss:            40.41216278076172\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.057066917419433594\n",
      "    test time:                0.012143611907958984\n",
      "    epoch time:               0.0703887939453125\n",
      "    joint lr:                 0.012593653131809358\n",
      "epoch:  87 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 84.33%\n",
      "    train overall loss:       3.9018037584092884\n",
      "    train cross_ent loss:     0.9005792737007141\n",
      "    test overall loss:        3.8779118855794272\n",
      "    test cross_ent loss:      0.8766866525014242\n",
      "    cluster loss:             2950.097900390625\n",
      "    separation loss:          6.593999067942302\n",
      "    avg separation loss:      16.359915097554524\n",
      "    l1_addon loss:            40.835941314697266\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.057010650634765625\n",
      "    test time:                0.012091398239135742\n",
      "    epoch time:               0.07026529312133789\n",
      "    joint lr:                 0.014530169367239798\n",
      "epoch:  88 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 85.33%\n",
      "    train overall loss:       3.818467802471585\n",
      "    train cross_ent loss:     0.8172396189636655\n",
      "    test overall loss:        3.95266064008077\n",
      "    test cross_ent loss:      0.9514386256535848\n",
      "    cluster loss:             2950.2103678385415\n",
      "    separation loss:          6.884241898854573\n",
      "    avg separation loss:      15.728805224100748\n",
      "    l1_addon loss:            40.728759765625\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05702853202819824\n",
      "    test time:                0.012117624282836914\n",
      "    epoch time:               0.0703132152557373\n",
      "    joint lr:                 0.01642670591264845\n",
      "epoch:  89 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 78.67%\n",
      "    train overall loss:       4.170800420973036\n",
      "    train cross_ent loss:     1.1695774727397494\n",
      "    test overall loss:        4.5465850830078125\n",
      "    test cross_ent loss:      1.5454033613204956\n",
      "    cluster loss:             2950.6013997395835\n",
      "    separation loss:          8.27593994140625\n",
      "    avg separation loss:      18.121654510498047\n",
      "    l1_addon loss:            39.38241958618164\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.056961774826049805\n",
      "    test time:                0.01219320297241211\n",
      "    epoch time:               0.07032918930053711\n",
      "    joint lr:                 0.018283868710212207\n",
      "epoch:  90 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 82.33%\n",
      "    train overall loss:       4.264606793721517\n",
      "    train cross_ent loss:     1.2633901569578383\n",
      "    test overall loss:        4.159064928690593\n",
      "    test cross_ent loss:      1.1578338344891865\n",
      "    cluster loss:             2950.671630859375\n",
      "    separation loss:          9.36445426940918\n",
      "    avg separation loss:      23.055116017659504\n",
      "    l1_addon loss:            41.02924728393555\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05688810348510742\n",
      "    test time:                0.01211237907409668\n",
      "    epoch time:               0.07015728950500488\n",
      "    joint lr:                 0.020102255581233422\n",
      "epoch:  91 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 90.00%\n",
      "    train overall loss:       4.254960695902507\n",
      "    train cross_ent loss:     1.2537379132376776\n",
      "    test overall loss:        4.21293044090271\n",
      "    test cross_ent loss:      1.21170179049174\n",
      "    cluster loss:             2950.9275716145835\n",
      "    separation loss:          10.438671747843424\n",
      "    avg separation loss:      24.43987973531087\n",
      "    l1_addon loss:            40.94105529785156\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.057190656661987305\n",
      "    test time:                0.012124061584472656\n",
      "    epoch time:               0.07047796249389648\n",
      "    joint lr:                 0.018912121374150048\n",
      "epoch:  92 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 89.00%\n",
      "    train overall loss:       4.140106174680922\n",
      "    train cross_ent loss:     1.1388789945178561\n",
      "    test overall loss:        4.025731086730957\n",
      "    test cross_ent loss:      1.0245008269945781\n",
      "    cluster loss:             2950.9086100260415\n",
      "    separation loss:          9.31029717127482\n",
      "    avg separation loss:      22.76949119567871\n",
      "    l1_addon loss:            41.003150939941406\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.0570979118347168\n",
      "    test time:                0.012099742889404297\n",
      "    epoch time:               0.07036399841308594\n",
      "    joint lr:                 0.017743789625650205\n",
      "epoch:  93 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 89.00%\n",
      "    train overall loss:       4.074030796686809\n",
      "    train cross_ent loss:     1.0728068947792053\n",
      "    test overall loss:        3.956530809402466\n",
      "    test cross_ent loss:      0.9553104241689047\n",
      "    cluster loss:             2951.00390625\n",
      "    separation loss:          9.01691977183024\n",
      "    avg separation loss:      21.039315541585285\n",
      "    l1_addon loss:            40.67686080932617\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05720067024230957\n",
      "    test time:                0.012073040008544922\n",
      "    epoch time:               0.07043099403381348\n",
      "    joint lr:                 0.01659694329998293\n",
      "epoch:  94 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 90.33%\n",
      "    train overall loss:       4.012360122468737\n",
      "    train cross_ent loss:     1.0111313727166917\n",
      "    test overall loss:        3.98781951268514\n",
      "    test cross_ent loss:      0.986613392829895\n",
      "    cluster loss:             2951.0808919270835\n",
      "    separation loss:          9.422205607096354\n",
      "    avg separation loss:      20.31644566853841\n",
      "    l1_addon loss:            40.19464874267578\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05728554725646973\n",
      "    test time:                0.01209568977355957\n",
      "    epoch time:               0.07055997848510742\n",
      "    joint lr:                 0.01547126952186645\n",
      "epoch:  95 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 84.33%\n",
      "    train overall loss:       3.9918301900227866\n",
      "    train cross_ent loss:     0.9905931353569031\n",
      "    test overall loss:        4.446244239807129\n",
      "    test cross_ent loss:      1.4450422922770183\n",
      "    cluster loss:             2951.4484049479165\n",
      "    separation loss:          10.332927703857422\n",
      "    avg separation loss:      21.2435302734375\n",
      "    l1_addon loss:            40.053321838378906\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05689811706542969\n",
      "    test time:                0.01210927963256836\n",
      "    epoch time:               0.07021498680114746\n",
      "    joint lr:                 0.014366459524982304\n",
      "epoch:  96 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 85.33%\n",
      "    train overall loss:       4.212081776724921\n",
      "    train cross_ent loss:     1.2108480797873602\n",
      "    test overall loss:        4.213588396708171\n",
      "    test cross_ent loss:      1.212338964144389\n",
      "    cluster loss:             2951.3389485677085\n",
      "    separation loss:          9.91027577718099\n",
      "    avg separation loss:      21.475037892659504\n",
      "    l1_addon loss:            41.648765563964844\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.056815147399902344\n",
      "    test time:                0.012106657028198242\n",
      "    epoch time:               0.0701148509979248\n",
      "    joint lr:                 0.013282208601083652\n",
      "epoch:  97 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 93.67%\n",
      "    train overall loss:       4.005525880389744\n",
      "    train cross_ent loss:     1.0042896336979337\n",
      "    test overall loss:        3.85362442334493\n",
      "    test cross_ent loss:      0.852380653222402\n",
      "    cluster loss:             2951.1774088541665\n",
      "    separation loss:          9.637792905171713\n",
      "    avg separation loss:      20.53988202412923\n",
      "    l1_addon loss:            41.45471954345703\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.057146549224853516\n",
      "    test time:                0.012145757675170898\n",
      "    epoch time:               0.07048678398132324\n",
      "    joint lr:                 0.012218216049710476\n",
      "epoch:  98 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 94.33%\n",
      "    train overall loss:       3.9079034328460693\n",
      "    train cross_ent loss:     0.9066436092058817\n",
      "    test overall loss:        3.8578720887502036\n",
      "    test cross_ent loss:      0.8566212058067322\n",
      "    cluster loss:             2951.1322428385415\n",
      "    separation loss:          9.484705607096354\n",
      "    avg separation loss:      19.759260813395183\n",
      "    l1_addon loss:            41.68682861328125\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058363914489746094\n",
      "    test time:                0.012112140655517578\n",
      "    epoch time:               0.0712132453918457\n",
      "    joint lr:                 0.011174185128504639\n",
      "epoch:  99 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 94.33%\n",
      "    train overall loss:       3.6430499818589954\n",
      "    train cross_ent loss:     0.6417863998148177\n",
      "    test overall loss:        3.585088570912679\n",
      "    test cross_ent loss:      0.5838320851325989\n",
      "    cluster loss:             2950.9810384114585\n",
      "    separation loss:          8.882706960042318\n",
      "    avg separation loss:      18.477610905965168\n",
      "    l1_addon loss:            41.87086486816406\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05841875076293945\n",
      "    test time:                0.012190818786621094\n",
      "    epoch time:               0.07140326499938965\n",
      "    joint lr:                 0.010149823004117963\n",
      "epoch: 100 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       3.521608935462104\n",
      "    train cross_ent loss:     0.5203407771057553\n",
      "    test overall loss:        3.464391072591146\n",
      "    test cross_ent loss:      0.46312078833580017\n",
      "    cluster loss:             2950.8592122395835\n",
      "    separation loss:          8.019625345865885\n",
      "    avg separation loss:      16.441511154174805\n",
      "    l1_addon loss:            42.33246994018555\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05830049514770508\n",
      "    test time:                0.012212514877319336\n",
      "    epoch time:               0.0712594985961914\n",
      "    joint lr:                 0.009144840703706159\n",
      "epoch: 101 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 94.00%\n",
      "    train overall loss:       3.4022405412462025\n",
      "    train cross_ent loss:     0.40097106993198395\n",
      "    test overall loss:        3.5328118006388345\n",
      "    test cross_ent loss:      0.5315613150596619\n",
      "    cluster loss:             2950.841552734375\n",
      "    separation loss:          7.9186774889628095\n",
      "    avg separation loss:      15.661979675292969\n",
      "    l1_addon loss:            41.67181396484375\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058167457580566406\n",
      "    test time:                0.012134552001953125\n",
      "    epoch time:               0.07106900215148926\n",
      "    joint lr:                 0.008158953067002189\n",
      "epoch: 102 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 93.67%\n",
      "    train overall loss:       3.4303196801079645\n",
      "    train cross_ent loss:     0.4290510382917192\n",
      "    test overall loss:        3.3959487279256186\n",
      "    test cross_ent loss:      0.39466627438863117\n",
      "    cluster loss:             2950.7433268229165\n",
      "    separation loss:          7.371721108754476\n",
      "    avg separation loss:      14.699055671691895\n",
      "    l1_addon loss:            42.74275207519531\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.0581812858581543\n",
      "    test time:                0.012113332748413086\n",
      "    epoch time:               0.07101321220397949\n",
      "    joint lr:                 0.0071918786989619305\n",
      "epoch: 103 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       3.4553205966949463\n",
      "    train cross_ent loss:     0.45405157738261753\n",
      "    test overall loss:        3.454463243484497\n",
      "    test cross_ent loss:      0.4532262980937958\n",
      "    cluster loss:             2950.7981770833335\n",
      "    separation loss:          7.624151388804118\n",
      "    avg separation loss:      14.357763290405273\n",
      "    l1_addon loss:            41.226173400878906\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05862092971801758\n",
      "    test time:                0.012169599533081055\n",
      "    epoch time:               0.07158374786376953\n",
      "    joint lr:                 0.006243339922975775\n",
      "epoch: 104 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       3.377427657445272\n",
      "    train cross_ent loss:     0.3761603848801719\n",
      "    test overall loss:        3.285749594370524\n",
      "    test cross_ent loss:      0.284489373366038\n",
      "    cluster loss:             2950.6416829427085\n",
      "    separation loss:          7.0612867673238116\n",
      "    avg separation loss:      13.98081143697103\n",
      "    l1_addon loss:            42.00508117675781\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058300018310546875\n",
      "    test time:                0.012146234512329102\n",
      "    epoch time:               0.07124519348144531\n",
      "    joint lr:                 0.005313062734639446\n",
      "epoch: 105 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       3.2033230198754206\n",
      "    train cross_ent loss:     0.20205350799693\n",
      "    test overall loss:        3.3077025413513184\n",
      "    test cross_ent loss:      0.30645457406838733\n",
      "    cluster loss:             2950.6739908854165\n",
      "    separation loss:          7.18553352355957\n",
      "    avg separation loss:      13.874630610148111\n",
      "    l1_addon loss:            41.59098434448242\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05913972854614258\n",
      "    test time:                0.012655019760131836\n",
      "    epoch time:               0.07256031036376953\n",
      "    joint lr:                 0.004400776756077547\n",
      "epoch: 106 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       3.1382045480940075\n",
      "    train cross_ent loss:     0.1369379096561008\n",
      "    test overall loss:        3.22877566019694\n",
      "    test cross_ent loss:      0.22749080012241998\n",
      "    cluster loss:             2950.6044108072915\n",
      "    separation loss:          6.568556308746338\n",
      "    avg separation loss:      12.70650577545166\n",
      "    l1_addon loss:            42.821380615234375\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05921435356140137\n",
      "    test time:                0.012720346450805664\n",
      "    epoch time:               0.0727071762084961\n",
      "    joint lr:                 0.0035062151908134102\n",
      "epoch: 107 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       3.1025281217363148\n",
      "    train cross_ent loss:     0.1012583975162771\n",
      "    test overall loss:        3.2067509492238364\n",
      "    test cross_ent loss:      0.20549122740825018\n",
      "    cluster loss:             2950.5908203125\n",
      "    separation loss:          6.591754913330078\n",
      "    avg separation loss:      12.469139099121094\n",
      "    l1_addon loss:            41.985511779785156\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058960676193237305\n",
      "    test time:                0.012657880783081055\n",
      "    epoch time:               0.0723733901977539\n",
      "    joint lr:                 0.0026291147791789593\n",
      "epoch: 108 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       3.08183044857449\n",
      "    train cross_ent loss:     0.08056369568738672\n",
      "    test overall loss:        3.176681915918986\n",
      "    test cross_ent loss:      0.17541642735401788\n",
      "    cluster loss:             2950.552001953125\n",
      "    separation loss:          6.321372667948405\n",
      "    avg separation loss:      12.020557085673014\n",
      "    l1_addon loss:            42.17628479003906\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05887484550476074\n",
      "    test time:                0.012624025344848633\n",
      "    epoch time:               0.0723114013671875\n",
      "    joint lr:                 0.001769215754258106\n",
      "epoch: 109 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       3.03958879576789\n",
      "    train cross_ent loss:     0.03832364951570829\n",
      "    test overall loss:        3.1701528231302896\n",
      "    test cross_ent loss:      0.1688892294963201\n",
      "    cluster loss:             2950.548583984375\n",
      "    separation loss:          6.238725662231445\n",
      "    avg separation loss:      11.785303433736166\n",
      "    l1_addon loss:            42.10993957519531\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05927920341491699\n",
      "    test time:                0.012631416320800781\n",
      "    epoch time:               0.07269573211669922\n",
      "    joint lr:                 0.0009262617983577627\n",
      "epoch: 110 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       3.0428702566358776\n",
      "    train cross_ent loss:     0.0416063042357564\n",
      "    test overall loss:        3.1640424728393555\n",
      "    test cross_ent loss:      0.16277936597665152\n",
      "    cluster loss:             2950.5426432291665\n",
      "    separation loss:          6.2192606925964355\n",
      "    avg separation loss:      11.753469785054525\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05876040458679199\n",
      "    test time:                0.012117147445678711\n",
      "    epoch time:               0.0716400146484375\n",
      "    joint lr:                 0.0001\n",
      "epoch: 110 (PUSH) - ArticularyWordRecognition\n",
      "    test acc:                 94.67%\n",
      "    train overall loss:       3.0428702566358776\n",
      "    train cross_ent loss:     0.0416063042357564\n",
      "    test overall loss:        3.2082719008127847\n",
      "    test cross_ent loss:      0.20700877780715624\n",
      "    cluster loss:             2949.3180338541665\n",
      "    separation loss:          2.7912599245707193\n",
      "    avg separation loss:      7.456373373667399\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05876040458679199\n",
      "    test time:                0.012585163116455078\n",
      "    epoch time:               0.3782844543457031\n",
      "epoch: 110 (1/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 94.67%\n",
      "    train overall loss:       3.075990253024631\n",
      "    train cross_ent loss:     0.0766900707450178\n",
      "    test overall loss:        3.203284740447998\n",
      "    test cross_ent loss:      0.20633267114559808\n",
      "    cluster loss:             2949.3177083333335\n",
      "    separation loss:          2.7912853558858237\n",
      "    avg separation loss:      7.43550173441569\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  2995.68896484375\n",
      "    train time:               0.022994518280029297\n",
      "    test time:                0.012090921401977539\n",
      "    epoch time:               0.03556990623474121\n",
      "    last layer lr:            0.0007599999999999978\n",
      "epoch: 110 (2/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 94.67%\n",
      "    train overall loss:       3.03487671746148\n",
      "    train cross_ent loss:     0.05280955218606525\n",
      "    test overall loss:        3.166834990183512\n",
      "    test cross_ent loss:      0.20361321667830148\n",
      "    cluster loss:             2949.318115234375\n",
      "    separation loss:          2.8063810666402182\n",
      "    avg separation loss:      7.462000211079915\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  2961.958740234375\n",
      "    train time:               0.022527694702148438\n",
      "    test time:                0.012032270431518555\n",
      "    epoch time:               0.03503084182739258\n",
      "    last layer lr:            0.0014200000000000013\n",
      "epoch: 110 (3/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       3.0005720456441245\n",
      "    train cross_ent loss:     0.06578228395018312\n",
      "    test overall loss:        3.100088914235433\n",
      "    test cross_ent loss:      0.20077044889330864\n",
      "    cluster loss:             2949.3185221354165\n",
      "    separation loss:          2.8068719704945884\n",
      "    avg separation loss:      7.476383209228516\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  2898.055419921875\n",
      "    train time:               0.022522687911987305\n",
      "    test time:                0.012067556381225586\n",
      "    epoch time:               0.03505873680114746\n",
      "    last layer lr:            0.0020799999999999985\n",
      "epoch: 110 (4/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       2.921605428059896\n",
      "    train cross_ent loss:     0.0630622622039583\n",
      "    test overall loss:        3.003212292989095\n",
      "    test cross_ent loss:      0.19625412796934447\n",
      "    cluster loss:             2949.3177897135415\n",
      "    separation loss:          2.8080763022104898\n",
      "    avg separation loss:      7.4488175710042315\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  2805.695068359375\n",
      "    train time:               0.02245807647705078\n",
      "    test time:                0.012080907821655273\n",
      "    epoch time:               0.035009145736694336\n",
      "    last layer lr:            0.0027400000000000024\n",
      "epoch: 110 (5/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       2.818152560128106\n",
      "    train cross_ent loss:     0.06629823872612582\n",
      "    test overall loss:        2.8835860888163247\n",
      "    test cross_ent loss:      0.20069260026017824\n",
      "    cluster loss:             2949.3186848958335\n",
      "    separation loss:          2.8155644734700522\n",
      "    avg separation loss:      7.414564927419026\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  2681.63037109375\n",
      "    train time:               0.022444486618041992\n",
      "    test time:                0.012038707733154297\n",
      "    epoch time:               0.034955501556396484\n",
      "    last layer lr:            0.0034\n",
      "epoch: 110 (6/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       2.7001040246751575\n",
      "    train cross_ent loss:     0.0853310984869798\n",
      "    test overall loss:        2.740254799524943\n",
      "    test cross_ent loss:      0.20959065233667692\n",
      "    cluster loss:             2949.3190104166665\n",
      "    separation loss:          2.8177013397216797\n",
      "    avg separation loss:      7.430897235870361\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  2529.401123046875\n",
      "    train time:               0.022429466247558594\n",
      "    test time:                0.012033700942993164\n",
      "    epoch time:               0.03493356704711914\n",
      "    last layer lr:            0.004059999999999998\n",
      "epoch: 110 (7/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       2.51688469780816\n",
      "    train cross_ent loss:     0.06489423103630543\n",
      "    test overall loss:        2.56585955619812\n",
      "    test cross_ent loss:      0.21297602728009224\n",
      "    cluster loss:             2949.3186848958335\n",
      "    separation loss:          2.821530024210612\n",
      "    avg separation loss:      7.479934374491374\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  2351.62060546875\n",
      "    train time:               0.02279829978942871\n",
      "    test time:                0.012130975723266602\n",
      "    epoch time:               0.03542518615722656\n",
      "    last layer lr:            0.004720000000000002\n",
      "epoch: 110 (8/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       2.3390883869595\n",
      "    train cross_ent loss:     0.07785450294613838\n",
      "    test overall loss:        2.366533120473226\n",
      "    test cross_ent loss:      0.22035798306266466\n",
      "    cluster loss:             2949.3191731770835\n",
      "    separation loss:          2.8200599352518716\n",
      "    avg separation loss:      7.441038608551025\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  2144.912109375\n",
      "    train time:               0.022564172744750977\n",
      "    test time:                0.012114524841308594\n",
      "    epoch time:               0.035160064697265625\n",
      "    last layer lr:            0.005379999999999999\n",
      "epoch: 110 (9/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       2.1156797541512384\n",
      "    train cross_ent loss:     0.07527353200647566\n",
      "    test overall loss:        2.140569806098938\n",
      "    test cross_ent loss:      0.23097561299800873\n",
      "    cluster loss:             2949.3190104166665\n",
      "    separation loss:          2.8173524538675943\n",
      "    avg separation loss:      7.449664910634358\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  1908.3311767578125\n",
      "    train time:               0.023537158966064453\n",
      "    test time:                0.012646675109863281\n",
      "    epoch time:               0.03671121597290039\n",
      "    last layer lr:            0.006040000000000003\n",
      "epoch: 110 (10/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       1.8830238580703735\n",
      "    train cross_ent loss:     0.08992211230927044\n",
      "    test overall loss:        1.888081669807434\n",
      "    test cross_ent loss:      0.23946915194392204\n",
      "    cluster loss:             2949.3185221354165\n",
      "    separation loss:          2.812627077102661\n",
      "    avg separation loss:      7.459321180979411\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  1647.3494873046875\n",
      "    train time:               0.023778438568115234\n",
      "    test time:                0.012652397155761719\n",
      "    epoch time:               0.03695869445800781\n",
      "    last layer lr:            0.0067\n",
      "epoch: 110 (11/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       1.6081528928544786\n",
      "    train cross_ent loss:     0.08562717214226723\n",
      "    test overall loss:        1.6167259613672893\n",
      "    test cross_ent loss:      0.25183942789832753\n",
      "    cluster loss:             2949.318603515625\n",
      "    separation loss:          2.814887444178263\n",
      "    avg separation loss:      7.4582139650980634\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  1363.62353515625\n",
      "    train time:               0.023816347122192383\n",
      "    test time:                0.012641429901123047\n",
      "    epoch time:               0.03698444366455078\n",
      "    last layer lr:            0.0073599999999999985\n",
      "epoch: 110 (12/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       1.328405910068088\n",
      "    train cross_ent loss:     0.09953834551076095\n",
      "    test overall loss:        1.3232409556706746\n",
      "    test cross_ent loss:      0.26561779777208966\n",
      "    cluster loss:             2949.3186848958335\n",
      "    separation loss:          2.8168946901957193\n",
      "    avg separation loss:      7.437087217966716\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  1056.3602294921875\n",
      "    train time:               0.023693323135375977\n",
      "    test time:                0.012651205062866211\n",
      "    epoch time:               0.03685331344604492\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 110 (13/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       1.0076944298214383\n",
      "    train cross_ent loss:     0.10008550807833672\n",
      "    test overall loss:        1.0036466519037883\n",
      "    test cross_ent loss:      0.28308629244565964\n",
      "    cluster loss:             2949.3191731770835\n",
      "    separation loss:          2.822173992792765\n",
      "    avg separation loss:      7.457580089569092\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  719.2974243164062\n",
      "    train time:               0.02381300926208496\n",
      "    test time:                0.012572288513183594\n",
      "    epoch time:               0.03689694404602051\n",
      "    last layer lr:            0.008679999999999998\n",
      "epoch: 110 (14/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.6856176720725166\n",
      "    train cross_ent loss:     0.12820280508862603\n",
      "    test overall loss:        0.6718262135982513\n",
      "    test cross_ent loss:      0.3035991018017133\n",
      "    cluster loss:             2949.3196614583335\n",
      "    separation loss:          2.8210339546203613\n",
      "    avg separation loss:      7.4445374806722\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  366.9642028808594\n",
      "    train time:               0.023707866668701172\n",
      "    test time:                0.012571096420288086\n",
      "    epoch time:               0.03677678108215332\n",
      "    last layer lr:            0.009340000000000003\n",
      "epoch: 110 (15/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.3886979851457808\n",
      "    train cross_ent loss:     0.12370638300975163\n",
      "    test overall loss:        0.45606186985969543\n",
      "    test cross_ent loss:      0.28240828216075897\n",
      "    cluster loss:             2949.3187662760415\n",
      "    separation loss:          2.8155261675516763\n",
      "    avg separation loss:      7.445608615875244\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  172.39068603515625\n",
      "    train time:               0.023746490478515625\n",
      "    test time:                0.012575864791870117\n",
      "    epoch time:               0.03682565689086914\n",
      "    last layer lr:            0.01\n",
      "epoch: 110 (16/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.2359136094649633\n",
      "    train cross_ent loss:     0.10093008354306221\n",
      "    test overall loss:        0.363081693649292\n",
      "    test cross_ent loss:      0.2668778946002324\n",
      "    cluster loss:             2949.3193359375\n",
      "    separation loss:          2.8164193630218506\n",
      "    avg separation loss:      7.430693785349528\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  94.94091033935547\n",
      "    train time:               0.023677349090576172\n",
      "    test time:                0.012567281723022461\n",
      "    epoch time:               0.03674602508544922\n",
      "    last layer lr:            0.009604000000000001\n",
      "epoch: 110 (17/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.16539645774496925\n",
      "    train cross_ent loss:     0.0878589583767785\n",
      "    test overall loss:        0.2858165254195531\n",
      "    test cross_ent loss:      0.22777018199364343\n",
      "    cluster loss:             2949.31787109375\n",
      "    separation loss:          2.804461638132731\n",
      "    avg separation loss:      7.433712482452393\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  56.783470153808594\n",
      "    train time:               0.023810863494873047\n",
      "    test time:                0.012578010559082031\n",
      "    epoch time:               0.03689312934875488\n",
      "    last layer lr:            0.009208\n",
      "epoch: 110 (18/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.12017729795641369\n",
      "    train cross_ent loss:     0.0711443947835101\n",
      "    test overall loss:        0.2633706331253052\n",
      "    test cross_ent loss:      0.22566559414068857\n",
      "    cluster loss:             2949.3181966145835\n",
      "    separation loss:          2.8063712120056152\n",
      "    avg separation loss:      7.442288080851237\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  36.442169189453125\n",
      "    train time:               0.02367997169494629\n",
      "    test time:                0.012594938278198242\n",
      "    epoch time:               0.036783695220947266\n",
      "    last layer lr:            0.008812\n",
      "epoch: 110 (19/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.09850720647308561\n",
      "    train cross_ent loss:     0.06618910531202953\n",
      "    test overall loss:        0.24252366026242575\n",
      "    test cross_ent loss:      0.21549519151449203\n",
      "    cluster loss:             2949.3189290364585\n",
      "    separation loss:          2.81679630279541\n",
      "    avg separation loss:      7.470204512278239\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  25.765592575073242\n",
      "    train time:               0.023691892623901367\n",
      "    test time:                0.012580394744873047\n",
      "    epoch time:               0.036776065826416016\n",
      "    last layer lr:            0.008415999999999998\n",
      "epoch: 110 (20/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.0800907930566205\n",
      "    train cross_ent loss:     0.056445798526207604\n",
      "    test overall loss:        0.2261679247021675\n",
      "    test cross_ent loss:      0.20583255092302957\n",
      "    cluster loss:             2949.3182779947915\n",
      "    separation loss:          2.8137950897216797\n",
      "    avg separation loss:      7.43167765935262\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  19.07249641418457\n",
      "    train time:               0.023659229278564453\n",
      "    test time:                0.012569427490234375\n",
      "    epoch time:               0.036733150482177734\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 110 (21/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.07637781194514698\n",
      "    train cross_ent loss:     0.05820031919413143\n",
      "    test overall loss:        0.2173302893837293\n",
      "    test cross_ent loss:      0.20138327032327652\n",
      "    cluster loss:             2949.318115234375\n",
      "    separation loss:          2.8108412424723306\n",
      "    avg separation loss:      7.4049177169799805\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  14.684151649475098\n",
      "    train time:               0.023680925369262695\n",
      "    test time:                0.012559652328491211\n",
      "    epoch time:               0.03674435615539551\n",
      "    last layer lr:            0.007624000000000002\n",
      "epoch: 110 (22/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.08346826417578591\n",
      "    train cross_ent loss:     0.06780921895470884\n",
      "    test overall loss:        0.21213365097840628\n",
      "    test cross_ent loss:      0.19754073396325111\n",
      "    cluster loss:             2949.3182779947915\n",
      "    separation loss:          2.8123594919840493\n",
      "    avg separation loss:      7.4450907707214355\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  13.330047607421875\n",
      "    train time:               0.023674726486206055\n",
      "    test time:                0.012558221817016602\n",
      "    epoch time:               0.036733150482177734\n",
      "    last layer lr:            0.007228000000000001\n",
      "epoch: 110 (23/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.07761337773667441\n",
      "    train cross_ent loss:     0.06288594483501381\n",
      "    test overall loss:        0.20734583834807077\n",
      "    test cross_ent loss:      0.19396171470483145\n",
      "    cluster loss:             2949.3186848958335\n",
      "    separation loss:          2.8169284661610923\n",
      "    avg separation loss:      7.447892824808757\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  12.121248245239258\n",
      "    train time:               0.02365899085998535\n",
      "    test time:                0.01266169548034668\n",
      "    epoch time:               0.036826372146606445\n",
      "    last layer lr:            0.006832000000000001\n",
      "epoch: 110 (24/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.06990938033494684\n",
      "    train cross_ent loss:     0.05670806165370676\n",
      "    test overall loss:        0.2030432124932607\n",
      "    test cross_ent loss:      0.19042281433939934\n",
      "    cluster loss:             2949.318603515625\n",
      "    separation loss:          2.8113158543904624\n",
      "    avg separation loss:      7.426783561706543\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  11.357522964477539\n",
      "    train time:               0.023630619049072266\n",
      "    test time:                0.012810707092285156\n",
      "    epoch time:               0.0369415283203125\n",
      "    last layer lr:            0.006436\n",
      "epoch: 110 (25/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.06163470778200361\n",
      "    train cross_ent loss:     0.050127570827802025\n",
      "    test overall loss:        0.19864645476142564\n",
      "    test cross_ent loss:      0.188372282932202\n",
      "    cluster loss:             2949.31884765625\n",
      "    separation loss:          2.809359550476074\n",
      "    avg separation loss:      7.412932554880778\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  9.011293411254883\n",
      "    train time:               0.023807764053344727\n",
      "    test time:                0.012506961822509766\n",
      "    epoch time:               0.03680777549743652\n",
      "    last layer lr:            0.00604\n",
      "epoch: 110 (26/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.06701607298519877\n",
      "    train cross_ent loss:     0.05704908652438058\n",
      "    test overall loss:        0.19544950996836027\n",
      "    test cross_ent loss:      0.18583527704079947\n",
      "    cluster loss:             2949.318603515625\n",
      "    separation loss:          2.811171293258667\n",
      "    avg separation loss:      7.422338962554932\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  8.351362228393555\n",
      "    train time:               0.02240920066833496\n",
      "    test time:                0.012034893035888672\n",
      "    epoch time:               0.03490877151489258\n",
      "    last layer lr:            0.005644000000000002\n",
      "epoch: 110 (27/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.06147653588818179\n",
      "    train cross_ent loss:     0.05210472664071454\n",
      "    test overall loss:        0.1916049433251222\n",
      "    test cross_ent loss:      0.18226142724355063\n",
      "    cluster loss:             2949.3185221354165\n",
      "    separation loss:          2.8152631918589273\n",
      "    avg separation loss:      7.442905426025391\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  8.080644607543945\n",
      "    train time:               0.022385120391845703\n",
      "    test time:                0.01204991340637207\n",
      "    epoch time:               0.03490257263183594\n",
      "    last layer lr:            0.005248\n",
      "epoch: 110 (28/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.061336093892653785\n",
      "    train cross_ent loss:     0.05241165403276682\n",
      "    test overall loss:        0.1901940256357193\n",
      "    test cross_ent loss:      0.18176780765255293\n",
      "    cluster loss:             2949.3189290364585\n",
      "    separation loss:          2.816521644592285\n",
      "    avg separation loss:      7.458352724711101\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  7.163339614868164\n",
      "    train time:               0.022420644760131836\n",
      "    test time:                0.012028217315673828\n",
      "    epoch time:               0.034914255142211914\n",
      "    last layer lr:            0.004852000000000001\n",
      "epoch: 110 (29/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.05953049080239402\n",
      "    train cross_ent loss:     0.05063808254069752\n",
      "    test overall loss:        0.18682038908203444\n",
      "    test cross_ent loss:      0.17850876723726591\n",
      "    cluster loss:             2949.31787109375\n",
      "    separation loss:          2.8020431200663247\n",
      "    avg separation loss:      7.423046429951985\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  7.048745155334473\n",
      "    train time:               0.022574663162231445\n",
      "    test time:                0.012026071548461914\n",
      "    epoch time:               0.03506779670715332\n",
      "    last layer lr:            0.004455999999999999\n",
      "epoch: 110 (30/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.05921049353977045\n",
      "    train cross_ent loss:     0.051455245456761785\n",
      "    test overall loss:        0.18544752399126688\n",
      "    test cross_ent loss:      0.1778089702129364\n",
      "    cluster loss:             2949.3184407552085\n",
      "    separation loss:          2.8133464654286704\n",
      "    avg separation loss:      7.439533074696858\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  6.3756818771362305\n",
      "    train time:               0.022450685501098633\n",
      "    test time:                0.012044191360473633\n",
      "    epoch time:               0.03497004508972168\n",
      "    last layer lr:            0.004060000000000001\n",
      "epoch: 110 (31/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.05063920012778706\n",
      "    train cross_ent loss:     0.04205224600931009\n",
      "    test overall loss:        0.1852437543372313\n",
      "    test cross_ent loss:      0.1768300806482633\n",
      "    cluster loss:             2949.318603515625\n",
      "    separation loss:          2.818819761276245\n",
      "    avg separation loss:      7.472380638122559\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  7.150796890258789\n",
      "    train time:               0.02249908447265625\n",
      "    test time:                0.012040138244628906\n",
      "    epoch time:               0.035007476806640625\n",
      "    last layer lr:            0.0036640000000000015\n",
      "epoch: 110 (32/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.05285141782628165\n",
      "    train cross_ent loss:     0.04535364659710063\n",
      "    test overall loss:        0.1825233201185862\n",
      "    test cross_ent loss:      0.17588072891036668\n",
      "    cluster loss:             2949.3190104166665\n",
      "    separation loss:          2.823755900065104\n",
      "    avg separation loss:      7.461568355560303\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  5.3797197341918945\n",
      "    train time:               0.02247166633605957\n",
      "    test time:                0.012019157409667969\n",
      "    epoch time:               0.0349576473236084\n",
      "    last layer lr:            0.0032679999999999996\n",
      "epoch: 110 (33/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.07693195984595352\n",
      "    train cross_ent loss:     0.0701309254186021\n",
      "    test overall loss:        0.18329844623804092\n",
      "    test cross_ent loss:      0.17610139275590578\n",
      "    cluster loss:             2949.319580078125\n",
      "    separation loss:          2.8252572218577066\n",
      "    avg separation loss:      7.485405604044597\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  5.934179306030273\n",
      "    train time:               0.022628068923950195\n",
      "    test time:                0.012054204940795898\n",
      "    epoch time:               0.0351560115814209\n",
      "    last layer lr:            0.002872000000000001\n",
      "epoch: 110 (34/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.052279607910248965\n",
      "    train cross_ent loss:     0.04455097205936909\n",
      "    test overall loss:        0.18198582157492638\n",
      "    test cross_ent loss:      0.17482634882132211\n",
      "    cluster loss:             2949.3182779947915\n",
      "    separation loss:          2.8007285594940186\n",
      "    avg separation loss:      7.418270270029704\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  5.896598815917969\n",
      "    train time:               0.02247905731201172\n",
      "    test time:                0.012108564376831055\n",
      "    epoch time:               0.03505086898803711\n",
      "    last layer lr:            0.0024759999999999986\n",
      "epoch: 110 (35/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.05329473585718208\n",
      "    train cross_ent loss:     0.04648148863472872\n",
      "    test overall loss:        0.1806923747062683\n",
      "    test cross_ent loss:      0.17445254201690355\n",
      "    cluster loss:             2949.3185221354165\n",
      "    separation loss:          2.8048699696858725\n",
      "    avg separation loss:      7.428730010986328\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  4.976956844329834\n",
      "    train time:               0.022417068481445312\n",
      "    test time:                0.012009143829345703\n",
      "    epoch time:               0.034891366958618164\n",
      "    last layer lr:            0.0020800000000000003\n",
      "epoch: 110 (36/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.04581865999433729\n",
      "    train cross_ent loss:     0.04004538680116335\n",
      "    test overall loss:        0.178640382985274\n",
      "    test cross_ent loss:      0.17358182619015375\n",
      "    cluster loss:             2949.3180338541665\n",
      "    separation loss:          2.8007161617279053\n",
      "    avg separation loss:      7.428648471832275\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  3.795680522918701\n",
      "    train time:               0.022446393966674805\n",
      "    test time:                0.012067079544067383\n",
      "    epoch time:               0.03500843048095703\n",
      "    last layer lr:            0.0016840000000000017\n",
      "epoch: 110 (37/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.05699214225427972\n",
      "    train cross_ent loss:     0.05240846539123191\n",
      "    test overall loss:        0.177219337473313\n",
      "    test cross_ent loss:      0.17290098965168\n",
      "    cluster loss:             2949.3179524739585\n",
      "    separation loss:          2.8058478832244873\n",
      "    avg separation loss:      7.420687675476074\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  3.0554685592651367\n",
      "    train time:               0.022572755813598633\n",
      "    test time:                0.01205301284790039\n",
      "    epoch time:               0.035094261169433594\n",
      "    last layer lr:            0.0012879999999999994\n",
      "epoch: 110 (38/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.049478250452213816\n",
      "    train cross_ent loss:     0.04545383548571004\n",
      "    test overall loss:        0.17655975744128227\n",
      "    test cross_ent loss:      0.1726927049458027\n",
      "    cluster loss:             2949.3177897135415\n",
      "    separation loss:          2.80849822362264\n",
      "    avg separation loss:      7.421623229980469\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  2.6041769981384277\n",
      "    train time:               0.022440671920776367\n",
      "    test time:                0.012048482894897461\n",
      "    epoch time:               0.03496146202087402\n",
      "    last layer lr:            0.0008920000000000009\n",
      "epoch: 110 (39/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.03907227050513029\n",
      "    train cross_ent loss:     0.03556745871901512\n",
      "    test overall loss:        0.175953837732474\n",
      "    test cross_ent loss:      0.17273126045862833\n",
      "    cluster loss:             2949.3190104166665\n",
      "    separation loss:          2.820962349573771\n",
      "    avg separation loss:      7.45035187403361\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  1.9596995115280151\n",
      "    train time:               0.022440671920776367\n",
      "    test time:                0.01206660270690918\n",
      "    epoch time:               0.03497505187988281\n",
      "    last layer lr:            0.0004959999999999986\n",
      "epoch: 110 (40/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.05390061582956049\n",
      "    train cross_ent loss:     0.05088614299893379\n",
      "    test overall loss:        0.17489363004763922\n",
      "    test cross_ent loss:      0.17206325257817903\n",
      "    cluster loss:             2949.3177083333335\n",
      "    separation loss:          2.801063299179077\n",
      "    avg separation loss:      7.414519786834717\n",
      "    l1_addon loss:            42.09585189819336\n",
      "    l1 loss:                  1.5674991607666016\n",
      "    train time:               0.022452831268310547\n",
      "    test time:                0.012363910675048828\n",
      "    epoch time:               0.03528642654418945\n",
      "    last layer lr:            0.0001\n",
      "epoch: 111 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.057213963423338204\n",
      "    train cross_ent loss:     0.0543837555580669\n",
      "    test overall loss:        0.1736454851925373\n",
      "    test cross_ent loss:      0.17081531758109728\n",
      "    cluster loss:             2949.3170572916665\n",
      "    separation loss:          2.8015411694844565\n",
      "    avg separation loss:      7.425001621246338\n",
      "    l1_addon loss:            42.08878707885742\n",
      "    l1 loss:                  1.5674991607666016\n",
      "    train time:               0.05844879150390625\n",
      "    test time:                0.012117147445678711\n",
      "    epoch time:               0.07131123542785645\n",
      "    joint lr:                 0.0017196383771408863\n",
      "epoch: 112 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.04371586307469341\n",
      "    train cross_ent loss:     0.04088408944921361\n",
      "    test overall loss:        0.1585762488345305\n",
      "    test cross_ent loss:      0.15574468672275543\n",
      "    cluster loss:             2949.3148600260415\n",
      "    separation loss:          2.791954517364502\n",
      "    avg separation loss:      7.400227069854736\n",
      "    l1_addon loss:            42.135372161865234\n",
      "    l1 loss:                  1.5674991607666016\n",
      "    train time:               0.058243751525878906\n",
      "    test time:                0.012103796005249023\n",
      "    epoch time:               0.07106971740722656\n",
      "    joint lr:                 0.0033068839867389757\n",
      "epoch: 113 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.04290214449995094\n",
      "    train cross_ent loss:     0.04007087875571516\n",
      "    test overall loss:        0.14407184844215712\n",
      "    test cross_ent loss:      0.14123782515525818\n",
      "    cluster loss:             2949.3094075520835\n",
      "    separation loss:          2.7195235888163247\n",
      "    avg separation loss:      7.199591636657715\n",
      "    l1_addon loss:            42.21763229370117\n",
      "    l1 loss:                  1.5674991607666016\n",
      "    train time:               0.058376312255859375\n",
      "    test time:                0.012116193771362305\n",
      "    epoch time:               0.07123470306396484\n",
      "    joint lr:                 0.0048622227203073696\n",
      "epoch: 114 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.029044340054194134\n",
      "    train cross_ent loss:     0.026213801931589842\n",
      "    test overall loss:        0.14140188011030355\n",
      "    test cross_ent loss:      0.13857285057504973\n",
      "    cluster loss:             2949.3173828125\n",
      "    separation loss:          2.704305410385132\n",
      "    avg separation loss:      6.901096185048421\n",
      "    l1_addon loss:            42.050960540771484\n",
      "    l1 loss:                  1.5674991607666016\n",
      "    train time:               0.05845189094543457\n",
      "    test time:                0.012110710144042969\n",
      "    epoch time:               0.07135581970214844\n",
      "    joint lr:                 0.00638613399080572\n",
      "epoch: 115 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.03915373618817992\n",
      "    train cross_ent loss:     0.03632130194455385\n",
      "    test overall loss:        0.14219938218593597\n",
      "    test cross_ent loss:      0.1393717067937056\n",
      "    cluster loss:             2949.3226725260415\n",
      "    separation loss:          2.753262519836426\n",
      "    avg separation loss:      6.876779556274414\n",
      "    l1_addon loss:            42.0059700012207\n",
      "    l1 loss:                  1.5674991607666016\n",
      "    train time:               0.05819058418273926\n",
      "    test time:                0.01218271255493164\n",
      "    epoch time:               0.07118797302246094\n",
      "    joint lr:                 0.007879090813622073\n",
      "epoch: 116 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 91.00%\n",
      "    train overall loss:       0.11668241541418764\n",
      "    train cross_ent loss:     0.11385735103653537\n",
      "    test overall loss:        0.4105430742104848\n",
      "    test cross_ent loss:      0.40774088601271313\n",
      "    cluster loss:             2949.4990234375\n",
      "    separation loss:          3.229586124420166\n",
      "    avg separation loss:      7.399116516113281\n",
      "    l1_addon loss:            41.156158447265625\n",
      "    l1 loss:                  1.5674991607666016\n",
      "    train time:               0.05822396278381348\n",
      "    test time:                0.012109518051147461\n",
      "    epoch time:               0.07110023498535156\n",
      "    joint lr:                 0.009341559886583039\n",
      "epoch: 117 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.2887658625841141\n",
      "    train cross_ent loss:     0.28593892686896855\n",
      "    test overall loss:        0.3973138729731242\n",
      "    test cross_ent loss:      0.39447852472464245\n",
      "    cluster loss:             2949.591064453125\n",
      "    separation loss:          3.588314692179362\n",
      "    avg separation loss:      8.765979766845703\n",
      "    l1_addon loss:            42.26146697998047\n",
      "    l1 loss:                  1.5674991607666016\n",
      "    train time:               0.05826401710510254\n",
      "    test time:                0.012123823165893555\n",
      "    epoch time:               0.07117772102355957\n",
      "    joint lr:                 0.010774001669003403\n",
      "epoch: 118 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 92.67%\n",
      "    train overall loss:       0.33863794638050926\n",
      "    train cross_ent loss:     0.3358095669084125\n",
      "    test overall loss:        0.38234053055445355\n",
      "    test cross_ent loss:      0.37952737261851627\n",
      "    cluster loss:             2949.5878092447915\n",
      "    separation loss:          4.141338030497233\n",
      "    avg separation loss:      9.43455982208252\n",
      "    l1_addon loss:            41.52198028564453\n",
      "    l1 loss:                  1.5674991607666016\n",
      "    train time:               0.05827927589416504\n",
      "    test time:                0.012117385864257812\n",
      "    epoch time:               0.07113242149353027\n",
      "    joint lr:                 0.012176870459786701\n",
      "epoch: 119 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.4784695936573876\n",
      "    train cross_ent loss:     0.4756376047929128\n",
      "    test overall loss:        0.43842531740665436\n",
      "    test cross_ent loss:      0.4355801194906235\n",
      "    cluster loss:             2949.6905924479165\n",
      "    separation loss:          4.618993759155273\n",
      "    avg separation loss:      10.61577065785726\n",
      "    l1_addon loss:            42.590110778808594\n",
      "    l1 loss:                  1.5674991607666016\n",
      "    train time:               0.05859255790710449\n",
      "    test time:                0.012089967727661133\n",
      "    epoch time:               0.07144427299499512\n",
      "    joint lr:                 0.013550614474587434\n",
      "epoch: 120 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.5076880604028702\n",
      "    train cross_ent loss:     0.5048477517233955\n",
      "    test overall loss:        0.40099411209424335\n",
      "    test cross_ent loss:      0.39815818270047504\n",
      "    cluster loss:             2949.712646484375\n",
      "    separation loss:          4.735742410024007\n",
      "    avg separation loss:      10.932754198710123\n",
      "    l1_addon loss:            42.2808837890625\n",
      "    l1 loss:                  1.5674991607666016\n",
      "    train time:               0.058475494384765625\n",
      "    test time:                0.012142658233642578\n",
      "    epoch time:               0.07142329216003418\n",
      "    joint lr:                 0.014895675922046181\n",
      "epoch: 121 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       0.41594139734903973\n",
      "    train cross_ent loss:     0.41310269633928937\n",
      "    test overall loss:        0.4192773352066676\n",
      "    test cross_ent loss:      0.416448915998141\n",
      "    cluster loss:             2949.7920735677085\n",
      "    separation loss:          5.034637610117595\n",
      "    avg separation loss:      11.517430941263834\n",
      "    l1_addon loss:            42.03082275390625\n",
      "    l1 loss:                  1.5674991607666016\n",
      "    train time:               0.05816364288330078\n",
      "    test time:                0.012102127075195312\n",
      "    epoch time:               0.07097363471984863\n",
      "    joint lr:                 0.014015333204684437\n",
      "epoch: 122 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 94.00%\n",
      "    train overall loss:       0.49254444738229114\n",
      "    train cross_ent loss:     0.48970846169524723\n",
      "    test overall loss:        0.46382637321949005\n",
      "    test cross_ent loss:      0.4609993149836858\n",
      "    cluster loss:             2949.9169921875\n",
      "    separation loss:          5.2074917157491045\n",
      "    avg separation loss:      11.531386693318685\n",
      "    l1_addon loss:            41.986106872558594\n",
      "    l1 loss:                  1.5674991607666016\n",
      "    train time:               0.0581820011138916\n",
      "    test time:                0.012158870697021484\n",
      "    epoch time:               0.07111287117004395\n",
      "    joint lr:                 0.01315111777407772\n",
      "epoch: 123 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.5560359027650621\n",
      "    train cross_ent loss:     0.5531849281655418\n",
      "    test overall loss:        0.4994586855173111\n",
      "    test cross_ent loss:      0.4965966393550237\n",
      "    cluster loss:             2949.9835611979165\n",
      "    separation loss:          5.459039370218913\n",
      "    avg separation loss:      12.319883028666178\n",
      "    l1_addon loss:            43.152374267578125\n",
      "    l1 loss:                  1.5674991607666016\n",
      "    train time:               0.06084299087524414\n",
      "    test time:                0.012389898300170898\n",
      "    epoch time:               0.07394909858703613\n",
      "    joint lr:                 0.012302795118762673\n",
      "epoch: 124 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.6071879731284248\n",
      "    train cross_ent loss:     0.6043358246485392\n",
      "    test overall loss:        0.5985849698384603\n",
      "    test cross_ent loss:      0.5957360963026682\n",
      "    cluster loss:             2950.098876953125\n",
      "    separation loss:          5.642997582753499\n",
      "    avg separation loss:      12.63628355662028\n",
      "    l1_addon loss:            42.71357345581055\n",
      "    l1 loss:                  1.5674991607666016\n",
      "    train time:               0.0600430965423584\n",
      "    test time:                0.012192726135253906\n",
      "    epoch time:               0.0729374885559082\n",
      "    joint lr:                 0.011470133804776505\n",
      "epoch: 125 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 94.33%\n",
      "    train overall loss:       0.4657651384671529\n",
      "    train cross_ent loss:     0.46291811929808724\n",
      "    test overall loss:        0.6619695325692495\n",
      "    test cross_ent loss:      0.6591560045878092\n",
      "    cluster loss:             2950.28857421875\n",
      "    separation loss:          6.006819248199463\n",
      "    avg separation loss:      12.85695711771647\n",
      "    l1_addon loss:            41.53491973876953\n",
      "    l1 loss:                  1.5674991607666016\n",
      "    train time:               0.06033611297607422\n",
      "    test time:                0.012147188186645508\n",
      "    epoch time:               0.0731961727142334\n",
      "    joint lr:                 0.010652905437558197\n",
      "epoch: 126 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.5026062577962875\n",
      "    train cross_ent loss:     0.49977262483702767\n",
      "    test overall loss:        0.5052840113639832\n",
      "    test cross_ent loss:      0.5024335285027822\n",
      "    cluster loss:             2950.0999348958335\n",
      "    separation loss:          5.414933840433757\n",
      "    avg separation loss:      12.818280220031738\n",
      "    l1_addon loss:            42.76605987548828\n",
      "    l1 loss:                  1.5674991607666016\n",
      "    train time:               0.060009002685546875\n",
      "    test time:                0.012215614318847656\n",
      "    epoch time:               0.07289433479309082\n",
      "    joint lr:                 0.009850884624303774\n",
      "epoch: 127 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.3310310228003396\n",
      "    train cross_ent loss:     0.3281891428762012\n",
      "    test overall loss:        0.38444624344507855\n",
      "    test cross_ent loss:      0.3816193441549937\n",
      "    cluster loss:             2950.0282389322915\n",
      "    separation loss:          5.191649436950684\n",
      "    avg separation loss:      11.601910591125488\n",
      "    l1_addon loss:            41.979278564453125\n",
      "    l1 loss:                  1.5674991607666016\n",
      "    train time:               0.059795379638671875\n",
      "    test time:                0.012147903442382812\n",
      "    epoch time:               0.07263660430908203\n",
      "    joint lr:                 0.00906384893677068\n",
      "epoch: 128 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 94.00%\n",
      "    train overall loss:       0.3110187103350957\n",
      "    train cross_ent loss:     0.30818608899911243\n",
      "    test overall loss:        0.42310193181037903\n",
      "    test cross_ent loss:      0.4202402929464976\n",
      "    cluster loss:             2949.9903971354165\n",
      "    separation loss:          4.829509258270264\n",
      "    avg separation loss:      11.025236129760742\n",
      "    l1_addon loss:            43.1378059387207\n",
      "    l1 loss:                  1.5674991607666016\n",
      "    train time:               0.06032919883728027\n",
      "    test time:                0.012232303619384766\n",
      "    epoch time:               0.07328104972839355\n",
      "    joint lr:                 0.00829157887452582\n",
      "epoch: 129 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 90.67%\n",
      "    train overall loss:       0.45007346239354873\n",
      "    train cross_ent loss:     0.4472344352139367\n",
      "    test overall loss:        0.5597193638483683\n",
      "    test cross_ent loss:      0.556865006685257\n",
      "    cluster loss:             2950.057861328125\n",
      "    separation loss:          5.125586827596028\n",
      "    avg separation loss:      11.863030433654785\n",
      "    l1_addon loss:            42.89537048339844\n",
      "    l1 loss:                  1.5674991607666016\n",
      "    train time:               0.06016731262207031\n",
      "    test time:                0.012131929397583008\n",
      "    epoch time:               0.07295489311218262\n",
      "    joint lr:                 0.007533857828632187\n",
      "epoch: 130 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 93.00%\n",
      "    train overall loss:       0.3983927567799886\n",
      "    train cross_ent loss:     0.39555976622634464\n",
      "    test overall loss:        0.4359282950560252\n",
      "    test cross_ent loss:      0.43311334649721783\n",
      "    cluster loss:             2949.984375\n",
      "    separation loss:          5.034640868504842\n",
      "    avg separation loss:      10.865791320800781\n",
      "    l1_addon loss:            41.58097839355469\n",
      "    l1 loss:                  1.5674991607666016\n",
      "    train time:               0.060094356536865234\n",
      "    test time:                0.012144088745117188\n",
      "    epoch time:               0.07291793823242188\n",
      "    joint lr:                 0.00679047204576897\n",
      "epoch: 131 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.2656198665499687\n",
      "    train cross_ent loss:     0.2627946096989844\n",
      "    test overall loss:        0.3147660990556081\n",
      "    test cross_ent loss:      0.3119501968224843\n",
      "    cluster loss:             2949.9434407552085\n",
      "    separation loss:          4.9541122118632\n",
      "    avg separation loss:      10.995179176330566\n",
      "    l1_addon loss:            41.6134033203125\n",
      "    l1 loss:                  1.5674991607666016\n",
      "    train time:               0.06043815612792969\n",
      "    test time:                0.012158632278442383\n",
      "    epoch time:               0.07330584526062012\n",
      "    joint lr:                 0.006061210592780146\n",
      "epoch: 132 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.19681005345450509\n",
      "    train cross_ent loss:     0.1939760148525238\n",
      "    test overall loss:        0.20167137930790582\n",
      "    test cross_ent loss:      0.19884206602970758\n",
      "    cluster loss:             2949.8602701822915\n",
      "    separation loss:          4.363250096638997\n",
      "    avg separation loss:      9.682536443074545\n",
      "    l1_addon loss:            42.06050491333008\n",
      "    l1 loss:                  1.5674991607666016\n",
      "    train time:               0.06019163131713867\n",
      "    test time:                0.01212930679321289\n",
      "    epoch time:               0.07305169105529785\n",
      "    joint lr:                 0.005345865321646531\n",
      "epoch: 133 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.07793780954347716\n",
      "    train cross_ent loss:     0.07510436409049565\n",
      "    test overall loss:        0.16528702651460966\n",
      "    test cross_ent loss:      0.16245117411017418\n",
      "    cluster loss:             2949.80908203125\n",
      "    separation loss:          4.120875914891561\n",
      "    avg separation loss:      9.337936719258627\n",
      "    l1_addon loss:            42.278343200683594\n",
      "    l1 loss:                  1.5674991607666016\n",
      "    train time:               0.06003856658935547\n",
      "    test time:                0.012141942977905273\n",
      "    epoch time:               0.0728306770324707\n",
      "    joint lr:                 0.00464423083487631\n",
      "epoch: 134 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.055672490348418556\n",
      "    train cross_ent loss:     0.05283878267639213\n",
      "    test overall loss:        0.1712698812286059\n",
      "    test cross_ent loss:      0.16843444854021072\n",
      "    cluster loss:             2949.7867838541665\n",
      "    separation loss:          3.8474526405334473\n",
      "    avg separation loss:      9.012016296386719\n",
      "    l1_addon loss:            42.26424026489258\n",
      "    l1 loss:                  1.5674991607666016\n",
      "    train time:               0.06029629707336426\n",
      "    test time:                0.012250900268554688\n",
      "    epoch time:               0.07325458526611328\n",
      "    joint lr:                 0.003956104451309328\n",
      "epoch: 135 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.04374798759818077\n",
      "    train cross_ent loss:     0.040914849274688296\n",
      "    test overall loss:        0.14044162382682165\n",
      "    test cross_ent loss:      0.13761050874988237\n",
      "    cluster loss:             2949.7783203125\n",
      "    separation loss:          3.7755203247070312\n",
      "    avg separation loss:      8.689399083455404\n",
      "    l1_addon loss:            42.120506286621094\n",
      "    l1 loss:                  1.5674991607666016\n",
      "    train time:               0.06113481521606445\n",
      "    test time:                0.01219630241394043\n",
      "    epoch time:               0.07401061058044434\n",
      "    joint lr:                 0.0032812861723301896\n",
      "epoch: 136 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.024196718612478837\n",
      "    train cross_ent loss:     0.021369479389654264\n",
      "    test overall loss:        0.1317282331486543\n",
      "    test cross_ent loss:      0.12889295692245165\n",
      "    cluster loss:             2949.7576497395835\n",
      "    separation loss:          3.6740614573160806\n",
      "    avg separation loss:      8.364704132080078\n",
      "    l1_addon loss:            42.25935745239258\n",
      "    l1 loss:                  1.5674991607666016\n",
      "    train time:               0.06015324592590332\n",
      "    test time:                0.012161493301391602\n",
      "    epoch time:               0.07300138473510742\n",
      "    joint lr:                 0.0026195786484855114\n",
      "epoch: 137 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.01802857540961769\n",
      "    train cross_ent loss:     0.015189780181066858\n",
      "    test overall loss:        0.1412340278426806\n",
      "    test cross_ent loss:      0.13839464324216047\n",
      "    cluster loss:             2949.7537434895835\n",
      "    separation loss:          3.6093764305114746\n",
      "    avg separation loss:      8.148455301920572\n",
      "    l1_addon loss:            42.39607238769531\n",
      "    l1 loss:                  1.5674991607666016\n",
      "    train time:               0.061312198638916016\n",
      "    test time:                0.01310276985168457\n",
      "    epoch time:               0.07518458366394043\n",
      "    joint lr:                 0.0019707871465004943\n",
      "epoch: 138 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.012450177067269882\n",
      "    train cross_ent loss:     0.009612695831391547\n",
      "    test overall loss:        0.1356421516587337\n",
      "    test cross_ent loss:      0.1328074565778176\n",
      "    cluster loss:             2949.7493489583335\n",
      "    separation loss:          3.5855795542399087\n",
      "    avg separation loss:      8.099926312764486\n",
      "    l1_addon loss:            42.239990234375\n",
      "    l1 loss:                  1.5674991607666016\n",
      "    train time:               0.060808658599853516\n",
      "    test time:                0.012643098831176758\n",
      "    epoch time:               0.07418251037597656\n",
      "    joint lr:                 0.0013347195166903292\n",
      "epoch: 139 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.009342464359684123\n",
      "    train cross_ent loss:     0.006509256212868624\n",
      "    test overall loss:        0.13334105287988982\n",
      "    test cross_ent loss:      0.1305085364729166\n",
      "    cluster loss:             2949.7491048177085\n",
      "    separation loss:          3.5717787742614746\n",
      "    avg separation loss:      8.039218584696451\n",
      "    l1_addon loss:            42.16716766357422\n",
      "    l1 loss:                  1.5674991607666016\n",
      "    train time:               0.06123971939086914\n",
      "    test time:                0.012629270553588867\n",
      "    epoch time:               0.07458305358886719\n",
      "    joint lr:                 0.0007111861607617089\n",
      "epoch: 140 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.013310628787924847\n",
      "    train cross_ent loss:     0.010477517498657107\n",
      "    test overall loss:        0.1325916312634945\n",
      "    test cross_ent loss:      0.12975738383829594\n",
      "    cluster loss:             2949.7445475260415\n",
      "    separation loss:          3.5461023648579917\n",
      "    avg separation loss:      8.022265752156576\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  1.5674991607666016\n",
      "    train time:               0.06136918067932129\n",
      "    test time:                0.012627124786376953\n",
      "    epoch time:               0.07469892501831055\n",
      "    joint lr:                 0.0001\n",
      "epoch: 140 (PUSH) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.013310628787924847\n",
      "    train cross_ent loss:     0.010477517498657107\n",
      "    test overall loss:        0.15031118566791216\n",
      "    test cross_ent loss:      0.14747694072624049\n",
      "    cluster loss:             2949.3101399739585\n",
      "    separation loss:          2.6897195180257163\n",
      "    avg separation loss:      7.032641410827637\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  1.5674991607666016\n",
      "    train time:               0.06136918067932129\n",
      "    test time:                0.012897014617919922\n",
      "    epoch time:               0.3579859733581543\n",
      "epoch: 140 (1/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.03474420226282544\n",
      "    train cross_ent loss:     0.032126235568688974\n",
      "    test overall loss:        0.1505731555322806\n",
      "    test cross_ent loss:      0.14815778471529484\n",
      "    cluster loss:             2949.3109537760415\n",
      "    separation loss:          2.6886433760325112\n",
      "    avg separation loss:      7.047988573710124\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  1.1486197710037231\n",
      "    train time:               0.024628162384033203\n",
      "    test time:                0.012677669525146484\n",
      "    epoch time:               0.037825822830200195\n",
      "    last layer lr:            0.0007599999999999978\n",
      "epoch: 140 (2/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.03211929752594895\n",
      "    train cross_ent loss:     0.02898834625052081\n",
      "    test overall loss:        0.1502410794297854\n",
      "    test cross_ent loss:      0.1470628846436739\n",
      "    cluster loss:             2949.31103515625\n",
      "    separation loss:          2.6911394596099854\n",
      "    avg separation loss:      7.03640874226888\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  1.911452054977417\n",
      "    train time:               0.024196863174438477\n",
      "    test time:                0.012600421905517578\n",
      "    epoch time:               0.03731060028076172\n",
      "    last layer lr:            0.0014199999999999955\n",
      "epoch: 140 (3/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.03257243076546325\n",
      "    train cross_ent loss:     0.029205097609923944\n",
      "    test overall loss:        0.1505254531900088\n",
      "    test cross_ent loss:      0.14726215973496437\n",
      "    cluster loss:             2949.31103515625\n",
      "    separation loss:          2.6895996729532876\n",
      "    avg separation loss:      7.041989962259929\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  1.9965462684631348\n",
      "    train time:               0.024341821670532227\n",
      "    test time:                0.012567996978759766\n",
      "    epoch time:               0.037419795989990234\n",
      "    last layer lr:            0.0020800000000000046\n",
      "epoch: 140 (4/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.037665770285659365\n",
      "    train cross_ent loss:     0.03406814506484403\n",
      "    test overall loss:        0.15056764458616576\n",
      "    test cross_ent loss:      0.14664274081587791\n",
      "    cluster loss:             2949.310546875\n",
      "    separation loss:          2.691911538441976\n",
      "    avg separation loss:      7.033559163411458\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  2.6581544876098633\n",
      "    train time:               0.024232864379882812\n",
      "    test time:                0.012570619583129883\n",
      "    epoch time:               0.03731822967529297\n",
      "    last layer lr:            0.0027400000000000024\n",
      "epoch: 140 (5/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.03641356693373786\n",
      "    train cross_ent loss:     0.03191537751505772\n",
      "    test overall loss:        0.14976105963190398\n",
      "    test cross_ent loss:      0.14498526913424334\n",
      "    cluster loss:             2949.3111165364585\n",
      "    separation loss:          2.6982521216074624\n",
      "    avg separation loss:      7.042527516682942\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  3.509044885635376\n",
      "    train time:               0.02422475814819336\n",
      "    test time:                0.012594223022460938\n",
      "    epoch time:               0.0373380184173584\n",
      "    last layer lr:            0.0034\n",
      "epoch: 140 (6/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.041134404432442456\n",
      "    train cross_ent loss:     0.035965492121047445\n",
      "    test overall loss:        0.14982682714859644\n",
      "    test cross_ent loss:      0.14439569786190987\n",
      "    cluster loss:             2949.3108723958335\n",
      "    separation loss:          2.6913061141967773\n",
      "    avg separation loss:      7.022445837656657\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  4.1643829345703125\n",
      "    train time:               0.024129867553710938\n",
      "    test time:                0.0126190185546875\n",
      "    epoch time:               0.037261962890625\n",
      "    last layer lr:            0.004059999999999998\n",
      "epoch: 140 (7/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.03680350879828135\n",
      "    train cross_ent loss:     0.030783801960448425\n",
      "    test overall loss:        0.15008999531467757\n",
      "    test cross_ent loss:      0.14363859655956426\n",
      "    cluster loss:             2949.3107096354165\n",
      "    separation loss:          2.6925886472066245\n",
      "    avg separation loss:      7.024770259857178\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  5.184656143188477\n",
      "    train time:               0.02418661117553711\n",
      "    test time:                0.01267695426940918\n",
      "    epoch time:               0.037374019622802734\n",
      "    last layer lr:            0.004719999999999996\n",
      "epoch: 140 (8/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.03628381548656358\n",
      "    train cross_ent loss:     0.029888372247417767\n",
      "    test overall loss:        0.14899542555212975\n",
      "    test cross_ent loss:      0.14201934511462846\n",
      "    cluster loss:             2949.3109537760415\n",
      "    separation loss:          2.694594462712606\n",
      "    avg separation loss:      7.021485328674316\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  5.70933198928833\n",
      "    train time:               0.024376392364501953\n",
      "    test time:                0.012583255767822266\n",
      "    epoch time:               0.03747057914733887\n",
      "    last layer lr:            0.0053800000000000054\n",
      "epoch: 140 (9/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.0336062146557702\n",
      "    train cross_ent loss:     0.02615887237091859\n",
      "    test overall loss:        0.14908419052759805\n",
      "    test cross_ent loss:      0.14218484920759997\n",
      "    cluster loss:             2949.3102213541665\n",
      "    separation loss:          2.6883757909139\n",
      "    avg separation loss:      7.016293525695801\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  5.632596015930176\n",
      "    train time:               0.024329662322998047\n",
      "    test time:                0.012577056884765625\n",
      "    epoch time:               0.0374150276184082\n",
      "    last layer lr:            0.006040000000000003\n",
      "epoch: 140 (10/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.028509947264360055\n",
      "    train cross_ent loss:     0.021322698487589758\n",
      "    test overall loss:        0.1489098034799099\n",
      "    test cross_ent loss:      0.14180604616800943\n",
      "    cluster loss:             2949.310546875\n",
      "    separation loss:          2.6885833740234375\n",
      "    avg separation loss:      7.023452917734782\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  5.837014198303223\n",
      "    train time:               0.02415323257446289\n",
      "    test time:                0.012566566467285156\n",
      "    epoch time:               0.03723287582397461\n",
      "    last layer lr:            0.0067\n",
      "epoch: 140 (11/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.029443241448865995\n",
      "    train cross_ent loss:     0.022255699667665694\n",
      "    test overall loss:        0.14810093740622202\n",
      "    test cross_ent loss:      0.1409918194015821\n",
      "    cluster loss:             2949.3111165364585\n",
      "    separation loss:          2.688610076904297\n",
      "    avg separation loss:      7.0357716878255205\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  5.842369079589844\n",
      "    train time:               0.024364471435546875\n",
      "    test time:                0.012600898742675781\n",
      "    epoch time:               0.03747367858886719\n",
      "    last layer lr:            0.0073599999999999985\n",
      "epoch: 140 (12/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.031170165580179956\n",
      "    train cross_ent loss:     0.02396245900955465\n",
      "    test overall loss:        0.1483020174006621\n",
      "    test cross_ent loss:      0.14054541351894537\n",
      "    cluster loss:             2949.310791015625\n",
      "    separation loss:          2.690063953399658\n",
      "    avg separation loss:      7.034160772959392\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  6.489853858947754\n",
      "    train time:               0.0241701602935791\n",
      "    test time:                0.012613058090209961\n",
      "    epoch time:               0.03729605674743652\n",
      "    last layer lr:            0.008019999999999994\n",
      "epoch: 140 (13/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.029051818574468296\n",
      "    train cross_ent loss:     0.020936405182712607\n",
      "    test overall loss:        0.1482739013930162\n",
      "    test cross_ent loss:      0.13978797507782778\n",
      "    cluster loss:             2949.310302734375\n",
      "    separation loss:          2.688213030497233\n",
      "    avg separation loss:      7.021237850189209\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  7.21917724609375\n",
      "    train time:               0.02420639991760254\n",
      "    test time:                0.012605905532836914\n",
      "    epoch time:               0.03732562065124512\n",
      "    last layer lr:            0.008680000000000005\n",
      "epoch: 140 (14/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.031088853668835428\n",
      "    train cross_ent loss:     0.022725828509363864\n",
      "    test overall loss:        0.14825715497136116\n",
      "    test cross_ent loss:      0.13949387210110822\n",
      "    cluster loss:             2949.3102213541665\n",
      "    separation loss:          2.6912280718485513\n",
      "    avg separation loss:      7.0062492688496905\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  7.496537208557129\n",
      "    train time:               0.024155855178833008\n",
      "    test time:                0.012581586837768555\n",
      "    epoch time:               0.037247419357299805\n",
      "    last layer lr:            0.009340000000000003\n",
      "epoch: 140 (15/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.025812607672479417\n",
      "    train cross_ent loss:     0.01676658271915383\n",
      "    test overall loss:        0.14603998512029648\n",
      "    test cross_ent loss:      0.1375001147389412\n",
      "    cluster loss:             2949.3104654947915\n",
      "    separation loss:          2.6921472549438477\n",
      "    avg separation loss:      7.0132527351379395\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  7.273126125335693\n",
      "    train time:               0.024188756942749023\n",
      "    test time:                0.012627124786376953\n",
      "    epoch time:               0.03732562065124512\n",
      "    last layer lr:            0.01\n",
      "epoch: 140 (16/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.03702638132704629\n",
      "    train cross_ent loss:     0.02740166460474332\n",
      "    test overall loss:        0.1491200216114521\n",
      "    test cross_ent loss:      0.13879856715599695\n",
      "    cluster loss:             2949.3103841145835\n",
      "    separation loss:          2.700176556905111\n",
      "    avg separation loss:      7.037423451741536\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  9.054710388183594\n",
      "    train time:               0.024196863174438477\n",
      "    test time:                0.01260066032409668\n",
      "    epoch time:               0.03730940818786621\n",
      "    last layer lr:            0.009604000000000001\n",
      "epoch: 140 (17/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.02911323257204559\n",
      "    train cross_ent loss:     0.018827340863127675\n",
      "    test overall loss:        0.14776872098445892\n",
      "    test cross_ent loss:      0.1381278478850921\n",
      "    cluster loss:             2949.310302734375\n",
      "    separation loss:          2.692933718363444\n",
      "    avg separation loss:      7.032206694285075\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  8.374129295349121\n",
      "    train time:               0.024277448654174805\n",
      "    test time:                0.012601137161254883\n",
      "    epoch time:               0.03738903999328613\n",
      "    last layer lr:            0.009208000000000003\n",
      "epoch: 140 (18/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.031915744559632406\n",
      "    train cross_ent loss:     0.02230669775356849\n",
      "    test overall loss:        0.1453229325513045\n",
      "    test cross_ent loss:      0.1359348315745592\n",
      "    cluster loss:             2949.3109537760415\n",
      "    separation loss:          2.695558786392212\n",
      "    avg separation loss:      7.028576850891113\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  8.12134838104248\n",
      "    train time:               0.024200916290283203\n",
      "    test time:                0.012665510177612305\n",
      "    epoch time:               0.03737807273864746\n",
      "    last layer lr:            0.008811999999999997\n",
      "epoch: 140 (19/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.03563433409565025\n",
      "    train cross_ent loss:     0.025550917204883363\n",
      "    test overall loss:        0.1470111347734928\n",
      "    test cross_ent loss:      0.13754375092685223\n",
      "    cluster loss:             2949.3108723958335\n",
      "    separation loss:          2.6983041763305664\n",
      "    avg separation loss:      7.0357638994852705\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  8.200637817382812\n",
      "    train time:               0.024148941040039062\n",
      "    test time:                0.012568473815917969\n",
      "    epoch time:               0.03723454475402832\n",
      "    last layer lr:            0.008415999999999998\n",
      "epoch: 140 (20/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.02960697002708912\n",
      "    train cross_ent loss:     0.020365235395729542\n",
      "    test overall loss:        0.14550049602985382\n",
      "    test cross_ent loss:      0.1362984503308932\n",
      "    cluster loss:             2949.3107096354165\n",
      "    separation loss:          2.695136864980062\n",
      "    avg separation loss:      7.03376038869222\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  7.93529748916626\n",
      "    train time:               0.024361371994018555\n",
      "    test time:                0.012630462646484375\n",
      "    epoch time:               0.0375058650970459\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 140 (21/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.025395467670427427\n",
      "    train cross_ent loss:     0.01647107323838605\n",
      "    test overall loss:        0.14512763917446136\n",
      "    test cross_ent loss:      0.13665147498250008\n",
      "    cluster loss:             2949.310791015625\n",
      "    separation loss:          2.696522871653239\n",
      "    avg separation loss:      7.0405778884887695\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  7.209413528442383\n",
      "    train time:               0.02416825294494629\n",
      "    test time:                0.012616395950317383\n",
      "    epoch time:               0.03729867935180664\n",
      "    last layer lr:            0.007624000000000002\n",
      "epoch: 140 (22/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.028524714418583445\n",
      "    train cross_ent loss:     0.02040031459182501\n",
      "    test overall loss:        0.14362055932482085\n",
      "    test cross_ent loss:      0.1357890913883845\n",
      "    cluster loss:             2949.31103515625\n",
      "    separation loss:          2.695709784825643\n",
      "    avg separation loss:      7.05383841196696\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  6.56472110748291\n",
      "    train time:               0.024190425872802734\n",
      "    test time:                0.012586355209350586\n",
      "    epoch time:               0.03729391098022461\n",
      "    last layer lr:            0.0072280000000000035\n",
      "epoch: 140 (23/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.024907895053426426\n",
      "    train cross_ent loss:     0.0170481541297502\n",
      "    test overall loss:        0.14229738836487135\n",
      "    test cross_ent loss:      0.1347852392743031\n",
      "    cluster loss:             2949.3107096354165\n",
      "    separation loss:          2.6909773349761963\n",
      "    avg separation loss:      7.03082259496053\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  6.245400428771973\n",
      "    train time:               0.024659395217895508\n",
      "    test time:                0.012867212295532227\n",
      "    epoch time:               0.038037776947021484\n",
      "    last layer lr:            0.006831999999999998\n",
      "epoch: 140 (24/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.028372510543300047\n",
      "    train cross_ent loss:     0.020863944043715794\n",
      "    test overall loss:        0.1422295868396759\n",
      "    test cross_ent loss:      0.13455140528579554\n",
      "    cluster loss:             2949.3111979166665\n",
      "    separation loss:          2.6898341178894043\n",
      "    avg separation loss:      7.045744101206462\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  6.411439895629883\n",
      "    train time:               0.025003671646118164\n",
      "    test time:                0.012861013412475586\n",
      "    epoch time:               0.03837943077087402\n",
      "    last layer lr:            0.006436\n",
      "epoch: 140 (25/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.023297690475980442\n",
      "    train cross_ent loss:     0.015742765687819984\n",
      "    test overall loss:        0.14072404677669206\n",
      "    test cross_ent loss:      0.133428410316507\n",
      "    cluster loss:             2949.311279296875\n",
      "    separation loss:          2.685385545094808\n",
      "    avg separation loss:      7.01861031850179\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  6.028886795043945\n",
      "    train time:               0.02483081817626953\n",
      "    test time:                0.012853860855102539\n",
      "    epoch time:               0.03819680213928223\n",
      "    last layer lr:            0.00604\n",
      "epoch: 140 (26/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.023239152195552986\n",
      "    train cross_ent loss:     0.016153952210313745\n",
      "    test overall loss:        0.14153659840424856\n",
      "    test cross_ent loss:      0.13481301565965018\n",
      "    cluster loss:             2949.310791015625\n",
      "    separation loss:          2.687004009882609\n",
      "    avg separation loss:      7.030613740285237\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  5.4568376541137695\n",
      "    train time:               0.02479076385498047\n",
      "    test time:                0.012853145599365234\n",
      "    epoch time:               0.03815507888793945\n",
      "    last layer lr:            0.005644000000000002\n",
      "epoch: 140 (27/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.02361211284167237\n",
      "    train cross_ent loss:     0.017112694008068904\n",
      "    test overall loss:        0.1400480680167675\n",
      "    test cross_ent loss:      0.13369816976288953\n",
      "    cluster loss:             2949.3108723958335\n",
      "    separation loss:          2.697981913884481\n",
      "    avg separation loss:      7.0396169026692705\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  5.083150863647461\n",
      "    train time:               0.024807453155517578\n",
      "    test time:                0.012912750244140625\n",
      "    epoch time:               0.03822946548461914\n",
      "    last layer lr:            0.005248000000000003\n",
      "epoch: 140 (28/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.01913612936105993\n",
      "    train cross_ent loss:     0.013081707991659641\n",
      "    test overall loss:        0.13925610234340033\n",
      "    test cross_ent loss:      0.13347488331298032\n",
      "    cluster loss:             2949.310546875\n",
      "    separation loss:          2.7037931283315024\n",
      "    avg separation loss:      7.0227287610371905\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  4.514475345611572\n",
      "    train time:               0.024829387664794922\n",
      "    test time:                0.012848615646362305\n",
      "    epoch time:               0.038188934326171875\n",
      "    last layer lr:            0.004851999999999998\n",
      "epoch: 140 (29/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.022946595628228452\n",
      "    train cross_ent loss:     0.017248094651020236\n",
      "    test overall loss:        0.13904905443390211\n",
      "    test cross_ent loss:      0.13334985511998335\n",
      "    cluster loss:             2949.310302734375\n",
      "    separation loss:          2.6906751791636148\n",
      "    avg separation loss:      7.01743745803833\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  4.4324493408203125\n",
      "    train time:               0.024866342544555664\n",
      "    test time:                0.012976646423339844\n",
      "    epoch time:               0.038353919982910156\n",
      "    last layer lr:            0.004455999999999999\n",
      "epoch: 140 (30/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.020512994171844587\n",
      "    train cross_ent loss:     0.015102259452558227\n",
      "    test overall loss:        0.13755865084628263\n",
      "    test cross_ent loss:      0.1323658482482036\n",
      "    cluster loss:             2949.310546875\n",
      "    separation loss:          2.6911778450012207\n",
      "    avg separation loss:      7.014475027720134\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  3.926060676574707\n",
      "    train time:               0.024821758270263672\n",
      "    test time:                0.012888193130493164\n",
      "    epoch time:               0.038221120834350586\n",
      "    last layer lr:            0.004060000000000001\n",
      "epoch: 140 (31/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.018349930540555053\n",
      "    train cross_ent loss:     0.013289770991024043\n",
      "    test overall loss:        0.13719036802649498\n",
      "    test cross_ent loss:      0.13232399274905524\n",
      "    cluster loss:             2949.3107096354165\n",
      "    separation loss:          2.6900827884674072\n",
      "    avg separation loss:      7.029108047485352\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  3.5996289253234863\n",
      "    train time:               0.02480626106262207\n",
      "    test time:                0.012865304946899414\n",
      "    epoch time:               0.03818035125732422\n",
      "    last layer lr:            0.0036640000000000015\n",
      "epoch: 140 (32/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.021114687642289534\n",
      "    train cross_ent loss:     0.01650340029866331\n",
      "    test overall loss:        0.13534316793084145\n",
      "    test cross_ent loss:      0.13070802887280783\n",
      "    cluster loss:             2949.3103841145835\n",
      "    separation loss:          2.691401163736979\n",
      "    avg separation loss:      7.0028378168741865\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  3.368391752243042\n",
      "    train time:               0.024955272674560547\n",
      "    test time:                0.012920379638671875\n",
      "    epoch time:               0.03838682174682617\n",
      "    last layer lr:            0.003268000000000003\n",
      "epoch: 140 (33/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.021620843662983842\n",
      "    train cross_ent loss:     0.017014886666503217\n",
      "    test overall loss:        0.1362398900091648\n",
      "    test cross_ent loss:      0.13156269925336042\n",
      "    cluster loss:             2949.310791015625\n",
      "    separation loss:          2.6981387933095298\n",
      "    avg separation loss:      7.010719458262126\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  3.410444736480713\n",
      "    train time:               0.024944782257080078\n",
      "    test time:                0.012908935546875\n",
      "    epoch time:               0.03836488723754883\n",
      "    last layer lr:            0.002871999999999997\n",
      "epoch: 140 (34/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.017848123899764486\n",
      "    train cross_ent loss:     0.013517888650919\n",
      "    test overall loss:        0.13538632603983083\n",
      "    test cross_ent loss:      0.13133681689699492\n",
      "    cluster loss:             2949.3104654947915\n",
      "    separation loss:          2.69810684521993\n",
      "    avg separation loss:      7.0064036051432295\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  2.7827634811401367\n",
      "    train time:               0.02484607696533203\n",
      "    test time:                0.012923240661621094\n",
      "    epoch time:               0.03829550743103027\n",
      "    last layer lr:            0.0024759999999999986\n",
      "epoch: 140 (35/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.017518213639656704\n",
      "    train cross_ent loss:     0.013718830835488107\n",
      "    test overall loss:        0.13469175063073635\n",
      "    test cross_ent loss:      0.13108056038618088\n",
      "    cluster loss:             2949.3107096354165\n",
      "    separation loss:          2.6943321228027344\n",
      "    avg separation loss:      7.02798589070638\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  2.34444260597229\n",
      "    train time:               0.025119543075561523\n",
      "    test time:                0.012915372848510742\n",
      "    epoch time:               0.03854680061340332\n",
      "    last layer lr:            0.0020800000000000003\n",
      "epoch: 140 (36/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.018609988710118666\n",
      "    train cross_ent loss:     0.015223728285895454\n",
      "    test overall loss:        0.13440373167395592\n",
      "    test cross_ent loss:      0.1310512119283279\n",
      "    cluster loss:             2949.3106282552085\n",
      "    separation loss:          2.6921602884928384\n",
      "    avg separation loss:      7.022330284118652\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  2.0857694149017334\n",
      "    train time:               0.02476954460144043\n",
      "    test time:                0.01293325424194336\n",
      "    epoch time:               0.038204193115234375\n",
      "    last layer lr:            0.0016840000000000017\n",
      "epoch: 140 (37/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.018966663111415174\n",
      "    train cross_ent loss:     0.01583615695643756\n",
      "    test overall loss:        0.13426267790297666\n",
      "    test cross_ent loss:      0.13127777042488256\n",
      "    cluster loss:             2949.3107096354165\n",
      "    separation loss:          2.6947208245595298\n",
      "    avg separation loss:      7.021370728810628\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  1.7181562185287476\n",
      "    train time:               0.024395227432250977\n",
      "    test time:                0.012873649597167969\n",
      "    epoch time:               0.03777265548706055\n",
      "    last layer lr:            0.001288000000000003\n",
      "epoch: 140 (38/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.022566829290654924\n",
      "    train cross_ent loss:     0.019792555132880807\n",
      "    test overall loss:        0.13440576630334058\n",
      "    test cross_ent loss:      0.1316145999977986\n",
      "    cluster loss:             2949.310546875\n",
      "    separation loss:          2.7025554180145264\n",
      "    avg separation loss:      7.02787971496582\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  1.5244228839874268\n",
      "    train time:               0.024397850036621094\n",
      "    test time:                0.012896299362182617\n",
      "    epoch time:               0.0377957820892334\n",
      "    last layer lr:            0.0008919999999999973\n",
      "epoch: 140 (39/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.014319011527631018\n",
      "    train cross_ent loss:     0.011582632652587362\n",
      "    test overall loss:        0.1338983935614427\n",
      "    test cross_ent loss:      0.1313439334432284\n",
      "    cluster loss:             2949.310791015625\n",
      "    separation loss:          2.693509896596273\n",
      "    avg separation loss:      7.022925853729248\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  1.2877130508422852\n",
      "    train time:               0.024348974227905273\n",
      "    test time:                0.012897968292236328\n",
      "    epoch time:               0.03775167465209961\n",
      "    last layer lr:            0.0004959999999999986\n",
      "epoch: 140 (40/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.0185606207491623\n",
      "    train cross_ent loss:     0.01629406503505177\n",
      "    test overall loss:        0.1334881093353033\n",
      "    test cross_ent loss:      0.13138166690866152\n",
      "    cluster loss:             2949.3103841145835\n",
      "    separation loss:          2.6940606435139975\n",
      "    avg separation loss:      7.027345657348633\n",
      "    l1_addon loss:            42.22477722167969\n",
      "    l1 loss:                  0.8396976590156555\n",
      "    train time:               0.024364471435546875\n",
      "    test time:                0.01299595832824707\n",
      "    epoch time:               0.03785896301269531\n",
      "    last layer lr:            0.0001\n",
      "epoch: 141 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.015644613653421402\n",
      "    train cross_ent loss:     0.01353804999962449\n",
      "    test overall loss:        0.13286705749730268\n",
      "    test cross_ent loss:      0.13076038906971613\n",
      "    cluster loss:             2949.310302734375\n",
      "    separation loss:          2.689751466115316\n",
      "    avg separation loss:      7.0299458503723145\n",
      "    l1_addon loss:            42.23252868652344\n",
      "    l1 loss:                  0.8396976590156555\n",
      "    train time:               0.06159329414367676\n",
      "    test time:                0.01294088363647461\n",
      "    epoch time:               0.07536530494689941\n",
      "    joint lr:                 0.001298047112325102\n",
      "epoch: 142 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.014331161561939452\n",
      "    train cross_ent loss:     0.01222398659835259\n",
      "    test overall loss:        0.1294916346669197\n",
      "    test cross_ent loss:      0.1273841286698977\n",
      "    cluster loss:             2949.3041178385415\n",
      "    separation loss:          2.6650984287261963\n",
      "    avg separation loss:      6.938803195953369\n",
      "    l1_addon loss:            42.26036834716797\n",
      "    l1 loss:                  0.8396976590156555\n",
      "    train time:               0.06135964393615723\n",
      "    test time:                0.012677669525146484\n",
      "    epoch time:               0.07482528686523438\n",
      "    joint lr:                 0.002472133282403701\n",
      "epoch: 143 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.01138965930375788\n",
      "    train cross_ent loss:     0.009279301390051842\n",
      "    test overall loss:        0.12464117382963498\n",
      "    test cross_ent loss:      0.12253087386488914\n",
      "    cluster loss:             2949.30126953125\n",
      "    separation loss:          2.628171920776367\n",
      "    avg separation loss:      6.916654745737712\n",
      "    l1_addon loss:            42.35342025756836\n",
      "    l1 loss:                  0.8396976590156555\n",
      "    train time:               0.05898165702819824\n",
      "    test time:                0.012655973434448242\n",
      "    epoch time:               0.07241463661193848\n",
      "    joint lr:                 0.0036226179243694966\n",
      "epoch: 144 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.008643680148654513\n",
      "    train cross_ent loss:     0.0065378212214758\n",
      "    test overall loss:        0.11477500076095264\n",
      "    test cross_ent loss:      0.11267222401996453\n",
      "    cluster loss:             2949.2913411458335\n",
      "    separation loss:          2.6196446418762207\n",
      "    avg separation loss:      6.816200574239095\n",
      "    l1_addon loss:            42.102630615234375\n",
      "    l1 loss:                  0.8396976590156555\n",
      "    train time:               0.0588226318359375\n",
      "    test time:                0.012633800506591797\n",
      "    epoch time:               0.07221102714538574\n",
      "    joint lr:                 0.004749855660167736\n",
      "epoch: 145 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.006098852466998829\n",
      "    train cross_ent loss:     0.003993498200240235\n",
      "    test overall loss:        0.12219566727677982\n",
      "    test cross_ent loss:      0.12008764408528805\n",
      "    cluster loss:             2949.29345703125\n",
      "    separation loss:          2.6080853939056396\n",
      "    avg separation loss:      6.762855688730876\n",
      "    l1_addon loss:            42.277313232421875\n",
      "    l1 loss:                  0.8396976590156555\n",
      "    train time:               0.058869123458862305\n",
      "    test time:                0.012665987014770508\n",
      "    epoch time:               0.07235026359558105\n",
      "    joint lr:                 0.005854196379457574\n",
      "epoch: 146 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.004772191867232323\n",
      "    train cross_ent loss:     0.002663776252625717\n",
      "    test overall loss:        0.11410993058234453\n",
      "    test cross_ent loss:      0.11200435583790143\n",
      "    cluster loss:             2949.2890625\n",
      "    separation loss:          2.5728855530420938\n",
      "    avg separation loss:      6.698324998219808\n",
      "    l1_addon loss:            42.19588088989258\n",
      "    l1 loss:                  0.8396976590156555\n",
      "    train time:               0.05878949165344238\n",
      "    test time:                0.012616634368896484\n",
      "    epoch time:               0.07220101356506348\n",
      "    joint lr:                 0.006935985298795627\n",
      "epoch: 147 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.005613329302933481\n",
      "    train cross_ent loss:     0.0035121168604948455\n",
      "    test overall loss:        0.11307574187715848\n",
      "    test cross_ent loss:      0.11097497120499611\n",
      "    cluster loss:             2949.294921875\n",
      "    separation loss:          2.6203327973683677\n",
      "    avg separation loss:      6.6694997151692705\n",
      "    l1_addon loss:            42.03582763671875\n",
      "    l1 loss:                  0.8396976590156555\n",
      "    train time:               0.058875322341918945\n",
      "    test time:                0.01266932487487793\n",
      "    epoch time:               0.07231593132019043\n",
      "    joint lr:                 0.007995563020108943\n",
      "epoch: 148 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.0059207033676405745\n",
      "    train cross_ent loss:     0.0038157884393715197\n",
      "    test overall loss:        0.11557873524725437\n",
      "    test cross_ent loss:      0.11347009614109993\n",
      "    cluster loss:             2949.3009440104165\n",
      "    separation loss:          2.5713165601094565\n",
      "    avg separation loss:      6.645132223765056\n",
      "    l1_addon loss:            42.29818344116211\n",
      "    l1 loss:                  0.8396976590156555\n",
      "    train time:               0.05887174606323242\n",
      "    test time:                0.012622356414794922\n",
      "    epoch time:               0.07227802276611328\n",
      "    joint lr:                 0.009033265588466115\n",
      "epoch: 149 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.006983040262841516\n",
      "    train cross_ent loss:     0.004876771586067561\n",
      "    test overall loss:        0.11492375346521537\n",
      "    test cross_ent loss:      0.11282065138220787\n",
      "    cluster loss:             2949.3101399739585\n",
      "    separation loss:          2.5458393494288125\n",
      "    avg separation loss:      6.577761650085449\n",
      "    l1_addon loss:            42.11351013183594\n",
      "    l1 loss:                  0.8396976590156555\n",
      "    train time:               0.058855533599853516\n",
      "    test time:                0.012637615203857422\n",
      "    epoch time:               0.07226777076721191\n",
      "    joint lr:                 0.010049424549154131\n",
      "epoch: 150 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.00964240383149849\n",
      "    train cross_ent loss:     0.007542300529571043\n",
      "    test overall loss:        0.13987266023953757\n",
      "    test cross_ent loss:      0.13776368151108423\n",
      "    cluster loss:             2949.32080078125\n",
      "    separation loss:          2.5417117277781167\n",
      "    avg separation loss:      6.4313530921936035\n",
      "    l1_addon loss:            42.309410095214844\n",
      "    l1 loss:                  0.8396976590156555\n",
      "    train time:               0.058945417404174805\n",
      "    test time:                0.012647628784179688\n",
      "    epoch time:               0.0723876953125\n",
      "    joint lr:                 0.011044367004069541\n",
      "epoch: 151 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 94.00%\n",
      "    train overall loss:       0.046773731553306185\n",
      "    train cross_ent loss:     0.04467005171399149\n",
      "    test overall loss:        0.188947727282842\n",
      "    test cross_ent loss:      0.18683940172195435\n",
      "    cluster loss:             2949.3800455729165\n",
      "    separation loss:          2.881996234258016\n",
      "    avg separation loss:      7.034346262613933\n",
      "    l1_addon loss:            42.28748321533203\n",
      "    l1 loss:                  0.8396976590156555\n",
      "    train time:               0.05886387825012207\n",
      "    test time:                0.012672662734985352\n",
      "    epoch time:               0.07235097885131836\n",
      "    joint lr:                 0.010393177167327405\n",
      "epoch: 152 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       0.0688274461362097\n",
      "    train cross_ent loss:     0.06672375773390134\n",
      "    test overall loss:        0.18066130578517914\n",
      "    test cross_ent loss:      0.17855182538429895\n",
      "    cluster loss:             2949.4412434895835\n",
      "    separation loss:          3.1301915645599365\n",
      "    avg separation loss:      7.51058292388916\n",
      "    l1_addon loss:            42.32594299316406\n",
      "    l1 loss:                  0.8396976590156555\n",
      "    train time:               0.05882382392883301\n",
      "    test time:                0.012637615203857422\n",
      "    epoch time:               0.07224702835083008\n",
      "    joint lr:                 0.009753916690619703\n",
      "epoch: 153 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 92.67%\n",
      "    train overall loss:       0.18553464828679958\n",
      "    train cross_ent loss:     0.18342885830336148\n",
      "    test overall loss:        0.2923257847627004\n",
      "    test cross_ent loss:      0.29021789878606796\n",
      "    cluster loss:             2949.6903483072915\n",
      "    separation loss:          3.9247873624165854\n",
      "    avg separation loss:      8.80319627126058\n",
      "    l1_addon loss:            42.27286911010742\n",
      "    l1 loss:                  0.8396976590156555\n",
      "    train time:               0.05905294418334961\n",
      "    test time:                0.0126190185546875\n",
      "    epoch time:               0.07245683670043945\n",
      "    joint lr:                 0.009126412105729424\n",
      "epoch: 154 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 94.00%\n",
      "    train overall loss:       0.2678936380479071\n",
      "    train cross_ent loss:     0.26578725543287063\n",
      "    test overall loss:        0.44250879685084027\n",
      "    test cross_ent loss:      0.44041382273038227\n",
      "    cluster loss:             2949.9762369791665\n",
      "    separation loss:          4.7440080642700195\n",
      "    avg separation loss:      10.550543467203775\n",
      "    l1_addon loss:            41.8421516418457\n",
      "    l1 loss:                  0.8396976590156555\n",
      "    train time:               0.0590817928314209\n",
      "    test time:                0.01266169548034668\n",
      "    epoch time:               0.07253742218017578\n",
      "    joint lr:                 0.008510492220867888\n",
      "epoch: 155 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 91.33%\n",
      "    train overall loss:       0.27423739102151656\n",
      "    train cross_ent loss:     0.27213385370042587\n",
      "    test overall loss:        0.37181803087393445\n",
      "    test cross_ent loss:      0.36972570419311523\n",
      "    cluster loss:             2950.0249837239585\n",
      "    separation loss:          5.025913715362549\n",
      "    avg separation loss:      11.308703104654947\n",
      "    l1_addon loss:            41.75385284423828\n",
      "    l1 loss:                  0.8396976590156555\n",
      "    train time:               0.0587611198425293\n",
      "    test time:                0.012644767761230469\n",
      "    epoch time:               0.07216525077819824\n",
      "    joint lr:                 0.00790598809249301\n",
      "epoch: 156 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       0.3075469574994511\n",
      "    train cross_ent loss:     0.3054443324605624\n",
      "    test overall loss:        0.2733755906422933\n",
      "    test cross_ent loss:      0.27126439412434894\n",
      "    cluster loss:             2950.041015625\n",
      "    separation loss:          4.915576457977295\n",
      "    avg separation loss:      11.154335339864096\n",
      "    l1_addon loss:            42.38323974609375\n",
      "    l1 loss:                  0.8396976590156555\n",
      "    train time:               0.058809518814086914\n",
      "    test time:                0.012606143951416016\n",
      "    epoch time:               0.07221722602844238\n",
      "    joint lr:                 0.007312732997463544\n",
      "epoch: 157 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       0.3242153368062443\n",
      "    train cross_ent loss:     0.32211121420065564\n",
      "    test overall loss:        0.7423835396766663\n",
      "    test cross_ent loss:      0.7402395606040955\n",
      "    cluster loss:             2950.319580078125\n",
      "    separation loss:          5.274436632792155\n",
      "    avg separation loss:      11.882685979207357\n",
      "    l1_addon loss:            43.474700927734375\n",
      "    l1 loss:                  0.8396976590156555\n",
      "    train time:               0.05878901481628418\n",
      "    test time:                0.012601375579833984\n",
      "    epoch time:               0.07219719886779785\n",
      "    joint lr:                 0.006730562405525418\n",
      "epoch: 158 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 93.67%\n",
      "    train overall loss:       0.31463567084736294\n",
      "    train cross_ent loss:     0.3125290705098046\n",
      "    test overall loss:        0.3435089737176895\n",
      "    test cross_ent loss:      0.34138165911038715\n",
      "    cluster loss:             2950.0232747395835\n",
      "    separation loss:          5.06303596496582\n",
      "    avg separation loss:      11.439738273620605\n",
      "    l1_addon loss:            42.92047882080078\n",
      "    l1 loss:                  0.8396976590156555\n",
      "    train time:               0.05879712104797363\n",
      "    test time:                0.01259303092956543\n",
      "    epoch time:               0.07215762138366699\n",
      "    joint lr:                 0.006159313952126306\n",
      "epoch: 159 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       0.31953444497452843\n",
      "    train cross_ent loss:     0.3174270863334338\n",
      "    test overall loss:        0.27559947470823926\n",
      "    test cross_ent loss:      0.2734760046005249\n",
      "    cluster loss:             2949.94140625\n",
      "    separation loss:          4.920325597127278\n",
      "    avg separation loss:      11.373182614644369\n",
      "    l1_addon loss:            42.79231643676758\n",
      "    l1 loss:                  0.8396976590156555\n",
      "    train time:               0.05850553512573242\n",
      "    test time:                0.012091398239135742\n",
      "    epoch time:               0.0713505744934082\n",
      "    joint lr:                 0.005598827411554625\n",
      "epoch: 160 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.1968582189745373\n",
      "    train cross_ent loss:     0.1947547338075108\n",
      "    test overall loss:        0.3300653000672658\n",
      "    test cross_ent loss:      0.3279336293538411\n",
      "    cluster loss:             2949.9715983072915\n",
      "    separation loss:          4.701394081115723\n",
      "    avg separation loss:      10.723443984985352\n",
      "    l1_addon loss:            43.06581497192383\n",
      "    l1 loss:                  0.8396976590156555\n",
      "    train time:               0.0582122802734375\n",
      "    test time:                0.012544631958007812\n",
      "    epoch time:               0.07137846946716309\n",
      "    joint lr:                 0.005048944670399165\n",
      "epoch: 161 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.17128921217388576\n",
      "    train cross_ent loss:     0.16918843322330052\n",
      "    test overall loss:        0.19166224698225656\n",
      "    test cross_ent loss:      0.18954709668954214\n",
      "    cluster loss:             2949.8035481770835\n",
      "    separation loss:          4.613138198852539\n",
      "    avg separation loss:      10.488361358642578\n",
      "    l1_addon loss:            42.51491928100586\n",
      "    l1 loss:                  0.8396976590156555\n",
      "    train time:               0.058011770248413086\n",
      "    test time:                0.012102603912353516\n",
      "    epoch time:               0.0708777904510498\n",
      "    joint lr:                 0.004509509701325646\n",
      "epoch: 162 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.11070557062824567\n",
      "    train cross_ent loss:     0.10859198081824514\n",
      "    test overall loss:        0.22418713693817457\n",
      "    test cross_ent loss:      0.22209635376930237\n",
      "    cluster loss:             2949.7842610677085\n",
      "    separation loss:          4.382645448048909\n",
      "    avg separation loss:      9.845110575358072\n",
      "    l1_addon loss:            41.7028694152832\n",
      "    l1 loss:                  0.8396976590156555\n",
      "    train time:               0.058211326599121094\n",
      "    test time:                0.012198686599731445\n",
      "    epoch time:               0.07116937637329102\n",
      "    joint lr:                 0.00398036853716657\n",
      "epoch: 163 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.08712106653385693\n",
      "    train cross_ent loss:     0.085012163552973\n",
      "    test overall loss:        0.18167124688625336\n",
      "    test cross_ent loss:      0.17955329765876135\n",
      "    cluster loss:             2949.7416178385415\n",
      "    separation loss:          4.224768320719401\n",
      "    avg separation loss:      9.69576644897461\n",
      "    l1_addon loss:            42.60814666748047\n",
      "    l1 loss:                  0.8396976590156555\n",
      "    train time:               0.05821633338928223\n",
      "    test time:                0.013477563858032227\n",
      "    epoch time:               0.07251429557800293\n",
      "    joint lr:                 0.0034613692453205423\n",
      "epoch: 164 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.03300004649079508\n",
      "    train cross_ent loss:     0.030891522040797606\n",
      "    test overall loss:        0.15099329501390457\n",
      "    test cross_ent loss:      0.1488870531320572\n",
      "    cluster loss:             2949.6803385416665\n",
      "    separation loss:          4.045669476191203\n",
      "    avg separation loss:      9.205923716227213\n",
      "    l1_addon loss:            42.21812057495117\n",
      "    l1 loss:                  0.8396976590156555\n",
      "    train time:               0.06131410598754883\n",
      "    test time:                0.012810230255126953\n",
      "    epoch time:               0.07488679885864258\n",
      "    joint lr:                 0.002952361902457719\n",
      "epoch: 165 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.029059146013524797\n",
      "    train cross_ent loss:     0.0269470252096653\n",
      "    test overall loss:        0.1420679229001204\n",
      "    test cross_ent loss:      0.1399584716806809\n",
      "    cluster loss:             2949.6673177083335\n",
      "    separation loss:          3.9163783391316733\n",
      "    avg separation loss:      8.936418215433756\n",
      "    l1_addon loss:            42.32502746582031\n",
      "    l1 loss:                  0.8396976590156555\n",
      "    train time:               0.061702728271484375\n",
      "    test time:                0.012660503387451172\n",
      "    epoch time:               0.07511639595031738\n",
      "    joint lr:                 0.0024531985695276076\n",
      "epoch: 166 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.02900101223753558\n",
      "    train cross_ent loss:     0.026897470828973584\n",
      "    test overall loss:        0.14174285903573036\n",
      "    test cross_ent loss:      0.13963550825913748\n",
      "    cluster loss:             2949.6483561197915\n",
      "    separation loss:          3.8775946299235025\n",
      "    avg separation loss:      8.784488677978516\n",
      "    l1_addon loss:            42.25502014160156\n",
      "    l1 loss:                  0.8396976590156555\n",
      "    train time:               0.061295509338378906\n",
      "    test time:                0.012653589248657227\n",
      "    epoch time:               0.0746452808380127\n",
      "    joint lr:                 0.001963733267065865\n",
      "epoch: 167 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.014686031887928644\n",
      "    train cross_ent loss:     0.012572079276045164\n",
      "    test overall loss:        0.1416953249524037\n",
      "    test cross_ent loss:      0.13957821329434714\n",
      "    cluster loss:             2949.6560872395835\n",
      "    separation loss:          3.797076384226481\n",
      "    avg separation loss:      8.70883560180664\n",
      "    l1_addon loss:            42.580467224121094\n",
      "    l1 loss:                  0.8396976590156555\n",
      "    train time:               0.06153106689453125\n",
      "    test time:                0.012638568878173828\n",
      "    epoch time:               0.07487010955810547\n",
      "    joint lr:                 0.001483821950796405\n",
      "epoch: 168 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.01164180412888527\n",
      "    train cross_ent loss:     0.009527364745736122\n",
      "    test overall loss:        0.13762398498753706\n",
      "    test cross_ent loss:      0.1355134298404058\n",
      "    cluster loss:             2949.6360677083335\n",
      "    separation loss:          3.753873268763224\n",
      "    avg separation loss:      8.567994117736816\n",
      "    l1_addon loss:            42.36187744140625\n",
      "    l1 loss:                  0.8396976590156555\n",
      "    train time:               0.06115889549255371\n",
      "    test time:                0.012720108032226562\n",
      "    epoch time:               0.07462334632873535\n",
      "    joint lr:                 0.0010133224875256274\n",
      "epoch: 169 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.009266213772611486\n",
      "    train cross_ent loss:     0.007157103753545218\n",
      "    test overall loss:        0.13458350983758768\n",
      "    test cross_ent loss:      0.13247655890882015\n",
      "    cluster loss:             2949.629638671875\n",
      "    separation loss:          3.748211145401001\n",
      "    avg separation loss:      8.544994672139486\n",
      "    l1_addon loss:            42.24188995361328\n",
      "    l1 loss:                  0.8396976590156555\n",
      "    train time:               0.06134176254272461\n",
      "    test time:                0.012763261795043945\n",
      "    epoch time:               0.07486414909362793\n",
      "    joint lr:                 0.0005520946313251855\n",
      "epoch: 170 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.008239784071014987\n",
      "    train cross_ent loss:     0.006133190692505903\n",
      "    test overall loss:        0.13526015914976597\n",
      "    test cross_ent loss:      0.133153909817338\n",
      "    cluster loss:             2949.6265462239585\n",
      "    separation loss:          3.755476792653402\n",
      "    avg separation loss:      8.543058713277182\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  0.8396976590156555\n",
      "    train time:               0.06148076057434082\n",
      "    test time:                0.012632131576538086\n",
      "    epoch time:               0.0748593807220459\n",
      "    joint lr:                 0.0001\n",
      "epoch: 170 (PUSH) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.008239784071014987\n",
      "    train cross_ent loss:     0.006133190692505903\n",
      "    test overall loss:        0.16250957051912943\n",
      "    test cross_ent loss:      0.16040331994493803\n",
      "    cluster loss:             2949.3396809895835\n",
      "    separation loss:          3.0001739660898843\n",
      "    avg separation loss:      7.624991734822591\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  0.8396976590156555\n",
      "    train time:               0.06148076057434082\n",
      "    test time:                0.012854576110839844\n",
      "    epoch time:               0.3721144199371338\n",
      "epoch: 170 (1/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.022404591035511758\n",
      "    train cross_ent loss:     0.02048898684895701\n",
      "    test overall loss:        0.1614761638144652\n",
      "    test cross_ent loss:      0.15969951078295708\n",
      "    cluster loss:             2949.3392740885415\n",
      "    separation loss:          3.010884920756022\n",
      "    avg separation loss:      7.628821849822998\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  0.5101035237312317\n",
      "    train time:               0.024837017059326172\n",
      "    test time:                0.012752532958984375\n",
      "    epoch time:               0.03811383247375488\n",
      "    last layer lr:            0.0007599999999999978\n",
      "epoch: 170 (2/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.028306104967163667\n",
      "    train cross_ent loss:     0.02595076968686448\n",
      "    test overall loss:        0.16227836782733598\n",
      "    test cross_ent loss:      0.15994824469089508\n",
      "    cluster loss:             2949.33935546875\n",
      "    separation loss:          3.000006596247355\n",
      "    avg separation loss:      7.594258944193522\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  1.0635652542114258\n",
      "    train time:               0.024163007736206055\n",
      "    test time:                0.0125885009765625\n",
      "    epoch time:               0.037265777587890625\n",
      "    last layer lr:            0.0014199999999999955\n",
      "epoch: 170 (3/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.02513636824571424\n",
      "    train cross_ent loss:     0.022346827408505812\n",
      "    test overall loss:        0.16207651297251383\n",
      "    test cross_ent loss:      0.15922618905703226\n",
      "    cluster loss:             2949.3392740885415\n",
      "    separation loss:          2.997469504674276\n",
      "    avg separation loss:      7.600619633992513\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  1.5837693214416504\n",
      "    train time:               0.024442672729492188\n",
      "    test time:                0.012599945068359375\n",
      "    epoch time:               0.037557363510131836\n",
      "    last layer lr:            0.0020800000000000046\n",
      "epoch: 170 (4/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.02666518061111371\n",
      "    train cross_ent loss:     0.023529420503311686\n",
      "    test overall loss:        0.16197315603494644\n",
      "    test cross_ent loss:      0.15881184240182242\n",
      "    cluster loss:             2949.3404134114585\n",
      "    separation loss:          2.9965131282806396\n",
      "    avg separation loss:      7.614556312561035\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  1.8947635889053345\n",
      "    train time:               0.02436661720275879\n",
      "    test time:                0.012620925903320312\n",
      "    epoch time:               0.0375058650970459\n",
      "    last layer lr:            0.0027400000000000024\n",
      "epoch: 170 (5/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.026919911408589944\n",
      "    train cross_ent loss:     0.02346062960310115\n",
      "    test overall loss:        0.15994870041807493\n",
      "    test cross_ent loss:      0.15621026853720346\n",
      "    cluster loss:             2949.3397623697915\n",
      "    separation loss:          2.9984422524770102\n",
      "    avg separation loss:      7.614204565684001\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  2.471876382827759\n",
      "    train time:               0.02423262596130371\n",
      "    test time:                0.012583255767822266\n",
      "    epoch time:               0.03732895851135254\n",
      "    last layer lr:            0.0034\n",
      "epoch: 170 (6/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.020993733261194494\n",
      "    train cross_ent loss:     0.016897504010962114\n",
      "    test overall loss:        0.16021988168358803\n",
      "    test cross_ent loss:      0.1558979464073976\n",
      "    cluster loss:             2949.3396809895835\n",
      "    separation loss:          2.9928698539733887\n",
      "    avg separation loss:      7.597087224324544\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  3.0553855895996094\n",
      "    train time:               0.02430582046508789\n",
      "    test time:                0.01258087158203125\n",
      "    epoch time:               0.03739666938781738\n",
      "    last layer lr:            0.004059999999999998\n",
      "epoch: 170 (7/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.027145100860959955\n",
      "    train cross_ent loss:     0.022539551835507154\n",
      "    test overall loss:        0.15864007050792375\n",
      "    test cross_ent loss:      0.15345418453216553\n",
      "    cluster loss:             2949.339599609375\n",
      "    separation loss:          2.988718827565511\n",
      "    avg separation loss:      7.5833892822265625\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  3.9193291664123535\n",
      "    train time:               0.02433633804321289\n",
      "    test time:                0.012563228607177734\n",
      "    epoch time:               0.03741455078125\n",
      "    last layer lr:            0.004719999999999996\n",
      "epoch: 170 (8/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.026047085515326925\n",
      "    train cross_ent loss:     0.020775903740690813\n",
      "    test overall loss:        0.15744484215974808\n",
      "    test cross_ent loss:      0.15212771917382875\n",
      "    cluster loss:             2949.3392740885415\n",
      "    separation loss:          2.9996023178100586\n",
      "    avg separation loss:      7.598612149556478\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  4.050570487976074\n",
      "    train time:               0.024355173110961914\n",
      "    test time:                0.012612104415893555\n",
      "    epoch time:               0.03747987747192383\n",
      "    last layer lr:            0.0053800000000000054\n",
      "epoch: 170 (9/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.02559815678331587\n",
      "    train cross_ent loss:     0.02005672061608897\n",
      "    test overall loss:        0.15508412942290306\n",
      "    test cross_ent loss:      0.14929760744174322\n",
      "    cluster loss:             2949.340087890625\n",
      "    separation loss:          3.003415505091349\n",
      "    avg separation loss:      7.6319780349731445\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  4.519964218139648\n",
      "    train time:               0.024207592010498047\n",
      "    test time:                0.012588024139404297\n",
      "    epoch time:               0.0373072624206543\n",
      "    last layer lr:            0.006040000000000003\n",
      "epoch: 170 (10/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.02393874443239636\n",
      "    train cross_ent loss:     0.01788887583340208\n",
      "    test overall loss:        0.15345199033617973\n",
      "    test cross_ent loss:      0.1473009536663691\n",
      "    cluster loss:             2949.33984375\n",
      "    separation loss:          3.00447408358256\n",
      "    avg separation loss:      7.628566424051921\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  4.884484767913818\n",
      "    train time:               0.024393796920776367\n",
      "    test time:                0.012578725814819336\n",
      "    epoch time:               0.03748607635498047\n",
      "    last layer lr:            0.0067\n",
      "epoch: 170 (11/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.027932151324219175\n",
      "    train cross_ent loss:     0.021413572727599077\n",
      "    test overall loss:        0.15368246038754782\n",
      "    test cross_ent loss:      0.1465970017015934\n",
      "    cluster loss:             2949.3396809895835\n",
      "    separation loss:          3.005751371383667\n",
      "    avg separation loss:      7.622058073679606\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  5.818907737731934\n",
      "    train time:               0.024276256561279297\n",
      "    test time:                0.012561559677124023\n",
      "    epoch time:               0.037349700927734375\n",
      "    last layer lr:            0.0073599999999999985\n",
      "epoch: 170 (12/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.027510035162170727\n",
      "    train cross_ent loss:     0.0199395598222812\n",
      "    test overall loss:        0.15158065035939217\n",
      "    test cross_ent loss:      0.1442822702229023\n",
      "    cluster loss:             2949.3399251302085\n",
      "    separation loss:          3.0092801253000894\n",
      "    avg separation loss:      7.62575896581014\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  6.031826496124268\n",
      "    train time:               0.024240732192993164\n",
      "    test time:                0.012569189071655273\n",
      "    epoch time:               0.03731989860534668\n",
      "    last layer lr:            0.008019999999999994\n",
      "epoch: 170 (13/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.02545721870329645\n",
      "    train cross_ent loss:     0.017599962548249297\n",
      "    test overall loss:        0.15056910986701647\n",
      "    test cross_ent loss:      0.14270138616363207\n",
      "    cluster loss:             2949.340576171875\n",
      "    separation loss:          3.0066362222035727\n",
      "    avg separation loss:      7.627602895100911\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  6.601169586181641\n",
      "    train time:               0.024202823638916016\n",
      "    test time:                0.01267552375793457\n",
      "    epoch time:               0.03739428520202637\n",
      "    last layer lr:            0.008680000000000005\n",
      "epoch: 170 (14/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.02338842385345035\n",
      "    train cross_ent loss:     0.015455895957226554\n",
      "    test overall loss:        0.14926753441492716\n",
      "    test cross_ent loss:      0.1412204752365748\n",
      "    cluster loss:             2949.33984375\n",
      "    separation loss:          3.0087084770202637\n",
      "    avg separation loss:      7.618643760681152\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  6.780506610870361\n",
      "    train time:               0.02437448501586914\n",
      "    test time:                0.012574195861816406\n",
      "    epoch time:               0.037456512451171875\n",
      "    last layer lr:            0.009340000000000003\n",
      "epoch: 170 (15/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.025050510755843587\n",
      "    train cross_ent loss:     0.016574327885690663\n",
      "    test overall loss:        0.1500237894554933\n",
      "    test cross_ent loss:      0.14137539640069008\n",
      "    cluster loss:             2949.339599609375\n",
      "    separation loss:          3.0094194412231445\n",
      "    avg separation loss:      7.603015422821045\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  7.381834983825684\n",
      "    train time:               0.024339914321899414\n",
      "    test time:                0.012565851211547852\n",
      "    epoch time:               0.03741931915283203\n",
      "    last layer lr:            0.01\n",
      "epoch: 170 (16/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.02499753391991059\n",
      "    train cross_ent loss:     0.016026284442179732\n",
      "    test overall loss:        0.14863359679778418\n",
      "    test cross_ent loss:      0.13913255805770555\n",
      "    cluster loss:             2949.3399251302085\n",
      "    separation loss:          3.011965751647949\n",
      "    avg separation loss:      7.616371472676595\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  8.234480857849121\n",
      "    train time:               0.024393796920776367\n",
      "    test time:                0.012573480606079102\n",
      "    epoch time:               0.037489891052246094\n",
      "    last layer lr:            0.009604000000000001\n",
      "epoch: 170 (17/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.02860088035878208\n",
      "    train cross_ent loss:     0.01952822009722392\n",
      "    test overall loss:        0.1473196397225062\n",
      "    test cross_ent loss:      0.13791615640123686\n",
      "    cluster loss:             2949.340087890625\n",
      "    separation loss:          3.017988443374634\n",
      "    avg separation loss:      7.624928633371989\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  8.136931419372559\n",
      "    train time:               0.02434086799621582\n",
      "    test time:                0.012585878372192383\n",
      "    epoch time:               0.03743720054626465\n",
      "    last layer lr:            0.009208000000000003\n",
      "epoch: 170 (18/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.025655219848785136\n",
      "    train cross_ent loss:     0.016308532303406134\n",
      "    test overall loss:        0.1453938161333402\n",
      "    test cross_ent loss:      0.1363182949523131\n",
      "    cluster loss:             2949.33984375\n",
      "    separation loss:          3.0104663372039795\n",
      "    avg separation loss:      7.619568347930908\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  7.808966159820557\n",
      "    train time:               0.024176359176635742\n",
      "    test time:                0.012559890747070312\n",
      "    epoch time:               0.037247657775878906\n",
      "    last layer lr:            0.008811999999999997\n",
      "epoch: 170 (19/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.022749034894837275\n",
      "    train cross_ent loss:     0.013951563535051214\n",
      "    test overall loss:        0.14261892437934875\n",
      "    test cross_ent loss:      0.1343965989847978\n",
      "    cluster loss:             2949.3400065104165\n",
      "    separation loss:          3.0103354454040527\n",
      "    avg separation loss:      7.631416479746501\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  6.955770492553711\n",
      "    train time:               0.025038957595825195\n",
      "    test time:                0.012921571731567383\n",
      "    epoch time:               0.038482666015625\n",
      "    last layer lr:            0.008415999999999998\n",
      "epoch: 170 (20/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.01966128001610438\n",
      "    train cross_ent loss:     0.011738888194991482\n",
      "    test overall loss:        0.14110850666960081\n",
      "    test cross_ent loss:      0.13331981872518858\n",
      "    cluster loss:             2949.3396809895835\n",
      "    separation loss:          3.0124297936757407\n",
      "    avg separation loss:      7.625643889109294\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  6.522135257720947\n",
      "    train time:               0.02487039566040039\n",
      "    test time:                0.01291656494140625\n",
      "    epoch time:               0.038298606872558594\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 170 (21/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.02343841569705142\n",
      "    train cross_ent loss:     0.015756112057715654\n",
      "    test overall loss:        0.1408947855234146\n",
      "    test cross_ent loss:      0.13322250296672186\n",
      "    cluster loss:             2949.3399251302085\n",
      "    separation loss:          3.0017449855804443\n",
      "    avg separation loss:      7.629991849263509\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  6.405732154846191\n",
      "    train time:               0.02507615089416504\n",
      "    test time:                0.012910604476928711\n",
      "    epoch time:               0.03849625587463379\n",
      "    last layer lr:            0.007624000000000002\n",
      "epoch: 170 (22/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.02252370512319936\n",
      "    train cross_ent loss:     0.015319018469502529\n",
      "    test overall loss:        0.13927866021792093\n",
      "    test cross_ent loss:      0.13206503664453825\n",
      "    cluster loss:             2949.339599609375\n",
      "    separation loss:          3.002653121948242\n",
      "    avg separation loss:      7.62478240331014\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  5.9470720291137695\n",
      "    train time:               0.025082826614379883\n",
      "    test time:                0.012912750244140625\n",
      "    epoch time:               0.03850960731506348\n",
      "    last layer lr:            0.0072280000000000035\n",
      "epoch: 170 (23/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.023860060402916536\n",
      "    train cross_ent loss:     0.016554423763106268\n",
      "    test overall loss:        0.13879780968030295\n",
      "    test cross_ent loss:      0.13144826143980026\n",
      "    cluster loss:             2949.339599609375\n",
      "    separation loss:          3.00244410832723\n",
      "    avg separation loss:      7.627003351847331\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  6.082989692687988\n",
      "    train time:               0.024854183197021484\n",
      "    test time:                0.012909173965454102\n",
      "    epoch time:               0.03828549385070801\n",
      "    last layer lr:            0.006831999999999998\n",
      "epoch: 170 (24/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.018582233641710546\n",
      "    train cross_ent loss:     0.01167800391299857\n",
      "    test overall loss:        0.13878236462672552\n",
      "    test cross_ent loss:      0.13189141328136125\n",
      "    cluster loss:             2949.3397623697915\n",
      "    separation loss:          2.997471570968628\n",
      "    avg separation loss:      7.5959194501241045\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  5.62439489364624\n",
      "    train time:               0.024883508682250977\n",
      "    test time:                0.012969970703125\n",
      "    epoch time:               0.03836774826049805\n",
      "    last layer lr:            0.006436\n",
      "epoch: 170 (25/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.017114764286412135\n",
      "    train cross_ent loss:     0.010555758968823485\n",
      "    test overall loss:        0.1359714431067308\n",
      "    test cross_ent loss:      0.12955805783470473\n",
      "    cluster loss:             2949.3391927083335\n",
      "    separation loss:          3.0008816719055176\n",
      "    avg separation loss:      7.602145353953044\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  5.146831512451172\n",
      "    train time:               0.025183439254760742\n",
      "    test time:                0.01291799545288086\n",
      "    epoch time:               0.03862404823303223\n",
      "    last layer lr:            0.00604\n",
      "epoch: 170 (26/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.018299651849601004\n",
      "    train cross_ent loss:     0.012169448037942251\n",
      "    test overall loss:        0.13512062033017477\n",
      "    test cross_ent loss:      0.1291025790075461\n",
      "    cluster loss:             2949.33935546875\n",
      "    separation loss:          2.996488412221273\n",
      "    avg separation loss:      7.602015018463135\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  4.751483917236328\n",
      "    train time:               0.024869918823242188\n",
      "    test time:                0.012933731079101562\n",
      "    epoch time:               0.0383150577545166\n",
      "    last layer lr:            0.005644000000000002\n",
      "epoch: 170 (27/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.017796271584100194\n",
      "    train cross_ent loss:     0.011910044950329594\n",
      "    test overall loss:        0.1344344305495421\n",
      "    test cross_ent loss:      0.12874364914993444\n",
      "    cluster loss:             2949.339111328125\n",
      "    separation loss:          3.0025508403778076\n",
      "    avg separation loss:      7.615384737650554\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  4.424221992492676\n",
      "    train time:               0.024888038635253906\n",
      "    test time:                0.012912273406982422\n",
      "    epoch time:               0.03831338882446289\n",
      "    last layer lr:            0.005248000000000003\n",
      "epoch: 170 (28/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.015268376717964808\n",
      "    train cross_ent loss:     0.009774999899996651\n",
      "    test overall loss:        0.13447725027799606\n",
      "    test cross_ent loss:      0.12906324242552122\n",
      "    cluster loss:             2949.3396809895835\n",
      "    separation loss:          2.993968963623047\n",
      "    avg separation loss:      7.613846143086751\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  4.1474504470825195\n",
      "    train time:               0.02513575553894043\n",
      "    test time:                0.012931108474731445\n",
      "    epoch time:               0.03858804702758789\n",
      "    last layer lr:            0.004851999999999998\n",
      "epoch: 170 (29/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.019127575784093805\n",
      "    train cross_ent loss:     0.013919454637087054\n",
      "    test overall loss:        0.13393312568465868\n",
      "    test cross_ent loss:      0.12872837235530218\n",
      "    cluster loss:             2949.34033203125\n",
      "    separation loss:          3.004037857055664\n",
      "    avg separation loss:      7.631510575612386\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  3.938202142715454\n",
      "    train time:               0.025022268295288086\n",
      "    test time:                0.012917280197143555\n",
      "    epoch time:               0.038454532623291016\n",
      "    last layer lr:            0.004455999999999999\n",
      "epoch: 170 (30/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.016015568644636206\n",
      "    train cross_ent loss:     0.011066613460166587\n",
      "    test overall loss:        0.13361859073241553\n",
      "    test cross_ent loss:      0.12881213302413622\n",
      "    cluster loss:             2949.3400065104165\n",
      "    separation loss:          3.005847136179606\n",
      "    avg separation loss:      7.632400830586751\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  3.5398991107940674\n",
      "    train time:               0.0249936580657959\n",
      "    test time:                0.012905120849609375\n",
      "    epoch time:               0.03841352462768555\n",
      "    last layer lr:            0.004060000000000001\n",
      "epoch: 170 (31/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.018727301775167387\n",
      "    train cross_ent loss:     0.014195536767753461\n",
      "    test overall loss:        0.13343296324213347\n",
      "    test cross_ent loss:      0.1289733164012432\n",
      "    cluster loss:             2949.3391927083335\n",
      "    separation loss:          3.000715653101603\n",
      "    avg separation loss:      7.615689595540364\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  3.193089008331299\n",
      "    train time:               0.025075197219848633\n",
      "    test time:                0.012938737869262695\n",
      "    epoch time:               0.0385289192199707\n",
      "    last layer lr:            0.0036640000000000015\n",
      "epoch: 170 (32/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.01591809130170279\n",
      "    train cross_ent loss:     0.011719403012345234\n",
      "    test overall loss:        0.13345527897278467\n",
      "    test cross_ent loss:      0.12915088484684625\n",
      "    cluster loss:             2949.3397623697915\n",
      "    separation loss:          3.0011401176452637\n",
      "    avg separation loss:      7.610190232594808\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  3.037838935852051\n",
      "    train time:               0.0250701904296875\n",
      "    test time:                0.012946128845214844\n",
      "    epoch time:               0.038524627685546875\n",
      "    last layer lr:            0.003268000000000003\n",
      "epoch: 170 (33/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.01730206287983391\n",
      "    train cross_ent loss:     0.012997052477051815\n",
      "    test overall loss:        0.13302227233846983\n",
      "    test cross_ent loss:      0.12893586916228136\n",
      "    cluster loss:             2949.3400065104165\n",
      "    separation loss:          3.0005542437235513\n",
      "    avg separation loss:      7.623826344807942\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  2.8198442459106445\n",
      "    train time:               0.024854421615600586\n",
      "    test time:                0.012923717498779297\n",
      "    epoch time:               0.038286447525024414\n",
      "    last layer lr:            0.002871999999999997\n",
      "epoch: 170 (34/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.014596311892900202\n",
      "    train cross_ent loss:     0.010682788574033313\n",
      "    test overall loss:        0.13213728740811348\n",
      "    test cross_ent loss:      0.1284066184113423\n",
      "    cluster loss:             2949.34033203125\n",
      "    separation loss:          3.0011185805002847\n",
      "    avg separation loss:      7.626503785451253\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  2.4641122817993164\n",
      "    train time:               0.025207996368408203\n",
      "    test time:                0.012904167175292969\n",
      "    epoch time:               0.03862452507019043\n",
      "    last layer lr:            0.0024759999999999986\n",
      "epoch: 170 (35/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.014358218397117324\n",
      "    train cross_ent loss:     0.010870613675150607\n",
      "    test overall loss:        0.132974182566007\n",
      "    test cross_ent loss:      0.1295844962199529\n",
      "    cluster loss:             2949.340576171875\n",
      "    separation loss:          3.0051511923472085\n",
      "    avg separation loss:      7.638936996459961\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  2.1231322288513184\n",
      "    train time:               0.027911663055419922\n",
      "    test time:                0.012989282608032227\n",
      "    epoch time:               0.04141378402709961\n",
      "    last layer lr:            0.0020800000000000003\n",
      "epoch: 170 (36/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.014107748866081238\n",
      "    train cross_ent loss:     0.010982426762994792\n",
      "    test overall loss:        0.1321019890407721\n",
      "    test cross_ent loss:      0.1290629878640175\n",
      "    cluster loss:             2949.34033203125\n",
      "    separation loss:          2.9989310105641684\n",
      "    avg separation loss:      7.616360028584798\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  1.772443175315857\n",
      "    train time:               0.025124311447143555\n",
      "    test time:                0.012969732284545898\n",
      "    epoch time:               0.038611412048339844\n",
      "    last layer lr:            0.0016840000000000017\n",
      "epoch: 170 (37/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.015876209880742762\n",
      "    train cross_ent loss:     0.013048297156476311\n",
      "    test overall loss:        0.13174119715889296\n",
      "    test cross_ent loss:      0.12899679193894067\n",
      "    cluster loss:             2949.3396809895835\n",
      "    separation loss:          3.005859613418579\n",
      "    avg separation loss:      7.632246176401774\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  1.4778492450714111\n",
      "    train time:               0.025082826614379883\n",
      "    test time:                0.012970685958862305\n",
      "    epoch time:               0.03856921195983887\n",
      "    last layer lr:            0.001288000000000003\n",
      "epoch: 170 (38/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.01489346246752474\n",
      "    train cross_ent loss:     0.012344584515732195\n",
      "    test overall loss:        0.1311711979409059\n",
      "    test cross_ent loss:      0.12874670450886092\n",
      "    cluster loss:             2949.339599609375\n",
      "    separation loss:          3.0062195460001626\n",
      "    avg separation loss:      7.62789249420166\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  1.1579396724700928\n",
      "    train time:               0.025132417678833008\n",
      "    test time:                0.013082027435302734\n",
      "    epoch time:               0.03874993324279785\n",
      "    last layer lr:            0.0008919999999999973\n",
      "epoch: 170 (39/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.012264052975094981\n",
      "    train cross_ent loss:     0.010068646580394771\n",
      "    test overall loss:        0.1297033131122589\n",
      "    test cross_ent loss:      0.12763197844227156\n",
      "    cluster loss:             2949.340087890625\n",
      "    separation loss:          3.006537914276123\n",
      "    avg separation loss:      7.647744496663411\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  0.8047803640365601\n",
      "    train time:               0.0250244140625\n",
      "    test time:                0.013200044631958008\n",
      "    epoch time:               0.03874516487121582\n",
      "    last layer lr:            0.0004959999999999986\n",
      "epoch: 170 (40/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.012185161467641592\n",
      "    train cross_ent loss:     0.010309574375342991\n",
      "    test overall loss:        0.13096186146140099\n",
      "    test cross_ent loss:      0.12916834031542143\n",
      "    cluster loss:             2949.3401692708335\n",
      "    separation loss:          3.009037971496582\n",
      "    avg separation loss:      7.633376757303874\n",
      "    l1_addon loss:            42.21842575073242\n",
      "    l1 loss:                  0.526971697807312\n",
      "    train time:               0.02511882781982422\n",
      "    test time:                0.012938737869262695\n",
      "    epoch time:               0.03857111930847168\n",
      "    last layer lr:            0.0001\n",
      "epoch: 171 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.011603349923259683\n",
      "    train cross_ent loss:     0.009809853612548776\n",
      "    test overall loss:        0.13045678163568178\n",
      "    test cross_ent loss:      0.12866327725350857\n",
      "    cluster loss:             2949.340087890625\n",
      "    separation loss:          3.006791830062866\n",
      "    avg separation loss:      7.624156792958577\n",
      "    l1_addon loss:            42.21781539916992\n",
      "    l1 loss:                  0.526971697807312\n",
      "    train time:               0.06325531005859375\n",
      "    test time:                0.012964487075805664\n",
      "    epoch time:               0.07703542709350586\n",
      "    joint lr:                 0.0009861958963236286\n",
      "epoch: 172 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.011480050420181619\n",
      "    train cross_ent loss:     0.009685915843066242\n",
      "    test overall loss:        0.1282129796842734\n",
      "    test cross_ent loss:      0.12641851790249348\n",
      "    cluster loss:             2949.336181640625\n",
      "    separation loss:          2.9809025128682456\n",
      "    avg separation loss:      7.581803798675537\n",
      "    l1_addon loss:            42.249916076660156\n",
      "    l1 loss:                  0.526971697807312\n",
      "    train time:               0.0633080005645752\n",
      "    test time:                0.012990474700927734\n",
      "    epoch time:               0.07709956169128418\n",
      "    joint lr:                 0.001854667874720785\n",
      "epoch: 173 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.008592352271080017\n",
      "    train cross_ent loss:     0.006799176982086565\n",
      "    test overall loss:        0.12461542834838231\n",
      "    test cross_ent loss:      0.12282345071434975\n",
      "    cluster loss:             2949.3295084635415\n",
      "    separation loss:          2.9370808601379395\n",
      "    avg separation loss:      7.470548311869304\n",
      "    l1_addon loss:            42.166954040527344\n",
      "    l1 loss:                  0.526971697807312\n",
      "    train time:               0.05928206443786621\n",
      "    test time:                0.01262807846069336\n",
      "    epoch time:               0.07262015342712402\n",
      "    joint lr:                 0.0027056817939603655\n",
      "epoch: 174 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.007921636984166171\n",
      "    train cross_ent loss:     0.006129518940320445\n",
      "    test overall loss:        0.1199091908832391\n",
      "    test cross_ent loss:      0.11811347678303719\n",
      "    cluster loss:             2949.3238118489585\n",
      "    separation loss:          2.890868663787842\n",
      "    avg separation loss:      7.406434853871663\n",
      "    l1_addon loss:            42.291507720947266\n",
      "    l1 loss:                  0.526971697807312\n",
      "    train time:               0.05908465385437012\n",
      "    test time:                0.012645721435546875\n",
      "    epoch time:               0.07250595092773438\n",
      "    joint lr:                 0.003539499968027705\n",
      "epoch: 175 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.0070355952096482115\n",
      "    train cross_ent loss:     0.005236817575577233\n",
      "    test overall loss:        0.11114092419544856\n",
      "    test cross_ent loss:      0.10934354054431121\n",
      "    cluster loss:             2949.3212076822915\n",
      "    separation loss:          2.8826948006947837\n",
      "    avg separation loss:      7.379673004150391\n",
      "    l1_addon loss:            42.3471794128418\n",
      "    l1 loss:                  0.526971697807312\n",
      "    train time:               0.05892467498779297\n",
      "    test time:                0.012609481811523438\n",
      "    epoch time:               0.07231640815734863\n",
      "    joint lr:                 0.00435638121043428\n",
      "epoch: 176 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.004864714134277569\n",
      "    train cross_ent loss:     0.003072712065962454\n",
      "    test overall loss:        0.10490277223289013\n",
      "    test cross_ent loss:      0.10311625711619854\n",
      "    cluster loss:             2949.3234049479165\n",
      "    separation loss:          2.919663588205973\n",
      "    avg separation loss:      7.445795853932698\n",
      "    l1_addon loss:            41.98479461669922\n",
      "    l1 loss:                  0.526971697807312\n",
      "    train time:               0.05920147895812988\n",
      "    test time:                0.012717962265014648\n",
      "    epoch time:               0.07268834114074707\n",
      "    joint lr:                 0.00515658087799592\n",
      "epoch: 177 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.006086817683859004\n",
      "    train cross_ent loss:     0.004300602090855439\n",
      "    test overall loss:        0.1025553656121095\n",
      "    test cross_ent loss:      0.10076764319092035\n",
      "    cluster loss:             2949.3216959635415\n",
      "    separation loss:          2.9085254669189453\n",
      "    avg separation loss:      7.373905181884766\n",
      "    l1_addon loss:            42.02503204345703\n",
      "    l1 loss:                  0.526971697807312\n",
      "    train time:               0.05900740623474121\n",
      "    test time:                0.012610197067260742\n",
      "    epoch time:               0.0723884105682373\n",
      "    joint lr:                 0.005940350914085284\n",
      "epoch: 178 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.0038734103242556253\n",
      "    train cross_ent loss:     0.0020829992912088833\n",
      "    test overall loss:        0.1013763692850868\n",
      "    test cross_ent loss:      0.09958434011787176\n",
      "    cluster loss:             2949.318359375\n",
      "    separation loss:          2.8729284604390464\n",
      "    avg separation loss:      7.308810234069824\n",
      "    l1_addon loss:            42.168617248535156\n",
      "    l1 loss:                  0.526971697807312\n",
      "    train time:               0.058990478515625\n",
      "    test time:                0.01262974739074707\n",
      "    epoch time:               0.07236123085021973\n",
      "    joint lr:                 0.00670793989136506\n",
      "epoch: 179 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.00411665783677664\n",
      "    train cross_ent loss:     0.0023240058734599086\n",
      "    test overall loss:        0.10044154028097789\n",
      "    test cross_ent loss:      0.09865048620849848\n",
      "    cluster loss:             2949.3142903645835\n",
      "    separation loss:          2.8284974892934165\n",
      "    avg separation loss:      7.19305419921875\n",
      "    l1_addon loss:            42.13616943359375\n",
      "    l1 loss:                  0.526971697807312\n",
      "    train time:               0.05882692337036133\n",
      "    test time:                0.012614727020263672\n",
      "    epoch time:               0.07222247123718262\n",
      "    joint lr:                 0.007459593054007833\n",
      "epoch: 180 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.00304569433339768\n",
      "    train cross_ent loss:     0.0012568725570518938\n",
      "    test overall loss:        0.09905348531901836\n",
      "    test cross_ent loss:      0.09726549405604601\n",
      "    cluster loss:             2949.313232421875\n",
      "    separation loss:          2.7995723883310952\n",
      "    avg separation loss:      7.122073809305827\n",
      "    l1_addon loss:            42.03404235839844\n",
      "    l1 loss:                  0.526971697807312\n",
      "    train time:               0.05904245376586914\n",
      "    test time:                0.012634992599487305\n",
      "    epoch time:               0.07242918014526367\n",
      "    joint lr:                 0.008195552359408614\n",
      "epoch: 181 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.0030678353634559447\n",
      "    train cross_ent loss:     0.0012774394708685577\n",
      "    test overall loss:        0.09930047765374184\n",
      "    test cross_ent loss:      0.09750820975750685\n",
      "    cluster loss:             2949.3128255208335\n",
      "    separation loss:          2.7688894271850586\n",
      "    avg separation loss:      7.069320360819499\n",
      "    l1_addon loss:            42.17657470703125\n",
      "    l1 loss:                  0.526971697807312\n",
      "    train time:               0.05895280838012695\n",
      "    test time:                0.012601137161254883\n",
      "    epoch time:               0.07230162620544434\n",
      "    joint lr:                 0.007713866994023813\n",
      "epoch: 182 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.0029870005479703345\n",
      "    train cross_ent loss:     0.0011953312205150723\n",
      "    test overall loss:        0.09645771359403928\n",
      "    test cross_ent loss:      0.09466701031972964\n",
      "    cluster loss:             2949.3084309895835\n",
      "    separation loss:          2.7804083029429116\n",
      "    avg separation loss:      6.990601221720378\n",
      "    l1_addon loss:            42.12444305419922\n",
      "    l1 loss:                  0.526971697807312\n",
      "    train time:               0.058859825134277344\n",
      "    test time:                0.01263880729675293\n",
      "    epoch time:               0.07227420806884766\n",
      "    joint lr:                 0.007241005780710745\n",
      "epoch: 183 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.0024427582199374833\n",
      "    train cross_ent loss:     0.0006528894349078959\n",
      "    test overall loss:        0.09764046718676885\n",
      "    test cross_ent loss:      0.09585135554273923\n",
      "    cluster loss:             2949.3069661458335\n",
      "    separation loss:          2.7801335652669272\n",
      "    avg separation loss:      6.962113539377849\n",
      "    l1_addon loss:            42.07133483886719\n",
      "    l1 loss:                  0.526971697807312\n",
      "    train time:               0.058705806732177734\n",
      "    test time:                0.01262354850769043\n",
      "    epoch time:               0.07210659980773926\n",
      "    joint lr:                 0.006776840404964548\n",
      "epoch: 184 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.003595878111405505\n",
      "    train cross_ent loss:     0.0018072028162552873\n",
      "    test overall loss:        0.0968074497456352\n",
      "    test cross_ent loss:      0.09502141053477924\n",
      "    cluster loss:             2949.3031412760415\n",
      "    separation loss:          2.7635587056477866\n",
      "    avg separation loss:      6.937047640482585\n",
      "    l1_addon loss:            41.968963623046875\n",
      "    l1 loss:                  0.526971697807312\n",
      "    train time:               0.05895400047302246\n",
      "    test time:                0.012644052505493164\n",
      "    epoch time:               0.07237100601196289\n",
      "    joint lr:                 0.006321244236155204\n",
      "epoch: 185 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.002520936515389217\n",
      "    train cross_ent loss:     0.0007390763882237176\n",
      "    test overall loss:        0.1019538389518857\n",
      "    test cross_ent loss:      0.1001743186886112\n",
      "    cluster loss:             2949.308349609375\n",
      "    separation loss:          2.8017618656158447\n",
      "    avg separation loss:      6.928545316060384\n",
      "    l1_addon loss:            41.751708984375\n",
      "    l1 loss:                  0.526971697807312\n",
      "    train time:               0.05896925926208496\n",
      "    test time:                0.012639999389648438\n",
      "    epoch time:               0.07237076759338379\n",
      "    joint lr:                 0.00587409230668155\n",
      "epoch: 186 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.002912026597186923\n",
      "    train cross_ent loss:     0.0011321536439936608\n",
      "    test overall loss:        0.10216270542393129\n",
      "    test cross_ent loss:      0.10037931054830551\n",
      "    cluster loss:             2949.3019205729165\n",
      "    separation loss:          2.7737318674723306\n",
      "    avg separation loss:      6.895993550618489\n",
      "    l1_addon loss:            41.880863189697266\n",
      "    l1 loss:                  0.526971697807312\n",
      "    train time:               0.058951377868652344\n",
      "    test time:                0.012621402740478516\n",
      "    epoch time:               0.0723574161529541\n",
      "    joint lr:                 0.0054352612913737535\n",
      "epoch: 187 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.002313103164649672\n",
      "    train cross_ent loss:     0.000525955718735026\n",
      "    test overall loss:        0.10030729820330937\n",
      "    test cross_ent loss:      0.0985172325745225\n",
      "    cluster loss:             2949.3014322916665\n",
      "    separation loss:          2.7212514082590737\n",
      "    avg separation loss:      6.882367293039958\n",
      "    l1_addon loss:            42.103145599365234\n",
      "    l1 loss:                  0.526971697807312\n",
      "    train time:               0.058803558349609375\n",
      "    test time:                0.012750864028930664\n",
      "    epoch time:               0.07234811782836914\n",
      "    joint lr:                 0.005004629487141445\n",
      "epoch: 188 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.003382963128387928\n",
      "    train cross_ent loss:     0.0015926068186268418\n",
      "    test overall loss:        0.10038791100184123\n",
      "    test cross_ent loss:      0.0986006207143267\n",
      "    cluster loss:             2949.298828125\n",
      "    separation loss:          2.7055880228678384\n",
      "    avg separation loss:      6.838696797688802\n",
      "    l1_addon loss:            42.01062774658203\n",
      "    l1 loss:                  0.526971697807312\n",
      "    train time:               0.05897331237792969\n",
      "    test time:                0.012628555297851562\n",
      "    epoch time:               0.07236266136169434\n",
      "    joint lr:                 0.004582076792864645\n",
      "epoch: 189 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.0024690174549404117\n",
      "    train cross_ent loss:     0.0006875901195194779\n",
      "    test overall loss:        0.10421007002393405\n",
      "    test cross_ent loss:      0.10243343375623226\n",
      "    cluster loss:             2949.3019205729165\n",
      "    separation loss:          2.77099879582723\n",
      "    avg separation loss:      6.904801209767659\n",
      "    l1_addon loss:            41.655513763427734\n",
      "    l1 loss:                  0.526971697807312\n",
      "    train time:               0.05884885787963867\n",
      "    test time:                0.012630462646484375\n",
      "    epoch time:               0.07224392890930176\n",
      "    joint lr:                 0.004167484689524657\n",
      "epoch: 190 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.0029190576945741973\n",
      "    train cross_ent loss:     0.0011420190292281201\n",
      "    test overall loss:        0.10439774456123511\n",
      "    test cross_ent loss:      0.1026191112274925\n",
      "    cluster loss:             2949.3002115885415\n",
      "    separation loss:          2.759608268737793\n",
      "    avg separation loss:      6.870018323262532\n",
      "    l1_addon loss:            41.722110748291016\n",
      "    l1 loss:                  0.526971697807312\n",
      "    train time:               0.05904865264892578\n",
      "    test time:                0.012661933898925781\n",
      "    epoch time:               0.07247757911682129\n",
      "    joint lr:                 0.003760736220572192\n",
      "epoch: 191 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.0026257625108377803\n",
      "    train cross_ent loss:     0.0008448111184407026\n",
      "    test overall loss:        0.10323538227627675\n",
      "    test cross_ent loss:      0.10145116752634446\n",
      "    cluster loss:             2949.296630859375\n",
      "    separation loss:          2.7156426906585693\n",
      "    avg separation loss:      6.808539231618245\n",
      "    l1_addon loss:            41.90821838378906\n",
      "    l1 loss:                  0.526971697807312\n",
      "    train time:               0.05893850326538086\n",
      "    test time:                0.012653350830078125\n",
      "    epoch time:               0.07233405113220215\n",
      "    joint lr:                 0.0033617159725298235\n",
      "epoch: 192 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.002300127073087626\n",
      "    train cross_ent loss:     0.0005147852918728151\n",
      "    test overall loss:        0.10203009222944577\n",
      "    test cross_ent loss:      0.10024415406708916\n",
      "    cluster loss:             2949.2964680989585\n",
      "    separation loss:          2.696798324584961\n",
      "    avg separation loss:      6.810946941375732\n",
      "    l1_addon loss:            41.96556854248047\n",
      "    l1 loss:                  0.526971697807312\n",
      "    train time:               0.058990478515625\n",
      "    test time:                0.012623071670532227\n",
      "    epoch time:               0.07239079475402832\n",
      "    joint lr:                 0.002970310055826246\n",
      "epoch: 193 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.002668263442400429\n",
      "    train cross_ent loss:     0.0008825405853308944\n",
      "    test overall loss:        0.10211913815389077\n",
      "    test cross_ent loss:      0.1003341378333668\n",
      "    cluster loss:             2949.2963053385415\n",
      "    separation loss:          2.6807045936584473\n",
      "    avg separation loss:      6.755858421325684\n",
      "    l1_addon loss:            41.93437957763672\n",
      "    l1 loss:                  0.526971697807312\n",
      "    train time:               0.05890011787414551\n",
      "    test time:                0.012650728225708008\n",
      "    epoch time:               0.0723111629486084\n",
      "    joint lr:                 0.0025864060858594865\n",
      "epoch: 194 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.002427209737814135\n",
      "    train cross_ent loss:     0.0006431950880343922\n",
      "    test overall loss:        0.10045162246872981\n",
      "    test cross_ent loss:      0.098668590032806\n",
      "    cluster loss:             2949.2940266927085\n",
      "    separation loss:          2.683259884516398\n",
      "    avg separation loss:      6.766710599263509\n",
      "    l1_addon loss:            41.868717193603516\n",
      "    l1 loss:                  0.526971697807312\n",
      "    train time:               0.059061527252197266\n",
      "    test time:                0.012616872787475586\n",
      "    epoch time:               0.07245016098022461\n",
      "    joint lr:                 0.00220989316428648\n",
      "epoch: 195 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.0021171618330602846\n",
      "    train cross_ent loss:     0.00033484580732571584\n",
      "    test overall loss:        0.10055725866307814\n",
      "    test cross_ent loss:      0.09877568498874705\n",
      "    cluster loss:             2949.2935384114585\n",
      "    separation loss:          2.7002514203389487\n",
      "    avg separation loss:      6.79297669728597\n",
      "    l1_addon loss:            41.82020568847656\n",
      "    l1 loss:                  0.526971697807312\n",
      "    train time:               0.0589144229888916\n",
      "    test time:                0.01262807846069336\n",
      "    epoch time:               0.07233119010925293\n",
      "    joint lr:                 0.0018406618605363474\n",
      "epoch: 196 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.002183670281536049\n",
      "    train cross_ent loss:     0.00040244928418865637\n",
      "    test overall loss:        0.0993131020416816\n",
      "    test cross_ent loss:      0.09753207070752978\n",
      "    cluster loss:             2949.293701171875\n",
      "    separation loss:          2.7025345961252847\n",
      "    avg separation loss:      6.807376225789388\n",
      "    l1_addon loss:            41.8019905090332\n",
      "    l1 loss:                  0.526971697807312\n",
      "    train time:               0.0589599609375\n",
      "    test time:                0.012637853622436523\n",
      "    epoch time:               0.07238554954528809\n",
      "    joint lr:                 0.001478604193544789\n",
      "epoch: 197 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.0025439399242815045\n",
      "    train cross_ent loss:     0.0007632260805823737\n",
      "    test overall loss:        0.0992136358593901\n",
      "    test cross_ent loss:      0.09743342005337279\n",
      "    cluster loss:             2949.2942708333335\n",
      "    separation loss:          2.712329546610514\n",
      "    avg separation loss:      6.797077496846517\n",
      "    l1_addon loss:            41.774810791015625\n",
      "    l1 loss:                  0.526971697807312\n",
      "    train time:               0.05897331237792969\n",
      "    test time:                0.012608528137207031\n",
      "    epoch time:               0.07237076759338379\n",
      "    joint lr:                 0.0011236136137069992\n",
      "epoch: 198 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.00217114619186355\n",
      "    train cross_ent loss:     0.0003910308296326548\n",
      "    test overall loss:        0.09901311248540878\n",
      "    test cross_ent loss:      0.09723311864460508\n",
      "    cluster loss:             2949.2932942708335\n",
      "    separation loss:          2.705869277318319\n",
      "    avg separation loss:      6.77579927444458\n",
      "    l1_addon loss:            41.76752471923828\n",
      "    l1 loss:                  0.526971697807312\n",
      "    train time:               0.059031009674072266\n",
      "    test time:                0.012745857238769531\n",
      "    epoch time:               0.0725700855255127\n",
      "    joint lr:                 0.0007755849850466195\n",
      "epoch: 199 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.00215193380912145\n",
      "    train cross_ent loss:     0.00037186071858741343\n",
      "    test overall loss:        0.09993428302307923\n",
      "    test cross_ent loss:      0.09815411533539493\n",
      "    cluster loss:             2949.2932942708335\n",
      "    separation loss:          2.697186311086019\n",
      "    avg separation loss:      6.751504898071289\n",
      "    l1_addon loss:            41.773223876953125\n",
      "    l1 loss:                  0.526971697807312\n",
      "    train time:               0.05902504920959473\n",
      "    test time:                0.012666940689086914\n",
      "    epoch time:               0.07243824005126953\n",
      "    joint lr:                 0.0004344145675980766\n",
      "epoch: 200 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.0027276596908147135\n",
      "    train cross_ent loss:     0.0009474179920895646\n",
      "    test overall loss:        0.0992630689094464\n",
      "    test cross_ent loss:      0.09748264246930678\n",
      "    cluster loss:             2949.2932942708335\n",
      "    separation loss:          2.6993484497070312\n",
      "    avg separation loss:      6.74700927734375\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  0.526971697807312\n",
      "    train time:               0.05907106399536133\n",
      "    test time:                0.012644529342651367\n",
      "    epoch time:               0.07246589660644531\n",
      "    joint lr:                 0.0001\n",
      "epoch: 200 (PUSH) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.0027276596908147135\n",
      "    train cross_ent loss:     0.0009474179920895646\n",
      "    test overall loss:        0.12407098710536957\n",
      "    test cross_ent loss:      0.12229056283831596\n",
      "    cluster loss:             2949.318115234375\n",
      "    separation loss:          2.633738398551941\n",
      "    avg separation loss:      6.701364994049072\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  0.526971697807312\n",
      "    train time:               0.05907106399536133\n",
      "    test time:                0.012892961502075195\n",
      "    epoch time:               0.3916788101196289\n",
      "epoch: 200 (1/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.007647660198724932\n",
      "    train cross_ent loss:     0.006054601580318477\n",
      "    test overall loss:        0.12306473466257255\n",
      "    test cross_ent loss:      0.12158637245496114\n",
      "    cluster loss:             2949.3182779947915\n",
      "    separation loss:          2.6410202582677207\n",
      "    avg separation loss:      6.7254360516866045\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  0.22490927577018738\n",
      "    train time:               0.02427816390991211\n",
      "    test time:                0.012643575668334961\n",
      "    epoch time:               0.03743100166320801\n",
      "    last layer lr:            0.0007600000000000095\n",
      "epoch: 200 (2/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.008722915831539366\n",
      "    train cross_ent loss:     0.006733875256031752\n",
      "    test overall loss:        0.12480451787511508\n",
      "    test cross_ent loss:      0.12286669636766116\n",
      "    cluster loss:             2949.3193359375\n",
      "    separation loss:          2.648646593093872\n",
      "    avg separation loss:      6.751101175944011\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  0.6843620538711548\n",
      "    train time:               0.02377009391784668\n",
      "    test time:                0.012625932693481445\n",
      "    epoch time:               0.03690600395202637\n",
      "    last layer lr:            0.0014199999999999955\n",
      "epoch: 200 (3/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.007830471835202642\n",
      "    train cross_ent loss:     0.005613727443334129\n",
      "    test overall loss:        0.12475066632032394\n",
      "    test cross_ent loss:      0.12252648795644443\n",
      "    cluster loss:             2949.3194986979165\n",
      "    separation loss:          2.640537222226461\n",
      "    avg separation loss:      6.739804108937581\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  0.9707213044166565\n",
      "    train time:               0.023731708526611328\n",
      "    test time:                0.01258707046508789\n",
      "    epoch time:               0.03682398796081543\n",
      "    last layer lr:            0.0020800000000000046\n",
      "epoch: 200 (4/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.008440562368681034\n",
      "    train cross_ent loss:     0.005914399089912574\n",
      "    test overall loss:        0.12360330484807491\n",
      "    test cross_ent loss:      0.12099902952710788\n",
      "    cluster loss:             2949.318603515625\n",
      "    separation loss:          2.6397475798924765\n",
      "    avg separation loss:      6.724850018819173\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  1.3508150577545166\n",
      "    train time:               0.02376723289489746\n",
      "    test time:                0.012593984603881836\n",
      "    epoch time:               0.0368647575378418\n",
      "    last layer lr:            0.0027399999999999907\n",
      "epoch: 200 (5/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.010032960006760227\n",
      "    train cross_ent loss:     0.007122315466403961\n",
      "    test overall loss:        0.1247161403298378\n",
      "    test cross_ent loss:      0.12168411103387673\n",
      "    cluster loss:             2949.319091796875\n",
      "    separation loss:          2.6264285246531167\n",
      "    avg separation loss:      6.698210557301839\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  1.7785699367523193\n",
      "    train time:               0.023725509643554688\n",
      "    test time:                0.01258087158203125\n",
      "    epoch time:               0.036813974380493164\n",
      "    last layer lr:            0.0034\n",
      "epoch: 200 (6/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.008315695139269033\n",
      "    train cross_ent loss:     0.0049236849623007905\n",
      "    test overall loss:        0.1260059867054224\n",
      "    test cross_ent loss:      0.12255845405161381\n",
      "    cluster loss:             2949.3194986979165\n",
      "    separation loss:          2.6365678310394287\n",
      "    avg separation loss:      6.737338860829671\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  2.19407320022583\n",
      "    train time:               0.02367997169494629\n",
      "    test time:                0.012584686279296875\n",
      "    epoch time:               0.03676962852478027\n",
      "    last layer lr:            0.00406000000000001\n",
      "epoch: 200 (7/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.010341857197797961\n",
      "    train cross_ent loss:     0.00648107985034585\n",
      "    test overall loss:        0.12611733625332514\n",
      "    test cross_ent loss:      0.12210129139324029\n",
      "    cluster loss:             2949.3194986979165\n",
      "    separation loss:          2.6346036990483603\n",
      "    avg separation loss:      6.738544623057048\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  2.7625906467437744\n",
      "    train time:               0.023879051208496094\n",
      "    test time:                0.012600183486938477\n",
      "    epoch time:               0.0369877815246582\n",
      "    last layer lr:            0.004719999999999996\n",
      "epoch: 200 (8/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.009680601199054055\n",
      "    train cross_ent loss:     0.005364894142581357\n",
      "    test overall loss:        0.12575244841476282\n",
      "    test cross_ent loss:      0.12130544645090897\n",
      "    cluster loss:             2949.3193359375\n",
      "    separation loss:          2.6336356004079184\n",
      "    avg separation loss:      6.732421398162842\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  3.1935489177703857\n",
      "    train time:               0.02372121810913086\n",
      "    test time:                0.012655019760131836\n",
      "    epoch time:               0.036893606185913086\n",
      "    last layer lr:            0.0053800000000000054\n",
      "epoch: 200 (9/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.010370204018221961\n",
      "    train cross_ent loss:     0.005569299527754386\n",
      "    test overall loss:        0.12551530823111534\n",
      "    test cross_ent loss:      0.12057476863265038\n",
      "    cluster loss:             2949.3182779947915\n",
      "    separation loss:          2.637619932492574\n",
      "    avg separation loss:      6.728680928548177\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  3.6870789527893066\n",
      "    train time:               0.02372431755065918\n",
      "    test time:                0.012578248977661133\n",
      "    epoch time:               0.036804914474487305\n",
      "    last layer lr:            0.0060399999999999916\n",
      "epoch: 200 (10/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.009841721349706253\n",
      "    train cross_ent loss:     0.004601358798229032\n",
      "    test overall loss:        0.1258150121817986\n",
      "    test cross_ent loss:      0.12064538213113944\n",
      "    cluster loss:             2949.3184407552085\n",
      "    separation loss:          2.6350906689961753\n",
      "    avg separation loss:      6.725034077962239\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  3.916170597076416\n",
      "    train time:               0.023868083953857422\n",
      "    test time:                0.012569189071655273\n",
      "    epoch time:               0.03693890571594238\n",
      "    last layer lr:            0.0067\n",
      "epoch: 200 (11/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.012352795547081364\n",
      "    train cross_ent loss:     0.00666834360971633\n",
      "    test overall loss:        0.1268913820385933\n",
      "    test cross_ent loss:      0.12100045817593734\n",
      "    cluster loss:             2949.3193359375\n",
      "    separation loss:          2.6343588829040527\n",
      "    avg separation loss:      6.728211720784505\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  4.637470245361328\n",
      "    train time:               0.023749589920043945\n",
      "    test time:                0.012602090835571289\n",
      "    epoch time:               0.03685140609741211\n",
      "    last layer lr:            0.007360000000000011\n",
      "epoch: 200 (12/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.010389083479013708\n",
      "    train cross_ent loss:     0.004272369823108117\n",
      "    test overall loss:        0.12592938107748827\n",
      "    test cross_ent loss:      0.11979247070848942\n",
      "    cluster loss:             2949.319091796875\n",
      "    separation loss:          2.639651815096537\n",
      "    avg separation loss:      6.729212125142415\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  4.883453369140625\n",
      "    train time:               0.023848295211791992\n",
      "    test time:                0.012698650360107422\n",
      "    epoch time:               0.03706979751586914\n",
      "    last layer lr:            0.008019999999999994\n",
      "epoch: 200 (13/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.011668186427818404\n",
      "    train cross_ent loss:     0.005181250524603658\n",
      "    test overall loss:        0.12632665038108826\n",
      "    test cross_ent loss:      0.11957841987411182\n",
      "    cluster loss:             2949.3190104166665\n",
      "    separation loss:          2.6456602811813354\n",
      "    avg separation loss:      6.7383395830790205\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  5.494773864746094\n",
      "    train time:               0.023940324783325195\n",
      "    test time:                0.012629508972167969\n",
      "    epoch time:               0.0370786190032959\n",
      "    last layer lr:            0.008680000000000005\n",
      "epoch: 200 (14/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.011862356940077411\n",
      "    train cross_ent loss:     0.004895657391494347\n",
      "    test overall loss:        0.1262089523176352\n",
      "    test cross_ent loss:      0.11903033064057429\n",
      "    cluster loss:             2949.3182779947915\n",
      "    separation loss:          2.642375191052755\n",
      "    avg separation loss:      6.718538920084636\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  5.92516565322876\n",
      "    train time:               0.023723840713500977\n",
      "    test time:                0.012589693069458008\n",
      "    epoch time:               0.03681612014770508\n",
      "    last layer lr:            0.00933999999999999\n",
      "epoch: 200 (15/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.012084658361143537\n",
      "    train cross_ent loss:     0.004689929450655149\n",
      "    test overall loss:        0.1270507282267014\n",
      "    test cross_ent loss:      0.11954683065414429\n",
      "    cluster loss:             2949.3187662760415\n",
      "    separation loss:          2.633451302846273\n",
      "    avg separation loss:      6.714619159698486\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  6.250438690185547\n",
      "    train time:               0.023724079132080078\n",
      "    test time:                0.013116836547851562\n",
      "    epoch time:               0.03735184669494629\n",
      "    last layer lr:            0.01\n",
      "epoch: 200 (16/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.012671608684791459\n",
      "    train cross_ent loss:     0.004909320074754457\n",
      "    test overall loss:        0.12710953628023466\n",
      "    test cross_ent loss:      0.11912629504998525\n",
      "    cluster loss:             2949.318603515625\n",
      "    separation loss:          2.6301263570785522\n",
      "    avg separation loss:      6.705942312876384\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  6.729787826538086\n",
      "    train time:               0.02459120750427246\n",
      "    test time:                0.012918949127197266\n",
      "    epoch time:               0.03801465034484863\n",
      "    last layer lr:            0.009603999999999994\n",
      "epoch: 200 (17/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.012104978474477926\n",
      "    train cross_ent loss:     0.004154189438041713\n",
      "    test overall loss:        0.12698578834533691\n",
      "    test cross_ent loss:      0.11911125232776006\n",
      "    cluster loss:             2949.3194173177085\n",
      "    separation loss:          2.634387413660685\n",
      "    avg separation loss:      6.728204568227132\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  6.621081352233887\n",
      "    train time:               0.024469852447509766\n",
      "    test time:                0.012876033782958984\n",
      "    epoch time:               0.037850379943847656\n",
      "    last layer lr:            0.009208000000000003\n",
      "epoch: 200 (18/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.012573379402359327\n",
      "    train cross_ent loss:     0.004886372247710824\n",
      "    test overall loss:        0.12696518748998642\n",
      "    test cross_ent loss:      0.1192469069113334\n",
      "    cluster loss:             2949.319091796875\n",
      "    separation loss:          2.63969353834788\n",
      "    avg separation loss:      6.742944558461507\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  6.464820861816406\n",
      "    train time:               0.02445507049560547\n",
      "    test time:                0.012928962707519531\n",
      "    epoch time:               0.0378873348236084\n",
      "    last layer lr:            0.008811999999999997\n",
      "epoch: 200 (19/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.011556290193564363\n",
      "    train cross_ent loss:     0.004258549694592754\n",
      "    test overall loss:        0.1267242170870304\n",
      "    test cross_ent loss:      0.11955026226739089\n",
      "    cluster loss:             2949.3186848958335\n",
      "    separation loss:          2.635032057762146\n",
      "    avg separation loss:      6.721666177113851\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  5.920493125915527\n",
      "    train time:               0.024557828903198242\n",
      "    test time:                0.012975931167602539\n",
      "    epoch time:               0.03803610801696777\n",
      "    last layer lr:            0.008416000000000005\n",
      "epoch: 200 (20/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.013254723201195398\n",
      "    train cross_ent loss:     0.006188774352065391\n",
      "    test overall loss:        0.12704898416996002\n",
      "    test cross_ent loss:      0.1199530183027188\n",
      "    cluster loss:             2949.318603515625\n",
      "    separation loss:          2.633007287979126\n",
      "    avg separation loss:      6.722335656483968\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  5.842512130737305\n",
      "    train time:               0.024412155151367188\n",
      "    test time:                0.012920618057250977\n",
      "    epoch time:               0.03783559799194336\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 200 (21/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.01129759330716398\n",
      "    train cross_ent loss:     0.004292774647991691\n",
      "    test overall loss:        0.12655451397101083\n",
      "    test cross_ent loss:      0.11955899962534507\n",
      "    cluster loss:             2949.3190104166665\n",
      "    separation loss:          2.634015758832296\n",
      "    avg separation loss:      6.7293985684712725\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  5.742053985595703\n",
      "    train time:               0.024414539337158203\n",
      "    test time:                0.013216495513916016\n",
      "    epoch time:               0.038135528564453125\n",
      "    last layer lr:            0.007623999999999995\n",
      "epoch: 200 (22/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.010429614637460973\n",
      "    train cross_ent loss:     0.0036707774917077688\n",
      "    test overall loss:        0.1266170653204123\n",
      "    test cross_ent loss:      0.12000220113744338\n",
      "    cluster loss:             2949.3193359375\n",
      "    separation loss:          2.644906997680664\n",
      "    avg separation loss:      6.743143399556478\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  5.361403942108154\n",
      "    train time:               0.02456045150756836\n",
      "    test time:                0.012901782989501953\n",
      "    epoch time:               0.03796672821044922\n",
      "    last layer lr:            0.0072280000000000035\n",
      "epoch: 200 (23/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.012237047362658713\n",
      "    train cross_ent loss:     0.005834547026703755\n",
      "    test overall loss:        0.1258532851934433\n",
      "    test cross_ent loss:      0.11949251374850671\n",
      "    cluster loss:             2949.3190104166665\n",
      "    separation loss:          2.6493523915608725\n",
      "    avg separation loss:      6.742050488789876\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  5.1073150634765625\n",
      "    train time:               0.024515628814697266\n",
      "    test time:                0.012929201126098633\n",
      "    epoch time:               0.03794598579406738\n",
      "    last layer lr:            0.006831999999999998\n",
      "epoch: 200 (24/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.010489221351842085\n",
      "    train cross_ent loss:     0.0041202335463215905\n",
      "    test overall loss:        0.1254873132954041\n",
      "    test cross_ent loss:      0.11911749932914972\n",
      "    cluster loss:             2949.3196614583335\n",
      "    separation loss:          2.647039850552877\n",
      "    avg separation loss:      6.753351370493571\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  5.1163530349731445\n",
      "    train time:               0.02477407455444336\n",
      "    test time:                0.012934446334838867\n",
      "    epoch time:               0.038213491439819336\n",
      "    last layer lr:            0.006436000000000007\n",
      "epoch: 200 (25/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.010484494993256198\n",
      "    train cross_ent loss:     0.004386085680582457\n",
      "    test overall loss:        0.12447027613719304\n",
      "    test cross_ent loss:      0.11851517669856548\n",
      "    cluster loss:             2949.3190104166665\n",
      "    separation loss:          2.6464532613754272\n",
      "    avg separation loss:      6.74694029490153\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  4.701638221740723\n",
      "    train time:               0.024558067321777344\n",
      "    test time:                0.01287221908569336\n",
      "    epoch time:               0.03793931007385254\n",
      "    last layer lr:            0.00604\n",
      "epoch: 200 (26/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.010699819980396165\n",
      "    train cross_ent loss:     0.004941230406984687\n",
      "    test overall loss:        0.12471865614255269\n",
      "    test cross_ent loss:      0.11900700815021992\n",
      "    cluster loss:             2949.3185221354165\n",
      "    separation loss:          2.6332143942515054\n",
      "    avg separation loss:      6.7229658762613935\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  4.458194732666016\n",
      "    train time:               0.024408817291259766\n",
      "    test time:                0.012891530990600586\n",
      "    epoch time:               0.03780174255371094\n",
      "    last layer lr:            0.0056439999999999945\n",
      "epoch: 200 (27/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.009234691814829906\n",
      "    train cross_ent loss:     0.0037675180808744496\n",
      "    test overall loss:        0.12496459173659484\n",
      "    test cross_ent loss:      0.11961747178186972\n",
      "    cluster loss:             2949.3186848958335\n",
      "    separation loss:          2.6388861338297525\n",
      "    avg separation loss:      6.728419303894043\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  4.093664169311523\n",
      "    train time:               0.024687528610229492\n",
      "    test time:                0.01292562484741211\n",
      "    epoch time:               0.038118600845336914\n",
      "    last layer lr:            0.005248000000000003\n",
      "epoch: 200 (28/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.00865882531636291\n",
      "    train cross_ent loss:     0.0035001059813011023\n",
      "    test overall loss:        0.12388482068975766\n",
      "    test cross_ent loss:      0.11891930519292752\n",
      "    cluster loss:             2949.3190104166665\n",
      "    separation loss:          2.635553518931071\n",
      "    avg separation loss:      6.726665019989014\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  3.7120585441589355\n",
      "    train time:               0.024607181549072266\n",
      "    test time:                0.012916326522827148\n",
      "    epoch time:               0.0380251407623291\n",
      "    last layer lr:            0.004851999999999998\n",
      "epoch: 200 (29/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.008565116001086103\n",
      "    train cross_ent loss:     0.003827356688109123\n",
      "    test overall loss:        0.1238521138827006\n",
      "    test cross_ent loss:      0.1191334209094445\n",
      "    cluster loss:             2949.3192545572915\n",
      "    separation loss:          2.6432045698165894\n",
      "    avg separation loss:      6.740096251169841\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  3.4652369022369385\n",
      "    train time:               0.02439141273498535\n",
      "    test time:                0.012911558151245117\n",
      "    epoch time:               0.03781437873840332\n",
      "    last layer lr:            0.004456000000000006\n",
      "epoch: 200 (30/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.007985934822095765\n",
      "    train cross_ent loss:     0.003468140416468183\n",
      "    test overall loss:        0.12367698736488819\n",
      "    test cross_ent loss:      0.11919775605201721\n",
      "    cluster loss:             2949.3194173177085\n",
      "    separation loss:          2.642441511154175\n",
      "    avg separation loss:      6.74519141515096\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  3.2257747650146484\n",
      "    train time:               0.02442002296447754\n",
      "    test time:                0.01298379898071289\n",
      "    epoch time:               0.03791642189025879\n",
      "    last layer lr:            0.004060000000000001\n",
      "epoch: 200 (31/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.007577577347142829\n",
      "    train cross_ent loss:     0.003357110654986981\n",
      "    test overall loss:        0.12287745314339797\n",
      "    test cross_ent loss:      0.11879118252545595\n",
      "    cluster loss:             2949.319580078125\n",
      "    separation loss:          2.647088646888733\n",
      "    avg separation loss:      6.755498886108398\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  2.832810640335083\n",
      "    train time:               0.02443242073059082\n",
      "    test time:                0.01291799545288086\n",
      "    epoch time:               0.03785538673400879\n",
      "    last layer lr:            0.0036639999999999945\n",
      "epoch: 200 (32/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.007758882258915239\n",
      "    train cross_ent loss:     0.0038182345969188544\n",
      "    test overall loss:        0.12232220110793908\n",
      "    test cross_ent loss:      0.11842506844550371\n",
      "    cluster loss:             2949.3186848958335\n",
      "    separation loss:          2.639379620552063\n",
      "    avg separation loss:      6.726432800292969\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  2.643676996231079\n",
      "    train time:               0.024372339248657227\n",
      "    test time:                0.012938261032104492\n",
      "    epoch time:               0.03781318664550781\n",
      "    last layer lr:            0.003268000000000003\n",
      "epoch: 200 (33/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.009115209337323904\n",
      "    train cross_ent loss:     0.005420900855420364\n",
      "    test overall loss:        0.12196581003566583\n",
      "    test cross_ent loss:      0.11837783455848694\n",
      "    cluster loss:             2949.3194173177085\n",
      "    separation loss:          2.637397845586141\n",
      "    avg separation loss:      6.731139659881592\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  2.3345141410827637\n",
      "    train time:               0.024644851684570312\n",
      "    test time:                0.012918710708618164\n",
      "    epoch time:               0.03807401657104492\n",
      "    last layer lr:            0.002871999999999997\n",
      "epoch: 200 (34/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.006684303128470977\n",
      "    train cross_ent loss:     0.0032388735303862225\n",
      "    test overall loss:        0.12186805034677188\n",
      "    test cross_ent loss:      0.11842842710514863\n",
      "    cluster loss:             2949.3194986979165\n",
      "    separation loss:          2.639520287513733\n",
      "    avg separation loss:      6.748327891031901\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  2.1861698627471924\n",
      "    train time:               0.0245969295501709\n",
      "    test time:                0.012884855270385742\n",
      "    epoch time:               0.037984609603881836\n",
      "    last layer lr:            0.0024760000000000055\n",
      "epoch: 200 (35/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.006562132129652632\n",
      "    train cross_ent loss:     0.0033923854611607063\n",
      "    test overall loss:        0.12167752409974734\n",
      "    test cross_ent loss:      0.11863801162689924\n",
      "    cluster loss:             2949.3194986979165\n",
      "    separation loss:          2.6403380632400513\n",
      "    avg separation loss:      6.7424295743306475\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  1.7860591411590576\n",
      "    train time:               0.024472713470458984\n",
      "    test time:                0.013045787811279297\n",
      "    epoch time:               0.03804826736450195\n",
      "    last layer lr:            0.0020800000000000003\n",
      "epoch: 200 (36/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.006700698907176654\n",
      "    train cross_ent loss:     0.0038178119575604796\n",
      "    test overall loss:        0.12083310633897781\n",
      "    test cross_ent loss:      0.11805327733357747\n",
      "    cluster loss:             2949.3197428385415\n",
      "    separation loss:          2.6401010751724243\n",
      "    avg separation loss:      6.748624960581462\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  1.526374101638794\n",
      "    train time:               0.02481389045715332\n",
      "    test time:                0.013007640838623047\n",
      "    epoch time:               0.03836655616760254\n",
      "    last layer lr:            0.0016839999999999945\n",
      "epoch: 200 (37/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.007211930118501186\n",
      "    train cross_ent loss:     0.004592333389963541\n",
      "    test overall loss:        0.12015193204085033\n",
      "    test cross_ent loss:      0.11757361081739266\n",
      "    cluster loss:             2949.31884765625\n",
      "    separation loss:          2.6452606121699014\n",
      "    avg separation loss:      6.744791189829509\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  1.3248679637908936\n",
      "    train time:               0.02456378936767578\n",
      "    test time:                0.012959480285644531\n",
      "    epoch time:               0.038030147552490234\n",
      "    last layer lr:            0.001288000000000003\n",
      "epoch: 200 (38/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.006283171319713195\n",
      "    train cross_ent loss:     0.0038866856031947667\n",
      "    test overall loss:        0.12001071094224851\n",
      "    test cross_ent loss:      0.11772752522180478\n",
      "    cluster loss:             2949.31884765625\n",
      "    separation loss:          2.641161561012268\n",
      "    avg separation loss:      6.735611120859782\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  1.0297261476516724\n",
      "    train time:               0.024451732635498047\n",
      "    test time:                0.012918949127197266\n",
      "    epoch time:               0.03787398338317871\n",
      "    last layer lr:            0.0008919999999999973\n",
      "epoch: 200 (39/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.007837364346616797\n",
      "    train cross_ent loss:     0.005737321257280807\n",
      "    test overall loss:        0.11934135636935632\n",
      "    test cross_ent loss:      0.11731134075671434\n",
      "    cluster loss:             2949.319091796875\n",
      "    separation loss:          2.6446355183919272\n",
      "    avg separation loss:      6.740974426269531\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  0.776557207107544\n",
      "    train time:               0.02445673942565918\n",
      "    test time:                0.012923955917358398\n",
      "    epoch time:               0.03788018226623535\n",
      "    last layer lr:            0.0004960000000000057\n",
      "epoch: 200 (40/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.0049268572798205745\n",
      "    train cross_ent loss:     0.003084782452788204\n",
      "    test overall loss:        0.11947061493992805\n",
      "    test cross_ent loss:      0.11774320403734843\n",
      "    cluster loss:             2949.3191731770835\n",
      "    separation loss:          2.6446030139923096\n",
      "    avg separation loss:      6.736632506052653\n",
      "    l1_addon loss:            41.78197479248047\n",
      "    l1 loss:                  0.4739537537097931\n",
      "    train time:               0.024645328521728516\n",
      "    test time:                0.012910604476928711\n",
      "    epoch time:               0.038062334060668945\n",
      "    last layer lr:            0.0001\n",
      "Finished training in 30.80 seconds\n",
      "Last epoch test accu: 96.67%\n",
      "Done in 200 epochs, 42.34s\n",
      "Training for ArticularyWordRecognition, proto len 144, reception 0.25, features_lr 0.001, protos per class 10, l1_addon 3e-05\n",
      "Params: {\n",
      "    \"protos_per_class\": 10,\n",
      "    \"proto_features\": 32,\n",
      "    \"proto_len_latent\": 144,\n",
      "    \"features_lr\": 0.001,\n",
      "    \"num_classes\": 25,\n",
      "    \"coeffs\": {\n",
      "        \"crs_ent\": 1,\n",
      "        \"clst\": 0,\n",
      "        \"sep\": 0,\n",
      "        \"l1\": 0.001,\n",
      "        \"l1_addon\": 3e-05\n",
      "    },\n",
      "    \"num_warm_epochs\": 50,\n",
      "    \"push_start_epoch\": 110,\n",
      "    \"num_last_layer_epochs\": 40,\n",
      "    \"epochs\": 200\n",
      "}\n",
      "Training encoder\n",
      "epoch:   10/300 mse loss: 0.0432\n",
      "epoch:   20/300 mse loss: 0.0308\n",
      "epoch:   30/300 mse loss: 0.0421\n",
      "epoch:   40/300 mse loss: 0.0451\n",
      "epoch:   50/300 mse loss: 0.0565\n",
      "epoch:   60/300 mse loss: 0.0613\n",
      "epoch:   70/300 mse loss: 0.0701\n",
      "epoch:   80/300 mse loss: 0.0751\n",
      "epoch:   90/300 mse loss: 0.0728\n",
      "epoch:  100/300 mse loss: 0.0724\n",
      "epoch:  110/300 mse loss: 0.0776\n",
      "epoch:  120/300 mse loss: 0.0782\n",
      "epoch:  130/300 mse loss: 0.0774\n",
      "epoch:  140/300 mse loss: 0.0774\n",
      "epoch:  150/300 mse loss: 0.0762\n",
      "epoch:  160/300 mse loss: 0.0760\n",
      "epoch:  170/300 mse loss: 0.0775\n",
      "epoch:  180/300 mse loss: 0.0779\n",
      "epoch:  190/300 mse loss: 0.0775\n",
      "epoch:  200/300 mse loss: 0.0770\n",
      "epoch:  210/300 mse loss: 0.0763\n",
      "epoch:  220/300 mse loss: 0.0763\n",
      "epoch:  230/300 mse loss: 0.0762\n",
      "epoch:  240/300 mse loss: 0.0759\n",
      "epoch:  250/300 mse loss: 0.0763\n",
      "epoch:  260/300 mse loss: 0.0765\n",
      "epoch:  270/300 mse loss: 0.0762\n",
      "epoch:  280/300 mse loss: 0.0766\n",
      "epoch:  290/300 mse loss: 0.0760\n",
      "epoch:  300/300 mse loss: 0.0766\n",
      "Training ProtoTSNet\n",
      "Starting training\n",
      "epoch:   1 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 4.00%\n",
      "    train overall loss:       6.224601957533094\n",
      "    train cross_ent loss:     3.21884822845459\n",
      "    test overall loss:        6.2241441408793134\n",
      "    test cross_ent loss:      3.2188240687052407\n",
      "    cluster loss:             3363.2147623697915\n",
      "    separation loss:          1140.391845703125\n",
      "    avg separation loss:      1162.2974039713542\n",
      "    l1_addon loss:            177.33328247070312\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.042891740798950195\n",
      "    test time:                0.012701034545898438\n",
      "    epoch time:               0.05624699592590332\n",
      "epoch:   2 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 6.33%\n",
      "    train overall loss:       6.223738034566243\n",
      "    train cross_ent loss:     3.218742767969767\n",
      "    test overall loss:        6.223339716593425\n",
      "    test cross_ent loss:      3.2187399864196777\n",
      "    cluster loss:             3363.8894856770835\n",
      "    separation loss:          1143.4263102213542\n",
      "    avg separation loss:      1177.8981119791667\n",
      "    l1_addon loss:            153.32644653320312\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.042198896408081055\n",
      "    test time:                0.012864112854003906\n",
      "    epoch time:               0.0557098388671875\n",
      "epoch:   3 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 9.67%\n",
      "    train overall loss:       6.22291448381212\n",
      "    train cross_ent loss:     3.218609677420722\n",
      "    test overall loss:        6.222527662913005\n",
      "    test cross_ent loss:      3.218578656514486\n",
      "    cluster loss:             3357.5997721354165\n",
      "    separation loss:          1125.6731770833333\n",
      "    avg separation loss:      1184.7672526041667\n",
      "    l1_addon loss:            131.61956787109375\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.047171831130981445\n",
      "    test time:                0.012581586837768555\n",
      "    epoch time:               0.060402870178222656\n",
      "epoch:   4 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 24.67%\n",
      "    train overall loss:       6.222141530778673\n",
      "    train cross_ent loss:     3.2184545728895397\n",
      "    test overall loss:        6.221731821695964\n",
      "    test cross_ent loss:      3.2183565298716226\n",
      "    cluster loss:             3352.65673828125\n",
      "    separation loss:          1121.5701904296875\n",
      "    avg separation loss:      1198.5767008463542\n",
      "    l1_addon loss:            112.494873046875\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04228997230529785\n",
      "    test time:                0.012605905532836914\n",
      "    epoch time:               0.05554556846618652\n",
      "epoch:   5 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 39.33%\n",
      "    train overall loss:       6.2214089499579535\n",
      "    train cross_ent loss:     3.218262407514784\n",
      "    test overall loss:        6.221007664998372\n",
      "    test cross_ent loss:      3.2181347211201987\n",
      "    cluster loss:             3345.5743815104165\n",
      "    separation loss:          1106.0031331380208\n",
      "    avg separation loss:      1204.0660807291667\n",
      "    l1_addon loss:            95.74784851074219\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04877591133117676\n",
      "    test time:                0.01256251335144043\n",
      "    epoch time:               0.06199526786804199\n",
      "epoch:   6 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 38.67%\n",
      "    train overall loss:       6.220732900831434\n",
      "    train cross_ent loss:     3.2180536058213978\n",
      "    test overall loss:        6.220331192016602\n",
      "    test cross_ent loss:      3.2178754011789956\n",
      "    cluster loss:             3331.538330078125\n",
      "    separation loss:          1073.0268961588542\n",
      "    avg separation loss:      1184.1721598307292\n",
      "    l1_addon loss:            81.85765075683594\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05213332176208496\n",
      "    test time:                0.012612342834472656\n",
      "    epoch time:               0.06539487838745117\n",
      "epoch:   7 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 43.00%\n",
      "    train overall loss:       6.2201128005981445\n",
      "    train cross_ent loss:     3.2178039815690784\n",
      "    test overall loss:        6.219677448272705\n",
      "    test cross_ent loss:      3.2175291379292807\n",
      "    cluster loss:             3306.0765787760415\n",
      "    separation loss:          1010.8681640625\n",
      "    avg separation loss:      1130.3409830729167\n",
      "    l1_addon loss:            71.61260986328125\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04200625419616699\n",
      "    test time:                0.012608528137207031\n",
      "    epoch time:               0.05526995658874512\n",
      "epoch:   8 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 48.33%\n",
      "    train overall loss:       6.219456566704644\n",
      "    train cross_ent loss:     3.217401319079929\n",
      "    test overall loss:        6.218958377838135\n",
      "    test cross_ent loss:      3.21699587504069\n",
      "    cluster loss:             3271.553466796875\n",
      "    separation loss:          925.3003336588541\n",
      "    avg separation loss:      1053.6834309895833\n",
      "    l1_addon loss:            65.3995590209961\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04971742630004883\n",
      "    test time:                0.012623071670532227\n",
      "    epoch time:               0.06299972534179688\n",
      "epoch:   9 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 52.67%\n",
      "    train overall loss:       6.218632857004802\n",
      "    train cross_ent loss:     3.2167171637217202\n",
      "    test overall loss:        6.218024730682373\n",
      "    test cross_ent loss:      3.216162363688151\n",
      "    cluster loss:             3228.8395182291665\n",
      "    separation loss:          817.5518391927084\n",
      "    avg separation loss:      957.1312052408854\n",
      "    l1_addon loss:            62.065181732177734\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04212212562561035\n",
      "    test time:                0.020775794982910156\n",
      "    epoch time:               0.06362438201904297\n",
      "epoch:  10 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 56.67%\n",
      "    train overall loss:       6.217444737752278\n",
      "    train cross_ent loss:     3.2156232992808023\n",
      "    test overall loss:        6.216645081837972\n",
      "    test cross_ent loss:      3.214874267578125\n",
      "    cluster loss:             3184.0704752604165\n",
      "    separation loss:          700.0088297526041\n",
      "    avg separation loss:      844.3350626627604\n",
      "    l1_addon loss:            59.01600646972656\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.042183876037597656\n",
      "    test time:                0.012590885162353516\n",
      "    epoch time:               0.05542778968811035\n",
      "epoch:  11 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 56.67%\n",
      "    train overall loss:       6.215896977318658\n",
      "    train cross_ent loss:     3.214203781551785\n",
      "    test overall loss:        6.214878877003987\n",
      "    test cross_ent loss:      3.2132911682128906\n",
      "    cluster loss:             3149.2403971354165\n",
      "    separation loss:          615.4325764973959\n",
      "    avg separation loss:      743.208251953125\n",
      "    l1_addon loss:            52.913387298583984\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04672122001647949\n",
      "    test time:                0.012634038925170898\n",
      "    epoch time:               0.060014963150024414\n",
      "epoch:  12 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 57.67%\n",
      "    train overall loss:       6.214074611663818\n",
      "    train cross_ent loss:     3.212551540798611\n",
      "    test overall loss:        6.212618192036946\n",
      "    test cross_ent loss:      3.211128314336141\n",
      "    cluster loss:             3121.5301920572915\n",
      "    separation loss:          542.7348836263021\n",
      "    avg separation loss:      674.3986612955729\n",
      "    l1_addon loss:            49.660972595214844\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04225969314575195\n",
      "    test time:                0.012611150741577148\n",
      "    epoch time:               0.055524349212646484\n",
      "epoch:  13 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 55.00%\n",
      "    train overall loss:       6.211578422122532\n",
      "    train cross_ent loss:     3.2101604408688016\n",
      "    test overall loss:        6.210013548533122\n",
      "    test cross_ent loss:      3.2086709340413413\n",
      "    cluster loss:             3101.6399739583335\n",
      "    separation loss:          497.6452331542969\n",
      "    avg separation loss:      625.2239990234375\n",
      "    l1_addon loss:            44.746910095214844\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04662466049194336\n",
      "    test time:                0.012599468231201172\n",
      "    epoch time:               0.05988287925720215\n",
      "epoch:  14 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 57.67%\n",
      "    train overall loss:       6.208657582600911\n",
      "    train cross_ent loss:     3.2073287698957653\n",
      "    test overall loss:        6.206601460774739\n",
      "    test cross_ent loss:      3.205292065938314\n",
      "    cluster loss:             3083.9551595052085\n",
      "    separation loss:          454.90943400065106\n",
      "    avg separation loss:      587.8470662434896\n",
      "    l1_addon loss:            43.650638580322266\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.042025089263916016\n",
      "    test time:                0.02442169189453125\n",
      "    epoch time:               0.06710219383239746\n",
      "epoch:  15 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 56.67%\n",
      "    train overall loss:       6.204954200320774\n",
      "    train cross_ent loss:     3.203656461503771\n",
      "    test overall loss:        6.2023383776346845\n",
      "    test cross_ent loss:      3.2010701497395835\n",
      "    cluster loss:             3067.4022623697915\n",
      "    separation loss:          414.8933410644531\n",
      "    avg separation loss:      550.1239624023438\n",
      "    l1_addon loss:            42.26321029663086\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.0419919490814209\n",
      "    test time:                0.012593269348144531\n",
      "    epoch time:               0.055237770080566406\n",
      "epoch:  16 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 58.00%\n",
      "    train overall loss:       6.200321038564046\n",
      "    train cross_ent loss:     3.1990516450670032\n",
      "    test overall loss:        6.196505864461263\n",
      "    test cross_ent loss:      3.195246378580729\n",
      "    cluster loss:             3052.488037109375\n",
      "    separation loss:          377.9315592447917\n",
      "    avg separation loss:      518.3754475911459\n",
      "    l1_addon loss:            41.98284912109375\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04235100746154785\n",
      "    test time:                0.012612581253051758\n",
      "    epoch time:               0.05562996864318848\n",
      "epoch:  17 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 56.33%\n",
      "    train overall loss:       6.193373892042372\n",
      "    train cross_ent loss:     3.192112578286065\n",
      "    test overall loss:        6.188139915466309\n",
      "    test cross_ent loss:      3.186906178792318\n",
      "    cluster loss:             3037.2545572916665\n",
      "    separation loss:          336.8479817708333\n",
      "    avg separation loss:      474.8579508463542\n",
      "    l1_addon loss:            41.120445251464844\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.042153120040893555\n",
      "    test time:                0.012598276138305664\n",
      "    epoch time:               0.05540800094604492\n",
      "epoch:  18 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 56.33%\n",
      "    train overall loss:       6.183549245198567\n",
      "    train cross_ent loss:     3.182307905620999\n",
      "    test overall loss:        6.175368309020996\n",
      "    test cross_ent loss:      3.1741272608439126\n",
      "    cluster loss:             3023.3160807291665\n",
      "    separation loss:          298.81005859375\n",
      "    avg separation loss:      441.1402893066406\n",
      "    l1_addon loss:            41.359397888183594\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.049874067306518555\n",
      "    test time:                0.01260519027709961\n",
      "    epoch time:               0.06313252449035645\n",
      "epoch:  19 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 56.67%\n",
      "    train overall loss:       6.168822712368435\n",
      "    train cross_ent loss:     3.1675863530900745\n",
      "    test overall loss:        6.15832503636678\n",
      "    test cross_ent loss:      3.1570774714152017\n",
      "    cluster loss:             3011.021484375\n",
      "    separation loss:          261.17918904622394\n",
      "    avg separation loss:      399.3509012858073\n",
      "    l1_addon loss:            41.58179473876953\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04216885566711426\n",
      "    test time:                0.014976978302001953\n",
      "    epoch time:               0.05780148506164551\n",
      "epoch:  20 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 56.33%\n",
      "    train overall loss:       6.147626082102458\n",
      "    train cross_ent loss:     3.146403127246433\n",
      "    test overall loss:        6.134517669677734\n",
      "    test cross_ent loss:      3.1333254973093667\n",
      "    cluster loss:             3000.237548828125\n",
      "    separation loss:          227.07617696126303\n",
      "    avg separation loss:      359.16724650065106\n",
      "    l1_addon loss:            39.73601531982422\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04223322868347168\n",
      "    test time:                0.01262354850769043\n",
      "    epoch time:               0.05551481246948242\n",
      "epoch:  21 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 57.33%\n",
      "    train overall loss:       6.1178915235731335\n",
      "    train cross_ent loss:     3.1166955629984536\n",
      "    test overall loss:        6.102560520172119\n",
      "    test cross_ent loss:      3.1013755003611245\n",
      "    cluster loss:             2990.9246419270835\n",
      "    separation loss:          197.01441955566406\n",
      "    avg separation loss:      326.16550699869794\n",
      "    l1_addon loss:            39.49082565307617\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.0507662296295166\n",
      "    test time:                0.012581825256347656\n",
      "    epoch time:               0.06400442123413086\n",
      "epoch:  22 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 59.33%\n",
      "    train overall loss:       6.0851072205437555\n",
      "    train cross_ent loss:     3.0839306248558893\n",
      "    test overall loss:        6.068815390268962\n",
      "    test cross_ent loss:      3.0676702658335366\n",
      "    cluster loss:             2983.6142578125\n",
      "    separation loss:          168.55776977539062\n",
      "    avg separation loss:      289.7886555989583\n",
      "    l1_addon loss:            38.16352844238281\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04212760925292969\n",
      "    test time:                0.012604475021362305\n",
      "    epoch time:               0.05538344383239746\n",
      "epoch:  23 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 62.33%\n",
      "    train overall loss:       6.047652032640245\n",
      "    train cross_ent loss:     3.0465063518948026\n",
      "    test overall loss:        6.0427314440409345\n",
      "    test cross_ent loss:      3.041576862335205\n",
      "    cluster loss:             2977.6990559895835\n",
      "    separation loss:          146.51759338378906\n",
      "    avg separation loss:      263.4540049235026\n",
      "    l1_addon loss:            38.48456954956055\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.043596506118774414\n",
      "    test time:                0.012601852416992188\n",
      "    epoch time:               0.05684328079223633\n",
      "epoch:  24 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 67.67%\n",
      "    train overall loss:       6.010077317555745\n",
      "    train cross_ent loss:     3.008943796157837\n",
      "    test overall loss:        6.019115606943767\n",
      "    test cross_ent loss:      3.0179953575134277\n",
      "    cluster loss:             2972.791259765625\n",
      "    separation loss:          127.6854731241862\n",
      "    avg separation loss:      238.19706217447916\n",
      "    l1_addon loss:            37.33539962768555\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05045366287231445\n",
      "    test time:                0.012585878372192383\n",
      "    epoch time:               0.06370878219604492\n",
      "epoch:  25 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 68.33%\n",
      "    train overall loss:       5.982487890455458\n",
      "    train cross_ent loss:     2.9813669522603354\n",
      "    test overall loss:        6.0053049723307295\n",
      "    test cross_ent loss:      3.0042404333750405\n",
      "    cluster loss:             2969.947509765625\n",
      "    separation loss:          115.61596171061198\n",
      "    avg separation loss:      220.3255818684896\n",
      "    l1_addon loss:            35.4811897277832\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04214906692504883\n",
      "    test time:                0.012732982635498047\n",
      "    epoch time:               0.055545806884765625\n",
      "epoch:  26 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 75.33%\n",
      "    train overall loss:       5.96109061770969\n",
      "    train cross_ent loss:     2.959994633992513\n",
      "    test overall loss:        5.987338701883952\n",
      "    test cross_ent loss:      2.9862473805745444\n",
      "    cluster loss:             2966.004638671875\n",
      "    separation loss:          98.99992370605469\n",
      "    avg separation loss:      200.25310770670572\n",
      "    l1_addon loss:            36.37046813964844\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.046253204345703125\n",
      "    test time:                0.012593746185302734\n",
      "    epoch time:               0.05949831008911133\n",
      "epoch:  27 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 77.00%\n",
      "    train overall loss:       5.932816028594971\n",
      "    train cross_ent loss:     2.931727886199951\n",
      "    test overall loss:        5.977578639984131\n",
      "    test cross_ent loss:      2.976506074269613\n",
      "    cluster loss:             2963.8564453125\n",
      "    separation loss:          90.30352020263672\n",
      "    avg separation loss:      190.30520629882812\n",
      "    l1_addon loss:            35.754478454589844\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.0421605110168457\n",
      "    test time:                0.01274418830871582\n",
      "    epoch time:               0.055556297302246094\n",
      "epoch:  28 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 79.67%\n",
      "    train overall loss:       5.9082626236809626\n",
      "    train cross_ent loss:     2.9071890778011746\n",
      "    test overall loss:        5.9639937082926435\n",
      "    test cross_ent loss:      2.9629196325937905\n",
      "    cluster loss:             2961.916259765625\n",
      "    separation loss:          81.70331573486328\n",
      "    avg separation loss:      177.74594116210938\n",
      "    l1_addon loss:            35.78904342651367\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.042328834533691406\n",
      "    test time:                0.012638330459594727\n",
      "    epoch time:               0.05561351776123047\n",
      "epoch:  29 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 80.33%\n",
      "    train overall loss:       5.876544793446858\n",
      "    train cross_ent loss:     2.875484175152249\n",
      "    test overall loss:        5.953776836395264\n",
      "    test cross_ent loss:      2.952735185623169\n",
      "    cluster loss:             2960.511962890625\n",
      "    separation loss:          74.27095286051433\n",
      "    avg separation loss:      163.5846913655599\n",
      "    l1_addon loss:            34.707275390625\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04375314712524414\n",
      "    test time:                0.0126953125\n",
      "    epoch time:               0.05710196495056152\n",
      "epoch:  30 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 81.33%\n",
      "    train overall loss:       5.854479789733887\n",
      "    train cross_ent loss:     2.853432946734958\n",
      "    test overall loss:        5.944448630015056\n",
      "    test cross_ent loss:      2.9434288342793784\n",
      "    cluster loss:             2959.9851888020835\n",
      "    separation loss:          70.55526606241862\n",
      "    avg separation loss:      156.6267344156901\n",
      "    l1_addon loss:            33.98013687133789\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04205679893493652\n",
      "    test time:                0.012614727020263672\n",
      "    epoch time:               0.05531454086303711\n",
      "epoch:  31 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 80.67%\n",
      "    train overall loss:       5.843615796830919\n",
      "    train cross_ent loss:     2.8425883717007108\n",
      "    test overall loss:        5.933602174123128\n",
      "    test cross_ent loss:      2.932572523752848\n",
      "    cluster loss:             2958.7411295572915\n",
      "    separation loss:          66.05306243896484\n",
      "    avg separation loss:      150.92933146158853\n",
      "    l1_addon loss:            34.32338333129883\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04642224311828613\n",
      "    test time:                0.012614250183105469\n",
      "    epoch time:               0.05969810485839844\n",
      "epoch:  32 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 80.67%\n",
      "    train overall loss:       5.837521394093831\n",
      "    train cross_ent loss:     2.8364959557851157\n",
      "    test overall loss:        5.938442230224609\n",
      "    test cross_ent loss:      2.937413454055786\n",
      "    cluster loss:             2958.392578125\n",
      "    separation loss:          62.331522623697914\n",
      "    avg separation loss:      145.8002726236979\n",
      "    l1_addon loss:            34.27876281738281\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04817318916320801\n",
      "    test time:                0.012630939483642578\n",
      "    epoch time:               0.061456918716430664\n",
      "epoch:  33 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 80.33%\n",
      "    train overall loss:       5.812689834170872\n",
      "    train cross_ent loss:     2.811680210961236\n",
      "    test overall loss:        5.927844206492106\n",
      "    test cross_ent loss:      2.926842371622721\n",
      "    cluster loss:             2957.933349609375\n",
      "    separation loss:          61.33436965942383\n",
      "    avg separation loss:      142.22279357910156\n",
      "    l1_addon loss:            33.4022216796875\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04203486442565918\n",
      "    test time:                0.012613534927368164\n",
      "    epoch time:               0.05530285835266113\n",
      "epoch:  34 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 80.00%\n",
      "    train overall loss:       5.787854618496365\n",
      "    train cross_ent loss:     2.7868568102518716\n",
      "    test overall loss:        5.920560995737712\n",
      "    test cross_ent loss:      2.919564723968506\n",
      "    cluster loss:             2957.4807942708335\n",
      "    separation loss:          58.455169677734375\n",
      "    avg separation loss:      138.03523763020834\n",
      "    l1_addon loss:            33.200321197509766\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04624509811401367\n",
      "    test time:                0.012569904327392578\n",
      "    epoch time:               0.05946087837219238\n",
      "epoch:  35 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 79.33%\n",
      "    train overall loss:       5.786306116316053\n",
      "    train cross_ent loss:     2.7853200435638428\n",
      "    test overall loss:        5.937918821970622\n",
      "    test cross_ent loss:      2.9368961652119956\n",
      "    cluster loss:             2957.7830403645835\n",
      "    separation loss:          58.022290547688804\n",
      "    avg separation loss:      136.90357208251953\n",
      "    l1_addon loss:            34.0794677734375\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.043688058853149414\n",
      "    test time:                0.012484073638916016\n",
      "    epoch time:               0.0568234920501709\n",
      "epoch:  36 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 77.67%\n",
      "    train overall loss:       5.785146925184462\n",
      "    train cross_ent loss:     2.7841631836361356\n",
      "    test overall loss:        5.919623215993245\n",
      "    test cross_ent loss:      2.918630282084147\n",
      "    cluster loss:             2957.4932454427085\n",
      "    separation loss:          55.61203384399414\n",
      "    avg separation loss:      134.60082499186197\n",
      "    l1_addon loss:            33.09111785888672\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.042031288146972656\n",
      "    test time:                0.012683629989624023\n",
      "    epoch time:               0.05536675453186035\n",
      "epoch:  37 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 76.67%\n",
      "    train overall loss:       5.740725888146295\n",
      "    train cross_ent loss:     2.7397570345136852\n",
      "    test overall loss:        5.888378938039144\n",
      "    test cross_ent loss:      2.887428601582845\n",
      "    cluster loss:             2956.8558756510415\n",
      "    separation loss:          53.21869023640951\n",
      "    avg separation loss:      128.06403605143228\n",
      "    l1_addon loss:            31.67401885986328\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04355597496032715\n",
      "    test time:                0.012619733810424805\n",
      "    epoch time:               0.05683493614196777\n",
      "epoch:  38 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 76.33%\n",
      "    train overall loss:       5.74168046315511\n",
      "    train cross_ent loss:     2.740726629892985\n",
      "    test overall loss:        5.891086260477702\n",
      "    test cross_ent loss:      2.890135129292806\n",
      "    cluster loss:             2956.9708658854165\n",
      "    separation loss:          52.695212046305336\n",
      "    avg separation loss:      126.27308909098308\n",
      "    l1_addon loss:            31.701282501220703\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04202461242675781\n",
      "    test time:                0.012594938278198242\n",
      "    epoch time:               0.05526328086853027\n",
      "epoch:  39 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 76.67%\n",
      "    train overall loss:       5.71906402375963\n",
      "    train cross_ent loss:     2.7181181642744274\n",
      "    test overall loss:        5.887155373891194\n",
      "    test cross_ent loss:      2.8862009048461914\n",
      "    cluster loss:             2956.8064778645835\n",
      "    separation loss:          51.61138916015625\n",
      "    avg separation loss:      125.34120686848958\n",
      "    l1_addon loss:            31.807674407958984\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.044318437576293945\n",
      "    test time:                0.012637615203857422\n",
      "    epoch time:               0.05761218070983887\n",
      "epoch:  40 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 76.00%\n",
      "    train overall loss:       5.702033095889622\n",
      "    train cross_ent loss:     2.701092481613159\n",
      "    test overall loss:        5.87550163269043\n",
      "    test cross_ent loss:      2.874582052230835\n",
      "    cluster loss:             2956.6222330729165\n",
      "    separation loss:          49.94891484578451\n",
      "    avg separation loss:      120.79745992024739\n",
      "    l1_addon loss:            30.643695831298828\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04211282730102539\n",
      "    test time:                0.012627840042114258\n",
      "    epoch time:               0.05538153648376465\n",
      "epoch:  41 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 75.67%\n",
      "    train overall loss:       5.703028255038792\n",
      "    train cross_ent loss:     2.7020999325646295\n",
      "    test overall loss:        5.867746194203694\n",
      "    test cross_ent loss:      2.866844733556112\n",
      "    cluster loss:             2956.5802408854165\n",
      "    separation loss:          49.53936640421549\n",
      "    avg separation loss:      120.44366200764973\n",
      "    l1_addon loss:            30.048675537109375\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.042414188385009766\n",
      "    test time:                0.012614250183105469\n",
      "    epoch time:               0.05568957328796387\n",
      "epoch:  42 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 75.00%\n",
      "    train overall loss:       5.700426472557916\n",
      "    train cross_ent loss:     2.699503501256307\n",
      "    test overall loss:        5.865938186645508\n",
      "    test cross_ent loss:      2.865047295888265\n",
      "    cluster loss:             2956.5083821614585\n",
      "    separation loss:          48.03119023640951\n",
      "    avg separation loss:      114.49960581461589\n",
      "    l1_addon loss:            29.691116333007812\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04344034194946289\n",
      "    test time:                0.012601375579833984\n",
      "    epoch time:               0.056697845458984375\n",
      "epoch:  43 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 76.00%\n",
      "    train overall loss:       5.691297743055555\n",
      "    train cross_ent loss:     2.6903838051689997\n",
      "    test overall loss:        5.856616020202637\n",
      "    test cross_ent loss:      2.8557117780049643\n",
      "    cluster loss:             2956.3614095052085\n",
      "    separation loss:          47.113783518473305\n",
      "    avg separation loss:      117.24793752034505\n",
      "    l1_addon loss:            30.1390323638916\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04212212562561035\n",
      "    test time:                0.012616872787475586\n",
      "    epoch time:               0.05539441108703613\n",
      "epoch:  44 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 74.67%\n",
      "    train overall loss:       5.654314253065321\n",
      "    train cross_ent loss:     2.6534106731414795\n",
      "    test overall loss:        5.846914768218994\n",
      "    test cross_ent loss:      2.8460280100504556\n",
      "    cluster loss:             2956.127197265625\n",
      "    separation loss:          45.9735959370931\n",
      "    avg separation loss:      111.48754374186198\n",
      "    l1_addon loss:            29.547954559326172\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.0421292781829834\n",
      "    test time:                0.012587785720825195\n",
      "    epoch time:               0.05535435676574707\n",
      "epoch:  45 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 75.00%\n",
      "    train overall loss:       5.646380053626166\n",
      "    train cross_ent loss:     2.6454896926879883\n",
      "    test overall loss:        5.838928858439128\n",
      "    test cross_ent loss:      2.838047424952189\n",
      "    cluster loss:             2955.9046223958335\n",
      "    separation loss:          44.06218592325846\n",
      "    avg separation loss:      109.08664957682292\n",
      "    l1_addon loss:            29.375560760498047\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.042265892028808594\n",
      "    test time:                0.012610673904418945\n",
      "    epoch time:               0.0555267333984375\n",
      "epoch:  46 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 74.67%\n",
      "    train overall loss:       5.641750335693359\n",
      "    train cross_ent loss:     2.64086209403144\n",
      "    test overall loss:        5.845345656077067\n",
      "    test cross_ent loss:      2.844471295674642\n",
      "    cluster loss:             2956.0391438802085\n",
      "    separation loss:          44.09424336751302\n",
      "    avg separation loss:      108.99249521891277\n",
      "    l1_addon loss:            29.127716064453125\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.042084693908691406\n",
      "    test time:                0.012631416320800781\n",
      "    epoch time:               0.05536246299743652\n",
      "epoch:  47 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 73.33%\n",
      "    train overall loss:       5.629606988694933\n",
      "    train cross_ent loss:     2.62872576713562\n",
      "    test overall loss:        5.835772514343262\n",
      "    test cross_ent loss:      2.834914525349935\n",
      "    cluster loss:             2955.8084309895835\n",
      "    separation loss:          42.629295349121094\n",
      "    avg separation loss:      104.99629720052083\n",
      "    l1_addon loss:            28.586397171020508\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.042122840881347656\n",
      "    test time:                0.012686729431152344\n",
      "    epoch time:               0.05544900894165039\n",
      "epoch:  48 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 75.00%\n",
      "    train overall loss:       5.605035728878445\n",
      "    train cross_ent loss:     2.6041622956593833\n",
      "    test overall loss:        5.830508708953857\n",
      "    test cross_ent loss:      2.82963236172994\n",
      "    cluster loss:             2955.7145182291665\n",
      "    separation loss:          41.640132904052734\n",
      "    avg separation loss:      107.10549418131511\n",
      "    l1_addon loss:            29.203384399414062\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04209017753601074\n",
      "    test time:                0.015297651290893555\n",
      "    epoch time:               0.0580286979675293\n",
      "epoch:  49 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 75.33%\n",
      "    train overall loss:       5.584558963775635\n",
      "    train cross_ent loss:     2.5836936632792153\n",
      "    test overall loss:        5.815886497497559\n",
      "    test cross_ent loss:      2.8150227069854736\n",
      "    cluster loss:             2955.472900390625\n",
      "    separation loss:          40.257179260253906\n",
      "    avg separation loss:      102.2071050008138\n",
      "    l1_addon loss:            28.781845092773438\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04219412803649902\n",
      "    test time:                0.012642383575439453\n",
      "    epoch time:               0.05549192428588867\n",
      "epoch:  50 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 75.00%\n",
      "    train overall loss:       5.564396116468641\n",
      "    train cross_ent loss:     2.5635381009843616\n",
      "    test overall loss:        5.808547496795654\n",
      "    test cross_ent loss:      2.807689984639486\n",
      "    cluster loss:             2955.409423828125\n",
      "    separation loss:          39.68706512451172\n",
      "    avg separation loss:      100.95241292317708\n",
      "    l1_addon loss:            28.58515167236328\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04220151901245117\n",
      "    test time:                0.012622356414794922\n",
      "    epoch time:               0.05546832084655762\n",
      "epoch:  51 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 74.67%\n",
      "    train overall loss:       5.639079782697889\n",
      "    train cross_ent loss:     2.6382269859313965\n",
      "    test overall loss:        5.780922730763753\n",
      "    test cross_ent loss:      2.780073324839274\n",
      "    cluster loss:             2955.1170247395835\n",
      "    separation loss:          39.28511428833008\n",
      "    avg separation loss:      108.06840006510417\n",
      "    l1_addon loss:            28.310863494873047\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05899190902709961\n",
      "    test time:                0.012634754180908203\n",
      "    epoch time:               0.07241702079772949\n",
      "    joint lr:                 0.0030601000000000087\n",
      "epoch:  52 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 46.33%\n",
      "    train overall loss:       5.92770258585612\n",
      "    train cross_ent loss:     2.926887141333686\n",
      "    test overall loss:        6.196384429931641\n",
      "    test cross_ent loss:      3.195591370264689\n",
      "    cluster loss:             3007.5337727864585\n",
      "    separation loss:          140.08421834309897\n",
      "    avg separation loss:      349.65565999348956\n",
      "    l1_addon loss:            26.433504104614258\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05909276008605957\n",
      "    test time:                0.012649297714233398\n",
      "    epoch time:               0.07251596450805664\n",
      "    joint lr:                 0.005960997999999999\n",
      "epoch:  53 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 57.67%\n",
      "    train overall loss:       5.571539719899495\n",
      "    train cross_ent loss:     2.5707237455579968\n",
      "    test overall loss:        6.189272880554199\n",
      "    test cross_ent loss:      3.188462495803833\n",
      "    cluster loss:             2994.5094401041665\n",
      "    separation loss:          141.69595591227213\n",
      "    avg separation loss:      278.4934895833333\n",
      "    l1_addon loss:            27.012027740478516\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.059058427810668945\n",
      "    test time:                0.012616395950317383\n",
      "    epoch time:               0.07244396209716797\n",
      "    joint lr:                 0.008803582030000007\n",
      "epoch:  54 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 62.33%\n",
      "    train overall loss:       5.1868313153584795\n",
      "    train cross_ent loss:     2.186027036772834\n",
      "    test overall loss:        6.134507338205974\n",
      "    test cross_ent loss:      3.133697191874186\n",
      "    cluster loss:             2970.1534016927085\n",
      "    separation loss:          71.57284673055013\n",
      "    avg separation loss:      148.9420928955078\n",
      "    l1_addon loss:            27.00877571105957\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05904102325439453\n",
      "    test time:                0.01264333724975586\n",
      "    epoch time:               0.0724802017211914\n",
      "    joint lr:                 0.011588728279599995\n",
      "epoch:  55 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 64.67%\n",
      "    train overall loss:       5.131720225016276\n",
      "    train cross_ent loss:     2.1309194564819336\n",
      "    test overall loss:        5.970708847045898\n",
      "    test cross_ent loss:      2.9698700110117593\n",
      "    cluster loss:             2959.2838541666665\n",
      "    separation loss:          42.07177988688151\n",
      "    avg separation loss:      108.3265151977539\n",
      "    l1_addon loss:            27.95139503479004\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.059304237365722656\n",
      "    test time:                0.012712717056274414\n",
      "    epoch time:               0.07277488708496094\n",
      "    joint lr:                 0.014317301246005004\n",
      "epoch:  56 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 64.33%\n",
      "    train overall loss:       4.967722521887885\n",
      "    train cross_ent loss:     1.966905501153734\n",
      "    test overall loss:        5.909195264180501\n",
      "    test cross_ent loss:      2.9083516597747803\n",
      "    cluster loss:             2956.4866536458335\n",
      "    separation loss:          33.090105056762695\n",
      "    avg separation loss:      79.03653971354167\n",
      "    l1_addon loss:            28.115758895874023\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058979034423828125\n",
      "    test time:                0.012674808502197266\n",
      "    epoch time:               0.07242274284362793\n",
      "    joint lr:                 0.016990153880253933\n",
      "epoch:  57 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 58.67%\n",
      "    train overall loss:       4.944759051005046\n",
      "    train cross_ent loss:     1.9439081350962322\n",
      "    test overall loss:        5.705277919769287\n",
      "    test cross_ent loss:      2.7044546604156494\n",
      "    cluster loss:             2953.5491536458335\n",
      "    separation loss:          19.459964752197266\n",
      "    avg separation loss:      59.685282389322914\n",
      "    l1_addon loss:            27.43697738647461\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05904746055603027\n",
      "    test time:                0.012766361236572266\n",
      "    epoch time:               0.07259607315063477\n",
      "    joint lr:                 0.019608127731693303\n",
      "epoch:  58 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 74.00%\n",
      "    train overall loss:       5.073972913953993\n",
      "    train cross_ent loss:     2.0730868842866688\n",
      "    test overall loss:        4.892213662465413\n",
      "    test cross_ent loss:      1.8913120826085408\n",
      "    cluster loss:             2951.023681640625\n",
      "    separation loss:          13.022976875305176\n",
      "    avg separation loss:      47.66063690185547\n",
      "    l1_addon loss:            30.04254913330078\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05896711349487305\n",
      "    test time:                0.012678861618041992\n",
      "    epoch time:               0.07243156433105469\n",
      "    joint lr:                 0.02217205309071584\n",
      "epoch:  59 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 68.00%\n",
      "    train overall loss:       4.730659643809001\n",
      "    train cross_ent loss:     1.7297286722395155\n",
      "    test overall loss:        5.280226389567058\n",
      "    test cross_ent loss:      2.279269059499105\n",
      "    cluster loss:             2951.4952799479165\n",
      "    separation loss:          14.451246897379557\n",
      "    avg separation loss:      40.428382873535156\n",
      "    l1_addon loss:            31.907634735107422\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05904364585876465\n",
      "    test time:                0.01263427734375\n",
      "    epoch time:               0.07247662544250488\n",
      "    joint lr:                 0.024682749129784777\n",
      "epoch:  60 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 69.33%\n",
      "    train overall loss:       4.836106088426378\n",
      "    train cross_ent loss:     1.8351463476816814\n",
      "    test overall loss:        5.016134579976399\n",
      "    test cross_ent loss:      2.015155831972758\n",
      "    cluster loss:             2951.32958984375\n",
      "    separation loss:          14.471800486246744\n",
      "    avg separation loss:      37.900796254475914\n",
      "    l1_addon loss:            32.610107421875\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05906510353088379\n",
      "    test time:                0.012618064880371094\n",
      "    epoch time:               0.07247591018676758\n",
      "    joint lr:                 0.027141024042763244\n",
      "epoch:  61 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 74.33%\n",
      "    train overall loss:       4.720795472462972\n",
      "    train cross_ent loss:     1.719808538754781\n",
      "    test overall loss:        4.916851838429769\n",
      "    test cross_ent loss:      1.9158559242884319\n",
      "    cluster loss:             2951.28564453125\n",
      "    separation loss:          14.368339538574219\n",
      "    avg separation loss:      44.27446619669596\n",
      "    l1_addon loss:            33.189083099365234\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.059227943420410156\n",
      "    test time:                0.012740373611450195\n",
      "    epoch time:               0.07274413108825684\n",
      "    joint lr:                 0.025532083112218835\n",
      "epoch:  62 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 76.33%\n",
      "    train overall loss:       4.653099324968126\n",
      "    train cross_ent loss:     1.6520952781041462\n",
      "    test overall loss:        4.620496908823649\n",
      "    test cross_ent loss:      1.6194896697998047\n",
      "    cluster loss:             2951.1670735677085\n",
      "    separation loss:          12.183668772379557\n",
      "    avg separation loss:      37.37979253133138\n",
      "    l1_addon loss:            33.56581115722656\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05891776084899902\n",
      "    test time:                0.012780427932739258\n",
      "    epoch time:               0.0725090503692627\n",
      "    joint lr:                 0.023952616897881036\n",
      "epoch:  63 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 76.00%\n",
      "    train overall loss:       4.672955354054769\n",
      "    train cross_ent loss:     1.6719458103179932\n",
      "    test overall loss:        4.711034774780273\n",
      "    test cross_ent loss:      1.7100616693496704\n",
      "    cluster loss:             2951.2388509114585\n",
      "    separation loss:          12.456021626790365\n",
      "    avg separation loss:      33.73535283406576\n",
      "    l1_addon loss:            32.42877960205078\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058574676513671875\n",
      "    test time:                0.012160778045654297\n",
      "    epoch time:               0.07149767875671387\n",
      "    joint lr:                 0.022402196799518763\n",
      "epoch:  64 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 67.67%\n",
      "    train overall loss:       4.82446633444892\n",
      "    train cross_ent loss:     1.8234455188115437\n",
      "    test overall loss:        4.503141085306804\n",
      "    test cross_ent loss:      1.5021370649337769\n",
      "    cluster loss:             2951.0442708333335\n",
      "    separation loss:          11.966863314310709\n",
      "    avg separation loss:      32.35273551940918\n",
      "    l1_addon loss:            33.45429229736328\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05828428268432617\n",
      "    test time:                0.012656450271606445\n",
      "    epoch time:               0.07172203063964844\n",
      "    joint lr:                 0.02088039984143395\n",
      "epoch:  65 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 76.00%\n",
      "    train overall loss:       4.605639616648356\n",
      "    train cross_ent loss:     1.6045967605378892\n",
      "    test overall loss:        4.439707438151042\n",
      "    test cross_ent loss:      1.4386624892552693\n",
      "    cluster loss:             2950.662353515625\n",
      "    separation loss:          10.897135416666666\n",
      "    avg separation loss:      31.95463689168294\n",
      "    l1_addon loss:            34.82121276855469\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.0589299201965332\n",
      "    test time:                0.012638330459594727\n",
      "    epoch time:               0.07236337661743164\n",
      "    joint lr:                 0.01938680860283089\n",
      "epoch:  66 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 79.00%\n",
      "    train overall loss:       4.413877063327366\n",
      "    train cross_ent loss:     1.4128202862209744\n",
      "    test overall loss:        4.223687648773193\n",
      "    test cross_ent loss:      1.2226402362187703\n",
      "    cluster loss:             2950.4857584635415\n",
      "    separation loss:          10.63005797068278\n",
      "    avg separation loss:      31.20034917195638\n",
      "    l1_addon loss:            34.90291213989258\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05895829200744629\n",
      "    test time:                0.012675285339355469\n",
      "    epoch time:               0.07242798805236816\n",
      "    joint lr:                 0.017921011149015745\n",
      "epoch:  67 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 79.67%\n",
      "    train overall loss:       4.439052634769016\n",
      "    train cross_ent loss:     1.4379921621746488\n",
      "    test overall loss:        4.657569567362468\n",
      "    test cross_ent loss:      1.656465729077657\n",
      "    cluster loss:             2950.916259765625\n",
      "    separation loss:          11.936015764872232\n",
      "    avg separation loss:      32.03029759724935\n",
      "    l1_addon loss:            36.780670166015625\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05910611152648926\n",
      "    test time:                0.012638092041015625\n",
      "    epoch time:               0.07253170013427734\n",
      "    joint lr:                 0.016482600963416614\n",
      "epoch:  68 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 77.67%\n",
      "    train overall loss:       4.07465492354499\n",
      "    train cross_ent loss:     1.0735823114713032\n",
      "    test overall loss:        4.036628484725952\n",
      "    test cross_ent loss:      1.0355467995007832\n",
      "    cluster loss:             2950.2495930989585\n",
      "    separation loss:          8.51949659983317\n",
      "    avg separation loss:      24.407408396402996\n",
      "    l1_addon loss:            36.050933837890625\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.0590357780456543\n",
      "    test time:                0.01269221305847168\n",
      "    epoch time:               0.07253742218017578\n",
      "    joint lr:                 0.015071176880414561\n",
      "epoch:  69 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 82.00%\n",
      "    train overall loss:       3.953174458609687\n",
      "    train cross_ent loss:     0.9520901375346713\n",
      "    test overall loss:        4.002332290013631\n",
      "    test cross_ent loss:      1.001245339711507\n",
      "    cluster loss:             2950.139892578125\n",
      "    separation loss:          8.214462598164877\n",
      "    avg separation loss:      23.317649205525715\n",
      "    l1_addon loss:            36.2174072265625\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05934309959411621\n",
      "    test time:                0.012632369995117188\n",
      "    epoch time:               0.07280635833740234\n",
      "    joint lr:                 0.01368634301897622\n",
      "epoch:  70 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 85.33%\n",
      "    train overall loss:       3.8118922180599637\n",
      "    train cross_ent loss:     0.8108031815952725\n",
      "    test overall loss:        3.620319684346517\n",
      "    test cross_ent loss:      0.619216317931811\n",
      "    cluster loss:             2949.88916015625\n",
      "    separation loss:          6.8837534586588545\n",
      "    avg separation loss:      20.35676447550456\n",
      "    l1_addon loss:            36.77320861816406\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05930042266845703\n",
      "    test time:                0.012659788131713867\n",
      "    epoch time:               0.07273983955383301\n",
      "    joint lr:                 0.012327708717078603\n",
      "epoch:  71 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       3.8143966727786593\n",
      "    train cross_ent loss:     0.813295821348826\n",
      "    test overall loss:        3.80934739112854\n",
      "    test cross_ent loss:      0.8082636396090189\n",
      "    cluster loss:             2949.98828125\n",
      "    separation loss:          6.60895299911499\n",
      "    avg separation loss:      19.094107309977215\n",
      "    l1_addon loss:            36.11723327636719\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05895543098449707\n",
      "    test time:                0.012641429901123047\n",
      "    epoch time:               0.07239055633544922\n",
      "    joint lr:                 0.01099488846691703\n",
      "epoch:  72 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 87.67%\n",
      "    train overall loss:       3.6969359980689154\n",
      "    train cross_ent loss:     0.6958373520109389\n",
      "    test overall loss:        3.543745517730713\n",
      "    test cross_ent loss:      0.5426487773656845\n",
      "    cluster loss:             2949.8435872395835\n",
      "    separation loss:          6.129881858825684\n",
      "    avg separation loss:      16.733043034871418\n",
      "    l1_addon loss:            36.548667907714844\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05920290946960449\n",
      "    test time:                0.012687206268310547\n",
      "    epoch time:               0.07269001007080078\n",
      "    joint lr:                 0.009687501850886984\n",
      "epoch:  73 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 86.67%\n",
      "    train overall loss:       3.5605627960628934\n",
      "    train cross_ent loss:     0.5594614247481028\n",
      "    test overall loss:        3.7202321688334146\n",
      "    test cross_ent loss:      0.7191413640975952\n",
      "    cluster loss:             2949.951904296875\n",
      "    separation loss:          5.795594056447347\n",
      "    avg separation loss:      14.544529914855957\n",
      "    l1_addon loss:            36.351165771484375\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05897021293640137\n",
      "    test time:                0.01268625259399414\n",
      "    epoch time:               0.07242393493652344\n",
      "    joint lr:                 0.008405173478330853\n",
      "epoch:  74 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 91.67%\n",
      "    train overall loss:       3.5368003845214844\n",
      "    train cross_ent loss:     0.5356972383128272\n",
      "    test overall loss:        3.5233852863311768\n",
      "    test cross_ent loss:      0.5222706298033396\n",
      "    cluster loss:             2949.7804361979165\n",
      "    separation loss:          5.595681985219319\n",
      "    avg separation loss:      15.197894096374512\n",
      "    l1_addon loss:            37.14359664916992\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05884242057800293\n",
      "    test time:                0.012671232223510742\n",
      "    epoch time:               0.07231259346008301\n",
      "    joint lr:                 0.007147532923040749\n",
      "epoch:  75 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 85.33%\n",
      "    train overall loss:       3.4407642947302923\n",
      "    train cross_ent loss:     0.4396547989712821\n",
      "    test overall loss:        3.542658567428589\n",
      "    test cross_ent loss:      0.5415727645158768\n",
      "    cluster loss:             2949.7627766927085\n",
      "    separation loss:          5.303261439005534\n",
      "    avg separation loss:      15.30125904083252\n",
      "    l1_addon loss:            36.18470764160156\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058951377868652344\n",
      "    test time:                0.012673139572143555\n",
      "    epoch time:               0.07241678237915039\n",
      "    joint lr:                 0.005914214661508615\n",
      "epoch:  76 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 91.67%\n",
      "    train overall loss:       3.4139387872483997\n",
      "    train cross_ent loss:     0.4128349787659115\n",
      "    test overall loss:        3.3844032287597656\n",
      "    test cross_ent loss:      0.3833012729883194\n",
      "    cluster loss:             2949.6786295572915\n",
      "    separation loss:          4.906978050867717\n",
      "    avg separation loss:      12.894824663798014\n",
      "    l1_addon loss:            36.7277946472168\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05917215347290039\n",
      "    test time:                0.012656688690185547\n",
      "    epoch time:               0.07261967658996582\n",
      "    joint lr:                 0.004704858011914826\n",
      "epoch:  77 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       3.3698844644758434\n",
      "    train cross_ent loss:     0.3687739604049259\n",
      "    test overall loss:        3.3068729241689048\n",
      "    test cross_ent loss:      0.30576662222544354\n",
      "    cluster loss:             2949.6177571614585\n",
      "    separation loss:          4.568704764048259\n",
      "    avg separation loss:      12.64960797627767\n",
      "    l1_addon loss:            36.86945724487305\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058925628662109375\n",
      "    test time:                0.01267862319946289\n",
      "    epoch time:               0.07237482070922852\n",
      "    joint lr:                 0.0035191070738467612\n",
      "epoch:  78 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 93.67%\n",
      "    train overall loss:       3.222478893068102\n",
      "    train cross_ent loss:     0.22136915764874882\n",
      "    test overall loss:        3.291548172632853\n",
      "    test cross_ent loss:      0.29044364392757416\n",
      "    cluster loss:             2949.5863444010415\n",
      "    separation loss:          4.3368667761484785\n",
      "    avg separation loss:      11.757673899332682\n",
      "    l1_addon loss:            36.81412887573242\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.059051513671875\n",
      "    test time:                0.012678146362304688\n",
      "    epoch time:               0.07249903678894043\n",
      "    joint lr:                 0.00235661066873886\n",
      "epoch:  79 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       3.170302152633667\n",
      "    train cross_ent loss:     0.16918956653939354\n",
      "    test overall loss:        3.223582903544108\n",
      "    test cross_ent loss:      0.22246375183264414\n",
      "    cluster loss:             2949.5502115885415\n",
      "    separation loss:          4.136168877283732\n",
      "    avg separation loss:      11.534358978271484\n",
      "    l1_addon loss:            37.297096252441406\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05908060073852539\n",
      "    test time:                0.012734174728393555\n",
      "    epoch time:               0.07259345054626465\n",
      "    joint lr:                 0.001217022281025732\n",
      "epoch:  80 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 94.67%\n",
      "    train overall loss:       3.11578991678026\n",
      "    train cross_ent loss:     0.11467797805865605\n",
      "    test overall loss:        3.256399393081665\n",
      "    test cross_ent loss:      0.255295068025589\n",
      "    cluster loss:             2949.5587565104165\n",
      "    separation loss:          4.031567891438802\n",
      "    avg separation loss:      11.149335225423178\n",
      "    l1_addon loss:            36.805908203125\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05880999565124512\n",
      "    test time:                0.012663602828979492\n",
      "    epoch time:               0.0722653865814209\n",
      "    joint lr:                 0.0001\n",
      "epoch:  81 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 94.67%\n",
      "    train overall loss:       3.112472322252062\n",
      "    train cross_ent loss:     0.11136694562931855\n",
      "    test overall loss:        3.2413989702860513\n",
      "    test cross_ent loss:      0.24029208098848662\n",
      "    cluster loss:             2949.5476888020835\n",
      "    separation loss:          4.028847138086955\n",
      "    avg separation loss:      11.1496795018514\n",
      "    l1_addon loss:            36.889137268066406\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05903172492980957\n",
      "    test time:                0.012634754180908203\n",
      "    epoch time:               0.07247161865234375\n",
      "    joint lr:                 0.00228958707526664\n",
      "epoch:  82 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 93.00%\n",
      "    train overall loss:       3.1050863001081677\n",
      "    train cross_ent loss:     0.10396807516614597\n",
      "    test overall loss:        3.2546534538269043\n",
      "    test cross_ent loss:      0.25354623794555664\n",
      "    cluster loss:             2949.54345703125\n",
      "    separation loss:          3.809835513432821\n",
      "    avg separation loss:      10.39945920308431\n",
      "    l1_addon loss:            36.901058197021484\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05926012992858887\n",
      "    test time:                0.01264500617980957\n",
      "    epoch time:               0.07269597053527832\n",
      "    joint lr:                 0.004435382409027948\n",
      "epoch:  83 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 89.33%\n",
      "    train overall loss:       3.1448085572984485\n",
      "    train cross_ent loss:     0.14369378570053312\n",
      "    test overall loss:        3.363310972849528\n",
      "    test cross_ent loss:      0.36221396426359814\n",
      "    cluster loss:             2949.607666015625\n",
      "    separation loss:          3.7116081714630127\n",
      "    avg separation loss:      9.997650782267252\n",
      "    l1_addon loss:            36.55432891845703\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058875083923339844\n",
      "    test time:                0.012628555297851562\n",
      "    epoch time:               0.07230424880981445\n",
      "    joint lr:                 0.006538042877406532\n",
      "epoch:  84 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 91.00%\n",
      "    train overall loss:       3.2247348891364203\n",
      "    train cross_ent loss:     0.2236218767033683\n",
      "    test overall loss:        3.325638771057129\n",
      "    test cross_ent loss:      0.3245337133606275\n",
      "    cluster loss:             2949.599365234375\n",
      "    separation loss:          3.4895105361938477\n",
      "    avg separation loss:      9.08518918355306\n",
      "    l1_addon loss:            36.827178955078125\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05890679359436035\n",
      "    test time:                0.012634754180908203\n",
      "    epoch time:               0.07235479354858398\n",
      "    joint lr:                 0.008598216598176611\n",
      "epoch:  85 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 83.33%\n",
      "    train overall loss:       3.4874909189012318\n",
      "    train cross_ent loss:     0.48638081053892773\n",
      "    test overall loss:        3.664016008377075\n",
      "    test cross_ent loss:      0.6629083355267843\n",
      "    cluster loss:             2949.7618001302085\n",
      "    separation loss:          4.072264512379964\n",
      "    avg separation loss:      9.547078132629395\n",
      "    l1_addon loss:            36.91324996948242\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05901455879211426\n",
      "    test time:                0.012644052505493164\n",
      "    epoch time:               0.07248759269714355\n",
      "    joint lr:                 0.010616543040243577\n",
      "epoch:  86 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 84.67%\n",
      "    train overall loss:       3.8137982156541614\n",
      "    train cross_ent loss:     0.8126862612035539\n",
      "    test overall loss:        3.666571537653605\n",
      "    test cross_ent loss:      0.6654987533887228\n",
      "    cluster loss:             2949.8480631510415\n",
      "    separation loss:          5.397508144378662\n",
      "    avg separation loss:      12.74820073445638\n",
      "    l1_addon loss:            35.7462158203125\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05905580520629883\n",
      "    test time:                0.012620687484741211\n",
      "    epoch time:               0.07243537902832031\n",
      "    joint lr:                 0.012593653131809358\n",
      "epoch:  87 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 90.00%\n",
      "    train overall loss:       4.193601899676853\n",
      "    train cross_ent loss:     1.1925203601519268\n",
      "    test overall loss:        3.896198829015096\n",
      "    test cross_ent loss:      0.8950901428858439\n",
      "    cluster loss:             2950.013671875\n",
      "    separation loss:          7.177821318308513\n",
      "    avg separation loss:      17.378061294555664\n",
      "    l1_addon loss:            36.948585510253906\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05905342102050781\n",
      "    test time:                0.012671232223510742\n",
      "    epoch time:               0.07250332832336426\n",
      "    joint lr:                 0.014530169367239798\n",
      "epoch:  88 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 73.00%\n",
      "    train overall loss:       4.417072984907362\n",
      "    train cross_ent loss:     1.4159864849514432\n",
      "    test overall loss:        4.651762167612712\n",
      "    test cross_ent loss:      1.650621732076009\n",
      "    cluster loss:             2951.1632486979165\n",
      "    separation loss:          11.518837610880533\n",
      "    avg separation loss:      25.7956968943278\n",
      "    l1_addon loss:            37.996063232421875\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05894279479980469\n",
      "    test time:                0.012650728225708008\n",
      "    epoch time:               0.07236218452453613\n",
      "    joint lr:                 0.01642670591264845\n",
      "epoch:  89 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 82.00%\n",
      "    train overall loss:       4.270512157016331\n",
      "    train cross_ent loss:     1.2694137493769329\n",
      "    test overall loss:        4.434478918711345\n",
      "    test cross_ent loss:      1.4334158102671306\n",
      "    cluster loss:             2950.9093424479165\n",
      "    separation loss:          10.05325190226237\n",
      "    avg separation loss:      24.24017842610677\n",
      "    l1_addon loss:            35.42479705810547\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05884122848510742\n",
      "    test time:                0.012622356414794922\n",
      "    epoch time:               0.07227015495300293\n",
      "    joint lr:                 0.018283868710212207\n",
      "epoch:  90 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 82.67%\n",
      "    train overall loss:       4.216330501768324\n",
      "    train cross_ent loss:     1.2152271668116252\n",
      "    test overall loss:        4.21317458152771\n",
      "    test cross_ent loss:      1.2120455304781597\n",
      "    cluster loss:             2950.88525390625\n",
      "    separation loss:          9.788850625356039\n",
      "    avg separation loss:      24.757897059122723\n",
      "    l1_addon loss:            37.623992919921875\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05901980400085449\n",
      "    test time:                0.01271367073059082\n",
      "    epoch time:               0.07256007194519043\n",
      "    joint lr:                 0.020102255581233422\n",
      "epoch:  91 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 83.00%\n",
      "    train overall loss:       4.163559383816189\n",
      "    train cross_ent loss:     1.1624445981449552\n",
      "    test overall loss:        4.156699577967326\n",
      "    test cross_ent loss:      1.155555287996928\n",
      "    cluster loss:             2951.2952473958335\n",
      "    separation loss:          10.23720614115397\n",
      "    avg separation loss:      23.620405197143555\n",
      "    l1_addon loss:            38.13768768310547\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05909442901611328\n",
      "    test time:                0.012616395950317383\n",
      "    epoch time:               0.07248663902282715\n",
      "    joint lr:                 0.018912121374150048\n",
      "epoch:  92 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 79.33%\n",
      "    train overall loss:       4.14910954899258\n",
      "    train cross_ent loss:     1.1479897300402324\n",
      "    test overall loss:        4.644515196482341\n",
      "    test cross_ent loss:      1.6433347066243489\n",
      "    cluster loss:             2952.186279296875\n",
      "    separation loss:          12.277264595031738\n",
      "    avg separation loss:      25.402122497558594\n",
      "    l1_addon loss:            39.34522247314453\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058929443359375\n",
      "    test time:                0.01264190673828125\n",
      "    epoch time:               0.0723733901977539\n",
      "    joint lr:                 0.017743789625650205\n",
      "epoch:  93 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 77.00%\n",
      "    train overall loss:       4.394924587673611\n",
      "    train cross_ent loss:     1.3937991327709622\n",
      "    test overall loss:        4.2500794728597\n",
      "    test cross_ent loss:      1.2489611705144246\n",
      "    cluster loss:             2951.9856770833335\n",
      "    separation loss:          11.362874348958334\n",
      "    avg separation loss:      23.944000879923504\n",
      "    l1_addon loss:            37.27241516113281\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058908700942993164\n",
      "    test time:                0.01266622543334961\n",
      "    epoch time:               0.07239603996276855\n",
      "    joint lr:                 0.01659694329998293\n",
      "epoch:  94 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 79.67%\n",
      "    train overall loss:       4.25405560599433\n",
      "    train cross_ent loss:     1.2529283033476935\n",
      "    test overall loss:        4.34544579188029\n",
      "    test cross_ent loss:      1.3442949056625366\n",
      "    cluster loss:             2952.374755859375\n",
      "    separation loss:          12.747453053792318\n",
      "    avg separation loss:      27.543498992919922\n",
      "    l1_addon loss:            38.35820007324219\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05888986587524414\n",
      "    test time:                0.012646913528442383\n",
      "    epoch time:               0.07230615615844727\n",
      "    joint lr:                 0.01547126952186645\n",
      "epoch:  95 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 73.00%\n",
      "    train overall loss:       4.360448731316461\n",
      "    train cross_ent loss:     1.35930687851376\n",
      "    test overall loss:        4.622640450795491\n",
      "    test cross_ent loss:      1.6215168635050456\n",
      "    cluster loss:             2952.53369140625\n",
      "    separation loss:          13.364924430847168\n",
      "    avg separation loss:      28.2312806447347\n",
      "    l1_addon loss:            37.44546890258789\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05908966064453125\n",
      "    test time:                0.012682437896728516\n",
      "    epoch time:               0.07260322570800781\n",
      "    joint lr:                 0.014366459524982304\n",
      "epoch:  96 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 79.33%\n",
      "    train overall loss:       4.3965103891160755\n",
      "    train cross_ent loss:     1.3953775829739041\n",
      "    test overall loss:        4.281938234965007\n",
      "    test cross_ent loss:      1.2807749509811401\n",
      "    cluster loss:             2952.607666015625\n",
      "    separation loss:          13.482735951741537\n",
      "    avg separation loss:      28.444359461466473\n",
      "    l1_addon loss:            38.7635498046875\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05941963195800781\n",
      "    test time:                0.012744903564453125\n",
      "    epoch time:               0.07292056083679199\n",
      "    joint lr:                 0.013282208601083652\n",
      "epoch:  97 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 85.00%\n",
      "    train overall loss:       4.091902547412449\n",
      "    train cross_ent loss:     1.0907535685433283\n",
      "    test overall loss:        4.07650367418925\n",
      "    test cross_ent loss:      1.0753629803657532\n",
      "    cluster loss:             2952.4784342447915\n",
      "    separation loss:          12.334131558736166\n",
      "    avg separation loss:      25.463210423787434\n",
      "    l1_addon loss:            38.01551818847656\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058966636657714844\n",
      "    test time:                0.012670516967773438\n",
      "    epoch time:               0.0724344253540039\n",
      "    joint lr:                 0.012218216049710476\n",
      "epoch:  98 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 79.33%\n",
      "    train overall loss:       3.8712019125620523\n",
      "    train cross_ent loss:     0.8700450592570834\n",
      "    test overall loss:        4.1958010991414385\n",
      "    test cross_ent loss:      1.1946149667104085\n",
      "    cluster loss:             2952.49365234375\n",
      "    separation loss:          12.431960105895996\n",
      "    avg separation loss:      24.944454193115234\n",
      "    l1_addon loss:            39.53407287597656\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05925488471984863\n",
      "    test time:                0.012674093246459961\n",
      "    epoch time:               0.07268762588500977\n",
      "    joint lr:                 0.011174185128504639\n",
      "epoch:  99 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 85.00%\n",
      "    train overall loss:       3.9162933826446533\n",
      "    train cross_ent loss:     0.9151289727952745\n",
      "    test overall loss:        4.020433108011882\n",
      "    test cross_ent loss:      1.0192912022272747\n",
      "    cluster loss:             2952.3877766927085\n",
      "    separation loss:          11.652080535888672\n",
      "    avg separation loss:      23.137730916341145\n",
      "    l1_addon loss:            38.05423355102539\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058736562728881836\n",
      "    test time:                0.012143135070800781\n",
      "    epoch time:               0.07169151306152344\n",
      "    joint lr:                 0.010149823004117963\n",
      "epoch: 100 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 89.67%\n",
      "    train overall loss:       3.8136220243242054\n",
      "    train cross_ent loss:     0.8124648928642273\n",
      "    test overall loss:        3.8614275455474854\n",
      "    test cross_ent loss:      0.8602672616640726\n",
      "    cluster loss:             2952.1399739583335\n",
      "    separation loss:          11.001054128011068\n",
      "    avg separation loss:      21.65869649251302\n",
      "    l1_addon loss:            38.67412567138672\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06258368492126465\n",
      "    test time:                0.01299905776977539\n",
      "    epoch time:               0.07633328437805176\n",
      "    joint lr:                 0.009144840703706159\n",
      "epoch: 101 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 89.33%\n",
      "    train overall loss:       3.666666136847602\n",
      "    train cross_ent loss:     0.6655020051532321\n",
      "    test overall loss:        3.6845173041025796\n",
      "    test cross_ent loss:      0.6833321253458658\n",
      "    cluster loss:             2951.987060546875\n",
      "    separation loss:          10.746774037679037\n",
      "    avg separation loss:      21.247692743937176\n",
      "    l1_addon loss:            39.49726867675781\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.061254024505615234\n",
      "    test time:                0.012784957885742188\n",
      "    epoch time:               0.07479739189147949\n",
      "    joint lr:                 0.008158953067002189\n",
      "epoch: 102 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 88.67%\n",
      "    train overall loss:       3.5858557489183216\n",
      "    train cross_ent loss:     0.584690597322252\n",
      "    test overall loss:        3.6144612630208335\n",
      "    test cross_ent loss:      0.6133188207944235\n",
      "    cluster loss:             2951.8961588541665\n",
      "    separation loss:          9.995891888936361\n",
      "    avg separation loss:      19.31957499186198\n",
      "    l1_addon loss:            38.07499694824219\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06148076057434082\n",
      "    test time:                0.012664079666137695\n",
      "    epoch time:               0.07488584518432617\n",
      "    joint lr:                 0.0071918786989619305\n",
      "epoch: 103 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 92.00%\n",
      "    train overall loss:       3.46555929713779\n",
      "    train cross_ent loss:     0.464404359459877\n",
      "    test overall loss:        3.479517857233683\n",
      "    test cross_ent loss:      0.4783671995004018\n",
      "    cluster loss:             2951.7456868489585\n",
      "    separation loss:          9.548498153686523\n",
      "    avg separation loss:      18.647544225056965\n",
      "    l1_addon loss:            38.34296417236328\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.061510562896728516\n",
      "    test time:                0.012662649154663086\n",
      "    epoch time:               0.07490110397338867\n",
      "    joint lr:                 0.006243339922975775\n",
      "epoch: 104 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 92.00%\n",
      "    train overall loss:       3.326622035768297\n",
      "    train cross_ent loss:     0.3254648761616813\n",
      "    test overall loss:        3.4285744031270347\n",
      "    test cross_ent loss:      0.42742518583933514\n",
      "    cluster loss:             2951.6966145833335\n",
      "    separation loss:          9.169702847798666\n",
      "    avg separation loss:      17.70235315958659\n",
      "    l1_addon loss:            38.2943115234375\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06143045425415039\n",
      "    test time:                0.012656211853027344\n",
      "    epoch time:               0.07479071617126465\n",
      "    joint lr:                 0.005313062734639446\n",
      "epoch: 105 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 92.00%\n",
      "    train overall loss:       3.289236863454183\n",
      "    train cross_ent loss:     0.2880784554613961\n",
      "    test overall loss:        3.351984898249308\n",
      "    test cross_ent loss:      0.3508340169986089\n",
      "    cluster loss:             2951.6763509114585\n",
      "    separation loss:          8.95349407196045\n",
      "    avg separation loss:      17.31990623474121\n",
      "    l1_addon loss:            38.3567008972168\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.0613245964050293\n",
      "    test time:                0.012700319290161133\n",
      "    epoch time:               0.07476067543029785\n",
      "    joint lr:                 0.004400776756077547\n",
      "epoch: 106 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 93.67%\n",
      "    train overall loss:       3.1821842193603516\n",
      "    train cross_ent loss:     0.181019004020426\n",
      "    test overall loss:        3.2918330828348794\n",
      "    test cross_ent loss:      0.2906758363048236\n",
      "    cluster loss:             2951.58251953125\n",
      "    separation loss:          8.582726319630941\n",
      "    avg separation loss:      16.610848426818848\n",
      "    l1_addon loss:            38.570037841796875\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06084871292114258\n",
      "    test time:                0.01264643669128418\n",
      "    epoch time:               0.0743706226348877\n",
      "    joint lr:                 0.0035062151908134102\n",
      "epoch: 107 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       3.138813469145033\n",
      "    train cross_ent loss:     0.1376456477575832\n",
      "    test overall loss:        3.2210742632548013\n",
      "    test cross_ent loss:      0.21988840649525324\n",
      "    cluster loss:             2951.51904296875\n",
      "    separation loss:          8.469542185465494\n",
      "    avg separation loss:      15.665847778320312\n",
      "    l1_addon loss:            39.519798278808594\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06008601188659668\n",
      "    test time:                0.012656927108764648\n",
      "    epoch time:               0.07366180419921875\n",
      "    joint lr:                 0.0026291147791789593\n",
      "epoch: 108 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       3.118725988599989\n",
      "    train cross_ent loss:     0.11755531032880147\n",
      "    test overall loss:        3.1879921754201255\n",
      "    test cross_ent loss:      0.18682633092006048\n",
      "    cluster loss:             2951.5108235677085\n",
      "    separation loss:          8.264589468638102\n",
      "    avg separation loss:      15.372034072875977\n",
      "    l1_addon loss:            38.85502243041992\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05991482734680176\n",
      "    test time:                0.012668848037719727\n",
      "    epoch time:               0.0734565258026123\n",
      "    joint lr:                 0.001769215754258106\n",
      "epoch: 109 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       3.073055797153049\n",
      "    train cross_ent loss:     0.07188009843230247\n",
      "    test overall loss:        3.185750881830851\n",
      "    test cross_ent loss:      0.1845866913596789\n",
      "    cluster loss:             2951.4991048177085\n",
      "    separation loss:          8.250208854675293\n",
      "    avg separation loss:      15.072732289632162\n",
      "    l1_addon loss:            38.798858642578125\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06027650833129883\n",
      "    test time:                0.012650728225708008\n",
      "    epoch time:               0.07381129264831543\n",
      "    joint lr:                 0.0009262617983577627\n",
      "epoch: 110 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       3.0504930284288196\n",
      "    train cross_ent loss:     0.04933246701127953\n",
      "    test overall loss:        3.178447882334391\n",
      "    test cross_ent loss:      0.17728455613056818\n",
      "    cluster loss:             2951.49609375\n",
      "    separation loss:          8.20286226272583\n",
      "    avg separation loss:      15.027820587158203\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.060272216796875\n",
      "    test time:                0.01270604133605957\n",
      "    epoch time:               0.07387709617614746\n",
      "    joint lr:                 0.0001\n",
      "epoch: 110 (PUSH) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       3.0504930284288196\n",
      "    train cross_ent loss:     0.04933246701127953\n",
      "    test overall loss:        3.174972136815389\n",
      "    test cross_ent loss:      0.17380887642502785\n",
      "    cluster loss:             2949.3155110677085\n",
      "    separation loss:          2.857086737950643\n",
      "    avg separation loss:      8.516602516174316\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.060272216796875\n",
      "    test time:                0.012501001358032227\n",
      "    epoch time:               0.3924078941345215\n",
      "epoch: 110 (1/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       3.0356547832489014\n",
      "    train cross_ent loss:     0.0367368044745591\n",
      "    test overall loss:        3.1707534790039062\n",
      "    test cross_ent loss:      0.17460588489969572\n",
      "    cluster loss:             2949.3159993489585\n",
      "    separation loss:          2.8607118129730225\n",
      "    avg separation loss:      8.551903565724691\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  2994.984375\n",
      "    train time:               0.023769140243530273\n",
      "    test time:                0.012134075164794922\n",
      "    epoch time:               0.03640174865722656\n",
      "    last layer lr:            0.0007599999999999978\n",
      "epoch: 110 (2/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       3.0133670700920954\n",
      "    train cross_ent loss:     0.033961429364151426\n",
      "    test overall loss:        3.1331607500712075\n",
      "    test cross_ent loss:      0.1746976375579834\n",
      "    cluster loss:             2949.3163248697915\n",
      "    separation loss:          2.8604695796966553\n",
      "    avg separation loss:      8.549811681111654\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  2957.300048828125\n",
      "    train time:               0.02319192886352539\n",
      "    test time:                0.012060880661010742\n",
      "    epoch time:               0.03573203086853027\n",
      "    last layer lr:            0.0014200000000000013\n",
      "epoch: 110 (3/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       2.9638461536831326\n",
      "    train cross_ent loss:     0.03690957008964486\n",
      "    test overall loss:        3.0637052853902182\n",
      "    test cross_ent loss:      0.1761614295343558\n",
      "    cluster loss:             2949.3163248697915\n",
      "    separation loss:          2.8605743249257407\n",
      "    avg separation loss:      8.550176302591959\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  2886.380859375\n",
      "    train time:               0.023090124130249023\n",
      "    test time:                0.012067794799804688\n",
      "    epoch time:               0.035640716552734375\n",
      "    last layer lr:            0.0020799999999999985\n",
      "epoch: 110 (4/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       2.8793174160851374\n",
      "    train cross_ent loss:     0.0381034669569797\n",
      "    test overall loss:        2.958449602127075\n",
      "    test cross_ent loss:      0.17496556291977564\n",
      "    cluster loss:             2949.3164876302085\n",
      "    separation loss:          2.863073746363322\n",
      "    avg separation loss:      8.550272146860758\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  2782.32080078125\n",
      "    train time:               0.023000001907348633\n",
      "    test time:                0.012030601501464844\n",
      "    epoch time:               0.035511016845703125\n",
      "    last layer lr:            0.0027400000000000024\n",
      "epoch: 110 (5/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       2.7660968568589954\n",
      "    train cross_ent loss:     0.04311556638114982\n",
      "    test overall loss:        2.8245657285054526\n",
      "    test cross_ent loss:      0.1768627626200517\n",
      "    cluster loss:             2949.3162434895835\n",
      "    separation loss:          2.8581621646881104\n",
      "    avg separation loss:      8.54608154296875\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  2646.539794921875\n",
      "    train time:               0.023107290267944336\n",
      "    test time:                0.012078046798706055\n",
      "    epoch time:               0.035672664642333984\n",
      "    last layer lr:            0.0034\n",
      "epoch: 110 (6/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       2.6154352823893228\n",
      "    train cross_ent loss:     0.042484431631035276\n",
      "    test overall loss:        2.6574140389760337\n",
      "    test cross_ent loss:      0.17785205443700156\n",
      "    cluster loss:             2949.3157552083335\n",
      "    separation loss:          2.8553914229075112\n",
      "    avg separation loss:      8.51485284169515\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  2478.39892578125\n",
      "    train time:               0.02306389808654785\n",
      "    test time:                0.012039899826049805\n",
      "    epoch time:               0.0355839729309082\n",
      "    last layer lr:            0.004059999999999998\n",
      "epoch: 110 (7/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       2.436896244684855\n",
      "    train cross_ent loss:     0.045952003759642444\n",
      "    test overall loss:        2.461030880610148\n",
      "    test cross_ent loss:      0.18126625567674637\n",
      "    cluster loss:             2949.315673828125\n",
      "    separation loss:          2.854173262914022\n",
      "    avg separation loss:      8.499951203664144\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  2278.6015625\n",
      "    train time:               0.022949695587158203\n",
      "    test time:                0.012047529220581055\n",
      "    epoch time:               0.035475730895996094\n",
      "    last layer lr:            0.004720000000000002\n",
      "epoch: 110 (8/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       2.2172610229916043\n",
      "    train cross_ent loss:     0.03975992753273911\n",
      "    test overall loss:        2.2347264289855957\n",
      "    test cross_ent loss:      0.1862771287560463\n",
      "    cluster loss:             2949.3155924479165\n",
      "    separation loss:          2.85306978225708\n",
      "    avg separation loss:      8.502771695454916\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  2047.2861328125\n",
      "    train time:               0.023061037063598633\n",
      "    test time:                0.012044429779052734\n",
      "    epoch time:               0.035581350326538086\n",
      "    last layer lr:            0.005379999999999999\n",
      "epoch: 110 (9/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       1.9707018269432917\n",
      "    train cross_ent loss:     0.04017425152576632\n",
      "    test overall loss:        1.9761711359024048\n",
      "    test cross_ent loss:      0.1939698892335097\n",
      "    cluster loss:             2949.3155924479165\n",
      "    separation loss:          2.8592384656270347\n",
      "    avg separation loss:      8.525152524312338\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  1781.0380859375\n",
      "    train time:               0.023095130920410156\n",
      "    test time:                0.012060165405273438\n",
      "    epoch time:               0.03564262390136719\n",
      "    last layer lr:            0.006040000000000003\n",
      "epoch: 110 (10/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       1.720789180861579\n",
      "    train cross_ent loss:     0.07135574519634247\n",
      "    test overall loss:        1.690167784690857\n",
      "    test cross_ent loss:      0.20493696878353754\n",
      "    cluster loss:             2949.31591796875\n",
      "    separation loss:          2.8620847860972085\n",
      "    avg separation loss:      8.558583577473959\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  1484.067626953125\n",
      "    train time:               0.022974491119384766\n",
      "    test time:                0.012043952941894531\n",
      "    epoch time:               0.03549695014953613\n",
      "    last layer lr:            0.0067\n",
      "epoch: 110 (11/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       1.4095052745607164\n",
      "    train cross_ent loss:     0.0675385861347119\n",
      "    test overall loss:        1.3808788855870564\n",
      "    test cross_ent loss:      0.21683749804894129\n",
      "    cluster loss:             2949.3155924479165\n",
      "    separation loss:          2.857241710027059\n",
      "    avg separation loss:      8.52158784866333\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  1162.878173828125\n",
      "    train time:               0.0229494571685791\n",
      "    test time:                0.012028932571411133\n",
      "    epoch time:               0.035457611083984375\n",
      "    last layer lr:            0.0073599999999999985\n",
      "epoch: 110 (12/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       1.0740926067034404\n",
      "    train cross_ent loss:     0.06764760779009925\n",
      "    test overall loss:        1.0414167841275532\n",
      "    test cross_ent loss:      0.22990952680508295\n",
      "    cluster loss:             2949.3157552083335\n",
      "    separation loss:          2.8613542715708413\n",
      "    avg separation loss:      8.533256848653158\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  810.3441162109375\n",
      "    train time:               0.022870302200317383\n",
      "    test time:                0.01213836669921875\n",
      "    epoch time:               0.03548908233642578\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 110 (13/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.7192379964722527\n",
      "    train cross_ent loss:     0.07599619817402628\n",
      "    test overall loss:        0.6784904599189758\n",
      "    test cross_ent loss:      0.24560080717007318\n",
      "    cluster loss:             2949.3160807291665\n",
      "    separation loss:          2.8633159001668296\n",
      "    avg separation loss:      8.549043814341227\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  431.7265625\n",
      "    train time:               0.02304387092590332\n",
      "    test time:                0.01204824447631836\n",
      "    epoch time:               0.03557944297790527\n",
      "    last layer lr:            0.008679999999999998\n",
      "epoch: 110 (14/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.3434438026613659\n",
      "    train cross_ent loss:     0.07873820182349947\n",
      "    test overall loss:        0.37642555435498554\n",
      "    test cross_ent loss:      0.2508857821424802\n",
      "    cluster loss:             2949.3159993489585\n",
      "    separation loss:          2.8631551265716553\n",
      "    avg separation loss:      8.530842304229736\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  124.37669372558594\n",
      "    train time:               0.0230715274810791\n",
      "    test time:                0.012053251266479492\n",
      "    epoch time:               0.03560328483581543\n",
      "    last layer lr:            0.009340000000000003\n",
      "epoch: 110 (15/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.20322603483994803\n",
      "    train cross_ent loss:     0.0874781579607063\n",
      "    test overall loss:        0.30751893917719525\n",
      "    test cross_ent loss:      0.22197375694910684\n",
      "    cluster loss:             2949.3155924479165\n",
      "    separation loss:          2.8634265263875327\n",
      "    avg separation loss:      8.532060305277506\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  84.38211822509766\n",
      "    train time:               0.022915363311767578\n",
      "    test time:                0.012090921401977539\n",
      "    epoch time:               0.035495758056640625\n",
      "    last layer lr:            0.01\n",
      "epoch: 110 (16/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.12742558287249672\n",
      "    train cross_ent loss:     0.053501434003313385\n",
      "    test overall loss:        0.25947100420792896\n",
      "    test cross_ent loss:      0.20344564442833266\n",
      "    cluster loss:             2949.3160807291665\n",
      "    separation loss:          2.854240338007609\n",
      "    avg separation loss:      8.506104787190756\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  54.86229705810547\n",
      "    train time:               0.022920608520507812\n",
      "    test time:                0.012201547622680664\n",
      "    epoch time:               0.035636186599731445\n",
      "    last layer lr:            0.009604000000000001\n",
      "epoch: 110 (17/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.0983713600370619\n",
      "    train cross_ent loss:     0.054446864459249705\n",
      "    test overall loss:        0.2231375277042389\n",
      "    test cross_ent loss:      0.19140396267175674\n",
      "    cluster loss:             2949.31640625\n",
      "    separation loss:          2.847787857055664\n",
      "    avg separation loss:      8.48006820678711\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  30.570491790771484\n",
      "    train time:               0.02323746681213379\n",
      "    test time:                0.012073278427124023\n",
      "    epoch time:               0.035808563232421875\n",
      "    last layer lr:            0.009208\n",
      "epoch: 110 (18/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.07440915662381384\n",
      "    train cross_ent loss:     0.04694404142598311\n",
      "    test overall loss:        0.20658484598000845\n",
      "    test cross_ent loss:      0.18526203806201616\n",
      "    cluster loss:             2949.3165690104165\n",
      "    separation loss:          2.8540027936299643\n",
      "    avg separation loss:      8.503262678782145\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  20.159738540649414\n",
      "    train time:               0.022892236709594727\n",
      "    test time:                0.012079000473022461\n",
      "    epoch time:               0.035466670989990234\n",
      "    last layer lr:            0.008812\n",
      "epoch: 110 (19/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.055243791805373296\n",
      "    train cross_ent loss:     0.0358904589795404\n",
      "    test overall loss:        0.1945386677980423\n",
      "    test cross_ent loss:      0.17791151131192842\n",
      "    cluster loss:             2949.31640625\n",
      "    separation loss:          2.8670080502827964\n",
      "    avg separation loss:      8.541207313537598\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  15.464086532592773\n",
      "    train time:               0.023070812225341797\n",
      "    test time:                0.012128114700317383\n",
      "    epoch time:               0.03568291664123535\n",
      "    last layer lr:            0.008415999999999998\n",
      "epoch: 110 (20/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.04994924532042609\n",
      "    train cross_ent loss:     0.03532232240670257\n",
      "    test overall loss:        0.18688759207725525\n",
      "    test cross_ent loss:      0.17437048877278963\n",
      "    cluster loss:             2949.3155110677085\n",
      "    separation loss:          2.857752720514933\n",
      "    avg separation loss:      8.517594655354818\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  11.354042053222656\n",
      "    train time:               0.02288961410522461\n",
      "    test time:                0.012063264846801758\n",
      "    epoch time:               0.035431623458862305\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 110 (21/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.05053657872809304\n",
      "    train cross_ent loss:     0.03882462055318885\n",
      "    test overall loss:        0.18060175577799478\n",
      "    test cross_ent loss:      0.16979391624530157\n",
      "    cluster loss:             2949.315673828125\n",
      "    separation loss:          2.859700600306193\n",
      "    avg separation loss:      8.54949696858724\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  9.64477252960205\n",
      "    train time:               0.023097753524780273\n",
      "    test time:                0.01204681396484375\n",
      "    epoch time:               0.03562736511230469\n",
      "    last layer lr:            0.007624000000000002\n",
      "epoch: 110 (22/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.04445960827999645\n",
      "    train cross_ent loss:     0.03431341021011273\n",
      "    test overall loss:        0.17636490861574808\n",
      "    test cross_ent loss:      0.1672619953751564\n",
      "    cluster loss:             2949.3160807291665\n",
      "    separation loss:          2.8665268421173096\n",
      "    avg separation loss:      8.561913013458252\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  7.939847946166992\n",
      "    train time:               0.022921085357666016\n",
      "    test time:                0.012037277221679688\n",
      "    epoch time:               0.035439252853393555\n",
      "    last layer lr:            0.007228000000000001\n",
      "epoch: 110 (23/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.04038442505730523\n",
      "    train cross_ent loss:     0.031045820150110457\n",
      "    test overall loss:        0.17214730257789293\n",
      "    test cross_ent loss:      0.1632890539864699\n",
      "    cluster loss:             2949.3163248697915\n",
      "    separation loss:          2.8775262037913003\n",
      "    avg separation loss:      8.57705545425415\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  7.695178985595703\n",
      "    train time:               0.022881746292114258\n",
      "    test time:                0.012145280838012695\n",
      "    epoch time:               0.03550577163696289\n",
      "    last layer lr:            0.006832000000000001\n",
      "epoch: 110 (24/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.03957937016255326\n",
      "    train cross_ent loss:     0.030994484201073647\n",
      "    test overall loss:        0.17088382070263228\n",
      "    test cross_ent loss:      0.16269967084129652\n",
      "    cluster loss:             2949.316162109375\n",
      "    separation loss:          2.868753989537557\n",
      "    avg separation loss:      8.563363711039225\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  7.021080017089844\n",
      "    train time:               0.022952795028686523\n",
      "    test time:                0.012065649032592773\n",
      "    epoch time:               0.03549790382385254\n",
      "    last layer lr:            0.006436\n",
      "epoch: 110 (25/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.0343672473811441\n",
      "    train cross_ent loss:     0.026410155205263033\n",
      "    test overall loss:        0.16877802088856697\n",
      "    test cross_ent loss:      0.16118483369549116\n",
      "    cluster loss:             2949.3159993489585\n",
      "    separation loss:          2.8629310925801597\n",
      "    avg separation loss:      8.56727647781372\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  6.430122375488281\n",
      "    train time:               0.023079872131347656\n",
      "    test time:                0.012054920196533203\n",
      "    epoch time:               0.035620927810668945\n",
      "    last layer lr:            0.00604\n",
      "epoch: 110 (26/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.051606438433130584\n",
      "    train cross_ent loss:     0.04374879981494612\n",
      "    test overall loss:        0.16788549224535623\n",
      "    test cross_ent loss:      0.15886879588166872\n",
      "    cluster loss:             2949.3162434895835\n",
      "    separation loss:          2.861983855565389\n",
      "    avg separation loss:      8.566564877827963\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  7.853632926940918\n",
      "    train time:               0.023085594177246094\n",
      "    test time:                0.012021780014038086\n",
      "    epoch time:               0.03558206558227539\n",
      "    last layer lr:            0.005644000000000002\n",
      "epoch: 110 (27/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.043302640318870544\n",
      "    train cross_ent loss:     0.034520937440296016\n",
      "    test overall loss:        0.16485785320401192\n",
      "    test cross_ent loss:      0.15698491409420967\n",
      "    cluster loss:             2949.3155924479165\n",
      "    separation loss:          2.8613810539245605\n",
      "    avg separation loss:      8.54408343633016\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  6.709870338439941\n",
      "    train time:               0.022906780242919922\n",
      "    test time:                0.01206660270690918\n",
      "    epoch time:               0.035454511642456055\n",
      "    last layer lr:            0.005248\n",
      "epoch: 110 (28/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.04680292266938421\n",
      "    train cross_ent loss:     0.03899404209935003\n",
      "    test overall loss:        0.16254511972268423\n",
      "    test cross_ent loss:      0.1541747065881888\n",
      "    cluster loss:             2949.3160807291665\n",
      "    separation loss:          2.868960460027059\n",
      "    avg separation loss:      8.576551755269369\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  7.207342624664307\n",
      "    train time:               0.023047447204589844\n",
      "    test time:                0.012067556381225586\n",
      "    epoch time:               0.035592079162597656\n",
      "    last layer lr:            0.004852000000000001\n",
      "epoch: 110 (29/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.04610269020001093\n",
      "    train cross_ent loss:     0.0381825767043564\n",
      "    test overall loss:        0.15851794679959616\n",
      "    test cross_ent loss:      0.15098515649636587\n",
      "    cluster loss:             2949.315673828125\n",
      "    separation loss:          2.866183121999105\n",
      "    avg separation loss:      8.532043933868408\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  6.369719505310059\n",
      "    train time:               0.02301621437072754\n",
      "    test time:                0.012057065963745117\n",
      "    epoch time:               0.035558223724365234\n",
      "    last layer lr:            0.004455999999999999\n",
      "epoch: 110 (30/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.03752458675040139\n",
      "    train cross_ent loss:     0.030360364717327885\n",
      "    test overall loss:        0.1566461039086183\n",
      "    test cross_ent loss:      0.15012164289752641\n",
      "    cluster loss:             2949.3151041666665\n",
      "    separation loss:          2.856624444325765\n",
      "    avg separation loss:      8.49639097849528\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  5.361397743225098\n",
      "    train time:               0.022933006286621094\n",
      "    test time:                0.012046098709106445\n",
      "    epoch time:               0.03545498847961426\n",
      "    last layer lr:            0.004060000000000001\n",
      "epoch: 110 (31/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.03911860670066542\n",
      "    train cross_ent loss:     0.0330976504418585\n",
      "    test overall loss:        0.15478073929746947\n",
      "    test cross_ent loss:      0.14881285279989243\n",
      "    cluster loss:             2949.3154296875\n",
      "    separation loss:          2.8629767894744873\n",
      "    avg separation loss:      8.546348730723063\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  4.8048200607299805\n",
      "    train time:               0.022921085357666016\n",
      "    test time:                0.012055397033691406\n",
      "    epoch time:               0.03545641899108887\n",
      "    last layer lr:            0.0036640000000000015\n",
      "epoch: 110 (32/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.042967856861650944\n",
      "    train cross_ent loss:     0.037081546150147915\n",
      "    test overall loss:        0.1547075373431047\n",
      "    test cross_ent loss:      0.14910766606529555\n",
      "    cluster loss:             2949.315673828125\n",
      "    separation loss:          2.8622891902923584\n",
      "    avg separation loss:      8.531343142191568\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  4.436803817749023\n",
      "    train time:               0.023086071014404297\n",
      "    test time:                0.012074470520019531\n",
      "    epoch time:               0.035643577575683594\n",
      "    last layer lr:            0.0032679999999999996\n",
      "epoch: 110 (33/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.03678163658413622\n",
      "    train cross_ent loss:     0.0316488951858547\n",
      "    test overall loss:        0.15199492995937666\n",
      "    test cross_ent loss:      0.1471501129368941\n",
      "    cluster loss:             2949.315673828125\n",
      "    separation loss:          2.861837943394979\n",
      "    avg separation loss:      8.50868527094523\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  3.6817526817321777\n",
      "    train time:               0.023180246353149414\n",
      "    test time:                0.012076139450073242\n",
      "    epoch time:               0.03574776649475098\n",
      "    last layer lr:            0.002872000000000001\n",
      "epoch: 110 (34/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.030060774439738855\n",
      "    train cross_ent loss:     0.025343973241332505\n",
      "    test overall loss:        0.15043923631310463\n",
      "    test cross_ent loss:      0.1460625392695268\n",
      "    cluster loss:             2949.3150227864585\n",
      "    separation loss:          2.85823647181193\n",
      "    avg separation loss:      8.495198726654053\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  3.2136342525482178\n",
      "    train time:               0.023093461990356445\n",
      "    test time:                0.012124061584472656\n",
      "    epoch time:               0.03570675849914551\n",
      "    last layer lr:            0.0024759999999999986\n",
      "epoch: 110 (35/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.02771264563004176\n",
      "    train cross_ent loss:     0.023663896549906995\n",
      "    test overall loss:        0.14992457131544748\n",
      "    test cross_ent loss:      0.14612164348363876\n",
      "    cluster loss:             2949.3153483072915\n",
      "    separation loss:          2.8602279822031655\n",
      "    avg separation loss:      8.515069325764975\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  2.639864444732666\n",
      "    train time:               0.023102283477783203\n",
      "    test time:                0.012088537216186523\n",
      "    epoch time:               0.03567075729370117\n",
      "    last layer lr:            0.0020800000000000003\n",
      "epoch: 110 (36/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.03172104164130158\n",
      "    train cross_ent loss:     0.02801173014773263\n",
      "    test overall loss:        0.14996825034419695\n",
      "    test cross_ent loss:      0.14637736851970354\n",
      "    cluster loss:             2949.3159993489585\n",
      "    separation loss:          2.872947374979655\n",
      "    avg separation loss:      8.58242384592692\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  2.427811622619629\n",
      "    train time:               0.02313232421875\n",
      "    test time:                0.012090921401977539\n",
      "    epoch time:               0.035698890686035156\n",
      "    last layer lr:            0.0016840000000000017\n",
      "epoch: 110 (37/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.03036165154642529\n",
      "    train cross_ent loss:     0.027058523303518694\n",
      "    test overall loss:        0.1492993968228499\n",
      "    test cross_ent loss:      0.14615663761893907\n",
      "    cluster loss:             2949.3160807291665\n",
      "    separation loss:          2.867636203765869\n",
      "    avg separation loss:      8.582382361094156\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  1.9796910285949707\n",
      "    train time:               0.0231168270111084\n",
      "    test time:                0.012102127075195312\n",
      "    epoch time:               0.035703420639038086\n",
      "    last layer lr:            0.0012879999999999994\n",
      "epoch: 110 (38/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.029138286494546466\n",
      "    train cross_ent loss:     0.026260924318598375\n",
      "    test overall loss:        0.15122329195340475\n",
      "    test cross_ent loss:      0.14839294676979384\n",
      "    cluster loss:             2949.3165690104165\n",
      "    separation loss:          2.861175855000814\n",
      "    avg separation loss:      8.561213175455729\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  1.6672816276550293\n",
      "    train time:               0.02309393882751465\n",
      "    test time:                0.012098073959350586\n",
      "    epoch time:               0.035674095153808594\n",
      "    last layer lr:            0.0008920000000000009\n",
      "epoch: 110 (39/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.02966808072394795\n",
      "    train cross_ent loss:     0.02712066311182247\n",
      "    test overall loss:        0.15108428398768106\n",
      "    test cross_ent loss:      0.14868757873773575\n",
      "    cluster loss:             2949.3168131510415\n",
      "    separation loss:          2.8619038263956704\n",
      "    avg separation loss:      8.562997976938883\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  1.2336416244506836\n",
      "    train time:               0.023119211196899414\n",
      "    test time:                0.012044191360473633\n",
      "    epoch time:               0.03564763069152832\n",
      "    last layer lr:            0.0004959999999999986\n",
      "epoch: 110 (40/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.025315913785662916\n",
      "    train cross_ent loss:     0.023164077972372372\n",
      "    test overall loss:        0.14808313051859537\n",
      "    test cross_ent loss:      0.1460518315434456\n",
      "    cluster loss:             2949.3157552083335\n",
      "    separation loss:          2.8634382088979087\n",
      "    avg separation loss:      8.543938477834066\n",
      "    l1_addon loss:            38.76897430419922\n",
      "    l1 loss:                  0.8682348728179932\n",
      "    train time:               0.02307295799255371\n",
      "    test time:                0.012082099914550781\n",
      "    epoch time:               0.03564190864562988\n",
      "    last layer lr:            0.0001\n",
      "epoch: 111 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.03613966858635346\n",
      "    train cross_ent loss:     0.034108010534611016\n",
      "    test overall loss:        0.14665630956490835\n",
      "    test cross_ent loss:      0.14462441578507423\n",
      "    cluster loss:             2949.31591796875\n",
      "    separation loss:          2.8664181232452393\n",
      "    avg separation loss:      8.543395201365152\n",
      "    l1_addon loss:            38.78871536254883\n",
      "    l1 loss:                  0.8682348728179932\n",
      "    train time:               0.06050753593444824\n",
      "    test time:                0.012111186981201172\n",
      "    epoch time:               0.07332158088684082\n",
      "    joint lr:                 0.0017196383771408863\n",
      "epoch: 112 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.024563355060915153\n",
      "    train cross_ent loss:     0.022532280896686845\n",
      "    test overall loss:        0.13703286523620287\n",
      "    test cross_ent loss:      0.1350008056809505\n",
      "    cluster loss:             2949.3053385416665\n",
      "    separation loss:          2.7976772785186768\n",
      "    avg separation loss:      8.399956385294596\n",
      "    l1_addon loss:            38.79433822631836\n",
      "    l1 loss:                  0.8682348728179932\n",
      "    train time:               0.05991768836975098\n",
      "    test time:                0.012665510177612305\n",
      "    epoch time:               0.07329511642456055\n",
      "    joint lr:                 0.0033068839867389757\n",
      "epoch: 113 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.014681182232581906\n",
      "    train cross_ent loss:     0.012648906765712632\n",
      "    test overall loss:        0.14204412574569383\n",
      "    test cross_ent loss:      0.14001519543429217\n",
      "    cluster loss:             2949.3053385416665\n",
      "    separation loss:          2.718085447947184\n",
      "    avg separation loss:      8.111250241597494\n",
      "    l1_addon loss:            38.6900634765625\n",
      "    l1 loss:                  0.8682348728179932\n",
      "    train time:               0.06171154975891113\n",
      "    test time:                0.012689828872680664\n",
      "    epoch time:               0.07510948181152344\n",
      "    joint lr:                 0.0048622227203073696\n",
      "epoch: 114 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.02367766211844153\n",
      "    train cross_ent loss:     0.021649815530205768\n",
      "    test overall loss:        0.1292921273658673\n",
      "    test cross_ent loss:      0.12725016102194786\n",
      "    cluster loss:             2949.3138834635415\n",
      "    separation loss:          2.806910991668701\n",
      "    avg separation loss:      8.241349697113037\n",
      "    l1_addon loss:            39.12444305419922\n",
      "    l1 loss:                  0.8682348728179932\n",
      "    train time:               0.060060977935791016\n",
      "    test time:                0.012680292129516602\n",
      "    epoch time:               0.07384037971496582\n",
      "    joint lr:                 0.00638613399080572\n",
      "epoch: 115 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 94.33%\n",
      "    train overall loss:       0.026081671213938132\n",
      "    train cross_ent loss:     0.02405048888694081\n",
      "    test overall loss:        0.17017805824677149\n",
      "    test cross_ent loss:      0.16816028455893198\n",
      "    cluster loss:             2949.3397623697915\n",
      "    separation loss:          2.6591355005900064\n",
      "    avg separation loss:      7.857022762298584\n",
      "    l1_addon loss:            38.31792068481445\n",
      "    l1 loss:                  0.8682348728179932\n",
      "    train time:               0.060266971588134766\n",
      "    test time:                0.01273798942565918\n",
      "    epoch time:               0.07400703430175781\n",
      "    joint lr:                 0.007879090813622073\n",
      "epoch: 116 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.025024343592425186\n",
      "    train cross_ent loss:     0.02299352093703217\n",
      "    test overall loss:        0.16834095741311708\n",
      "    test cross_ent loss:      0.16630429401993752\n",
      "    cluster loss:             2949.3629557291665\n",
      "    separation loss:          2.883873780568441\n",
      "    avg separation loss:      8.268501440684\n",
      "    l1_addon loss:            38.947776794433594\n",
      "    l1 loss:                  0.8682348728179932\n",
      "    train time:               0.060005903244018555\n",
      "    test time:                0.012637853622436523\n",
      "    epoch time:               0.0736544132232666\n",
      "    joint lr:                 0.009341559886583039\n",
      "epoch: 117 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       0.07303784208165275\n",
      "    train cross_ent loss:     0.07100633718073368\n",
      "    test overall loss:        0.17363445709149042\n",
      "    test cross_ent loss:      0.1716011998554071\n",
      "    cluster loss:             2949.3768717447915\n",
      "    separation loss:          2.831216255823771\n",
      "    avg separation loss:      7.960231781005859\n",
      "    l1_addon loss:            38.83415222167969\n",
      "    l1 loss:                  0.8682348728179932\n",
      "    train time:               0.06000661849975586\n",
      "    test time:                0.012656211853027344\n",
      "    epoch time:               0.0736846923828125\n",
      "    joint lr:                 0.010774001669003403\n",
      "epoch: 118 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.18856506215201485\n",
      "    train cross_ent loss:     0.18653408479359415\n",
      "    test overall loss:        0.2592356627186139\n",
      "    test cross_ent loss:      0.25719164063533145\n",
      "    cluster loss:             2949.4456380208335\n",
      "    separation loss:          3.099637508392334\n",
      "    avg separation loss:      8.127148310343424\n",
      "    l1_addon loss:            39.19288635253906\n",
      "    l1 loss:                  0.8682348728179932\n",
      "    train time:               0.059876441955566406\n",
      "    test time:                0.012349843978881836\n",
      "    epoch time:               0.07323312759399414\n",
      "    joint lr:                 0.012176870459786701\n",
      "epoch: 119 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 87.33%\n",
      "    train overall loss:       0.5346768887506591\n",
      "    train cross_ent loss:     0.5326430838969018\n",
      "    test overall loss:        0.6263543864091238\n",
      "    test cross_ent loss:      0.6243190169334412\n",
      "    cluster loss:             2949.69873046875\n",
      "    separation loss:          4.322438398996989\n",
      "    avg separation loss:      10.81556510925293\n",
      "    l1_addon loss:            38.90391159057617\n",
      "    l1 loss:                  0.8682348728179932\n",
      "    train time:               0.059488534927368164\n",
      "    test time:                0.012135505676269531\n",
      "    epoch time:               0.07247376441955566\n",
      "    joint lr:                 0.013550614474587434\n",
      "epoch: 120 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 91.33%\n",
      "    train overall loss:       0.8115710814793905\n",
      "    train cross_ent loss:     0.8095464706420898\n",
      "    test overall loss:        0.7052667240301768\n",
      "    test cross_ent loss:      0.7032739122708639\n",
      "    cluster loss:             2949.9122721354165\n",
      "    separation loss:          5.959912300109863\n",
      "    avg separation loss:      15.34315268198649\n",
      "    l1_addon loss:            37.48569869995117\n",
      "    l1 loss:                  0.8682348728179932\n",
      "    train time:               0.05951952934265137\n",
      "    test time:                0.012144088745117188\n",
      "    epoch time:               0.07251143455505371\n",
      "    joint lr:                 0.014895675922046181\n",
      "epoch: 121 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 90.00%\n",
      "    train overall loss:       0.8296841515435113\n",
      "    train cross_ent loss:     0.8276699648963081\n",
      "    test overall loss:        0.745031327009201\n",
      "    test cross_ent loss:      0.7430129448572794\n",
      "    cluster loss:             2950.090087890625\n",
      "    separation loss:          6.52686882019043\n",
      "    avg separation loss:      16.70791021982829\n",
      "    l1_addon loss:            38.33773422241211\n",
      "    l1 loss:                  0.8682348728179932\n",
      "    train time:               0.05937933921813965\n",
      "    test time:                0.012139558792114258\n",
      "    epoch time:               0.07240653038024902\n",
      "    joint lr:                 0.014015333204684437\n",
      "epoch: 122 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 89.67%\n",
      "    train overall loss:       0.7989048527346717\n",
      "    train cross_ent loss:     0.7968936661879221\n",
      "    test overall loss:        0.6355930964152018\n",
      "    test cross_ent loss:      0.6335648198922476\n",
      "    cluster loss:             2950.1102701822915\n",
      "    separation loss:          6.743378798166911\n",
      "    avg separation loss:      17.45615069071452\n",
      "    l1_addon loss:            38.66722106933594\n",
      "    l1 loss:                  0.8682348728179932\n",
      "    train time:               0.059531211853027344\n",
      "    test time:                0.012163877487182617\n",
      "    epoch time:               0.07254242897033691\n",
      "    joint lr:                 0.01315111777407772\n",
      "epoch: 123 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 84.67%\n",
      "    train overall loss:       0.6251443227132162\n",
      "    train cross_ent loss:     0.6231342554092407\n",
      "    test overall loss:        0.7207569479942322\n",
      "    test cross_ent loss:      0.7187706430753072\n",
      "    cluster loss:             2950.200439453125\n",
      "    separation loss:          6.842092196146647\n",
      "    avg separation loss:      16.191930770874023\n",
      "    l1_addon loss:            37.26969909667969\n",
      "    l1 loss:                  0.8682348728179932\n",
      "    train time:               0.05918741226196289\n",
      "    test time:                0.012138843536376953\n",
      "    epoch time:               0.07236623764038086\n",
      "    joint lr:                 0.012302795118762673\n",
      "epoch: 124 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 91.33%\n",
      "    train overall loss:       0.6712769269943237\n",
      "    train cross_ent loss:     0.6692643033133613\n",
      "    test overall loss:        0.5527991056442261\n",
      "    test cross_ent loss:      0.5507815082867941\n",
      "    cluster loss:             2950.1636555989585\n",
      "    separation loss:          6.349767684936523\n",
      "    avg separation loss:      14.721627235412598\n",
      "    l1_addon loss:            38.312347412109375\n",
      "    l1 loss:                  0.8682348728179932\n",
      "    train time:               0.05945110321044922\n",
      "    test time:                0.012155294418334961\n",
      "    epoch time:               0.07248592376708984\n",
      "    joint lr:                 0.011470133804776505\n",
      "epoch: 125 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 88.00%\n",
      "    train overall loss:       0.6281961136394076\n",
      "    train cross_ent loss:     0.6261848277515836\n",
      "    test overall loss:        0.6531769335269928\n",
      "    test cross_ent loss:      0.6511744558811188\n",
      "    cluster loss:             2950.32763671875\n",
      "    separation loss:          6.25050671895345\n",
      "    avg separation loss:      13.501826922098795\n",
      "    l1_addon loss:            37.808170318603516\n",
      "    l1 loss:                  0.8682348728179932\n",
      "    train time:               0.05926704406738281\n",
      "    test time:                0.012166023254394531\n",
      "    epoch time:               0.07224917411804199\n",
      "    joint lr:                 0.010652905437558197\n",
      "epoch: 126 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 90.67%\n",
      "    train overall loss:       0.5782203210724725\n",
      "    train cross_ent loss:     0.5762032585011588\n",
      "    test overall loss:        0.48818250993887585\n",
      "    test cross_ent loss:      0.48616605003674823\n",
      "    cluster loss:             2950.243896484375\n",
      "    separation loss:          6.410016377766927\n",
      "    avg separation loss:      14.732831637064615\n",
      "    l1_addon loss:            38.273773193359375\n",
      "    l1 loss:                  0.8682348728179932\n",
      "    train time:               0.06038784980773926\n",
      "    test time:                0.012226581573486328\n",
      "    epoch time:               0.07332253456115723\n",
      "    joint lr:                 0.009850884624303774\n",
      "epoch: 127 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 90.00%\n",
      "    train overall loss:       0.5329940385288663\n",
      "    train cross_ent loss:     0.5309780471854739\n",
      "    test overall loss:        0.5884035378694534\n",
      "    test cross_ent loss:      0.5864032208919525\n",
      "    cluster loss:             2950.2582194010415\n",
      "    separation loss:          6.2502055168151855\n",
      "    avg separation loss:      14.223717053731283\n",
      "    l1_addon loss:            37.73530960083008\n",
      "    l1 loss:                  0.8682348728179932\n",
      "    train time:               0.060624122619628906\n",
      "    test time:                0.012134552001953125\n",
      "    epoch time:               0.07348990440368652\n",
      "    joint lr:                 0.00906384893677068\n",
      "epoch: 128 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 91.00%\n",
      "    train overall loss:       0.4070429967509376\n",
      "    train cross_ent loss:     0.4050224439965354\n",
      "    test overall loss:        0.5332218011220297\n",
      "    test cross_ent loss:      0.531201442082723\n",
      "    cluster loss:             2950.1707356770835\n",
      "    separation loss:          5.945815881093343\n",
      "    avg separation loss:      14.459862073262533\n",
      "    l1_addon loss:            38.40423583984375\n",
      "    l1 loss:                  0.8682348728179932\n",
      "    train time:               0.060674428939819336\n",
      "    test time:                0.012120723724365234\n",
      "    epoch time:               0.0734720230102539\n",
      "    joint lr:                 0.00829157887452582\n",
      "epoch: 129 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 92.00%\n",
      "    train overall loss:       0.3446146166986889\n",
      "    train cross_ent loss:     0.34258275892999435\n",
      "    test overall loss:        0.3557503918806712\n",
      "    test cross_ent loss:      0.3537321239709854\n",
      "    cluster loss:             2950.1373697916665\n",
      "    separation loss:          5.673357645670573\n",
      "    avg separation loss:      12.69575309753418\n",
      "    l1_addon loss:            38.334251403808594\n",
      "    l1 loss:                  0.8682348728179932\n",
      "    train time:               0.06056976318359375\n",
      "    test time:                0.012176752090454102\n",
      "    epoch time:               0.07346868515014648\n",
      "    joint lr:                 0.007533857828632187\n",
      "epoch: 130 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 91.67%\n",
      "    train overall loss:       0.32659178641107345\n",
      "    train cross_ent loss:     0.3245619469218784\n",
      "    test overall loss:        0.4429108003775279\n",
      "    test cross_ent loss:      0.4408927261829376\n",
      "    cluster loss:             2950.1454264322915\n",
      "    separation loss:          5.598594029744466\n",
      "    avg separation loss:      12.220958709716797\n",
      "    l1_addon loss:            38.327327728271484\n",
      "    l1 loss:                  0.8682348728179932\n",
      "    train time:               0.06175351142883301\n",
      "    test time:                0.01298666000366211\n",
      "    epoch time:               0.07553267478942871\n",
      "    joint lr:                 0.00679047204576897\n",
      "epoch: 131 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 90.67%\n",
      "    train overall loss:       0.23244574086533654\n",
      "    train cross_ent loss:     0.23041656696134144\n",
      "    test overall loss:        0.3858381162087123\n",
      "    test cross_ent loss:      0.38381943106651306\n",
      "    cluster loss:             2950.0992838541665\n",
      "    separation loss:          5.332836786905925\n",
      "    avg separation loss:      11.75544548034668\n",
      "    l1_addon loss:            38.348297119140625\n",
      "    l1 loss:                  0.8682348728179932\n",
      "    train time:               0.06164669990539551\n",
      "    test time:                0.012887239456176758\n",
      "    epoch time:               0.0753176212310791\n",
      "    joint lr:                 0.006061210592780146\n",
      "epoch: 132 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 93.00%\n",
      "    train overall loss:       0.2083464397324456\n",
      "    train cross_ent loss:     0.20631001393000284\n",
      "    test overall loss:        0.27257442226012546\n",
      "    test cross_ent loss:      0.27054622521003086\n",
      "    cluster loss:             2950.0263671875\n",
      "    separation loss:          5.139963150024414\n",
      "    avg separation loss:      11.304231961568197\n",
      "    l1_addon loss:            38.66519546508789\n",
      "    l1 loss:                  0.8682348728179932\n",
      "    train time:               0.062050580978393555\n",
      "    test time:                0.01277780532836914\n",
      "    epoch time:               0.07561826705932617\n",
      "    joint lr:                 0.005345865321646531\n",
      "epoch: 133 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.10839403006765577\n",
      "    train cross_ent loss:     0.10635712742805481\n",
      "    test overall loss:        0.22564993053674698\n",
      "    test cross_ent loss:      0.22361513475577036\n",
      "    cluster loss:             2949.991943359375\n",
      "    separation loss:          5.027586936950684\n",
      "    avg separation loss:      11.030985514322916\n",
      "    l1_addon loss:            38.885467529296875\n",
      "    l1 loss:                  0.8682348728179932\n",
      "    train time:               0.06107068061828613\n",
      "    test time:                0.012797117233276367\n",
      "    epoch time:               0.07465171813964844\n",
      "    joint lr:                 0.00464423083487631\n",
      "epoch: 134 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.06380963242716259\n",
      "    train cross_ent loss:     0.06177582840124766\n",
      "    test overall loss:        0.18463470041751862\n",
      "    test cross_ent loss:      0.18260089928905168\n",
      "    cluster loss:             2949.9488118489585\n",
      "    separation loss:          4.902403195699056\n",
      "    avg separation loss:      10.95547358194987\n",
      "    l1_addon loss:            38.852294921875\n",
      "    l1 loss:                  0.8682348728179932\n",
      "    train time:               0.06146693229675293\n",
      "    test time:                0.012863636016845703\n",
      "    epoch time:               0.0750739574432373\n",
      "    joint lr:                 0.003956104451309328\n",
      "epoch: 135 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.04792427230212423\n",
      "    train cross_ent loss:     0.04588757279432482\n",
      "    test overall loss:        0.17032712325453758\n",
      "    test cross_ent loss:      0.16828703631957373\n",
      "    cluster loss:             2949.9271647135415\n",
      "    separation loss:          4.762565453847249\n",
      "    avg separation loss:      10.615533510843912\n",
      "    l1_addon loss:            39.061668395996094\n",
      "    l1 loss:                  0.8682348728179932\n",
      "    train time:               0.0616602897644043\n",
      "    test time:                0.012771368026733398\n",
      "    epoch time:               0.07524824142456055\n",
      "    joint lr:                 0.0032812861723301896\n",
      "epoch: 136 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 94.67%\n",
      "    train overall loss:       0.031082433855368033\n",
      "    train cross_ent loss:     0.02904517576098442\n",
      "    test overall loss:        0.17174348856012026\n",
      "    test cross_ent loss:      0.16970992336670557\n",
      "    cluster loss:             2949.931396484375\n",
      "    separation loss:          4.629101753234863\n",
      "    avg separation loss:      10.32459799448649\n",
      "    l1_addon loss:            38.844573974609375\n",
      "    l1 loss:                  0.8682348728179932\n",
      "    train time:               0.06108546257019043\n",
      "    test time:                0.012307167053222656\n",
      "    epoch time:               0.07414126396179199\n",
      "    joint lr:                 0.0026195786484855114\n",
      "epoch: 137 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.023502160795032978\n",
      "    train cross_ent loss:     0.02146453896744384\n",
      "    test overall loss:        0.15406752626101175\n",
      "    test cross_ent loss:      0.1520301066339016\n",
      "    cluster loss:             2949.9138997395835\n",
      "    separation loss:          4.576797803243001\n",
      "    avg separation loss:      10.176851590474447\n",
      "    l1_addon loss:            38.972755432128906\n",
      "    l1 loss:                  0.8682348728179932\n",
      "    train time:               0.060494422912597656\n",
      "    test time:                0.012230873107910156\n",
      "    epoch time:               0.07346963882446289\n",
      "    joint lr:                 0.0019707871465004943\n",
      "epoch: 138 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.014573572824398676\n",
      "    train cross_ent loss:     0.012538005132228136\n",
      "    test overall loss:        0.15183398375908533\n",
      "    test cross_ent loss:      0.1497972458600998\n",
      "    cluster loss:             2949.90869140625\n",
      "    separation loss:          4.5479780832926435\n",
      "    avg separation loss:      10.054989178975424\n",
      "    l1_addon loss:            38.95021057128906\n",
      "    l1 loss:                  0.8682348728179932\n",
      "    train time:               0.061130523681640625\n",
      "    test time:                0.012660741806030273\n",
      "    epoch time:               0.0745401382446289\n",
      "    joint lr:                 0.0013347195166903292\n",
      "epoch: 139 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.03141289266447226\n",
      "    train cross_ent loss:     0.029374974676304393\n",
      "    test overall loss:        0.1479312131802241\n",
      "    test cross_ent loss:      0.14589419464270273\n",
      "    cluster loss:             2949.9031575520835\n",
      "    separation loss:          4.539422671000163\n",
      "    avg separation loss:      9.988367080688477\n",
      "    l1_addon loss:            38.95940017700195\n",
      "    l1 loss:                  0.8682348728179932\n",
      "    train time:               0.06114339828491211\n",
      "    test time:                0.012653350830078125\n",
      "    epoch time:               0.0745537281036377\n",
      "    joint lr:                 0.0007111861607617089\n",
      "epoch: 140 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.010523147622330321\n",
      "    train cross_ent loss:     0.00848847684553928\n",
      "    test overall loss:        0.159884724766016\n",
      "    test cross_ent loss:      0.15785182764132819\n",
      "    cluster loss:             2949.9122721354165\n",
      "    separation loss:          4.547472874323527\n",
      "    avg separation loss:      9.948304494222006\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  0.8682348728179932\n",
      "    train time:               0.06099295616149902\n",
      "    test time:                0.012665510177612305\n",
      "    epoch time:               0.07441163063049316\n",
      "    joint lr:                 0.0001\n",
      "epoch: 140 (PUSH) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       0.010523147622330321\n",
      "    train cross_ent loss:     0.00848847684553928\n",
      "    test overall loss:        0.16788944726188978\n",
      "    test cross_ent loss:      0.16585655510425568\n",
      "    cluster loss:             2949.3157552083335\n",
      "    separation loss:          2.7647631963094077\n",
      "    avg separation loss:      7.572068532307942\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  0.8682348728179932\n",
      "    train time:               0.06099295616149902\n",
      "    test time:                0.012874603271484375\n",
      "    epoch time:               0.36887121200561523\n",
      "epoch: 140 (1/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       0.02951354802482658\n",
      "    train cross_ent loss:     0.027670955104339454\n",
      "    test overall loss:        0.17025077839692435\n",
      "    test cross_ent loss:      0.16857468088467917\n",
      "    cluster loss:             2949.3160807291665\n",
      "    separation loss:          2.7632358074188232\n",
      "    avg separation loss:      7.575067043304443\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  0.5114381909370422\n",
      "    train time:               0.02464771270751953\n",
      "    test time:                0.012639999389648438\n",
      "    epoch time:               0.037810564041137695\n",
      "    last layer lr:            0.0007599999999999978\n",
      "epoch: 140 (2/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       0.025930597136418026\n",
      "    train cross_ent loss:     0.02349184163742595\n",
      "    test overall loss:        0.1727106273174286\n",
      "    test cross_ent loss:      0.17021033043662706\n",
      "    cluster loss:             2949.316650390625\n",
      "    separation loss:          2.7566798528035483\n",
      "    avg separation loss:      7.562683900197347\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  1.3356382846832275\n",
      "    train time:               0.024234294891357422\n",
      "    test time:                0.012620210647583008\n",
      "    epoch time:               0.03736519813537598\n",
      "    last layer lr:            0.0014199999999999955\n",
      "epoch: 140 (3/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       0.02714503339181344\n",
      "    train cross_ent loss:     0.024236504091984697\n",
      "    test overall loss:        0.1745666190981865\n",
      "    test cross_ent loss:      0.17165199294686317\n",
      "    cluster loss:             2949.3173014322915\n",
      "    separation loss:          2.757621924082438\n",
      "    avg separation loss:      7.567557017008464\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  1.749959111213684\n",
      "    train time:               0.0241701602935791\n",
      "    test time:                0.012574434280395508\n",
      "    epoch time:               0.03725552558898926\n",
      "    last layer lr:            0.0020800000000000046\n",
      "epoch: 140 (4/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       0.027588621609740786\n",
      "    train cross_ent loss:     0.02441217227735453\n",
      "    test overall loss:        0.17236356933911642\n",
      "    test cross_ent loss:      0.16910587747891745\n",
      "    cluster loss:             2949.3163248697915\n",
      "    separation loss:          2.7636303106943765\n",
      "    avg separation loss:      7.5978085199991865\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  2.0930304527282715\n",
      "    train time:               0.02424335479736328\n",
      "    test time:                0.012598037719726562\n",
      "    epoch time:               0.037355899810791016\n",
      "    last layer lr:            0.0027400000000000024\n",
      "epoch: 140 (5/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       0.026148679355780285\n",
      "    train cross_ent loss:     0.02222039457410574\n",
      "    test overall loss:        0.17153191193938255\n",
      "    test cross_ent loss:      0.16751597573359808\n",
      "    cluster loss:             2949.3165690104165\n",
      "    separation loss:          2.7634077072143555\n",
      "    avg separation loss:      7.5751668612162275\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  2.8512754440307617\n",
      "    train time:               0.024312496185302734\n",
      "    test time:                0.012594461441040039\n",
      "    epoch time:               0.03742218017578125\n",
      "    last layer lr:            0.0034\n",
      "epoch: 140 (6/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.025573659274313185\n",
      "    train cross_ent loss:     0.02136183561136325\n",
      "    test overall loss:        0.16961934914191565\n",
      "    test cross_ent loss:      0.16510309278964996\n",
      "    cluster loss:             2949.3162434895835\n",
      "    separation loss:          2.761735121409098\n",
      "    avg separation loss:      7.5701904296875\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  3.351593017578125\n",
      "    train time:               0.024129629135131836\n",
      "    test time:                0.012611150741577148\n",
      "    epoch time:               0.0372471809387207\n",
      "    last layer lr:            0.004059999999999998\n",
      "epoch: 140 (7/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.03148390808039241\n",
      "    train cross_ent loss:     0.02638351818960574\n",
      "    test overall loss:        0.1670642929772536\n",
      "    test cross_ent loss:      0.16190859799583754\n",
      "    cluster loss:             2949.3155110677085\n",
      "    separation loss:          2.7702123324076333\n",
      "    avg separation loss:      7.605425993601481\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  3.991029739379883\n",
      "    train time:               0.024155616760253906\n",
      "    test time:                0.012687921524047852\n",
      "    epoch time:               0.03735685348510742\n",
      "    last layer lr:            0.004719999999999996\n",
      "epoch: 140 (8/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.03274143994268444\n",
      "    train cross_ent loss:     0.027346876863804128\n",
      "    test overall loss:        0.16751071562369665\n",
      "    test cross_ent loss:      0.16180486977100372\n",
      "    cluster loss:             2949.3155924479165\n",
      "    separation loss:          2.768065849939982\n",
      "    avg separation loss:      7.5886656443278\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  4.541182518005371\n",
      "    train time:               0.025776386260986328\n",
      "    test time:                0.01297760009765625\n",
      "    epoch time:               0.03930521011352539\n",
      "    last layer lr:            0.0053800000000000054\n",
      "epoch: 140 (9/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.029485826484031148\n",
      "    train cross_ent loss:     0.023258600746177964\n",
      "    test overall loss:        0.17320149888594946\n",
      "    test cross_ent loss:      0.16652434319257736\n",
      "    cluster loss:             2949.31591796875\n",
      "    separation loss:          2.7616921265920005\n",
      "    avg separation loss:      7.592576662699382\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  5.512491226196289\n",
      "    train time:               0.024448394775390625\n",
      "    test time:                0.012626886367797852\n",
      "    epoch time:               0.03759336471557617\n",
      "    last layer lr:            0.006040000000000003\n",
      "epoch: 140 (10/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.025930487033393648\n",
      "    train cross_ent loss:     0.019307513410846393\n",
      "    test overall loss:        0.17037991185983023\n",
      "    test cross_ent loss:      0.1640163113673528\n",
      "    cluster loss:             2949.3155924479165\n",
      "    separation loss:          2.763063351313273\n",
      "    avg separation loss:      7.590167999267578\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  5.198940277099609\n",
      "    train time:               0.024371623992919922\n",
      "    test time:                0.012569189071655273\n",
      "    epoch time:               0.03745317459106445\n",
      "    last layer lr:            0.0067\n",
      "epoch: 140 (11/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.026063406839966774\n",
      "    train cross_ent loss:     0.01932418460233344\n",
      "    test overall loss:        0.1746679445107778\n",
      "    test cross_ent loss:      0.1671354758242766\n",
      "    cluster loss:             2949.316162109375\n",
      "    separation loss:          2.7482006549835205\n",
      "    avg separation loss:      7.523223718007405\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  6.367805480957031\n",
      "    train time:               0.025348186492919922\n",
      "    test time:                0.01269841194152832\n",
      "    epoch time:               0.03861594200134277\n",
      "    last layer lr:            0.0073599999999999985\n",
      "epoch: 140 (12/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.025415144653783903\n",
      "    train cross_ent loss:     0.018043235565225284\n",
      "    test overall loss:        0.17507732411225638\n",
      "    test cross_ent loss:      0.16697166860103607\n",
      "    cluster loss:             2949.31640625\n",
      "    separation loss:          2.7559675375620523\n",
      "    avg separation loss:      7.545571168263753\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  6.94099235534668\n",
      "    train time:               0.024862051010131836\n",
      "    test time:                0.012695789337158203\n",
      "    epoch time:               0.03809762001037598\n",
      "    last layer lr:            0.008019999999999994\n",
      "epoch: 140 (13/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.024126314765049353\n",
      "    train cross_ent loss:     0.016135818738904264\n",
      "    test overall loss:        0.1746001367767652\n",
      "    test cross_ent loss:      0.16668927172819772\n",
      "    cluster loss:             2949.3162434895835\n",
      "    separation loss:          2.757968266805013\n",
      "    avg separation loss:      7.552419026692708\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  6.746197700500488\n",
      "    train time:               0.024344444274902344\n",
      "    test time:                0.012643098831176758\n",
      "    epoch time:               0.0375056266784668\n",
      "    last layer lr:            0.008680000000000005\n",
      "epoch: 140 (14/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.025057687424123287\n",
      "    train cross_ent loss:     0.0169401162614425\n",
      "    test overall loss:        0.1722126603126526\n",
      "    test cross_ent loss:      0.16335897396008173\n",
      "    cluster loss:             2949.316650390625\n",
      "    separation loss:          2.7521797815958657\n",
      "    avg separation loss:      7.531661033630371\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  7.689020156860352\n",
      "    train time:               0.02420210838317871\n",
      "    test time:                0.012605667114257812\n",
      "    epoch time:               0.03732657432556152\n",
      "    last layer lr:            0.009340000000000003\n",
      "epoch: 140 (15/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.02438296977844503\n",
      "    train cross_ent loss:     0.015198156729133593\n",
      "    test overall loss:        0.17034368962049484\n",
      "    test cross_ent loss:      0.16141469279925028\n",
      "    cluster loss:             2949.3157552083335\n",
      "    separation loss:          2.759481906890869\n",
      "    avg separation loss:      7.557976404825847\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  7.7643327713012695\n",
      "    train time:               0.02435922622680664\n",
      "    test time:                0.012597322463989258\n",
      "    epoch time:               0.03747057914733887\n",
      "    last layer lr:            0.01\n",
      "epoch: 140 (16/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.021815922628674243\n",
      "    train cross_ent loss:     0.01273669002370702\n",
      "    test overall loss:        0.17052864531675974\n",
      "    test cross_ent loss:      0.16110419730345407\n",
      "    cluster loss:             2949.3160807291665\n",
      "    separation loss:          2.7583842277526855\n",
      "    avg separation loss:      7.552833875020345\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  8.259784698486328\n",
      "    train time:               0.024312973022460938\n",
      "    test time:                0.012597084045410156\n",
      "    epoch time:               0.03741884231567383\n",
      "    last layer lr:            0.009604000000000001\n",
      "epoch: 140 (17/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.020943833101126883\n",
      "    train cross_ent loss:     0.011923952131635614\n",
      "    test overall loss:        0.17129465689261755\n",
      "    test cross_ent loss:      0.16243112087249756\n",
      "    cluster loss:             2949.3163248697915\n",
      "    separation loss:          2.755117972691854\n",
      "    avg separation loss:      7.551820278167725\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  7.698870658874512\n",
      "    train time:               0.02419281005859375\n",
      "    test time:                0.012591361999511719\n",
      "    epoch time:               0.037297964096069336\n",
      "    last layer lr:            0.009208000000000003\n",
      "epoch: 140 (18/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.020442620437178347\n",
      "    train cross_ent loss:     0.011862914802299606\n",
      "    test overall loss:        0.17011782775322595\n",
      "    test cross_ent loss:      0.16158683598041534\n",
      "    cluster loss:             2949.3162434895835\n",
      "    separation loss:          2.7565287748972573\n",
      "    avg separation loss:      7.56037441889445\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  7.366323471069336\n",
      "    train time:               0.024325847625732422\n",
      "    test time:                0.012655496597290039\n",
      "    epoch time:               0.037491798400878906\n",
      "    last layer lr:            0.008811999999999997\n",
      "epoch: 140 (19/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.021740615264409117\n",
      "    train cross_ent loss:     0.013430943039970266\n",
      "    test overall loss:        0.16768952459096909\n",
      "    test cross_ent loss:      0.1593477949500084\n",
      "    cluster loss:             2949.3158365885415\n",
      "    separation loss:          2.7559142112731934\n",
      "    avg separation loss:      7.559003512064616\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  7.177067756652832\n",
      "    train time:               0.02429485321044922\n",
      "    test time:                0.01256418228149414\n",
      "    epoch time:               0.037383079528808594\n",
      "    last layer lr:            0.008415999999999998\n",
      "epoch: 140 (20/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.021178041584789753\n",
      "    train cross_ent loss:     0.012694336448071731\n",
      "    test overall loss:        0.16653424998124441\n",
      "    test cross_ent loss:      0.15781796226898828\n",
      "    cluster loss:             2949.3159993489585\n",
      "    separation loss:          2.7535202503204346\n",
      "    avg separation loss:      7.538856824239095\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  7.551630020141602\n",
      "    train time:               0.024521350860595703\n",
      "    test time:                0.012607812881469727\n",
      "    epoch time:               0.0376436710357666\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 140 (21/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.019003247635232076\n",
      "    train cross_ent loss:     0.010855647761167752\n",
      "    test overall loss:        0.16726126025120416\n",
      "    test cross_ent loss:      0.15944393227497736\n",
      "    cluster loss:             2949.316650390625\n",
      "    separation loss:          2.7566400369008384\n",
      "    avg separation loss:      7.554151852925618\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  6.652667045593262\n",
      "    train time:               0.024405956268310547\n",
      "    test time:                0.012713909149169922\n",
      "    epoch time:               0.03763985633850098\n",
      "    last layer lr:            0.007624000000000002\n",
      "epoch: 140 (22/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.017105714935395453\n",
      "    train cross_ent loss:     0.009605035910175906\n",
      "    test overall loss:        0.16772373765707016\n",
      "    test cross_ent loss:      0.16054528206586838\n",
      "    cluster loss:             2949.31689453125\n",
      "    separation loss:          2.7521544297536216\n",
      "    avg separation loss:      7.5472690264383955\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  6.013794898986816\n",
      "    train time:               0.024631977081298828\n",
      "    test time:                0.012790918350219727\n",
      "    epoch time:               0.03793525695800781\n",
      "    last layer lr:            0.0072280000000000035\n",
      "epoch: 140 (23/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.020012975256476138\n",
      "    train cross_ent loss:     0.012897860931439532\n",
      "    test overall loss:        0.16675560176372528\n",
      "    test cross_ent loss:      0.15976633379856744\n",
      "    cluster loss:             2949.31689453125\n",
      "    separation loss:          2.7587546507517495\n",
      "    avg separation loss:      7.562583923339844\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  5.8246049880981445\n",
      "    train time:               0.024626970291137695\n",
      "    test time:                0.012786149978637695\n",
      "    epoch time:               0.03792309761047363\n",
      "    last layer lr:            0.006831999999999998\n",
      "epoch: 140 (24/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.016288097947835922\n",
      "    train cross_ent loss:     0.009625516650784347\n",
      "    test overall loss:        0.16609365493059158\n",
      "    test cross_ent loss:      0.15950522323449454\n",
      "    cluster loss:             2949.3170572916665\n",
      "    separation loss:          2.7575600147247314\n",
      "    avg separation loss:      7.548688888549805\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  5.423775672912598\n",
      "    train time:               0.02464771270751953\n",
      "    test time:                0.0128326416015625\n",
      "    epoch time:               0.03799724578857422\n",
      "    last layer lr:            0.006436\n",
      "epoch: 140 (25/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.018197588726050325\n",
      "    train cross_ent loss:     0.011781659908592701\n",
      "    test overall loss:        0.16097715745369592\n",
      "    test cross_ent loss:      0.15453697741031647\n",
      "    cluster loss:             2949.3157552083335\n",
      "    separation loss:          2.7637800375620523\n",
      "    avg separation loss:      7.587429841359456\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  5.275522232055664\n",
      "    train time:               0.024753570556640625\n",
      "    test time:                0.012836217880249023\n",
      "    epoch time:               0.0381014347076416\n",
      "    last layer lr:            0.00604\n",
      "epoch: 140 (26/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.017914054294427235\n",
      "    train cross_ent loss:     0.011710128850407071\n",
      "    test overall loss:        0.16050598273674646\n",
      "    test cross_ent loss:      0.15428582082192102\n",
      "    cluster loss:             2949.31591796875\n",
      "    separation loss:          2.759037892023722\n",
      "    avg separation loss:      7.573872725168864\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  5.055499076843262\n",
      "    train time:               0.024737834930419922\n",
      "    test time:                0.012851715087890625\n",
      "    epoch time:               0.0381009578704834\n",
      "    last layer lr:            0.005644000000000002\n",
      "epoch: 140 (27/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.017789298047622044\n",
      "    train cross_ent loss:     0.011834493217368921\n",
      "    test overall loss:        0.1595189074675242\n",
      "    test cross_ent loss:      0.15365889171759287\n",
      "    cluster loss:             2949.3160807291665\n",
      "    separation loss:          2.759256680806478\n",
      "    avg separation loss:      7.554028352101644\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  4.695359230041504\n",
      "    train time:               0.02475285530090332\n",
      "    test time:                0.012878179550170898\n",
      "    epoch time:               0.03815817832946777\n",
      "    last layer lr:            0.005248000000000003\n",
      "epoch: 140 (28/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.01563322709666358\n",
      "    train cross_ent loss:     0.009961204577444328\n",
      "    test overall loss:        0.16162555168072382\n",
      "    test cross_ent loss:      0.15617341299851736\n",
      "    cluster loss:             2949.3164876302085\n",
      "    separation loss:          2.7590938409169516\n",
      "    avg separation loss:      7.573757330576579\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  4.287474632263184\n",
      "    train time:               0.025048494338989258\n",
      "    test time:                0.01288294792175293\n",
      "    epoch time:               0.03844571113586426\n",
      "    last layer lr:            0.004851999999999998\n",
      "epoch: 140 (29/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.015858995003832713\n",
      "    train cross_ent loss:     0.010331920244627528\n",
      "    test overall loss:        0.16019594420989355\n",
      "    test cross_ent loss:      0.15490969518820444\n",
      "    cluster loss:             2949.31640625\n",
      "    separation loss:          2.754518985748291\n",
      "    avg separation loss:      7.559283256530762\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  4.121592044830322\n",
      "    train time:               0.024815082550048828\n",
      "    test time:                0.012937784194946289\n",
      "    epoch time:               0.03826594352722168\n",
      "    last layer lr:            0.004455999999999999\n",
      "epoch: 140 (30/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.017765659942395158\n",
      "    train cross_ent loss:     0.012784966733306646\n",
      "    test overall loss:        0.15847297261158624\n",
      "    test cross_ent loss:      0.15372702727715173\n",
      "    cluster loss:             2949.3163248697915\n",
      "    separation loss:          2.7575014432271323\n",
      "    avg separation loss:      7.574171543121338\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  3.581282377243042\n",
      "    train time:               0.024834394454956055\n",
      "    test time:                0.01294398307800293\n",
      "    epoch time:               0.03829169273376465\n",
      "    last layer lr:            0.004060000000000001\n",
      "epoch: 140 (31/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.015594417798436351\n",
      "    train cross_ent loss:     0.011025722345544232\n",
      "    test overall loss:        0.15888304511706033\n",
      "    test cross_ent loss:      0.15438898652791977\n",
      "    cluster loss:             2949.3160807291665\n",
      "    separation loss:          2.7544428507486978\n",
      "    avg separation loss:      7.548167864481608\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  3.3294007778167725\n",
      "    train time:               0.02501511573791504\n",
      "    test time:                0.012947797775268555\n",
      "    epoch time:               0.03847360610961914\n",
      "    last layer lr:            0.0036640000000000015\n",
      "epoch: 140 (32/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.017348470994167857\n",
      "    train cross_ent loss:     0.0129625983018842\n",
      "    test overall loss:        0.1573429008324941\n",
      "    test cross_ent loss:      0.15302388618389764\n",
      "    cluster loss:             2949.3160807291665\n",
      "    separation loss:          2.757570425669352\n",
      "    avg separation loss:      7.558935801188151\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  3.15435791015625\n",
      "    train time:               0.02493000030517578\n",
      "    test time:                0.012914657592773438\n",
      "    epoch time:               0.03835725784301758\n",
      "    last layer lr:            0.003268000000000003\n",
      "epoch: 140 (33/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.012821460453172525\n",
      "    train cross_ent loss:     0.0088287353153444\n",
      "    test overall loss:        0.15720083067814508\n",
      "    test cross_ent loss:      0.15327176451683044\n",
      "    cluster loss:             2949.3160807291665\n",
      "    separation loss:          2.7531257470448813\n",
      "    avg separation loss:      7.543012777964274\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  2.7644107341766357\n",
      "    train time:               0.024998903274536133\n",
      "    test time:                0.012933731079101562\n",
      "    epoch time:               0.03844785690307617\n",
      "    last layer lr:            0.002871999999999997\n",
      "epoch: 140 (34/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.012590968257023228\n",
      "    train cross_ent loss:     0.008902594214305282\n",
      "    test overall loss:        0.15760716050863266\n",
      "    test cross_ent loss:      0.1541058619817098\n",
      "    cluster loss:             2949.3164876302085\n",
      "    separation loss:          2.7536720434824624\n",
      "    avg separation loss:      7.557148615519206\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  2.3366429805755615\n",
      "    train time:               0.024918079376220703\n",
      "    test time:                0.012954473495483398\n",
      "    epoch time:               0.03839254379272461\n",
      "    last layer lr:            0.0024759999999999986\n",
      "epoch: 140 (35/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.01067274058651593\n",
      "    train cross_ent loss:     0.007347855121932096\n",
      "    test overall loss:        0.1569683700799942\n",
      "    test cross_ent loss:      0.15377730131149292\n",
      "    cluster loss:             2949.3160807291665\n",
      "    separation loss:          2.7608054478963218\n",
      "    avg separation loss:      7.574411392211914\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  2.0264089107513428\n",
      "    train time:               0.025014162063598633\n",
      "    test time:                0.012933731079101562\n",
      "    epoch time:               0.03846120834350586\n",
      "    last layer lr:            0.0020800000000000003\n",
      "epoch: 140 (36/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.012386368898053965\n",
      "    train cross_ent loss:     0.009395485122998556\n",
      "    test overall loss:        0.15827618539333344\n",
      "    test cross_ent loss:      0.15542423476775488\n",
      "    cluster loss:             2949.3168131510415\n",
      "    separation loss:          2.7564213275909424\n",
      "    avg separation loss:      7.5608140627543134\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  1.687294840812683\n",
      "    train time:               0.025009632110595703\n",
      "    test time:                0.012946367263793945\n",
      "    epoch time:               0.03847312927246094\n",
      "    last layer lr:            0.0016840000000000017\n",
      "epoch: 140 (37/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.01370312873688009\n",
      "    train cross_ent loss:     0.01101683173328638\n",
      "    test overall loss:        0.15641592939694723\n",
      "    test cross_ent loss:      0.15380090971787772\n",
      "    cluster loss:             2949.3162434895835\n",
      "    separation loss:          2.764632304509481\n",
      "    avg separation loss:      7.61248795191447\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  1.4503623247146606\n",
      "    train time:               0.025067567825317383\n",
      "    test time:                0.012932300567626953\n",
      "    epoch time:               0.038510799407958984\n",
      "    last layer lr:            0.001288000000000003\n",
      "epoch: 140 (38/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.013479968791620599\n",
      "    train cross_ent loss:     0.011039782600063417\n",
      "    test overall loss:        0.15664741645256677\n",
      "    test cross_ent loss:      0.1543152928352356\n",
      "    cluster loss:             2949.3165690104165\n",
      "    separation loss:          2.7621798515319824\n",
      "    avg separation loss:      7.599660078684489\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  1.1674668788909912\n",
      "    train time:               0.025057554244995117\n",
      "    test time:                0.012926101684570312\n",
      "    epoch time:               0.03849339485168457\n",
      "    last layer lr:            0.0008919999999999973\n",
      "epoch: 140 (39/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.011164930183440447\n",
      "    train cross_ent loss:     0.009026236832141876\n",
      "    test overall loss:        0.15580325573682785\n",
      "    test cross_ent loss:      0.1537662371993065\n",
      "    cluster loss:             2949.31640625\n",
      "    separation loss:          2.759880304336548\n",
      "    avg separation loss:      7.580710252126058\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  0.8723616600036621\n",
      "    train time:               0.024888992309570312\n",
      "    test time:                0.012939453125\n",
      "    epoch time:               0.038344621658325195\n",
      "    last layer lr:            0.0004959999999999986\n",
      "epoch: 140 (40/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.010838962470491728\n",
      "    train cross_ent loss:     0.00902130296971235\n",
      "    test overall loss:        0.15408785889546076\n",
      "    test cross_ent loss:      0.15237720559040704\n",
      "    cluster loss:             2949.3164876302085\n",
      "    separation loss:          2.760377804438273\n",
      "    avg separation loss:      7.555664698282878\n",
      "    l1_addon loss:            38.822021484375\n",
      "    l1 loss:                  0.5459918975830078\n",
      "    train time:               0.025065898895263672\n",
      "    test time:                0.013005733489990234\n",
      "    epoch time:               0.03858757019042969\n",
      "    last layer lr:            0.0001\n",
      "epoch: 141 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.010233316260079542\n",
      "    train cross_ent loss:     0.00852269738809102\n",
      "    test overall loss:        0.1541780730088552\n",
      "    test cross_ent loss:      0.15246741970380148\n",
      "    cluster loss:             2949.3163248697915\n",
      "    separation loss:          2.7624109586079917\n",
      "    avg separation loss:      7.583298842112224\n",
      "    l1_addon loss:            38.821983337402344\n",
      "    l1 loss:                  0.5459918975830078\n",
      "    train time:               0.06285715103149414\n",
      "    test time:                0.01276397705078125\n",
      "    epoch time:               0.07635045051574707\n",
      "    joint lr:                 0.001298047112325102\n",
      "epoch: 142 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.011087363223648734\n",
      "    train cross_ent loss:     0.009375850902870297\n",
      "    test overall loss:        0.15064910302559534\n",
      "    test cross_ent loss:      0.1489361251393954\n",
      "    cluster loss:             2949.31201171875\n",
      "    separation loss:          2.732369899749756\n",
      "    avg separation loss:      7.484053770701091\n",
      "    l1_addon loss:            38.899574279785156\n",
      "    l1 loss:                  0.5459918975830078\n",
      "    train time:               0.06163907051086426\n",
      "    test time:                0.012801408767700195\n",
      "    epoch time:               0.07518506050109863\n",
      "    joint lr:                 0.002472133282403701\n",
      "epoch: 143 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.009515845268550847\n",
      "    train cross_ent loss:     0.007800421237738596\n",
      "    test overall loss:        0.13757183651129404\n",
      "    test cross_ent loss:      0.13585595538218817\n",
      "    cluster loss:             2949.3068033854165\n",
      "    separation loss:          2.7237000465393066\n",
      "    avg separation loss:      7.486491521199544\n",
      "    l1_addon loss:            38.996131896972656\n",
      "    l1 loss:                  0.5459918975830078\n",
      "    train time:               0.060945987701416016\n",
      "    test time:                0.012667179107666016\n",
      "    epoch time:               0.07431817054748535\n",
      "    joint lr:                 0.0036226179243694966\n",
      "epoch: 144 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.0057900350592616535\n",
      "    train cross_ent loss:     0.00407846371591505\n",
      "    test overall loss:        0.14854995161294937\n",
      "    test cross_ent loss:      0.14684154838323593\n",
      "    cluster loss:             2949.3062337239585\n",
      "    separation loss:          2.6397949854532876\n",
      "    avg separation loss:      7.333349704742432\n",
      "    l1_addon loss:            38.747032165527344\n",
      "    l1 loss:                  0.5459918975830078\n",
      "    train time:               0.060810089111328125\n",
      "    test time:                0.012707710266113281\n",
      "    epoch time:               0.07425117492675781\n",
      "    joint lr:                 0.004749855660167736\n",
      "epoch: 145 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.0044692793809291385\n",
      "    train cross_ent loss:     0.002760235013233291\n",
      "    test overall loss:        0.12625092267990112\n",
      "    test cross_ent loss:      0.12453980495532353\n",
      "    cluster loss:             2949.3046875\n",
      "    separation loss:          2.6344727675120034\n",
      "    avg separation loss:      7.308966159820557\n",
      "    l1_addon loss:            38.837528228759766\n",
      "    l1 loss:                  0.5459918975830078\n",
      "    train time:               0.061730384826660156\n",
      "    test time:                0.012731075286865234\n",
      "    epoch time:               0.07527017593383789\n",
      "    joint lr:                 0.005854196379457574\n",
      "epoch: 146 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.008330257531876365\n",
      "    train cross_ent loss:     0.006617403666799267\n",
      "    test overall loss:        0.11913787076870601\n",
      "    test cross_ent loss:      0.11742781102657318\n",
      "    cluster loss:             2949.3042805989585\n",
      "    separation loss:          2.6304057439168296\n",
      "    avg separation loss:      7.268379211425781\n",
      "    l1_addon loss:            38.80234146118164\n",
      "    l1 loss:                  0.5459918975830078\n",
      "    train time:               0.061132192611694336\n",
      "    test time:                0.012678146362304688\n",
      "    epoch time:               0.07454681396484375\n",
      "    joint lr:                 0.006935985298795627\n",
      "epoch: 147 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       0.013059586493505372\n",
      "    train cross_ent loss:     0.01135532805023508\n",
      "    test overall loss:        0.11547922467192014\n",
      "    test cross_ent loss:      0.11376098667581876\n",
      "    cluster loss:             2949.322998046875\n",
      "    separation loss:          2.7326348622639975\n",
      "    avg separation loss:      7.376425425211589\n",
      "    l1_addon loss:            39.0748405456543\n",
      "    l1 loss:                  0.5459918975830078\n",
      "    train time:               0.06124234199523926\n",
      "    test time:                0.01263880729675293\n",
      "    epoch time:               0.07465672492980957\n",
      "    joint lr:                 0.007995563020108943\n",
      "epoch: 148 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 94.33%\n",
      "    train overall loss:       0.015167043078690767\n",
      "    train cross_ent loss:     0.01345782020750145\n",
      "    test overall loss:        0.15649681352078915\n",
      "    test cross_ent loss:      0.15479470478991667\n",
      "    cluster loss:             2949.3575032552085\n",
      "    separation loss:          2.697468916575114\n",
      "    avg separation loss:      7.198290189107259\n",
      "    l1_addon loss:            38.537315368652344\n",
      "    l1 loss:                  0.5459918975830078\n",
      "    train time:               0.060849905014038086\n",
      "    test time:                0.012699604034423828\n",
      "    epoch time:               0.07428169250488281\n",
      "    joint lr:                 0.009033265588466115\n",
      "epoch: 149 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.01385209230809576\n",
      "    train cross_ent loss:     0.012145421040865282\n",
      "    test overall loss:        0.1432438182334105\n",
      "    test cross_ent loss:      0.1415448496118188\n",
      "    cluster loss:             2949.3702799479165\n",
      "    separation loss:          2.7872560024261475\n",
      "    avg separation loss:      7.619449933369954\n",
      "    l1_addon loss:            38.432373046875\n",
      "    l1 loss:                  0.5459918975830078\n",
      "    train time:               0.06151628494262695\n",
      "    test time:                0.013001441955566406\n",
      "    epoch time:               0.07525801658630371\n",
      "    joint lr:                 0.010049424549154131\n",
      "epoch: 150 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 93.00%\n",
      "    train overall loss:       0.046917238583167396\n",
      "    train cross_ent loss:     0.0452061629233261\n",
      "    test overall loss:        0.21447535417973995\n",
      "    test cross_ent loss:      0.21276097558438778\n",
      "    cluster loss:             2949.4630533854165\n",
      "    separation loss:          3.0672181447347007\n",
      "    avg separation loss:      7.953469117482503\n",
      "    l1_addon loss:            38.94622039794922\n",
      "    l1 loss:                  0.5459918975830078\n",
      "    train time:               0.061246395111083984\n",
      "    test time:                0.01268911361694336\n",
      "    epoch time:               0.0746450424194336\n",
      "    joint lr:                 0.011044367004069541\n",
      "epoch: 151 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.06864270547197925\n",
      "    train cross_ent loss:     0.06692599712146653\n",
      "    test overall loss:        0.15357408920923868\n",
      "    test cross_ent loss:      0.1518572506805261\n",
      "    cluster loss:             2949.545166015625\n",
      "    separation loss:          3.4073264598846436\n",
      "    avg separation loss:      8.390530904134115\n",
      "    l1_addon loss:            39.028289794921875\n",
      "    l1 loss:                  0.5459918975830078\n",
      "    train time:               0.061411380767822266\n",
      "    test time:                0.01302957534790039\n",
      "    epoch time:               0.07535958290100098\n",
      "    joint lr:                 0.010393177167327405\n",
      "epoch: 152 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.04809665152182182\n",
      "    train cross_ent loss:     0.04637755163841777\n",
      "    test overall loss:        0.2345407654841741\n",
      "    test cross_ent loss:      0.2328298936287562\n",
      "    cluster loss:             2949.5940755208335\n",
      "    separation loss:          3.460907777150472\n",
      "    avg separation loss:      8.223802407582602\n",
      "    l1_addon loss:            38.82954406738281\n",
      "    l1 loss:                  0.5459918975830078\n",
      "    train time:               0.062103271484375\n",
      "    test time:                0.012361288070678711\n",
      "    epoch time:               0.07522869110107422\n",
      "    joint lr:                 0.009753916690619703\n",
      "epoch: 153 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.04462253716256884\n",
      "    train cross_ent loss:     0.04291063754094972\n",
      "    test overall loss:        0.15539911513527235\n",
      "    test cross_ent loss:      0.15368730947375298\n",
      "    cluster loss:             2949.59033203125\n",
      "    separation loss:          3.565061330795288\n",
      "    avg separation loss:      8.453872998555502\n",
      "    l1_addon loss:            38.86073303222656\n",
      "    l1 loss:                  0.5459918975830078\n",
      "    train time:               0.06042003631591797\n",
      "    test time:                0.012143135070800781\n",
      "    epoch time:               0.07326436042785645\n",
      "    joint lr:                 0.009126412105729424\n",
      "epoch: 154 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 94.67%\n",
      "    train overall loss:       0.04266753596150213\n",
      "    train cross_ent loss:     0.040955834090709686\n",
      "    test overall loss:        0.3256056805451711\n",
      "    test cross_ent loss:      0.3238903780778249\n",
      "    cluster loss:             2949.6569010416665\n",
      "    separation loss:          3.696929852167765\n",
      "    avg separation loss:      8.801783243815104\n",
      "    l1_addon loss:            38.976959228515625\n",
      "    l1 loss:                  0.5459918975830078\n",
      "    train time:               0.06081557273864746\n",
      "    test time:                0.012213706970214844\n",
      "    epoch time:               0.07375597953796387\n",
      "    joint lr:                 0.008510492220867888\n",
      "epoch: 155 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.08477411046624184\n",
      "    train cross_ent loss:     0.0830653967956702\n",
      "    test overall loss:        0.24553118149439493\n",
      "    test cross_ent loss:      0.2438003122806549\n",
      "    cluster loss:             2949.6751302083335\n",
      "    separation loss:          3.970905860265096\n",
      "    avg separation loss:      8.94268767038981\n",
      "    l1_addon loss:            39.49586868286133\n",
      "    l1 loss:                  0.5459918975830078\n",
      "    train time:               0.05952000617980957\n",
      "    test time:                0.012903690338134766\n",
      "    epoch time:               0.07323670387268066\n",
      "    joint lr:                 0.00790598809249301\n",
      "epoch: 156 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 88.67%\n",
      "    train overall loss:       0.26045656411184204\n",
      "    train cross_ent loss:     0.25874385237693787\n",
      "    test overall loss:        0.356771523753802\n",
      "    test cross_ent loss:      0.3550940006971359\n",
      "    cluster loss:             2949.721435546875\n",
      "    separation loss:          3.949085553487142\n",
      "    avg separation loss:      9.513137499491373\n",
      "    l1_addon loss:            37.71828079223633\n",
      "    l1 loss:                  0.5459918975830078\n",
      "    train time:               0.05898404121398926\n",
      "    test time:                0.01270604133605957\n",
      "    epoch time:               0.07247471809387207\n",
      "    joint lr:                 0.007312732997463544\n",
      "epoch: 157 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 91.67%\n",
      "    train overall loss:       0.36942889127466416\n",
      "    train cross_ent loss:     0.3677256107330322\n",
      "    test overall loss:        0.3606121639410655\n",
      "    test cross_ent loss:      0.3589307169119517\n",
      "    cluster loss:             2949.7626953125\n",
      "    separation loss:          4.351150592168172\n",
      "    avg separation loss:      10.602886199951172\n",
      "    l1_addon loss:            37.84878921508789\n",
      "    l1 loss:                  0.5459918975830078\n",
      "    train time:               0.058875083923339844\n",
      "    test time:                0.012620925903320312\n",
      "    epoch time:               0.07228755950927734\n",
      "    joint lr:                 0.006730562405525418\n",
      "epoch: 158 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 93.67%\n",
      "    train overall loss:       0.23104507641659844\n",
      "    train cross_ent loss:     0.2293411683705118\n",
      "    test overall loss:        0.3236002301176389\n",
      "    test cross_ent loss:      0.3219279870390892\n",
      "    cluster loss:             2949.7682291666665\n",
      "    separation loss:          4.636545181274414\n",
      "    avg separation loss:      11.104900042215982\n",
      "    l1_addon loss:            37.541954040527344\n",
      "    l1 loss:                  0.5459918975830078\n",
      "    train time:               0.05909156799316406\n",
      "    test time:                0.012661933898925781\n",
      "    epoch time:               0.07255220413208008\n",
      "    joint lr:                 0.006159313952126306\n",
      "epoch: 159 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 91.33%\n",
      "    train overall loss:       0.17752716607517666\n",
      "    train cross_ent loss:     0.17582768698533377\n",
      "    test overall loss:        0.31663380066553753\n",
      "    test cross_ent loss:      0.3149489810069402\n",
      "    cluster loss:             2949.6997884114585\n",
      "    separation loss:          4.291963656743367\n",
      "    avg separation loss:      10.448887825012207\n",
      "    l1_addon loss:            37.9610595703125\n",
      "    l1 loss:                  0.5459918975830078\n",
      "    train time:               0.05880141258239746\n",
      "    test time:                0.012638568878173828\n",
      "    epoch time:               0.07227396965026855\n",
      "    joint lr:                 0.005598827411554625\n",
      "epoch: 160 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 92.67%\n",
      "    train overall loss:       0.13847462005085415\n",
      "    train cross_ent loss:     0.13676364802651936\n",
      "    test overall loss:        0.2775353416800499\n",
      "    test cross_ent loss:      0.2758435805638631\n",
      "    cluster loss:             2949.69140625\n",
      "    separation loss:          4.287784020105998\n",
      "    avg separation loss:      10.383475621541342\n",
      "    l1_addon loss:            38.19236755371094\n",
      "    l1 loss:                  0.5459918975830078\n",
      "    train time:               0.05911707878112793\n",
      "    test time:                0.012652158737182617\n",
      "    epoch time:               0.07258129119873047\n",
      "    joint lr:                 0.005048944670399165\n",
      "epoch: 161 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.07732147930396928\n",
      "    train cross_ent loss:     0.07560991889072789\n",
      "    test overall loss:        0.16199669366081557\n",
      "    test cross_ent loss:      0.16029013693332672\n",
      "    cluster loss:             2949.57861328125\n",
      "    separation loss:          4.044137557347615\n",
      "    avg separation loss:      10.081695556640625\n",
      "    l1_addon loss:            38.68551254272461\n",
      "    l1 loss:                  0.5459918975830078\n",
      "    train time:               0.05878472328186035\n",
      "    test time:                0.012683629989624023\n",
      "    epoch time:               0.07224369049072266\n",
      "    joint lr:                 0.004509509701325646\n",
      "epoch: 162 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.029466543139682874\n",
      "    train cross_ent loss:     0.02776158828702238\n",
      "    test overall loss:        0.13686668251951536\n",
      "    test cross_ent loss:      0.13515102242430052\n",
      "    cluster loss:             2949.5464680989585\n",
      "    separation loss:          3.917605002721151\n",
      "    avg separation loss:      9.61941401163737\n",
      "    l1_addon loss:            38.98884582519531\n",
      "    l1 loss:                  0.5459918975830078\n",
      "    train time:               0.058913469314575195\n",
      "    test time:                0.012746810913085938\n",
      "    epoch time:               0.07245016098022461\n",
      "    joint lr:                 0.00398036853716657\n",
      "epoch: 163 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.013022593636479642\n",
      "    train cross_ent loss:     0.011304548993292782\n",
      "    test overall loss:        0.14748283723990122\n",
      "    test cross_ent loss:      0.14576911181211472\n",
      "    cluster loss:             2949.5340169270835\n",
      "    separation loss:          3.819084803263346\n",
      "    avg separation loss:      9.329477945963541\n",
      "    l1_addon loss:            38.92451858520508\n",
      "    l1 loss:                  0.5459918975830078\n",
      "    train time:               0.058915138244628906\n",
      "    test time:                0.012659788131713867\n",
      "    epoch time:               0.07234787940979004\n",
      "    joint lr:                 0.0034613692453205423\n",
      "epoch: 164 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.010805382755481534\n",
      "    train cross_ent loss:     0.009093969749907652\n",
      "    test overall loss:        0.13537672037879625\n",
      "    test cross_ent loss:      0.13366675128539404\n",
      "    cluster loss:             2949.5172526041665\n",
      "    separation loss:          3.7287325064341226\n",
      "    avg separation loss:      9.241053899129232\n",
      "    l1_addon loss:            38.799285888671875\n",
      "    l1 loss:                  0.5459918975830078\n",
      "    train time:               0.05898785591125488\n",
      "    test time:                0.012672662734985352\n",
      "    epoch time:               0.07244682312011719\n",
      "    joint lr:                 0.002952361902457719\n",
      "epoch: 165 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.005585929352997078\n",
      "    train cross_ent loss:     0.003873749442088107\n",
      "    test overall loss:        0.11673528452714284\n",
      "    test cross_ent loss:      0.11502087861299515\n",
      "    cluster loss:             2949.502197265625\n",
      "    separation loss:          3.695538600285848\n",
      "    avg separation loss:      9.172517776489258\n",
      "    l1_addon loss:            38.946937561035156\n",
      "    l1 loss:                  0.5459918975830078\n",
      "    train time:               0.05887603759765625\n",
      "    test time:                0.012667655944824219\n",
      "    epoch time:               0.07232975959777832\n",
      "    joint lr:                 0.0024531985695276076\n",
      "epoch: 166 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.009103291667997837\n",
      "    train cross_ent loss:     0.007389270144307779\n",
      "    test overall loss:        0.1157844066619873\n",
      "    test cross_ent loss:      0.11407253021995227\n",
      "    cluster loss:             2949.4993489583335\n",
      "    separation loss:          3.639173905054728\n",
      "    avg separation loss:      9.018388430277506\n",
      "    l1_addon loss:            38.862850189208984\n",
      "    l1 loss:                  0.5459918975830078\n",
      "    train time:               0.05837225914001465\n",
      "    test time:                0.012685775756835938\n",
      "    epoch time:               0.07220077514648438\n",
      "    joint lr:                 0.001963733267065865\n",
      "epoch: 167 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.004300800126252903\n",
      "    train cross_ent loss:     0.0025899448664858937\n",
      "    test overall loss:        0.11522396529714267\n",
      "    test cross_ent loss:      0.11351392418146133\n",
      "    cluster loss:             2949.4966634114585\n",
      "    separation loss:          3.619665543238322\n",
      "    avg separation loss:      8.998303095499674\n",
      "    l1_addon loss:            38.80156707763672\n",
      "    l1 loss:                  0.5459918975830078\n",
      "    train time:               0.05814790725708008\n",
      "    test time:                0.012677431106567383\n",
      "    epoch time:               0.07190084457397461\n",
      "    joint lr:                 0.001483821950796405\n",
      "epoch: 168 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.005750165993554724\n",
      "    train cross_ent loss:     0.0040403261470297975\n",
      "    test overall loss:        0.11316708847880363\n",
      "    test cross_ent loss:      0.11145723735292752\n",
      "    cluster loss:             2949.4943033854165\n",
      "    separation loss:          3.6093575159708657\n",
      "    avg separation loss:      8.965978304545084\n",
      "    l1_addon loss:            38.79538345336914\n",
      "    l1 loss:                  0.5459918975830078\n",
      "    train time:               0.05840325355529785\n",
      "    test time:                0.012652397155761719\n",
      "    epoch time:               0.07185769081115723\n",
      "    joint lr:                 0.0010133224875256274\n",
      "epoch: 169 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.004180153417918418\n",
      "    train cross_ent loss:     0.002470276331425541\n",
      "    test overall loss:        0.11339117959141731\n",
      "    test cross_ent loss:      0.11168107762932777\n",
      "    cluster loss:             2949.4934895833335\n",
      "    separation loss:          3.594034751256307\n",
      "    avg separation loss:      8.922659238179525\n",
      "    l1_addon loss:            38.80363082885742\n",
      "    l1 loss:                  0.5459918975830078\n",
      "    train time:               0.058824777603149414\n",
      "    test time:                0.012693643569946289\n",
      "    epoch time:               0.07231283187866211\n",
      "    joint lr:                 0.0005520946313251855\n",
      "epoch: 170 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.0077475163206044174\n",
      "    train cross_ent loss:     0.00603724412050926\n",
      "    test overall loss:        0.11167942484219869\n",
      "    test cross_ent loss:      0.10996907204389572\n",
      "    cluster loss:             2949.4916178385415\n",
      "    separation loss:          3.6023596127827964\n",
      "    avg separation loss:      8.967155774434408\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  0.5459918975830078\n",
      "    train time:               0.0591888427734375\n",
      "    test time:                0.01262521743774414\n",
      "    epoch time:               0.07260751724243164\n",
      "    joint lr:                 0.0001\n",
      "epoch: 170 (PUSH) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.0077475163206044174\n",
      "    train cross_ent loss:     0.00603724412050926\n",
      "    test overall loss:        0.12881850451231003\n",
      "    test cross_ent loss:      0.12710815171400705\n",
      "    cluster loss:             2949.335693359375\n",
      "    separation loss:          3.047342618306478\n",
      "    avg separation loss:      8.189860661824545\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  0.5459918975830078\n",
      "    train time:               0.0591888427734375\n",
      "    test time:                0.012868404388427734\n",
      "    epoch time:               0.36772727966308594\n",
      "epoch: 170 (1/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.010573409290777313\n",
      "    train cross_ent loss:     0.009058221553762754\n",
      "    test overall loss:        0.13316036884983382\n",
      "    test cross_ent loss:      0.13176693270603815\n",
      "    cluster loss:             2949.3370768229165\n",
      "    separation loss:          3.038442770640055\n",
      "    avg separation loss:      8.170199553171793\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  0.22907763719558716\n",
      "    train time:               0.024387598037719727\n",
      "    test time:                0.012679815292358398\n",
      "    epoch time:               0.03757882118225098\n",
      "    last layer lr:            0.0007599999999999978\n",
      "epoch: 170 (2/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.011459114340444406\n",
      "    train cross_ent loss:     0.009519753874176078\n",
      "    test overall loss:        0.13286283736427626\n",
      "    test cross_ent loss:      0.1309645933409532\n",
      "    cluster loss:             2949.3369954427085\n",
      "    separation loss:          3.0405353705088296\n",
      "    avg separation loss:      8.166870276133219\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  0.7338884472846985\n",
      "    train time:               0.02383708953857422\n",
      "    test time:                0.012609243392944336\n",
      "    epoch time:               0.0369572639465332\n",
      "    last layer lr:            0.0014199999999999955\n",
      "epoch: 170 (3/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.01573649374768138\n",
      "    train cross_ent loss:     0.013517717520395914\n",
      "    test overall loss:        0.1312198614080747\n",
      "    test cross_ent loss:      0.12895999973018965\n",
      "    cluster loss:             2949.3375651041665\n",
      "    separation loss:          3.049447456995646\n",
      "    avg separation loss:      8.186860084533691\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  1.095499038696289\n",
      "    train time:               0.023777484893798828\n",
      "    test time:                0.012606620788574219\n",
      "    epoch time:               0.03689694404602051\n",
      "    last layer lr:            0.0020800000000000046\n",
      "epoch: 170 (4/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.014259797055274248\n",
      "    train cross_ent loss:     0.011652354823632373\n",
      "    test overall loss:        0.1317160800099373\n",
      "    test cross_ent loss:      0.129001314441363\n",
      "    cluster loss:             2949.3370768229165\n",
      "    separation loss:          3.0469695727030435\n",
      "    avg separation loss:      8.1992875734965\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  1.5504049062728882\n",
      "    train time:               0.0238955020904541\n",
      "    test time:                0.012579917907714844\n",
      "    epoch time:               0.03699040412902832\n",
      "    last layer lr:            0.0027400000000000024\n",
      "epoch: 170 (5/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.01417895033955574\n",
      "    train cross_ent loss:     0.011173151071286865\n",
      "    test overall loss:        0.13117229441801706\n",
      "    test cross_ent loss:      0.1279746244351069\n",
      "    cluster loss:             2949.3369140625\n",
      "    separation loss:          3.0429155031840005\n",
      "    avg separation loss:      8.159973621368408\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  2.0333149433135986\n",
      "    train time:               0.023739337921142578\n",
      "    test time:                0.012582778930664062\n",
      "    epoch time:               0.03684067726135254\n",
      "    last layer lr:            0.0034\n",
      "epoch: 170 (6/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.014324594651245408\n",
      "    train cross_ent loss:     0.010804542236857943\n",
      "    test overall loss:        0.130057655274868\n",
      "    test cross_ent loss:      0.12640919784704843\n",
      "    cluster loss:             2949.3367513020835\n",
      "    separation loss:          3.0507123470306396\n",
      "    avg separation loss:      8.205992221832275\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  2.484097480773926\n",
      "    train time:               0.02378058433532715\n",
      "    test time:                0.012603759765625\n",
      "    epoch time:               0.03688836097717285\n",
      "    last layer lr:            0.004059999999999998\n",
      "epoch: 170 (7/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.014209326149688827\n",
      "    train cross_ent loss:     0.01022142081314491\n",
      "    test overall loss:        0.1312833527723948\n",
      "    test cross_ent loss:      0.12709733471274376\n",
      "    cluster loss:             2949.33642578125\n",
      "    separation loss:          3.0458887418111167\n",
      "    avg separation loss:      8.18849484125773\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  3.0216612815856934\n",
      "    train time:               0.022791385650634766\n",
      "    test time:                0.012049198150634766\n",
      "    epoch time:               0.03533053398132324\n",
      "    last layer lr:            0.004719999999999996\n",
      "epoch: 170 (8/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.015050832699570391\n",
      "    train cross_ent loss:     0.010658448768986596\n",
      "    test overall loss:        0.1296761358777682\n",
      "    test cross_ent loss:      0.12513006975253424\n",
      "    cluster loss:             2949.3372395833335\n",
      "    separation loss:          3.0502305825551352\n",
      "    avg separation loss:      8.169530232747396\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  3.381706714630127\n",
      "    train time:               0.02252817153930664\n",
      "    test time:                0.012040138244628906\n",
      "    epoch time:               0.035048723220825195\n",
      "    last layer lr:            0.0053800000000000054\n",
      "epoch: 170 (9/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.015952954896622233\n",
      "    train cross_ent loss:     0.010901814404254159\n",
      "    test overall loss:        0.12966655443112055\n",
      "    test cross_ent loss:      0.12427384033799171\n",
      "    cluster loss:             2949.3373209635415\n",
      "    separation loss:          3.0570665995279946\n",
      "    avg separation loss:      8.195948600769043\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  4.228357791900635\n",
      "    train time:               0.022528886795043945\n",
      "    test time:                0.01204538345336914\n",
      "    epoch time:               0.03504204750061035\n",
      "    last layer lr:            0.006040000000000003\n",
      "epoch: 170 (10/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.014260672446754243\n",
      "    train cross_ent loss:     0.008709315702112185\n",
      "    test overall loss:        0.13040351495146751\n",
      "    test cross_ent loss:      0.12482733776172002\n",
      "    cluster loss:             2949.3369140625\n",
      "    separation loss:          3.052332083384196\n",
      "    avg separation loss:      8.208632469177246\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  4.4118194580078125\n",
      "    train time:               0.022687673568725586\n",
      "    test time:                0.012031793594360352\n",
      "    epoch time:               0.035201072692871094\n",
      "    last layer lr:            0.0067\n",
      "epoch: 170 (11/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.01464912026292748\n",
      "    train cross_ent loss:     0.008834960999795131\n",
      "    test overall loss:        0.1316245123744011\n",
      "    test cross_ent loss:      0.1256500892341137\n",
      "    cluster loss:             2949.337890625\n",
      "    separation loss:          3.0428288777669272\n",
      "    avg separation loss:      8.163278102874756\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  4.810061931610107\n",
      "    train time:               0.022551774978637695\n",
      "    test time:                0.01204538345336914\n",
      "    epoch time:               0.035077810287475586\n",
      "    last layer lr:            0.0073599999999999985\n",
      "epoch: 170 (12/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.01444546826597717\n",
      "    train cross_ent loss:     0.008203559399892887\n",
      "    test overall loss:        0.13014129300912222\n",
      "    test cross_ent loss:      0.12366741274793942\n",
      "    cluster loss:             2949.3365885416665\n",
      "    separation loss:          3.045321067174276\n",
      "    avg separation loss:      8.178353468577066\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  5.3095197677612305\n",
      "    train time:               0.022553205490112305\n",
      "    test time:                0.012064218521118164\n",
      "    epoch time:               0.03508901596069336\n",
      "    last layer lr:            0.008019999999999994\n",
      "epoch: 170 (13/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.014619264544712173\n",
      "    train cross_ent loss:     0.007907518599596288\n",
      "    test overall loss:        0.12880480165282884\n",
      "    test cross_ent loss:      0.1219649463891983\n",
      "    cluster loss:             2949.3372395833335\n",
      "    separation loss:          3.053208510080973\n",
      "    avg separation loss:      8.194858392079672\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  5.675497055053711\n",
      "    train time:               0.02257513999938965\n",
      "    test time:                0.012109041213989258\n",
      "    epoch time:               0.035152435302734375\n",
      "    last layer lr:            0.008680000000000005\n",
      "epoch: 170 (14/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.016920557763013575\n",
      "    train cross_ent loss:     0.009319345647883084\n",
      "    test overall loss:        0.13020535558462143\n",
      "    test cross_ent loss:      0.12224421774347623\n",
      "    cluster loss:             2949.3370768229165\n",
      "    separation loss:          3.049762487411499\n",
      "    avg separation loss:      8.170638720194498\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  6.796781539916992\n",
      "    train time:               0.0225830078125\n",
      "    test time:                0.01203298568725586\n",
      "    epoch time:               0.03508305549621582\n",
      "    last layer lr:            0.009340000000000003\n",
      "epoch: 170 (15/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.01574555215322309\n",
      "    train cross_ent loss:     0.007615797532101472\n",
      "    test overall loss:        0.13236189633607864\n",
      "    test cross_ent loss:      0.12426873669028282\n",
      "    cluster loss:             2949.3377278645835\n",
      "    separation loss:          3.042423963546753\n",
      "    avg separation loss:      8.163111845652262\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  6.928798675537109\n",
      "    train time:               0.022539615631103516\n",
      "    test time:                0.01204061508178711\n",
      "    epoch time:               0.0350489616394043\n",
      "    last layer lr:            0.01\n",
      "epoch: 170 (16/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.01724468989090787\n",
      "    train cross_ent loss:     0.008789758999935456\n",
      "    test overall loss:        0.13084824879964194\n",
      "    test cross_ent loss:      0.1222457488377889\n",
      "    cluster loss:             2949.3369140625\n",
      "    separation loss:          3.037062088648478\n",
      "    avg separation loss:      8.14083989461263\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  7.438144207000732\n",
      "    train time:               0.022688865661621094\n",
      "    test time:                0.012029886245727539\n",
      "    epoch time:               0.03520774841308594\n",
      "    last layer lr:            0.009604000000000001\n",
      "epoch: 170 (17/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.016386467239095107\n",
      "    train cross_ent loss:     0.007975966152217653\n",
      "    test overall loss:        0.12906835600733757\n",
      "    test cross_ent loss:      0.12076528246204059\n",
      "    cluster loss:             2949.3365885416665\n",
      "    separation loss:          3.03753662109375\n",
      "    avg separation loss:      8.143999099731445\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  7.138713836669922\n",
      "    train time:               0.022566795349121094\n",
      "    test time:                0.012033939361572266\n",
      "    epoch time:               0.03506922721862793\n",
      "    last layer lr:            0.009208000000000003\n",
      "epoch: 170 (18/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.016254351267384157\n",
      "    train cross_ent loss:     0.008093369167505039\n",
      "    test overall loss:        0.12746361767252287\n",
      "    test cross_ent loss:      0.11937201892336209\n",
      "    cluster loss:             2949.3361002604165\n",
      "    separation loss:          3.043860117594401\n",
      "    avg separation loss:      8.186602910359701\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  6.927244186401367\n",
      "    train time:               0.022598981857299805\n",
      "    test time:                0.012040138244628906\n",
      "    epoch time:               0.03510737419128418\n",
      "    last layer lr:            0.008811999999999997\n",
      "epoch: 170 (19/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.01709889806807041\n",
      "    train cross_ent loss:     0.009255863363958068\n",
      "    test overall loss:        0.12672810877362886\n",
      "    test cross_ent loss:      0.11891383553544681\n",
      "    cluster loss:             2949.3369140625\n",
      "    separation loss:          3.050078868865967\n",
      "    avg separation loss:      8.210497856140137\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  6.6499176025390625\n",
      "    train time:               0.022545576095581055\n",
      "    test time:                0.012040138244628906\n",
      "    epoch time:               0.03505396842956543\n",
      "    last layer lr:            0.008415999999999998\n",
      "epoch: 170 (20/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.01418987661600113\n",
      "    train cross_ent loss:     0.006468973950379425\n",
      "    test overall loss:        0.12425420929988225\n",
      "    test cross_ent loss:      0.11660698801279068\n",
      "    cluster loss:             2949.3369140625\n",
      "    separation loss:          3.0522801081339517\n",
      "    avg separation loss:      8.20150089263916\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  6.482861518859863\n",
      "    train time:               0.02324986457824707\n",
      "    test time:                0.012403249740600586\n",
      "    epoch time:               0.03612232208251953\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 170 (21/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.013717465620074008\n",
      "    train cross_ent loss:     0.0063856575870886445\n",
      "    test overall loss:        0.12249948332707088\n",
      "    test cross_ent loss:      0.115291777998209\n",
      "    cluster loss:             2949.3361002604165\n",
      "    separation loss:          3.048558155695597\n",
      "    avg separation loss:      8.189740180969238\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  6.043349266052246\n",
      "    train time:               0.0232546329498291\n",
      "    test time:                0.012384653091430664\n",
      "    epoch time:               0.03610801696777344\n",
      "    last layer lr:            0.007624000000000002\n",
      "epoch: 170 (22/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.014051931134114662\n",
      "    train cross_ent loss:     0.007055794613228904\n",
      "    test overall loss:        0.12165794521570206\n",
      "    test cross_ent loss:      0.11480076238512993\n",
      "    cluster loss:             2949.33544921875\n",
      "    separation loss:          3.0435867309570312\n",
      "    avg separation loss:      8.159984588623047\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  5.692821502685547\n",
      "    train time:               0.023433446884155273\n",
      "    test time:                0.012387752532958984\n",
      "    epoch time:               0.03630518913269043\n",
      "    last layer lr:            0.0072280000000000035\n",
      "epoch: 170 (23/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.014107511585785283\n",
      "    train cross_ent loss:     0.007433911837223504\n",
      "    test overall loss:        0.12059562156597774\n",
      "    test cross_ent loss:      0.11398817971348763\n",
      "    cluster loss:             2949.336181640625\n",
      "    separation loss:          3.0523237387339273\n",
      "    avg separation loss:      8.187646547953287\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  5.443086624145508\n",
      "    train time:               0.023285627365112305\n",
      "    test time:                0.01239633560180664\n",
      "    epoch time:               0.036164045333862305\n",
      "    last layer lr:            0.006831999999999998\n",
      "epoch: 170 (24/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.012585207509497801\n",
      "    train cross_ent loss:     0.00612520263530314\n",
      "    test overall loss:        0.1214163489639759\n",
      "    test cross_ent loss:      0.11487776786088943\n",
      "    cluster loss:             2949.3360188802085\n",
      "    separation loss:          3.0413529872894287\n",
      "    avg separation loss:      8.159502983093262\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  5.374217987060547\n",
      "    train time:               0.02330613136291504\n",
      "    test time:                0.012449026107788086\n",
      "    epoch time:               0.036221981048583984\n",
      "    last layer lr:            0.006436\n",
      "epoch: 170 (25/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.01201888442867332\n",
      "    train cross_ent loss:     0.005855210384147035\n",
      "    test overall loss:        0.12256335963805516\n",
      "    test cross_ent loss:      0.1165442168712616\n",
      "    cluster loss:             2949.336669921875\n",
      "    separation loss:          3.0376277764638266\n",
      "    avg separation loss:      8.154568195343018\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  4.854781150817871\n",
      "    train time:               0.023407697677612305\n",
      "    test time:                0.012428760528564453\n",
      "    epoch time:               0.03632855415344238\n",
      "    last layer lr:            0.00604\n",
      "epoch: 170 (26/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.01171800804634889\n",
      "    train cross_ent loss:     0.005924658617004752\n",
      "    test overall loss:        0.12111619611581166\n",
      "    test cross_ent loss:      0.11540261531869571\n",
      "    cluster loss:             2949.3375651041665\n",
      "    separation loss:          3.051321109135946\n",
      "    avg separation loss:      8.184878985087076\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  4.549222469329834\n",
      "    train time:               0.023284435272216797\n",
      "    test time:                0.012408256530761719\n",
      "    epoch time:               0.03617715835571289\n",
      "    last layer lr:            0.005644000000000002\n",
      "epoch: 170 (27/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.012291052947855659\n",
      "    train cross_ent loss:     0.006784451944339607\n",
      "    test overall loss:        0.12065713852643967\n",
      "    test cross_ent loss:      0.11518688127398491\n",
      "    cluster loss:             2949.337158203125\n",
      "    separation loss:          3.046600341796875\n",
      "    avg separation loss:      8.18405278523763\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  4.305896759033203\n",
      "    train time:               0.023217439651489258\n",
      "    test time:                0.012365341186523438\n",
      "    epoch time:               0.036051034927368164\n",
      "    last layer lr:            0.005248000000000003\n",
      "epoch: 170 (28/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.012675565874411\n",
      "    train cross_ent loss:     0.007354670307702488\n",
      "    test overall loss:        0.12142981092135112\n",
      "    test cross_ent loss:      0.11604800696174304\n",
      "    cluster loss:             2949.3370768229165\n",
      "    separation loss:          3.0450092951456704\n",
      "    avg separation loss:      8.185280958811441\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  4.217442512512207\n",
      "    train time:               0.023835420608520508\n",
      "    test time:                0.012520074844360352\n",
      "    epoch time:               0.0368499755859375\n",
      "    last layer lr:            0.004851999999999998\n",
      "epoch: 170 (29/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.012156445998698473\n",
      "    train cross_ent loss:     0.007102120628890892\n",
      "    test overall loss:        0.11828506365418434\n",
      "    test cross_ent loss:      0.11342815061410268\n",
      "    cluster loss:             2949.3359375\n",
      "    separation loss:          3.0453151861826577\n",
      "    avg separation loss:      8.186220010121664\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  3.6925551891326904\n",
      "    train time:               0.023425817489624023\n",
      "    test time:                0.012394428253173828\n",
      "    epoch time:               0.03630638122558594\n",
      "    last layer lr:            0.004455999999999999\n",
      "epoch: 170 (30/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.011442958170341121\n",
      "    train cross_ent loss:     0.00673849914326436\n",
      "    test overall loss:        0.12028520305951436\n",
      "    test cross_ent loss:      0.11565295855204265\n",
      "    cluster loss:             2949.337646484375\n",
      "    separation loss:          3.045130411783854\n",
      "    avg separation loss:      8.18162473042806\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  3.4678807258605957\n",
      "    train time:               0.02344346046447754\n",
      "    test time:                0.012377023696899414\n",
      "    epoch time:               0.03630423545837402\n",
      "    last layer lr:            0.004060000000000001\n",
      "epoch: 170 (31/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.010532250938316187\n",
      "    train cross_ent loss:     0.006089484060390128\n",
      "    test overall loss:        0.11921952292323112\n",
      "    test cross_ent loss:      0.11493513112266858\n",
      "    cluster loss:             2949.337890625\n",
      "    separation loss:          3.051063855489095\n",
      "    avg separation loss:      8.188525358835856\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  3.120028018951416\n",
      "    train time:               0.023595809936523438\n",
      "    test time:                0.012402534484863281\n",
      "    epoch time:               0.036467552185058594\n",
      "    last layer lr:            0.0036640000000000015\n",
      "epoch: 170 (32/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.009986042355497679\n",
      "    train cross_ent loss:     0.005916350055485964\n",
      "    test overall loss:        0.11820860082904498\n",
      "    test cross_ent loss:      0.11420762414733569\n",
      "    cluster loss:             2949.3365071614585\n",
      "    separation loss:          3.0443569819132485\n",
      "    avg separation loss:      8.169333457946777\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  2.836620807647705\n",
      "    train time:               0.023435115814208984\n",
      "    test time:                0.012383699417114258\n",
      "    epoch time:               0.03630328178405762\n",
      "    last layer lr:            0.003268000000000003\n",
      "epoch: 170 (33/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.00959284013758103\n",
      "    train cross_ent loss:     0.0057753591229104334\n",
      "    test overall loss:        0.1165921042362849\n",
      "    test cross_ent loss:      0.11292257532477379\n",
      "    cluster loss:             2949.3368326822915\n",
      "    separation loss:          3.0457846323649087\n",
      "    avg separation loss:      8.163421789805094\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  2.505171298980713\n",
      "    train time:               0.023416996002197266\n",
      "    test time:                0.012379646301269531\n",
      "    epoch time:               0.03627943992614746\n",
      "    last layer lr:            0.002871999999999997\n",
      "epoch: 170 (34/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.010311905501617325\n",
      "    train cross_ent loss:     0.006770568408278955\n",
      "    test overall loss:        0.11711327234903972\n",
      "    test cross_ent loss:      0.11362741390864055\n",
      "    cluster loss:             2949.3365071614585\n",
      "    separation loss:          3.04301381111145\n",
      "    avg separation loss:      8.15402110417684\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  2.321502923965454\n",
      "    train time:               0.023570775985717773\n",
      "    test time:                0.012394905090332031\n",
      "    epoch time:               0.03644847869873047\n",
      "    last layer lr:            0.0024759999999999986\n",
      "epoch: 170 (35/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.009189569184349643\n",
      "    train cross_ent loss:     0.00593259082072311\n",
      "    test overall loss:        0.11589382092158\n",
      "    test cross_ent loss:      0.112791758030653\n",
      "    cluster loss:             2949.3365071614585\n",
      "    separation loss:          3.0464701652526855\n",
      "    avg separation loss:      8.166268825531006\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  1.9377049207687378\n",
      "    train time:               0.0234372615814209\n",
      "    test time:                0.012452363967895508\n",
      "    epoch time:               0.03635859489440918\n",
      "    last layer lr:            0.0020800000000000003\n",
      "epoch: 170 (36/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.009628812782466412\n",
      "    train cross_ent loss:     0.006676215005831586\n",
      "    test overall loss:        0.11540948102871577\n",
      "    test cross_ent loss:      0.11253710587819417\n",
      "    cluster loss:             2949.3369140625\n",
      "    separation loss:          3.0496856371561685\n",
      "    avg separation loss:      8.159162203470865\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  1.7080174684524536\n",
      "    train time:               0.023400068283081055\n",
      "    test time:                0.012383222579956055\n",
      "    epoch time:               0.03626441955566406\n",
      "    last layer lr:            0.0016840000000000017\n",
      "epoch: 170 (37/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.007822506440182527\n",
      "    train cross_ent loss:     0.0051560527127650045\n",
      "    test overall loss:        0.11670116831858952\n",
      "    test cross_ent loss:      0.11415339882175128\n",
      "    cluster loss:             2949.3367513020835\n",
      "    separation loss:          3.050514539082845\n",
      "    avg separation loss:      8.1809450785319\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  1.3834106922149658\n",
      "    train time:               0.023591041564941406\n",
      "    test time:                0.012401342391967773\n",
      "    epoch time:               0.03647756576538086\n",
      "    last layer lr:            0.001288000000000003\n",
      "epoch: 170 (38/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.008066621350331439\n",
      "    train cross_ent loss:     0.0057038506363622015\n",
      "    test overall loss:        0.11756232753396034\n",
      "    test cross_ent loss:      0.11528030907114346\n",
      "    cluster loss:             2949.3368326822915\n",
      "    separation loss:          3.039190928141276\n",
      "    avg separation loss:      8.155543168385824\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  1.1176550388336182\n",
      "    train time:               0.023388147354125977\n",
      "    test time:                0.012387752532958984\n",
      "    epoch time:               0.03625941276550293\n",
      "    last layer lr:            0.0008919999999999973\n",
      "epoch: 170 (39/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.007774295078383552\n",
      "    train cross_ent loss:     0.005694105729667677\n",
      "    test overall loss:        0.11647514378031094\n",
      "    test cross_ent loss:      0.11452309414744377\n",
      "    cluster loss:             2949.3369954427085\n",
      "    separation loss:          3.0497841040293374\n",
      "    avg separation loss:      8.166304588317871\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  0.7876887321472168\n",
      "    train time:               0.023368358612060547\n",
      "    test time:                0.012361288070678711\n",
      "    epoch time:               0.03622031211853027\n",
      "    last layer lr:            0.0004959999999999986\n",
      "epoch: 170 (40/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.007966832102586826\n",
      "    train cross_ent loss:     0.006209510533759992\n",
      "    test overall loss:        0.11816203470031421\n",
      "    test cross_ent loss:      0.11650167653958003\n",
      "    cluster loss:             2949.3378092447915\n",
      "    separation loss:          3.040494362513224\n",
      "    avg separation loss:      8.148402372996012\n",
      "    l1_addon loss:            38.81184768676758\n",
      "    l1 loss:                  0.4959976077079773\n",
      "    train time:               0.023532629013061523\n",
      "    test time:                0.012389421463012695\n",
      "    epoch time:               0.036412715911865234\n",
      "    last layer lr:            0.0001\n",
      "epoch: 171 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.009817187312162585\n",
      "    train cross_ent loss:     0.008156852486232916\n",
      "    test overall loss:        0.11639707162976265\n",
      "    test cross_ent loss:      0.11473672712842624\n",
      "    cluster loss:             2949.3363444010415\n",
      "    separation loss:          3.044918696085612\n",
      "    avg separation loss:      8.188565413157145\n",
      "    l1_addon loss:            38.81140899658203\n",
      "    l1 loss:                  0.4959976077079773\n",
      "    train time:               0.05963301658630371\n",
      "    test time:                0.012412548065185547\n",
      "    epoch time:               0.0733339786529541\n",
      "    joint lr:                 0.0009861958963236286\n",
      "epoch: 172 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.007565513693003191\n",
      "    train cross_ent loss:     0.005904623876429266\n",
      "    test overall loss:        0.11491114149490993\n",
      "    test cross_ent loss:      0.11324973776936531\n",
      "    cluster loss:             2949.3346354166665\n",
      "    separation loss:          3.0357274214426675\n",
      "    avg separation loss:      8.101584434509277\n",
      "    l1_addon loss:            38.84679412841797\n",
      "    l1 loss:                  0.4959976077079773\n",
      "    train time:               0.05931735038757324\n",
      "    test time:                0.01221013069152832\n",
      "    epoch time:               0.07272076606750488\n",
      "    joint lr:                 0.001854667874720785\n",
      "epoch: 173 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.006317538674920797\n",
      "    train cross_ent loss:     0.0046563407716651755\n",
      "    test overall loss:        0.11908045535286267\n",
      "    test cross_ent loss:      0.11741905038555463\n",
      "    cluster loss:             2949.3289388020835\n",
      "    separation loss:          3.0172365506490073\n",
      "    avg separation loss:      8.072340170542398\n",
      "    l1_addon loss:            38.84693145751953\n",
      "    l1 loss:                  0.4959976077079773\n",
      "    train time:               0.0570223331451416\n",
      "    test time:                0.012141704559326172\n",
      "    epoch time:               0.07035565376281738\n",
      "    joint lr:                 0.0027056817939603655\n",
      "epoch: 174 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.004442200064659119\n",
      "    train cross_ent loss:     0.002779353539355927\n",
      "    test overall loss:        0.1110103391110897\n",
      "    test cross_ent loss:      0.10934612154960632\n",
      "    cluster loss:             2949.3221842447915\n",
      "    separation loss:          3.0228686332702637\n",
      "    avg separation loss:      8.093069076538086\n",
      "    l1_addon loss:            38.94050598144531\n",
      "    l1 loss:                  0.4959976077079773\n",
      "    train time:               0.056763648986816406\n",
      "    test time:                0.012115478515625\n",
      "    epoch time:               0.07003331184387207\n",
      "    joint lr:                 0.003539499968027705\n",
      "epoch: 175 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.0033866719394508335\n",
      "    train cross_ent loss:     0.0017226947562044694\n",
      "    test overall loss:        0.1112588495016098\n",
      "    test cross_ent loss:      0.10959597180287044\n",
      "    cluster loss:             2949.3167317708335\n",
      "    separation loss:          2.9849044481913247\n",
      "    avg separation loss:      7.975659529368083\n",
      "    l1_addon loss:            38.895843505859375\n",
      "    l1 loss:                  0.4959976077079773\n",
      "    train time:               0.05689120292663574\n",
      "    test time:                0.01215505599975586\n",
      "    epoch time:               0.07023167610168457\n",
      "    joint lr:                 0.00435638121043428\n",
      "epoch: 176 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.0032465999118155902\n",
      "    train cross_ent loss:     0.0015848830484578179\n",
      "    test overall loss:        0.10797018185257912\n",
      "    test cross_ent loss:      0.10631032784779866\n",
      "    cluster loss:             2949.312255859375\n",
      "    separation loss:          2.9557534058888755\n",
      "    avg separation loss:      7.917952537536621\n",
      "    l1_addon loss:            38.795169830322266\n",
      "    l1 loss:                  0.4959976077079773\n",
      "    train time:               0.056833505630493164\n",
      "    test time:                0.012207508087158203\n",
      "    epoch time:               0.07024931907653809\n",
      "    joint lr:                 0.00515658087799592\n",
      "epoch: 177 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.0027109781124939523\n",
      "    train cross_ent loss:     0.0010535894026462403\n",
      "    test overall loss:        0.11247921238342921\n",
      "    test cross_ent loss:      0.11082327862580617\n",
      "    cluster loss:             2949.3111979166665\n",
      "    separation loss:          2.92526912689209\n",
      "    avg separation loss:      7.885568777720134\n",
      "    l1_addon loss:            38.66444396972656\n",
      "    l1 loss:                  0.4959976077079773\n",
      "    train time:               0.056741952896118164\n",
      "    test time:                0.012125253677368164\n",
      "    epoch time:               0.07003974914550781\n",
      "    joint lr:                 0.005940350914085284\n",
      "epoch: 178 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.0041742246184084154\n",
      "    train cross_ent loss:     0.0025175176366853216\n",
      "    test overall loss:        0.09275342834492524\n",
      "    test cross_ent loss:      0.09109228166441123\n",
      "    cluster loss:             2949.309814453125\n",
      "    separation loss:          2.971621831258138\n",
      "    avg separation loss:      7.968508243560791\n",
      "    l1_addon loss:            38.838218688964844\n",
      "    l1 loss:                  0.4959976077079773\n",
      "    train time:               0.05671072006225586\n",
      "    test time:                0.012087106704711914\n",
      "    epoch time:               0.06997919082641602\n",
      "    joint lr:                 0.00670793989136506\n",
      "epoch: 179 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.00927432036648194\n",
      "    train cross_ent loss:     0.007607340942033463\n",
      "    test overall loss:        0.10329901427030563\n",
      "    test cross_ent loss:      0.10164545103907585\n",
      "    cluster loss:             2949.3219401041665\n",
      "    separation loss:          2.8967436154683432\n",
      "    avg separation loss:      7.757741769154866\n",
      "    l1_addon loss:            38.58531951904297\n",
      "    l1 loss:                  0.4959976077079773\n",
      "    train time:               0.056928157806396484\n",
      "    test time:                0.01212000846862793\n",
      "    epoch time:               0.07021856307983398\n",
      "    joint lr:                 0.007459593054007833\n",
      "epoch: 180 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.006445869518857863\n",
      "    train cross_ent loss:     0.0048012128229149515\n",
      "    test overall loss:        0.11650703847408295\n",
      "    test cross_ent loss:      0.11485736072063446\n",
      "    cluster loss:             2949.355712890625\n",
      "    separation loss:          3.007308085759481\n",
      "    avg separation loss:      7.898702780405681\n",
      "    l1_addon loss:            38.456092834472656\n",
      "    l1 loss:                  0.4959976077079773\n",
      "    train time:               0.05681443214416504\n",
      "    test time:                0.01211237907409668\n",
      "    epoch time:               0.07009673118591309\n",
      "    joint lr:                 0.008195552359408614\n",
      "epoch: 181 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.0037673949781391355\n",
      "    train cross_ent loss:     0.0021101459860801697\n",
      "    test overall loss:        0.10140151530504227\n",
      "    test cross_ent loss:      0.09974052757024765\n",
      "    cluster loss:             2949.357666015625\n",
      "    separation loss:          3.078188975652059\n",
      "    avg separation loss:      7.930566151936849\n",
      "    l1_addon loss:            38.83305740356445\n",
      "    l1 loss:                  0.4959976077079773\n",
      "    train time:               0.05681943893432617\n",
      "    test time:                0.012162208557128906\n",
      "    epoch time:               0.07016563415527344\n",
      "    joint lr:                 0.007713866994023813\n",
      "epoch: 182 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.002842892608087924\n",
      "    train cross_ent loss:     0.0011860071422739162\n",
      "    test overall loss:        0.11763795961936314\n",
      "    test cross_ent loss:      0.11598618576924007\n",
      "    cluster loss:             2949.3595377604165\n",
      "    separation loss:          3.038058042526245\n",
      "    avg separation loss:      7.902129332224528\n",
      "    l1_addon loss:            38.52573776245117\n",
      "    l1 loss:                  0.4959976077079773\n",
      "    train time:               0.0569000244140625\n",
      "    test time:                0.012110233306884766\n",
      "    epoch time:               0.07014989852905273\n",
      "    joint lr:                 0.007241005780710745\n",
      "epoch: 183 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.0027624591667619017\n",
      "    train cross_ent loss:     0.0011131860406344964\n",
      "    test overall loss:        0.12477237731218338\n",
      "    test cross_ent loss:      0.1231246367096901\n",
      "    cluster loss:             2949.3663736979165\n",
      "    separation loss:          3.00952418645223\n",
      "    avg separation loss:      7.845833460489909\n",
      "    l1_addon loss:            38.39134216308594\n",
      "    l1 loss:                  0.4959976077079773\n",
      "    train time:               0.056925058364868164\n",
      "    test time:                0.01212167739868164\n",
      "    epoch time:               0.07026124000549316\n",
      "    joint lr:                 0.006776840404964548\n",
      "epoch: 184 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.002396143106226292\n",
      "    train cross_ent loss:     0.0007471394977377107\n",
      "    test overall loss:        0.11951194951931636\n",
      "    test cross_ent loss:      0.11786155651013057\n",
      "    cluster loss:             2949.3623046875\n",
      "    separation loss:          2.9937455654144287\n",
      "    avg separation loss:      7.778021653493245\n",
      "    l1_addon loss:            38.47988510131836\n",
      "    l1 loss:                  0.4959976077079773\n",
      "    train time:               0.056772470474243164\n",
      "    test time:                0.012140512466430664\n",
      "    epoch time:               0.07008981704711914\n",
      "    joint lr:                 0.006321244236155204\n",
      "epoch: 185 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.004017559979628358\n",
      "    train cross_ent loss:     0.0023664340034075496\n",
      "    test overall loss:        0.11240217834711075\n",
      "    test cross_ent loss:      0.11075050383806229\n",
      "    cluster loss:             2949.359375\n",
      "    separation loss:          3.002186934153239\n",
      "    avg separation loss:      7.785506407419841\n",
      "    l1_addon loss:            38.522369384765625\n",
      "    l1 loss:                  0.4959976077079773\n",
      "    train time:               0.056859493255615234\n",
      "    test time:                0.012148141860961914\n",
      "    epoch time:               0.07019281387329102\n",
      "    joint lr:                 0.00587409230668155\n",
      "epoch: 186 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.005944477950429751\n",
      "    train cross_ent loss:     0.004294089329454841\n",
      "    test overall loss:        0.11147663493951161\n",
      "    test cross_ent loss:      0.10982867330312729\n",
      "    cluster loss:             2949.3705240885415\n",
      "    separation loss:          3.026761213938395\n",
      "    avg separation loss:      7.85929520924886\n",
      "    l1_addon loss:            38.398582458496094\n",
      "    l1 loss:                  0.4959976077079773\n",
      "    train time:               0.05683183670043945\n",
      "    test time:                0.012120246887207031\n",
      "    epoch time:               0.07013678550720215\n",
      "    joint lr:                 0.0054352612913737535\n",
      "epoch: 187 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.0029883570451703337\n",
      "    train cross_ent loss:     0.001340814963138352\n",
      "    test overall loss:        0.11263372004032135\n",
      "    test cross_ent loss:      0.11098552246888478\n",
      "    cluster loss:             2949.366455078125\n",
      "    separation loss:          2.997347116470337\n",
      "    avg separation loss:      7.777076403299968\n",
      "    l1_addon loss:            38.406593322753906\n",
      "    l1 loss:                  0.4959976077079773\n",
      "    train time:               0.05697154998779297\n",
      "    test time:                0.012195825576782227\n",
      "    epoch time:               0.07030820846557617\n",
      "    joint lr:                 0.005004629487141445\n",
      "epoch: 188 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.0027941852394077512\n",
      "    train cross_ent loss:     0.0011443055894536276\n",
      "    test overall loss:        0.11514278252919515\n",
      "    test cross_ent loss:      0.11349125703175862\n",
      "    cluster loss:             2949.3601888020835\n",
      "    separation loss:          2.980212370554606\n",
      "    avg separation loss:      7.67782465616862\n",
      "    l1_addon loss:            38.51756286621094\n",
      "    l1 loss:                  0.4959976077079773\n",
      "    train time:               0.05673384666442871\n",
      "    test time:                0.012130260467529297\n",
      "    epoch time:               0.07003450393676758\n",
      "    joint lr:                 0.004582076792864645\n",
      "epoch: 189 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.0021645628019339508\n",
      "    train cross_ent loss:     0.0005120402137334975\n",
      "    test overall loss:        0.11232522626717885\n",
      "    test cross_ent loss:      0.11067211627960205\n",
      "    cluster loss:             2949.3578287760415\n",
      "    separation loss:          2.970925251642863\n",
      "    avg separation loss:      7.606998602549235\n",
      "    l1_addon loss:            38.570369720458984\n",
      "    l1 loss:                  0.4959976077079773\n",
      "    train time:               0.05699896812438965\n",
      "    test time:                0.01212310791015625\n",
      "    epoch time:               0.07027363777160645\n",
      "    joint lr:                 0.004167484689524657\n",
      "epoch: 190 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.002399765381899973\n",
      "    train cross_ent loss:     0.0007471032230468052\n",
      "    test overall loss:        0.11071583131949107\n",
      "    test cross_ent loss:      0.10906390349070232\n",
      "    cluster loss:             2949.3568522135415\n",
      "    separation loss:          2.9709831873575845\n",
      "    avg separation loss:      7.610390663146973\n",
      "    l1_addon loss:            38.530853271484375\n",
      "    l1 loss:                  0.4959976077079773\n",
      "    train time:               0.05680990219116211\n",
      "    test time:                0.012124300003051758\n",
      "    epoch time:               0.07011890411376953\n",
      "    joint lr:                 0.003760736220572192\n",
      "epoch: 191 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.0023601605531035196\n",
      "    train cross_ent loss:     0.0007091925767276229\n",
      "    test overall loss:        0.10998870680729549\n",
      "    test cross_ent loss:      0.1083392674724261\n",
      "    cluster loss:             2949.3545735677085\n",
      "    separation loss:          2.9631687800089517\n",
      "    avg separation loss:      7.633215268452962\n",
      "    l1_addon loss:            38.44791030883789\n",
      "    l1 loss:                  0.4959976077079773\n",
      "    train time:               0.05694866180419922\n",
      "    test time:                0.012138843536376953\n",
      "    epoch time:               0.07026481628417969\n",
      "    joint lr:                 0.0033617159725298235\n",
      "epoch: 192 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.002327673654589388\n",
      "    train cross_ent loss:     0.0006793691734654001\n",
      "    test overall loss:        0.10988108813762665\n",
      "    test cross_ent loss:      0.10823370516300201\n",
      "    cluster loss:             2949.354736328125\n",
      "    separation loss:          2.9510210355122886\n",
      "    avg separation loss:      7.6166049639383955\n",
      "    l1_addon loss:            38.379371643066406\n",
      "    l1 loss:                  0.4959976077079773\n",
      "    train time:               0.0567774772644043\n",
      "    test time:                0.012114763259887695\n",
      "    epoch time:               0.07008147239685059\n",
      "    joint lr:                 0.002970310055826246\n",
      "epoch: 193 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.00210181864288946\n",
      "    train cross_ent loss:     0.00045464761852700677\n",
      "    test overall loss:        0.11030287792285283\n",
      "    test cross_ent loss:      0.10865574826796849\n",
      "    cluster loss:             2949.3558756510415\n",
      "    separation loss:          2.948873202006022\n",
      "    avg separation loss:      7.627390702565511\n",
      "    l1_addon loss:            38.37110900878906\n",
      "    l1 loss:                  0.4959976077079773\n",
      "    train time:               0.056745052337646484\n",
      "    test time:                0.012125015258789062\n",
      "    epoch time:               0.07006025314331055\n",
      "    joint lr:                 0.0025864060858594865\n",
      "epoch: 194 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.002144574886187911\n",
      "    train cross_ent loss:     0.0004969529060569281\n",
      "    test overall loss:        0.10470673193534215\n",
      "    test cross_ent loss:      0.10305884232123692\n",
      "    cluster loss:             2949.3519694010415\n",
      "    separation loss:          2.950136184692383\n",
      "    avg separation loss:      7.616304238637288\n",
      "    l1_addon loss:            38.39635467529297\n",
      "    l1 loss:                  0.4959976077079773\n",
      "    train time:               0.05676722526550293\n",
      "    test time:                0.012138128280639648\n",
      "    epoch time:               0.07008481025695801\n",
      "    joint lr:                 0.00220989316428648\n",
      "epoch: 195 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.0020333951364995707\n",
      "    train cross_ent loss:     0.00038553323085782013\n",
      "    test overall loss:        0.10646583636601765\n",
      "    test cross_ent loss:      0.10481788714726765\n",
      "    cluster loss:             2949.3531087239585\n",
      "    separation loss:          2.9460886319478354\n",
      "    avg separation loss:      7.6153178215026855\n",
      "    l1_addon loss:            38.398353576660156\n",
      "    l1 loss:                  0.4959976077079773\n",
      "    train time:               0.05682539939880371\n",
      "    test time:                0.012128829956054688\n",
      "    epoch time:               0.07014608383178711\n",
      "    joint lr:                 0.0018406618605363474\n",
      "epoch: 196 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.002046568125175933\n",
      "    train cross_ent loss:     0.00039836358903105266\n",
      "    test overall loss:        0.10484722008307774\n",
      "    test cross_ent loss:      0.10319874932368596\n",
      "    cluster loss:             2949.3512369791665\n",
      "    separation loss:          2.941593885421753\n",
      "    avg separation loss:      7.595395723978679\n",
      "    l1_addon loss:            38.41565704345703\n",
      "    l1 loss:                  0.4959976077079773\n",
      "    train time:               0.05682706832885742\n",
      "    test time:                0.012134313583374023\n",
      "    epoch time:               0.07013916969299316\n",
      "    joint lr:                 0.001478604193544789\n",
      "epoch: 197 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.002191661844133503\n",
      "    train cross_ent loss:     0.0005431515536555606\n",
      "    test overall loss:        0.10268799712260564\n",
      "    test cross_ent loss:      0.10103948290149371\n",
      "    cluster loss:             2949.3511555989585\n",
      "    separation loss:          2.9453699588775635\n",
      "    avg separation loss:      7.6136752764383955\n",
      "    l1_addon loss:            38.417240142822266\n",
      "    l1 loss:                  0.4959976077079773\n",
      "    train time:               0.05699300765991211\n",
      "    test time:                0.012149333953857422\n",
      "    epoch time:               0.0702965259552002\n",
      "    joint lr:                 0.0011236136137069992\n",
      "epoch: 198 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.0025514589053475195\n",
      "    train cross_ent loss:     0.00090290319672527\n",
      "    test overall loss:        0.10418134679396947\n",
      "    test cross_ent loss:      0.10253263761599858\n",
      "    cluster loss:             2949.3505045572915\n",
      "    separation loss:          2.947524150212606\n",
      "    avg separation loss:      7.6426107088724775\n",
      "    l1_addon loss:            38.423736572265625\n",
      "    l1 loss:                  0.4959976077079773\n",
      "    train time:               0.05682563781738281\n",
      "    test time:                0.012201309204101562\n",
      "    epoch time:               0.07019376754760742\n",
      "    joint lr:                 0.0007755849850466195\n",
      "epoch: 199 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.0022065574691320458\n",
      "    train cross_ent loss:     0.0005575289065341672\n",
      "    test overall loss:        0.10335690528154373\n",
      "    test cross_ent loss:      0.10170765221118927\n",
      "    cluster loss:             2949.3501790364585\n",
      "    separation loss:          2.934088706970215\n",
      "    avg separation loss:      7.5799204508463545\n",
      "    l1_addon loss:            38.44175338745117\n",
      "    l1 loss:                  0.4959976077079773\n",
      "    train time:               0.056731224060058594\n",
      "    test time:                0.012128353118896484\n",
      "    epoch time:               0.07003974914550781\n",
      "    joint lr:                 0.0004344145675980766\n",
      "epoch: 200 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.0023727396554831\n",
      "    train cross_ent loss:     0.0007235090549026305\n",
      "    test overall loss:        0.10411839932203293\n",
      "    test cross_ent loss:      0.10246924310922623\n",
      "    cluster loss:             2949.3499348958335\n",
      "    separation loss:          2.9291863441467285\n",
      "    avg separation loss:      7.546011288960774\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  0.4959976077079773\n",
      "    train time:               0.05673098564147949\n",
      "    test time:                0.012129545211791992\n",
      "    epoch time:               0.07004785537719727\n",
      "    joint lr:                 0.0001\n",
      "epoch: 200 (PUSH) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.0023727396554831\n",
      "    train cross_ent loss:     0.0007235090549026305\n",
      "    test overall loss:        0.12116182595491409\n",
      "    test cross_ent loss:      0.11951266974210739\n",
      "    cluster loss:             2949.32080078125\n",
      "    separation loss:          2.7082305749257407\n",
      "    avg separation loss:      7.204858462015788\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  0.4959976077079773\n",
      "    train time:               0.05673098564147949\n",
      "    test time:                0.012315034866333008\n",
      "    epoch time:               0.38802552223205566\n",
      "epoch: 200 (1/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.005832819475067986\n",
      "    train cross_ent loss:     0.004358723190509611\n",
      "    test overall loss:        0.12057643632094066\n",
      "    test cross_ent loss:      0.11920137455066045\n",
      "    cluster loss:             2949.3206380208335\n",
      "    separation loss:          2.7155418395996094\n",
      "    avg separation loss:      7.236181894938151\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  0.22190332412719727\n",
      "    train time:               0.023203611373901367\n",
      "    test time:                0.01209402084350586\n",
      "    epoch time:               0.035778045654296875\n",
      "    last layer lr:            0.0007600000000000095\n",
      "epoch: 200 (2/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.004760216041985486\n",
      "    train cross_ent loss:     0.0029191133216954768\n",
      "    test overall loss:        0.12097829580307007\n",
      "    test cross_ent loss:      0.11916257689396541\n",
      "    cluster loss:             2949.3209635416665\n",
      "    separation loss:          2.7109851042429605\n",
      "    avg separation loss:      7.218626817067464\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  0.6625586748123169\n",
      "    train time:               0.022735595703125\n",
      "    test time:                0.012048482894897461\n",
      "    epoch time:               0.035269975662231445\n",
      "    last layer lr:            0.0014199999999999955\n",
      "epoch: 200 (3/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.005579548525727457\n",
      "    train cross_ent loss:     0.003463140559486217\n",
      "    test overall loss:        0.1206877628962199\n",
      "    test cross_ent loss:      0.1185412382086118\n",
      "    cluster loss:             2949.3207194010415\n",
      "    separation loss:          2.717940886815389\n",
      "    avg separation loss:      7.234889030456543\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  0.9933642148971558\n",
      "    train time:               0.022670507431030273\n",
      "    test time:                0.01207590103149414\n",
      "    epoch time:               0.035218238830566406\n",
      "    last layer lr:            0.0020800000000000046\n",
      "epoch: 200 (4/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.0058163184569113785\n",
      "    train cross_ent loss:     0.0033577325003635553\n",
      "    test overall loss:        0.12009035795927048\n",
      "    test cross_ent loss:      0.11753838260968526\n",
      "    cluster loss:             2949.321044921875\n",
      "    separation loss:          2.719703276952108\n",
      "    avg separation loss:      7.226905186971028\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  1.3988215923309326\n",
      "    train time:               0.023259639739990234\n",
      "    test time:                0.012142658233642578\n",
      "    epoch time:               0.035894155502319336\n",
      "    last layer lr:            0.0027399999999999907\n",
      "epoch: 200 (5/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.005385896139260795\n",
      "    train cross_ent loss:     0.002517816002687646\n",
      "    test overall loss:        0.12060672293106715\n",
      "    test cross_ent loss:      0.11771520972251892\n",
      "    cluster loss:             2949.3212076822915\n",
      "    separation loss:          2.7177090644836426\n",
      "    avg separation loss:      7.22991418838501\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  1.7383594512939453\n",
      "    train time:               0.022701740264892578\n",
      "    test time:                0.012053489685058594\n",
      "    epoch time:               0.03524184226989746\n",
      "    last layer lr:            0.0034\n",
      "epoch: 200 (6/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.006722492735005087\n",
      "    train cross_ent loss:     0.0034248638225512374\n",
      "    test overall loss:        0.11872878422339757\n",
      "    test cross_ent loss:      0.1153210997581482\n",
      "    cluster loss:             2949.3209635416665\n",
      "    separation loss:          2.729843854904175\n",
      "    avg separation loss:      7.25949748357137\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  2.254525661468506\n",
      "    train time:               0.022653818130493164\n",
      "    test time:                0.012067556381225586\n",
      "    epoch time:               0.03520679473876953\n",
      "    last layer lr:            0.00406000000000001\n",
      "epoch: 200 (7/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.0073819707872139085\n",
      "    train cross_ent loss:     0.003668875123063723\n",
      "    test overall loss:        0.12292175988356273\n",
      "    test cross_ent loss:      0.1191692128777504\n",
      "    cluster loss:             2949.3213704427085\n",
      "    separation loss:          2.7214740912119546\n",
      "    avg separation loss:      7.254499117533366\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  2.599393844604492\n",
      "    train time:               0.022821903228759766\n",
      "    test time:                0.012092351913452148\n",
      "    epoch time:               0.03540301322937012\n",
      "    last layer lr:            0.004719999999999996\n",
      "epoch: 200 (8/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.00739159466077884\n",
      "    train cross_ent loss:     0.003236816743285292\n",
      "    test overall loss:        0.12132619818051656\n",
      "    test cross_ent loss:      0.1170306106408437\n",
      "    cluster loss:             2949.3211263020835\n",
      "    separation loss:          2.7225873470306396\n",
      "    avg separation loss:      7.251323541005452\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  3.14243221282959\n",
      "    train time:               0.02267932891845703\n",
      "    test time:                0.012115955352783203\n",
      "    epoch time:               0.03527569770812988\n",
      "    last layer lr:            0.0053800000000000054\n",
      "epoch: 200 (9/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.007355680792695946\n",
      "    train cross_ent loss:     0.002690053292705367\n",
      "    test overall loss:        0.12186842411756516\n",
      "    test cross_ent loss:      0.11707187692324321\n",
      "    cluster loss:             2949.321533203125\n",
      "    separation loss:          2.728226661682129\n",
      "    avg separation loss:      7.273579756418864\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  3.6433868408203125\n",
      "    train time:               0.022748231887817383\n",
      "    test time:                0.012067079544067383\n",
      "    epoch time:               0.035299062728881836\n",
      "    last layer lr:            0.0060399999999999916\n",
      "epoch: 200 (10/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.008973628386027284\n",
      "    train cross_ent loss:     0.0039066412589616245\n",
      "    test overall loss:        0.12339462836583455\n",
      "    test cross_ent loss:      0.11828491340080897\n",
      "    cluster loss:             2949.3216959635415\n",
      "    separation loss:          2.7243178685506186\n",
      "    avg separation loss:      7.265974044799805\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  3.9565610885620117\n",
      "    train time:               0.02279520034790039\n",
      "    test time:                0.012047529220581055\n",
      "    epoch time:               0.03532576560974121\n",
      "    last layer lr:            0.0067\n",
      "epoch: 200 (11/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.010673129879352119\n",
      "    train cross_ent loss:     0.005145204175884525\n",
      "    test overall loss:        0.12448567400376002\n",
      "    test cross_ent loss:      0.11855075011650722\n",
      "    cluster loss:             2949.3208821614585\n",
      "    separation loss:          2.7087201277414956\n",
      "    avg separation loss:      7.211776256561279\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  4.781764984130859\n",
      "    train time:               0.022633790969848633\n",
      "    test time:                0.012066841125488281\n",
      "    epoch time:               0.03517913818359375\n",
      "    last layer lr:            0.007360000000000011\n",
      "epoch: 200 (12/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.00962315153123604\n",
      "    train cross_ent loss:     0.0033061487160416115\n",
      "    test overall loss:        0.12363223731517792\n",
      "    test cross_ent loss:      0.11733160664637883\n",
      "    cluster loss:             2949.3209635416665\n",
      "    separation loss:          2.710289239883423\n",
      "    avg separation loss:      7.212361971537272\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  5.147478103637695\n",
      "    train time:               0.02268385887145996\n",
      "    test time:                0.012053251266479492\n",
      "    epoch time:               0.03521585464477539\n",
      "    last layer lr:            0.008019999999999994\n",
      "epoch: 200 (13/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.009258805825892422\n",
      "    train cross_ent loss:     0.002741591642714209\n",
      "    test overall loss:        0.12524558107058206\n",
      "    test cross_ent loss:      0.1186925396323204\n",
      "    cluster loss:             2949.3209635416665\n",
      "    separation loss:          2.7063633600870767\n",
      "    avg separation loss:      7.205837726593018\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  5.39988899230957\n",
      "    train time:               0.02277684211730957\n",
      "    test time:                0.012106657028198242\n",
      "    epoch time:               0.035364389419555664\n",
      "    last layer lr:            0.008680000000000005\n",
      "epoch: 200 (14/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.012435900564822886\n",
      "    train cross_ent loss:     0.005547345227872332\n",
      "    test overall loss:        0.1247287318110466\n",
      "    test cross_ent loss:      0.11701648434003194\n",
      "    cluster loss:             2949.3212890625\n",
      "    separation loss:          2.7099219957987466\n",
      "    avg separation loss:      7.198174953460693\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  6.5590949058532715\n",
      "    train time:               0.024101734161376953\n",
      "    test time:                0.012324333190917969\n",
      "    epoch time:               0.03697371482849121\n",
      "    last layer lr:            0.00933999999999999\n",
      "epoch: 200 (15/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.011038578839765655\n",
      "    train cross_ent loss:     0.0024218476351557505\n",
      "    test overall loss:        0.1266047184665998\n",
      "    test cross_ent loss:      0.11829030265410741\n",
      "    cluster loss:             2949.3213704427085\n",
      "    separation loss:          2.70623779296875\n",
      "    avg separation loss:      7.2057998975118\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  7.161259174346924\n",
      "    train time:               0.023130178451538086\n",
      "    test time:                0.01208806037902832\n",
      "    epoch time:               0.03570556640625\n",
      "    last layer lr:            0.01\n",
      "epoch: 200 (16/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.012315762229263783\n",
      "    train cross_ent loss:     0.003746007963652826\n",
      "    test overall loss:        0.12553484737873077\n",
      "    test cross_ent loss:      0.11725545177857082\n",
      "    cluster loss:             2949.3216959635415\n",
      "    separation loss:          2.714442253112793\n",
      "    avg separation loss:      7.201502005259196\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  7.126237869262695\n",
      "    train time:               0.023449182510375977\n",
      "    test time:                0.012417793273925781\n",
      "    epoch time:               0.036351680755615234\n",
      "    last layer lr:            0.009603999999999994\n",
      "epoch: 200 (17/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.011520052639146646\n",
      "    train cross_ent loss:     0.0033516922525854576\n",
      "    test overall loss:        0.12330169230699539\n",
      "    test cross_ent loss:      0.11536114662885666\n",
      "    cluster loss:             2949.321044921875\n",
      "    separation loss:          2.7151270707448325\n",
      "    avg separation loss:      7.2042341232299805\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  6.787389278411865\n",
      "    train time:               0.023665666580200195\n",
      "    test time:                0.012419939041137695\n",
      "    epoch time:               0.03656268119812012\n",
      "    last layer lr:            0.009208000000000003\n",
      "epoch: 200 (18/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.011600521186159717\n",
      "    train cross_ent loss:     0.0036459214623189634\n",
      "    test overall loss:        0.1229867438475291\n",
      "    test cross_ent loss:      0.11498099317153294\n",
      "    cluster loss:             2949.3208821614585\n",
      "    separation loss:          2.713477293650309\n",
      "    avg separation loss:      7.218458493550618\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  6.852590560913086\n",
      "    train time:               0.023826122283935547\n",
      "    test time:                0.012678861618041992\n",
      "    epoch time:               0.03699088096618652\n",
      "    last layer lr:            0.008811999999999997\n",
      "epoch: 200 (19/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.01055172054717938\n",
      "    train cross_ent loss:     0.00285719963721931\n",
      "    test overall loss:        0.12215389808019002\n",
      "    test cross_ent loss:      0.1146847332517306\n",
      "    cluster loss:             2949.321044921875\n",
      "    separation loss:          2.7144702275594077\n",
      "    avg separation loss:      7.225627581278483\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  6.316012382507324\n",
      "    train time:               0.02377629280090332\n",
      "    test time:                0.01248478889465332\n",
      "    epoch time:               0.03674602508544922\n",
      "    last layer lr:            0.008416000000000005\n",
      "epoch: 200 (20/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.00988032016903162\n",
      "    train cross_ent loss:     0.002669950481504202\n",
      "    test overall loss:        0.11963081111510594\n",
      "    test cross_ent loss:      0.11252413441737492\n",
      "    cluster loss:             2949.3206380208335\n",
      "    separation loss:          2.7203445434570312\n",
      "    avg separation loss:      7.227498531341553\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  5.953522682189941\n",
      "    train time:               0.02361607551574707\n",
      "    test time:                0.012404918670654297\n",
      "    epoch time:               0.03650069236755371\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 200 (21/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.009342538503309092\n",
      "    train cross_ent loss:     0.00240228524328106\n",
      "    test overall loss:        0.12109507371981938\n",
      "    test cross_ent loss:      0.11422098676363628\n",
      "    cluster loss:             2949.3211263020835\n",
      "    separation loss:          2.717190980911255\n",
      "    avg separation loss:      7.226180076599121\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  5.7209320068359375\n",
      "    train time:               0.0237276554107666\n",
      "    test time:                0.012431859970092773\n",
      "    epoch time:               0.03664088249206543\n",
      "    last layer lr:            0.007623999999999995\n",
      "epoch: 200 (22/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.01070552815993627\n",
      "    train cross_ent loss:     0.004079883180869122\n",
      "    test overall loss:        0.12162727365891139\n",
      "    test cross_ent loss:      0.11503389726082484\n",
      "    cluster loss:             2949.3212076822915\n",
      "    separation loss:          2.711585362752279\n",
      "    avg separation loss:      7.221199194590251\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  5.440221786499023\n",
      "    train time:               0.023908376693725586\n",
      "    test time:                0.012386083602905273\n",
      "    epoch time:               0.036780357360839844\n",
      "    last layer lr:            0.0072280000000000035\n",
      "epoch: 200 (23/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.008950516167614195\n",
      "    train cross_ent loss:     0.002512601980318626\n",
      "    test overall loss:        0.11995603144168854\n",
      "    test cross_ent loss:      0.11369271824757259\n",
      "    cluster loss:             2949.32080078125\n",
      "    separation loss:          2.718796968460083\n",
      "    avg separation loss:      7.2395243644714355\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  5.110158920288086\n",
      "    train time:               0.02372121810913086\n",
      "    test time:                0.012403011322021484\n",
      "    epoch time:               0.03660702705383301\n",
      "    last layer lr:            0.006831999999999998\n",
      "epoch: 200 (24/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.008912015137159161\n",
      "    train cross_ent loss:     0.0027319215134614045\n",
      "    test overall loss:        0.11742472400267918\n",
      "    test cross_ent loss:      0.11140179385741551\n",
      "    cluster loss:             2949.320556640625\n",
      "    separation loss:          2.7246525287628174\n",
      "    avg separation loss:      7.239799817403157\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  4.869772911071777\n",
      "    train time:               0.023673534393310547\n",
      "    test time:                0.012404680252075195\n",
      "    epoch time:               0.0365602970123291\n",
      "    last layer lr:            0.006436000000000007\n",
      "epoch: 200 (25/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.008587554718057314\n",
      "    train cross_ent loss:     0.002646749696901275\n",
      "    test overall loss:        0.11837188402811687\n",
      "    test cross_ent loss:      0.1124647706747055\n",
      "    cluster loss:             2949.32080078125\n",
      "    separation loss:          2.71949036916097\n",
      "    avg separation loss:      7.233140627543132\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  4.753957271575928\n",
      "    train time:               0.023752212524414062\n",
      "    test time:                0.012424468994140625\n",
      "    epoch time:               0.036661624908447266\n",
      "    last layer lr:            0.00604\n",
      "epoch: 200 (26/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.007884979144566588\n",
      "    train cross_ent loss:     0.002257018647570577\n",
      "    test overall loss:        0.11793306718269984\n",
      "    test cross_ent loss:      0.11242364595333736\n",
      "    cluster loss:             2949.3212076822915\n",
      "    separation loss:          2.7196973959604898\n",
      "    avg separation loss:      7.228303909301758\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  4.35626220703125\n",
      "    train time:               0.02360844612121582\n",
      "    test time:                0.0124053955078125\n",
      "    epoch time:               0.03649568557739258\n",
      "    last layer lr:            0.0056439999999999945\n",
      "epoch: 200 (27/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.007533371810697847\n",
      "    train cross_ent loss:     0.0021911594538121587\n",
      "    test overall loss:        0.11830764512221019\n",
      "    test cross_ent loss:      0.11299573630094528\n",
      "    cluster loss:             2949.3208821614585\n",
      "    separation loss:          2.7164063453674316\n",
      "    avg separation loss:      7.237294356028239\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  4.158755302429199\n",
      "    train time:               0.023677825927734375\n",
      "    test time:                0.012420654296875\n",
      "    epoch time:               0.0365900993347168\n",
      "    last layer lr:            0.005248000000000003\n",
      "epoch: 200 (28/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.007393636637263828\n",
      "    train cross_ent loss:     0.002333309895928121\n",
      "    test overall loss:        0.11687465757131577\n",
      "    test cross_ent loss:      0.11196882277727127\n",
      "    cluster loss:             2949.3212890625\n",
      "    separation loss:          2.72144349416097\n",
      "    avg separation loss:      7.251453558603923\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  3.7526776790618896\n",
      "    train time:               0.023709535598754883\n",
      "    test time:                0.012465953826904297\n",
      "    epoch time:               0.036661386489868164\n",
      "    last layer lr:            0.004851999999999998\n",
      "epoch: 200 (29/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.0077050236157245105\n",
      "    train cross_ent loss:     0.0029985486891948515\n",
      "    test overall loss:        0.11982740710179011\n",
      "    test cross_ent loss:      0.1151148999730746\n",
      "    cluster loss:             2949.32177734375\n",
      "    separation loss:          2.7159942785898843\n",
      "    avg separation loss:      7.247321128845215\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  3.559353828430176\n",
      "    train time:               0.023798465728759766\n",
      "    test time:                0.012418985366821289\n",
      "    epoch time:               0.03670692443847656\n",
      "    last layer lr:            0.004456000000000006\n",
      "epoch: 200 (30/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.006645920531203349\n",
      "    train cross_ent loss:     0.002164083636469311\n",
      "    test overall loss:        0.11916768550872803\n",
      "    test cross_ent loss:      0.11482751121123631\n",
      "    cluster loss:             2949.3216145833335\n",
      "    separation loss:          2.716776212056478\n",
      "    avg separation loss:      7.238133430480957\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  3.187020778656006\n",
      "    train time:               0.023773908615112305\n",
      "    test time:                0.012736797332763672\n",
      "    epoch time:               0.036994218826293945\n",
      "    last layer lr:            0.004060000000000001\n",
      "epoch: 200 (31/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.006841430026623938\n",
      "    train cross_ent loss:     0.0026186774226112496\n",
      "    test overall loss:        0.11909559865792592\n",
      "    test cross_ent loss:      0.11501150329907735\n",
      "    cluster loss:             2949.3208821614585\n",
      "    separation loss:          2.7070534229278564\n",
      "    avg separation loss:      7.213172594706218\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  2.930941581726074\n",
      "    train time:               0.023628950119018555\n",
      "    test time:                0.012430191040039062\n",
      "    epoch time:               0.0365450382232666\n",
      "    last layer lr:            0.0036639999999999945\n",
      "epoch: 200 (32/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.006828279441429509\n",
      "    train cross_ent loss:     0.0029269511190553508\n",
      "    test overall loss:        0.11984420319398244\n",
      "    test cross_ent loss:      0.11605069289604823\n",
      "    cluster loss:             2949.3208821614585\n",
      "    separation loss:          2.702385584513346\n",
      "    avg separation loss:      7.192360877990723\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  2.6403515338897705\n",
      "    train time:               0.023767948150634766\n",
      "    test time:                0.012431621551513672\n",
      "    epoch time:               0.03667593002319336\n",
      "    last layer lr:            0.003268000000000003\n",
      "epoch: 200 (33/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.0056589048148857225\n",
      "    train cross_ent loss:     0.0020510941135904025\n",
      "    test overall loss:        0.1194847250978152\n",
      "    test cross_ent loss:      0.11591880768537521\n",
      "    cluster loss:             2949.3212890625\n",
      "    separation loss:          2.7093992233276367\n",
      "    avg separation loss:      7.2127180099487305\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  2.412759780883789\n",
      "    train time:               0.023726701736450195\n",
      "    test time:                0.012772798538208008\n",
      "    epoch time:               0.03699946403503418\n",
      "    last layer lr:            0.002871999999999997\n",
      "epoch: 200 (34/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.005976535121185912\n",
      "    train cross_ent loss:     0.0026096072720570695\n",
      "    test overall loss:        0.1168019250035286\n",
      "    test cross_ent loss:      0.11355202148358028\n",
      "    cluster loss:             2949.321044921875\n",
      "    separation loss:          2.7183868885040283\n",
      "    avg separation loss:      7.218576908111572\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  2.0967466831207275\n",
      "    train time:               0.02396535873413086\n",
      "    test time:                0.01248311996459961\n",
      "    epoch time:               0.03694415092468262\n",
      "    last layer lr:            0.0024760000000000055\n",
      "epoch: 200 (35/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.005460641502092282\n",
      "    train cross_ent loss:     0.0023757791172506083\n",
      "    test overall loss:        0.11718194435040157\n",
      "    test cross_ent loss:      0.1141774629553159\n",
      "    cluster loss:             2949.3212890625\n",
      "    separation loss:          2.719374497731527\n",
      "    avg separation loss:      7.228823661804199\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  1.8513245582580566\n",
      "    train time:               0.023727893829345703\n",
      "    test time:                0.012417078018188477\n",
      "    epoch time:               0.03663206100463867\n",
      "    last layer lr:            0.0020800000000000003\n",
      "epoch: 200 (36/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.005676964297890663\n",
      "    train cross_ent loss:     0.0028528200540070734\n",
      "    test overall loss:        0.11877344300349553\n",
      "    test cross_ent loss:      0.11602478971083958\n",
      "    cluster loss:             2949.3213704427085\n",
      "    separation loss:          2.710117975870768\n",
      "    avg separation loss:      7.219856897989909\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  1.5954999923706055\n",
      "    train time:               0.02382636070251465\n",
      "    test time:                0.012412071228027344\n",
      "    epoch time:               0.03672218322753906\n",
      "    last layer lr:            0.0016839999999999945\n",
      "epoch: 200 (37/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.005122840404510498\n",
      "    train cross_ent loss:     0.002556122955866158\n",
      "    test overall loss:        0.11619143933057785\n",
      "    test cross_ent loss:      0.11369165033102036\n",
      "    cluster loss:             2949.3214518229165\n",
      "    separation loss:          2.7159624099731445\n",
      "    avg separation loss:      7.235112984975179\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  1.3466320037841797\n",
      "    train time:               0.023834228515625\n",
      "    test time:                0.012383460998535156\n",
      "    epoch time:               0.0366969108581543\n",
      "    last layer lr:            0.001288000000000003\n",
      "epoch: 200 (38/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.004984517788721455\n",
      "    train cross_ent loss:     0.002684015366766188\n",
      "    test overall loss:        0.11719890932242076\n",
      "    test cross_ent loss:      0.1150042861700058\n",
      "    cluster loss:             2949.3213704427085\n",
      "    separation loss:          2.719456513722738\n",
      "    avg separation loss:      7.25631856918335\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  1.041465401649475\n",
      "    train time:               0.024523019790649414\n",
      "    test time:                0.012956619262695312\n",
      "    epoch time:               0.03799724578857422\n",
      "    last layer lr:            0.0008919999999999973\n",
      "epoch: 200 (39/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.004439810006361868\n",
      "    train cross_ent loss:     0.002411223689301146\n",
      "    test overall loss:        0.11630357801914215\n",
      "    test cross_ent loss:      0.11436022321383159\n",
      "    cluster loss:             2949.32080078125\n",
      "    separation loss:          2.7121335665384927\n",
      "    avg separation loss:      7.213277339935303\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  0.7901999354362488\n",
      "    train time:               0.025038480758666992\n",
      "    test time:                0.012954235076904297\n",
      "    epoch time:               0.03851723670959473\n",
      "    last layer lr:            0.0004960000000000057\n",
      "epoch: 200 (40/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.005057809201793538\n",
      "    train cross_ent loss:     0.0033179669731503558\n",
      "    test overall loss:        0.11917013178269069\n",
      "    test cross_ent loss:      0.11753177891174953\n",
      "    cluster loss:             2949.3212076822915\n",
      "    separation loss:          2.707838694254557\n",
      "    avg separation loss:      7.207159519195557\n",
      "    l1_addon loss:            38.43859100341797\n",
      "    l1 loss:                  0.4851989150047302\n",
      "    train time:               0.025150537490844727\n",
      "    test time:                0.012945413589477539\n",
      "    epoch time:               0.03861498832702637\n",
      "    last layer lr:            0.0001\n",
      "Finished training in 30.76 seconds\n",
      "Last epoch test accu: 96.67%\n",
      "Done in 200 epochs, 41.92s\n",
      "Training for ArticularyWordRecognition, proto len 144, reception 0.25, features_lr 0.001, protos per class 10, l1_addon 3e-05\n",
      "Params: {\n",
      "    \"protos_per_class\": 10,\n",
      "    \"proto_features\": 32,\n",
      "    \"proto_len_latent\": 144,\n",
      "    \"features_lr\": 0.001,\n",
      "    \"num_classes\": 25,\n",
      "    \"coeffs\": {\n",
      "        \"crs_ent\": 1,\n",
      "        \"clst\": 0,\n",
      "        \"sep\": 0,\n",
      "        \"l1\": 0.001,\n",
      "        \"l1_addon\": 3e-05\n",
      "    },\n",
      "    \"num_warm_epochs\": 50,\n",
      "    \"push_start_epoch\": 110,\n",
      "    \"num_last_layer_epochs\": 40,\n",
      "    \"epochs\": 200\n",
      "}\n",
      "Training encoder\n",
      "epoch:   10/300 mse loss: 0.0344\n",
      "epoch:   20/300 mse loss: 0.0288\n",
      "epoch:   30/300 mse loss: 0.0399\n",
      "epoch:   40/300 mse loss: 0.0483\n",
      "epoch:   50/300 mse loss: 0.0574\n",
      "epoch:   60/300 mse loss: 0.0669\n",
      "epoch:   70/300 mse loss: 0.0774\n",
      "epoch:   80/300 mse loss: 0.0792\n",
      "epoch:   90/300 mse loss: 0.0819\n",
      "epoch:  100/300 mse loss: 0.0834\n",
      "epoch:  110/300 mse loss: 0.0826\n",
      "epoch:  120/300 mse loss: 0.0803\n",
      "epoch:  130/300 mse loss: 0.0807\n",
      "epoch:  140/300 mse loss: 0.0803\n",
      "epoch:  150/300 mse loss: 0.0795\n",
      "epoch:  160/300 mse loss: 0.0802\n",
      "epoch:  170/300 mse loss: 0.0801\n",
      "epoch:  180/300 mse loss: 0.0791\n",
      "epoch:  190/300 mse loss: 0.0789\n",
      "epoch:  200/300 mse loss: 0.0776\n",
      "epoch:  210/300 mse loss: 0.0784\n",
      "epoch:  220/300 mse loss: 0.0783\n",
      "epoch:  230/300 mse loss: 0.0789\n",
      "epoch:  240/300 mse loss: 0.0782\n",
      "epoch:  250/300 mse loss: 0.0785\n",
      "epoch:  260/300 mse loss: 0.0782\n",
      "epoch:  270/300 mse loss: 0.0779\n",
      "epoch:  280/300 mse loss: 0.0786\n",
      "epoch:  290/300 mse loss: 0.0784\n",
      "epoch:  300/300 mse loss: 0.0786\n",
      "Training ProtoTSNet\n",
      "Starting training\n",
      "epoch:   1 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 5.67%\n",
      "    train overall loss:       6.2244110107421875\n",
      "    train cross_ent loss:     3.218855381011963\n",
      "    test overall loss:        6.223974386850993\n",
      "    test cross_ent loss:      3.218850056330363\n",
      "    cluster loss:             3363.4521484375\n",
      "    separation loss:          1140.7884928385417\n",
      "    avg separation loss:      1163.4955647786458\n",
      "    l1_addon loss:            170.80210876464844\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04296445846557617\n",
      "    test time:                0.012668848037719727\n",
      "    epoch time:               0.056296586990356445\n",
      "epoch:   2 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 10.00%\n",
      "    train overall loss:       6.2235361735026045\n",
      "    train cross_ent loss:     3.218731853697035\n",
      "    test overall loss:        6.223175048828125\n",
      "    test cross_ent loss:      3.218757708867391\n",
      "    cluster loss:             3341.9713541666665\n",
      "    separation loss:          1082.5100504557292\n",
      "    avg separation loss:      1116.447509765625\n",
      "    l1_addon loss:            147.22897338867188\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04221820831298828\n",
      "    test time:                0.01686859130859375\n",
      "    epoch time:               0.05974888801574707\n",
      "epoch:   3 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 13.67%\n",
      "    train overall loss:       6.222731060451931\n",
      "    train cross_ent loss:     3.218599557876587\n",
      "    test overall loss:        6.222399075826009\n",
      "    test cross_ent loss:      3.2186100482940674\n",
      "    cluster loss:             3342.7316080729165\n",
      "    separation loss:          1090.2471516927083\n",
      "    avg separation loss:      1136.636474609375\n",
      "    l1_addon loss:            126.29752349853516\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04221820831298828\n",
      "    test time:                0.012594461441040039\n",
      "    epoch time:               0.05545926094055176\n",
      "epoch:   4 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 18.00%\n",
      "    train overall loss:       6.221990214453803\n",
      "    train cross_ent loss:     3.2184547583262124\n",
      "    test overall loss:        6.221671104431152\n",
      "    test cross_ent loss:      3.2184364000956216\n",
      "    cluster loss:             3342.946044921875\n",
      "    separation loss:          1097.9365641276042\n",
      "    avg separation loss:      1156.1503092447917\n",
      "    l1_addon loss:            107.80960083007812\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.050196170806884766\n",
      "    test time:                0.012592315673828125\n",
      "    epoch time:               0.0634315013885498\n",
      "epoch:   5 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 21.00%\n",
      "    train overall loss:       6.221315966712104\n",
      "    train cross_ent loss:     3.2182980643378363\n",
      "    test overall loss:        6.221017360687256\n",
      "    test cross_ent loss:      3.2182528972625732\n",
      "    cluster loss:             3336.5310872395835\n",
      "    separation loss:          1092.6113688151042\n",
      "    avg separation loss:      1158.3939615885417\n",
      "    l1_addon loss:            92.144287109375\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.041996002197265625\n",
      "    test time:                0.01258540153503418\n",
      "    epoch time:               0.05524086952209473\n",
      "epoch:   6 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 29.67%\n",
      "    train overall loss:       6.220699893103705\n",
      "    train cross_ent loss:     3.2181113031175403\n",
      "    test overall loss:        6.220433076222737\n",
      "    test cross_ent loss:      3.2180469036102295\n",
      "    cluster loss:             3322.9679361979165\n",
      "    separation loss:          1064.0426025390625\n",
      "    avg separation loss:      1139.1663818359375\n",
      "    l1_addon loss:            79.54098510742188\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04704689979553223\n",
      "    test time:                0.012599706649780273\n",
      "    epoch time:               0.06030392646789551\n",
      "epoch:   7 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 37.67%\n",
      "    train overall loss:       6.220108932918972\n",
      "    train cross_ent loss:     3.2178472677866616\n",
      "    test overall loss:        6.219852606455485\n",
      "    test cross_ent loss:      3.2177254358927407\n",
      "    cluster loss:             3298.4951171875\n",
      "    separation loss:          1003.7275390625\n",
      "    avg separation loss:      1091.12451171875\n",
      "    l1_addon loss:            70.89969635009766\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04216575622558594\n",
      "    test time:                0.02077460289001465\n",
      "    epoch time:               0.06362557411193848\n",
      "epoch:   8 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 52.00%\n",
      "    train overall loss:       6.219470977783203\n",
      "    train cross_ent loss:     3.2174093988206653\n",
      "    test overall loss:        6.2191416422526045\n",
      "    test cross_ent loss:      3.21713916460673\n",
      "    cluster loss:             3259.1463216145835\n",
      "    separation loss:          899.3360595703125\n",
      "    avg separation loss:      1009.6822509765625\n",
      "    l1_addon loss:            66.73762512207031\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.043602943420410156\n",
      "    test time:                0.012890815734863281\n",
      "    epoch time:               0.057204484939575195\n",
      "epoch:   9 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 66.67%\n",
      "    train overall loss:       6.218611717224121\n",
      "    train cross_ent loss:     3.2166436778174505\n",
      "    test overall loss:        6.2182847658793134\n",
      "    test cross_ent loss:      3.216374079386393\n",
      "    cluster loss:             3221.727783203125\n",
      "    separation loss:          800.3011474609375\n",
      "    avg separation loss:      932.0127156575521\n",
      "    l1_addon loss:            63.695556640625\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04745793342590332\n",
      "    test time:                0.012766122817993164\n",
      "    epoch time:               0.06089496612548828\n",
      "epoch:  10 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 71.33%\n",
      "    train overall loss:       6.21754429075453\n",
      "    train cross_ent loss:     3.2157057921091714\n",
      "    test overall loss:        6.217099666595459\n",
      "    test cross_ent loss:      3.2153536478678384\n",
      "    cluster loss:             3184.7588704427085\n",
      "    separation loss:          708.8631388346354\n",
      "    avg separation loss:      835.5894775390625\n",
      "    l1_addon loss:            58.186134338378906\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.0431821346282959\n",
      "    test time:                0.01273488998413086\n",
      "    epoch time:               0.05660223960876465\n",
      "epoch:  11 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 75.33%\n",
      "    train overall loss:       6.21614138285319\n",
      "    train cross_ent loss:     3.214446783065796\n",
      "    test overall loss:        6.215483983357747\n",
      "    test cross_ent loss:      3.2138426303863525\n",
      "    cluster loss:             3147.599365234375\n",
      "    separation loss:          613.9310302734375\n",
      "    avg separation loss:      738.3859049479166\n",
      "    l1_addon loss:            54.71587371826172\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05133938789367676\n",
      "    test time:                0.012746334075927734\n",
      "    epoch time:               0.0647742748260498\n",
      "epoch:  12 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 67.00%\n",
      "    train overall loss:       6.214291943444146\n",
      "    train cross_ent loss:     3.212700049082438\n",
      "    test overall loss:        6.2136430740356445\n",
      "    test cross_ent loss:      3.212157964706421\n",
      "    cluster loss:             3123.9764811197915\n",
      "    separation loss:          561.4518025716146\n",
      "    avg separation loss:      677.3543497721354\n",
      "    l1_addon loss:            49.49584197998047\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04353809356689453\n",
      "    test time:                0.012616395950317383\n",
      "    epoch time:               0.056847333908081055\n",
      "epoch:  13 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 68.00%\n",
      "    train overall loss:       6.212143262227376\n",
      "    train cross_ent loss:     3.210681014590793\n",
      "    test overall loss:        6.211191177368164\n",
      "    test cross_ent loss:      3.2097890377044678\n",
      "    cluster loss:             3102.287109375\n",
      "    separation loss:          510.6067301432292\n",
      "    avg separation loss:      629.5965372721354\n",
      "    l1_addon loss:            46.73065185546875\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04331326484680176\n",
      "    test time:                0.012812137603759766\n",
      "    epoch time:               0.056838035583496094\n",
      "epoch:  14 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 66.33%\n",
      "    train overall loss:       6.2095525529649525\n",
      "    train cross_ent loss:     3.2081782817840576\n",
      "    test overall loss:        6.208433628082275\n",
      "    test cross_ent loss:      3.2070749600728354\n",
      "    cluster loss:             3085.3828125\n",
      "    separation loss:          472.4726053873698\n",
      "    avg separation loss:      597.6596476236979\n",
      "    l1_addon loss:            45.281192779541016\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.051535606384277344\n",
      "    test time:                0.012852191925048828\n",
      "    epoch time:               0.06503820419311523\n",
      "epoch:  15 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 60.67%\n",
      "    train overall loss:       6.206138292948405\n",
      "    train cross_ent loss:     3.2048048973083496\n",
      "    test overall loss:        6.204906304677327\n",
      "    test cross_ent loss:      3.203576644261678\n",
      "    cluster loss:             3069.6046549479165\n",
      "    separation loss:          436.2097574869792\n",
      "    avg separation loss:      566.4321085611979\n",
      "    l1_addon loss:            44.31646728515625\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.043581247329711914\n",
      "    test time:                0.020699262619018555\n",
      "    epoch time:               0.06497859954833984\n",
      "epoch:  16 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 59.00%\n",
      "    train overall loss:       6.201713297102186\n",
      "    train cross_ent loss:     3.2004090944925943\n",
      "    test overall loss:        6.199776649475098\n",
      "    test cross_ent loss:      3.198476473490397\n",
      "    cluster loss:             3053.2504069010415\n",
      "    separation loss:          395.72386678059894\n",
      "    avg separation loss:      530.2256266276041\n",
      "    l1_addon loss:            43.334781646728516\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04316353797912598\n",
      "    test time:                0.01235508918762207\n",
      "    epoch time:               0.05621767044067383\n",
      "epoch:  17 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 58.33%\n",
      "    train overall loss:       6.195161554548475\n",
      "    train cross_ent loss:     3.193871683544583\n",
      "    test overall loss:        6.192417939503987\n",
      "    test cross_ent loss:      3.1911450227101645\n",
      "    cluster loss:             3038.2891438802085\n",
      "    separation loss:          357.2015380859375\n",
      "    avg separation loss:      496.3214619954427\n",
      "    l1_addon loss:            42.41501235961914\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04592418670654297\n",
      "    test time:                0.012111186981201172\n",
      "    epoch time:               0.058702945709228516\n",
      "epoch:  18 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 61.67%\n",
      "    train overall loss:       6.185658984714085\n",
      "    train cross_ent loss:     3.1843858559926352\n",
      "    test overall loss:        6.181763648986816\n",
      "    test cross_ent loss:      3.1805059909820557\n",
      "    cluster loss:             3024.1537272135415\n",
      "    separation loss:          317.2714131673177\n",
      "    avg separation loss:      457.7783711751302\n",
      "    l1_addon loss:            41.91851043701172\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04118943214416504\n",
      "    test time:                0.012125015258789062\n",
      "    epoch time:               0.05397629737854004\n",
      "epoch:  19 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 58.67%\n",
      "    train overall loss:       6.172709835900201\n",
      "    train cross_ent loss:     3.171464787589179\n",
      "    test overall loss:        6.167564868927002\n",
      "    test cross_ent loss:      3.1663538614908853\n",
      "    cluster loss:             3011.3251953125\n",
      "    separation loss:          277.88318888346356\n",
      "    avg separation loss:      417.8179626464844\n",
      "    l1_addon loss:            40.35326385498047\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04807448387145996\n",
      "    test time:                0.012109994888305664\n",
      "    epoch time:               0.060845136642456055\n",
      "epoch:  20 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 61.67%\n",
      "    train overall loss:       6.154372109307183\n",
      "    train cross_ent loss:     3.153149710761176\n",
      "    test overall loss:        6.148852348327637\n",
      "    test cross_ent loss:      3.147653420766195\n",
      "    cluster loss:             2999.6818033854165\n",
      "    separation loss:          241.2672373453776\n",
      "    avg separation loss:      378.55751546223956\n",
      "    l1_addon loss:            39.956031799316406\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04114580154418945\n",
      "    test time:                0.020055294036865234\n",
      "    epoch time:               0.0618739128112793\n",
      "epoch:  21 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 65.67%\n",
      "    train overall loss:       6.123926480611165\n",
      "    train cross_ent loss:     3.122717433505588\n",
      "    test overall loss:        6.12129545211792\n",
      "    test cross_ent loss:      3.1200969219207764\n",
      "    cluster loss:             2988.9461263020835\n",
      "    separation loss:          205.32177225748697\n",
      "    avg separation loss:      341.9902852376302\n",
      "    l1_addon loss:            39.93645477294922\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.041138410568237305\n",
      "    test time:                0.012077569961547852\n",
      "    epoch time:               0.05387687683105469\n",
      "epoch:  22 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 70.00%\n",
      "    train overall loss:       6.096157444847955\n",
      "    train cross_ent loss:     3.0949750741322837\n",
      "    test overall loss:        6.09591007232666\n",
      "    test cross_ent loss:      3.0947611331939697\n",
      "    cluster loss:             2980.8472493489585\n",
      "    separation loss:          177.06512959798178\n",
      "    avg separation loss:      309.39441935221356\n",
      "    l1_addon loss:            38.29359817504883\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04252147674560547\n",
      "    test time:                0.012079715728759766\n",
      "    epoch time:               0.05526471138000488\n",
      "epoch:  23 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 79.67%\n",
      "    train overall loss:       6.057340039147271\n",
      "    train cross_ent loss:     3.056176874372694\n",
      "    test overall loss:        6.064208984375\n",
      "    test cross_ent loss:      3.063030958175659\n",
      "    cluster loss:             2973.7989908854165\n",
      "    separation loss:          149.76094563802084\n",
      "    avg separation loss:      279.80406697591144\n",
      "    l1_addon loss:            39.25593566894531\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.041147708892822266\n",
      "    test time:                0.012093305587768555\n",
      "    epoch time:               0.05389285087585449\n",
      "epoch:  24 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 83.00%\n",
      "    train overall loss:       6.019838121202257\n",
      "    train cross_ent loss:     3.01868912908766\n",
      "    test overall loss:        6.036445140838623\n",
      "    test cross_ent loss:      3.035307248433431\n",
      "    cluster loss:             2968.8900553385415\n",
      "    separation loss:          130.00393422444662\n",
      "    avg separation loss:      252.37364196777344\n",
      "    l1_addon loss:            37.92183303833008\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04598736763000488\n",
      "    test time:                0.01223611831665039\n",
      "    epoch time:               0.058892250061035156\n",
      "epoch:  25 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 85.33%\n",
      "    train overall loss:       5.99104102452596\n",
      "    train cross_ent loss:     2.9899204042222767\n",
      "    test overall loss:        6.013932228088379\n",
      "    test cross_ent loss:      3.012826442718506\n",
      "    cluster loss:             2964.8942057291665\n",
      "    separation loss:          113.64640299479167\n",
      "    avg separation loss:      233.64617919921875\n",
      "    l1_addon loss:            36.8395881652832\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04130911827087402\n",
      "    test time:                0.01934957504272461\n",
      "    epoch time:               0.06131410598754883\n",
      "epoch:  26 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 84.33%\n",
      "    train overall loss:       5.952210532294379\n",
      "    train cross_ent loss:     2.9511025746663413\n",
      "    test overall loss:        5.992385546366374\n",
      "    test cross_ent loss:      2.991283337275187\n",
      "    cluster loss:             2962.38427734375\n",
      "    separation loss:          99.3564961751302\n",
      "    avg separation loss:      211.7885284423828\n",
      "    l1_addon loss:            36.72876739501953\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.0411684513092041\n",
      "    test time:                0.012087106704711914\n",
      "    epoch time:               0.05392193794250488\n",
      "epoch:  27 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 85.00%\n",
      "    train overall loss:       5.90693728129069\n",
      "    train cross_ent loss:     2.905843310885959\n",
      "    test overall loss:        5.974956671396892\n",
      "    test cross_ent loss:      2.9738756020863852\n",
      "    cluster loss:             2960.2032063802085\n",
      "    separation loss:          90.34723154703777\n",
      "    avg separation loss:      201.03357442220053\n",
      "    l1_addon loss:            36.0253791809082\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04324984550476074\n",
      "    test time:                0.012080907821655273\n",
      "    epoch time:               0.055985450744628906\n",
      "epoch:  28 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 85.00%\n",
      "    train overall loss:       5.880314932929145\n",
      "    train cross_ent loss:     2.8792399565378823\n",
      "    test overall loss:        5.957554181416829\n",
      "    test cross_ent loss:      2.956494092941284\n",
      "    cluster loss:             2958.9908040364585\n",
      "    separation loss:          81.82068125406902\n",
      "    avg separation loss:      185.9510498046875\n",
      "    l1_addon loss:            35.327880859375\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.041181325912475586\n",
      "    test time:                0.012101411819458008\n",
      "    epoch time:               0.05393576622009277\n",
      "epoch:  29 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 83.67%\n",
      "    train overall loss:       5.839035087161594\n",
      "    train cross_ent loss:     2.8379680845472546\n",
      "    test overall loss:        5.949597517649333\n",
      "    test cross_ent loss:      2.948570728302002\n",
      "    cluster loss:             2958.101318359375\n",
      "    separation loss:          77.58791605631511\n",
      "    avg separation loss:      184.9569854736328\n",
      "    l1_addon loss:            34.2249755859375\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.048569679260253906\n",
      "    test time:                0.012058496475219727\n",
      "    epoch time:               0.06125926971435547\n",
      "epoch:  30 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 79.67%\n",
      "    train overall loss:       5.825891547732883\n",
      "    train cross_ent loss:     2.824858453538683\n",
      "    test overall loss:        5.947348594665527\n",
      "    test cross_ent loss:      2.9462947050730386\n",
      "    cluster loss:             2958.0481770833335\n",
      "    separation loss:          72.47830200195312\n",
      "    avg separation loss:      173.72210693359375\n",
      "    l1_addon loss:            35.13048553466797\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04124903678894043\n",
      "    test time:                0.013982295989990234\n",
      "    epoch time:               0.05589008331298828\n",
      "epoch:  31 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 80.67%\n",
      "    train overall loss:       5.824401166703966\n",
      "    train cross_ent loss:     2.823366536034478\n",
      "    test overall loss:        5.931158383687337\n",
      "    test cross_ent loss:      2.930156946182251\n",
      "    cluster loss:             2957.3193359375\n",
      "    separation loss:          69.955628712972\n",
      "    avg separation loss:      171.37042236328125\n",
      "    l1_addon loss:            33.37608337402344\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04128599166870117\n",
      "    test time:                0.012083292007446289\n",
      "    epoch time:               0.05402851104736328\n",
      "epoch:  32 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 81.00%\n",
      "    train overall loss:       5.788336859809028\n",
      "    train cross_ent loss:     2.787321170171102\n",
      "    test overall loss:        5.916767120361328\n",
      "    test cross_ent loss:      2.91576353708903\n",
      "    cluster loss:             2957.1322428385415\n",
      "    separation loss:          66.68082173665364\n",
      "    avg separation loss:      163.92390950520834\n",
      "    l1_addon loss:            33.43781280517578\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.046000003814697266\n",
      "    test time:                0.012139558792114258\n",
      "    epoch time:               0.0587918758392334\n",
      "epoch:  33 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 79.67%\n",
      "    train overall loss:       5.766664346059163\n",
      "    train cross_ent loss:     2.765655093722873\n",
      "    test overall loss:        5.905621846516927\n",
      "    test cross_ent loss:      2.90462589263916\n",
      "    cluster loss:             2956.9115397135415\n",
      "    separation loss:          64.69050852457683\n",
      "    avg separation loss:      164.27820841471353\n",
      "    l1_addon loss:            33.19483184814453\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04154539108276367\n",
      "    test time:                0.012145757675170898\n",
      "    epoch time:               0.054372549057006836\n",
      "epoch:  34 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 80.00%\n",
      "    train overall loss:       5.74622376759847\n",
      "    train cross_ent loss:     2.7452319198184543\n",
      "    test overall loss:        5.906937122344971\n",
      "    test cross_ent loss:      2.905928293863932\n",
      "    cluster loss:             2956.8529459635415\n",
      "    separation loss:          63.03896967569987\n",
      "    avg separation loss:      161.26536560058594\n",
      "    l1_addon loss:            33.624717712402344\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04129219055175781\n",
      "    test time:                0.01211857795715332\n",
      "    epoch time:               0.05408072471618652\n",
      "epoch:  35 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 76.33%\n",
      "    train overall loss:       5.717829492357042\n",
      "    train cross_ent loss:     2.7168403466542563\n",
      "    test overall loss:        5.906236330668132\n",
      "    test cross_ent loss:      2.9052932262420654\n",
      "    cluster loss:             2956.8509114583335\n",
      "    separation loss:          60.90760040283203\n",
      "    avg separation loss:      154.5926259358724\n",
      "    l1_addon loss:            31.421791076660156\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04144477844238281\n",
      "    test time:                0.014690876007080078\n",
      "    epoch time:               0.05679512023925781\n",
      "epoch:  36 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 76.67%\n",
      "    train overall loss:       5.737447897593181\n",
      "    train cross_ent loss:     2.736470275455051\n",
      "    test overall loss:        5.89602518081665\n",
      "    test cross_ent loss:      2.895049730936686\n",
      "    cluster loss:             2956.6216634114585\n",
      "    separation loss:          59.75907643636068\n",
      "    avg separation loss:      154.00493876139322\n",
      "    l1_addon loss:            32.507102966308594\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04132890701293945\n",
      "    test time:                0.012262105941772461\n",
      "    epoch time:               0.05423140525817871\n",
      "epoch:  37 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 77.00%\n",
      "    train overall loss:       5.714834213256836\n",
      "    train cross_ent loss:     2.7138688034481473\n",
      "    test overall loss:        5.877821445465088\n",
      "    test cross_ent loss:      2.876879930496216\n",
      "    cluster loss:             2956.2085774739585\n",
      "    separation loss:          57.60603332519531\n",
      "    avg separation loss:      153.12725830078125\n",
      "    l1_addon loss:            31.373592376708984\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04126310348510742\n",
      "    test time:                0.012145519256591797\n",
      "    epoch time:               0.054067373275756836\n",
      "epoch:  38 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 76.00%\n",
      "    train overall loss:       5.67627657784356\n",
      "    train cross_ent loss:     2.6753254201677112\n",
      "    test overall loss:        5.876482009887695\n",
      "    test cross_ent loss:      2.875520388285319\n",
      "    cluster loss:             2956.1993815104165\n",
      "    separation loss:          56.7662099202474\n",
      "    avg separation loss:      150.21922302246094\n",
      "    l1_addon loss:            32.044960021972656\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04130387306213379\n",
      "    test time:                0.012187480926513672\n",
      "    epoch time:               0.05417156219482422\n",
      "epoch:  39 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 76.33%\n",
      "    train overall loss:       5.641073915693495\n",
      "    train cross_ent loss:     2.64011984401279\n",
      "    test overall loss:        5.857036113739014\n",
      "    test cross_ent loss:      2.8560994466145835\n",
      "    cluster loss:             2955.861328125\n",
      "    separation loss:          54.83254369099935\n",
      "    avg separation loss:      149.32935587565103\n",
      "    l1_addon loss:            31.21068000793457\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04134249687194824\n",
      "    test time:                0.012081384658813477\n",
      "    epoch time:               0.05409598350524902\n",
      "epoch:  40 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 73.33%\n",
      "    train overall loss:       5.614990446302626\n",
      "    train cross_ent loss:     2.614051103591919\n",
      "    test overall loss:        5.852428913116455\n",
      "    test cross_ent loss:      2.8515297571818032\n",
      "    cluster loss:             2955.8042805989585\n",
      "    separation loss:          53.46663920084635\n",
      "    avg separation loss:      143.8520253499349\n",
      "    l1_addon loss:            29.954177856445312\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04138612747192383\n",
      "    test time:                0.013759613037109375\n",
      "    epoch time:               0.05580782890319824\n",
      "epoch:  41 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 73.00%\n",
      "    train overall loss:       5.6419255998399525\n",
      "    train cross_ent loss:     2.640990866555108\n",
      "    test overall loss:        5.850406964619954\n",
      "    test cross_ent loss:      2.849513133366903\n",
      "    cluster loss:             2955.7571614583335\n",
      "    separation loss:          52.88502756754557\n",
      "    avg separation loss:      142.83793131510416\n",
      "    l1_addon loss:            29.793813705444336\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.041463613510131836\n",
      "    test time:                0.01217961311340332\n",
      "    epoch time:               0.054312705993652344\n",
      "epoch:  42 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 73.00%\n",
      "    train overall loss:       5.6358256340026855\n",
      "    train cross_ent loss:     2.6349014706081815\n",
      "    test overall loss:        5.834927558898926\n",
      "    test cross_ent loss:      2.83402156829834\n",
      "    cluster loss:             2955.5183919270835\n",
      "    separation loss:          51.61550521850586\n",
      "    avg separation loss:      143.14412434895834\n",
      "    l1_addon loss:            30.203468322753906\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.045304059982299805\n",
      "    test time:                0.012062311172485352\n",
      "    epoch time:               0.058019399642944336\n",
      "epoch:  43 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 73.33%\n",
      "    train overall loss:       5.595757166544597\n",
      "    train cross_ent loss:     2.594839096069336\n",
      "    test overall loss:        5.824727535247803\n",
      "    test cross_ent loss:      2.8238211472829184\n",
      "    cluster loss:             2955.3417154947915\n",
      "    separation loss:          50.44862620035807\n",
      "    avg separation loss:      141.8935546875\n",
      "    l1_addon loss:            30.192455291748047\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04132795333862305\n",
      "    test time:                0.012140750885009766\n",
      "    epoch time:               0.05410265922546387\n",
      "epoch:  44 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 71.33%\n",
      "    train overall loss:       5.565798176659478\n",
      "    train cross_ent loss:     2.5648917886945934\n",
      "    test overall loss:        5.83955717086792\n",
      "    test cross_ent loss:      2.838639497756958\n",
      "    cluster loss:             2955.4025065104165\n",
      "    separation loss:          50.39495849609375\n",
      "    avg separation loss:      140.37817891438803\n",
      "    l1_addon loss:            30.584991455078125\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.041654348373413086\n",
      "    test time:                0.012196779251098633\n",
      "    epoch time:               0.054499149322509766\n",
      "epoch:  45 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 73.67%\n",
      "    train overall loss:       5.577361371782091\n",
      "    train cross_ent loss:     2.5764529705047607\n",
      "    test overall loss:        5.823361714680989\n",
      "    test cross_ent loss:      2.822464386622111\n",
      "    cluster loss:             2955.170654296875\n",
      "    separation loss:          48.908766428629555\n",
      "    avg separation loss:      138.6163787841797\n",
      "    l1_addon loss:            29.901065826416016\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04203033447265625\n",
      "    test time:                0.012091636657714844\n",
      "    epoch time:               0.05479598045349121\n",
      "epoch:  46 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 72.00%\n",
      "    train overall loss:       5.606169488694933\n",
      "    train cross_ent loss:     2.6052733527289496\n",
      "    test overall loss:        5.829556941986084\n",
      "    test cross_ent loss:      2.8286993503570557\n",
      "    cluster loss:             2955.4730631510415\n",
      "    separation loss:          48.643731435139976\n",
      "    avg separation loss:      136.1290079752604\n",
      "    l1_addon loss:            28.576553344726562\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04140591621398926\n",
      "    test time:                0.012106895446777344\n",
      "    epoch time:               0.05417323112487793\n",
      "epoch:  47 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 71.00%\n",
      "    train overall loss:       5.615145842234294\n",
      "    train cross_ent loss:     2.614248620139228\n",
      "    test overall loss:        5.834137757619222\n",
      "    test cross_ent loss:      2.833298126856486\n",
      "    cluster loss:             2955.5653483072915\n",
      "    separation loss:          47.75910568237305\n",
      "    avg separation loss:      134.17687479654947\n",
      "    l1_addon loss:            27.969615936279297\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04146313667297363\n",
      "    test time:                0.012316226959228516\n",
      "    epoch time:               0.05443739891052246\n",
      "epoch:  48 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 73.00%\n",
      "    train overall loss:       5.60521576139662\n",
      "    train cross_ent loss:     2.6043425930870905\n",
      "    test overall loss:        5.8122687339782715\n",
      "    test cross_ent loss:      2.8113935788472495\n",
      "    cluster loss:             2955.254150390625\n",
      "    separation loss:          46.83906936645508\n",
      "    avg separation loss:      135.64586130777994\n",
      "    l1_addon loss:            29.165733337402344\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.041454315185546875\n",
      "    test time:                0.0163114070892334\n",
      "    epoch time:               0.058474063873291016\n",
      "epoch:  49 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 72.67%\n",
      "    train overall loss:       5.539336151546902\n",
      "    train cross_ent loss:     2.5384604136149087\n",
      "    test overall loss:        5.803938706715901\n",
      "    test cross_ent loss:      2.803064505259196\n",
      "    cluster loss:             2955.0784505208335\n",
      "    separation loss:          45.13895034790039\n",
      "    avg separation loss:      131.5617446899414\n",
      "    l1_addon loss:            29.126996994018555\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04148697853088379\n",
      "    test time:                0.01223134994506836\n",
      "    epoch time:               0.05437803268432617\n",
      "epoch:  50 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 72.00%\n",
      "    train overall loss:       5.501260015699598\n",
      "    train cross_ent loss:     2.5003876951005726\n",
      "    test overall loss:        5.794662634531657\n",
      "    test cross_ent loss:      2.7938002745310464\n",
      "    cluster loss:             2954.8536783854165\n",
      "    separation loss:          44.574161529541016\n",
      "    avg separation loss:      131.54922485351562\n",
      "    l1_addon loss:            28.74357795715332\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04129338264465332\n",
      "    test time:                0.012206315994262695\n",
      "    epoch time:               0.05416560173034668\n",
      "epoch:  51 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 74.00%\n",
      "    train overall loss:       5.552811675601536\n",
      "    train cross_ent loss:     2.5519490242004395\n",
      "    test overall loss:        5.786093076070149\n",
      "    test cross_ent loss:      2.7852330207824707\n",
      "    cluster loss:             2954.9252115885415\n",
      "    separation loss:          45.84570185343424\n",
      "    avg separation loss:      142.33228047688803\n",
      "    l1_addon loss:            28.652862548828125\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05824899673461914\n",
      "    test time:                0.012150287628173828\n",
      "    epoch time:               0.07109522819519043\n",
      "    joint lr:                 0.0030601000000000087\n",
      "epoch:  52 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 21.67%\n",
      "    train overall loss:       6.0854573249816895\n",
      "    train cross_ent loss:     3.0846324231889515\n",
      "    test overall loss:        6.218066851298015\n",
      "    test cross_ent loss:      3.217278480529785\n",
      "    cluster loss:             3239.3092447916665\n",
      "    separation loss:          709.3740234375\n",
      "    avg separation loss:      1134.3896077473958\n",
      "    l1_addon loss:            26.279788970947266\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05837869644165039\n",
      "    test time:                0.01221466064453125\n",
      "    epoch time:               0.07135128974914551\n",
      "    joint lr:                 0.005960997999999999\n",
      "epoch:  53 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 36.00%\n",
      "    train overall loss:       6.054210980733235\n",
      "    train cross_ent loss:     3.0534326235453286\n",
      "    test overall loss:        6.196225802103679\n",
      "    test cross_ent loss:      3.1954065958658853\n",
      "    cluster loss:             3011.302490234375\n",
      "    separation loss:          111.1679204305013\n",
      "    avg separation loss:      439.7422688802083\n",
      "    l1_addon loss:            27.313323974609375\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.0585942268371582\n",
      "    test time:                0.012201309204101562\n",
      "    epoch time:               0.07159018516540527\n",
      "    joint lr:                 0.008803582030000007\n",
      "epoch:  54 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 46.33%\n",
      "    train overall loss:       5.702049255371094\n",
      "    train cross_ent loss:     2.7012132273779974\n",
      "    test overall loss:        6.148743947347005\n",
      "    test cross_ent loss:      3.147918701171875\n",
      "    cluster loss:             2985.1065266927085\n",
      "    separation loss:          69.35405985514323\n",
      "    avg separation loss:      333.41847229003906\n",
      "    l1_addon loss:            27.493404388427734\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05893898010253906\n",
      "    test time:                0.012157917022705078\n",
      "    epoch time:               0.07186269760131836\n",
      "    joint lr:                 0.011588728279599995\n",
      "epoch:  55 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 58.67%\n",
      "    train overall loss:       5.360352145300971\n",
      "    train cross_ent loss:     2.359523137410482\n",
      "    test overall loss:        6.105360507965088\n",
      "    test cross_ent loss:      3.1045401891072593\n",
      "    cluster loss:             2968.1665852864585\n",
      "    separation loss:          55.855576833089195\n",
      "    avg separation loss:      238.45494079589844\n",
      "    l1_addon loss:            27.346393585205078\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05886197090148926\n",
      "    test time:                0.012214899063110352\n",
      "    epoch time:               0.07183504104614258\n",
      "    joint lr:                 0.014317301246005004\n",
      "epoch:  56 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 47.33%\n",
      "    train overall loss:       5.276813983917236\n",
      "    train cross_ent loss:     2.275966074731615\n",
      "    test overall loss:        6.085972944895427\n",
      "    test cross_ent loss:      3.085127274195353\n",
      "    cluster loss:             2965.831787109375\n",
      "    separation loss:          53.0488166809082\n",
      "    avg separation loss:      205.66960652669272\n",
      "    l1_addon loss:            28.183021545410156\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05856776237487793\n",
      "    test time:                0.012173175811767578\n",
      "    epoch time:               0.07148289680480957\n",
      "    joint lr:                 0.016990153880253933\n",
      "epoch:  57 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 67.00%\n",
      "    train overall loss:       5.199441803826226\n",
      "    train cross_ent loss:     2.1985626220703125\n",
      "    test overall loss:        5.9194715817769366\n",
      "    test cross_ent loss:      2.918522040049235\n",
      "    cluster loss:             2956.1708984375\n",
      "    separation loss:          33.97246487935384\n",
      "    avg separation loss:      113.29979197184245\n",
      "    l1_addon loss:            31.64513397216797\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058624267578125\n",
      "    test time:                0.01226353645324707\n",
      "    epoch time:               0.07165813446044922\n",
      "    joint lr:                 0.019608127731693303\n",
      "epoch:  58 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 71.67%\n",
      "    train overall loss:       4.976071993509929\n",
      "    train cross_ent loss:     1.975142651134067\n",
      "    test overall loss:        5.563851992289226\n",
      "    test cross_ent loss:      2.5628886222839355\n",
      "    cluster loss:             2953.1142578125\n",
      "    separation loss:          23.588107426961262\n",
      "    avg separation loss:      78.87050120035808\n",
      "    l1_addon loss:            32.107852935791016\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058626651763916016\n",
      "    test time:                0.012242555618286133\n",
      "    epoch time:               0.07165265083312988\n",
      "    joint lr:                 0.02217205309071584\n",
      "epoch:  59 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 62.00%\n",
      "    train overall loss:       5.197517130109999\n",
      "    train cross_ent loss:     2.196535733011034\n",
      "    test overall loss:        5.711868762969971\n",
      "    test cross_ent loss:      2.7108494440714517\n",
      "    cluster loss:             2954.680908203125\n",
      "    separation loss:          22.624233881632488\n",
      "    avg separation loss:      82.48503112792969\n",
      "    l1_addon loss:            33.95979309082031\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05859684944152832\n",
      "    test time:                0.012199878692626953\n",
      "    epoch time:               0.07153940200805664\n",
      "    joint lr:                 0.024682749129784777\n",
      "epoch:  60 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 72.33%\n",
      "    train overall loss:       5.120292292700873\n",
      "    train cross_ent loss:     2.1192774772644043\n",
      "    test overall loss:        5.116324583689372\n",
      "    test cross_ent loss:      2.115264415740967\n",
      "    cluster loss:             2951.410888671875\n",
      "    separation loss:          17.983469645182293\n",
      "    avg separation loss:      59.0758425394694\n",
      "    l1_addon loss:            35.340293884277344\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05879807472229004\n",
      "    test time:                0.012262821197509766\n",
      "    epoch time:               0.07181549072265625\n",
      "    joint lr:                 0.027141024042763244\n",
      "epoch:  61 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 71.67%\n",
      "    train overall loss:       4.93422089682685\n",
      "    train cross_ent loss:     1.9331750604841444\n",
      "    test overall loss:        4.882976373036702\n",
      "    test cross_ent loss:      1.8819127480189006\n",
      "    cluster loss:             2951.2041829427085\n",
      "    separation loss:          16.692133903503418\n",
      "    avg separation loss:      56.851731618245445\n",
      "    l1_addon loss:            35.44021987915039\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.0587310791015625\n",
      "    test time:                0.012197017669677734\n",
      "    epoch time:               0.07165312767028809\n",
      "    joint lr:                 0.025532083112218835\n",
      "epoch:  62 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 69.33%\n",
      "    train overall loss:       4.939608256022136\n",
      "    train cross_ent loss:     1.9385235044691298\n",
      "    test overall loss:        5.028084595998128\n",
      "    test cross_ent loss:      2.026973327000936\n",
      "    cluster loss:             2951.7007649739585\n",
      "    separation loss:          16.106958389282227\n",
      "    avg separation loss:      51.79057693481445\n",
      "    l1_addon loss:            37.03239822387695\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05921435356140137\n",
      "    test time:                0.012655019760131836\n",
      "    epoch time:               0.07263588905334473\n",
      "    joint lr:                 0.023952616897881036\n",
      "epoch:  63 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 72.33%\n",
      "    train overall loss:       4.933891667260064\n",
      "    train cross_ent loss:     1.932760967148675\n",
      "    test overall loss:        4.86026668548584\n",
      "    test cross_ent loss:      1.8591349124908447\n",
      "    cluster loss:             2951.2229817708335\n",
      "    separation loss:          15.14519214630127\n",
      "    avg separation loss:      47.86955769856771\n",
      "    l1_addon loss:            37.711700439453125\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.0589909553527832\n",
      "    test time:                0.012653112411499023\n",
      "    epoch time:               0.07244133949279785\n",
      "    joint lr:                 0.022402196799518763\n",
      "epoch:  64 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 72.00%\n",
      "    train overall loss:       5.041894806755914\n",
      "    train cross_ent loss:     2.0407216681374445\n",
      "    test overall loss:        4.778918584187825\n",
      "    test cross_ent loss:      1.7777294715245564\n",
      "    cluster loss:             2951.0355631510415\n",
      "    separation loss:          14.983240763346354\n",
      "    avg separation loss:      49.01062266031901\n",
      "    l1_addon loss:            39.6265869140625\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.059198617935180664\n",
      "    test time:                0.012633323669433594\n",
      "    epoch time:               0.07262992858886719\n",
      "    joint lr:                 0.02088039984143395\n",
      "epoch:  65 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 67.67%\n",
      "    train overall loss:       4.686806625790066\n",
      "    train cross_ent loss:     1.685619182056851\n",
      "    test overall loss:        4.820903460184733\n",
      "    test cross_ent loss:      1.819710612297058\n",
      "    cluster loss:             2951.0533854166665\n",
      "    separation loss:          14.017879486083984\n",
      "    avg separation loss:      43.41708246866862\n",
      "    l1_addon loss:            39.758056640625\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.0589144229888916\n",
      "    test time:                0.012642145156860352\n",
      "    epoch time:               0.0723576545715332\n",
      "    joint lr:                 0.01938680860283089\n",
      "epoch:  66 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 73.00%\n",
      "    train overall loss:       4.829034805297852\n",
      "    train cross_ent loss:     1.827842156092326\n",
      "    test overall loss:        4.606851736704509\n",
      "    test cross_ent loss:      1.6056472063064575\n",
      "    cluster loss:             2950.8855794270835\n",
      "    separation loss:          14.42577044169108\n",
      "    avg separation loss:      47.779040018717446\n",
      "    l1_addon loss:            40.147830963134766\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05909585952758789\n",
      "    test time:                0.01266169548034668\n",
      "    epoch time:               0.07256865501403809\n",
      "    joint lr:                 0.017921011149015745\n",
      "epoch:  67 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 77.67%\n",
      "    train overall loss:       4.688908365037706\n",
      "    train cross_ent loss:     1.687730974621243\n",
      "    test overall loss:        4.534462769826253\n",
      "    test cross_ent loss:      1.533295750617981\n",
      "    cluster loss:             2950.5071614583335\n",
      "    separation loss:          12.567200660705566\n",
      "    avg separation loss:      43.60772832234701\n",
      "    l1_addon loss:            38.88726806640625\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05905723571777344\n",
      "    test time:                0.012653350830078125\n",
      "    epoch time:               0.07249188423156738\n",
      "    joint lr:                 0.016482600963416614\n",
      "epoch:  68 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 83.00%\n",
      "    train overall loss:       4.260352028740777\n",
      "    train cross_ent loss:     1.2591721481747098\n",
      "    test overall loss:        4.207789897918701\n",
      "    test cross_ent loss:      1.2066304683685303\n",
      "    cluster loss:             2950.3107096354165\n",
      "    separation loss:          10.73248545328776\n",
      "    avg separation loss:      36.00619379679362\n",
      "    l1_addon loss:            38.64067077636719\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05895423889160156\n",
      "    test time:                0.012762069702148438\n",
      "    epoch time:               0.0725247859954834\n",
      "    joint lr:                 0.015071176880414561\n",
      "epoch:  69 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 76.67%\n",
      "    train overall loss:       4.139064523908827\n",
      "    train cross_ent loss:     1.137871954176161\n",
      "    test overall loss:        4.203573226928711\n",
      "    test cross_ent loss:      1.2024073998133342\n",
      "    cluster loss:             2950.2437337239585\n",
      "    separation loss:          9.421258131663004\n",
      "    avg separation loss:      29.424257278442383\n",
      "    l1_addon loss:            38.838768005371094\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.0592801570892334\n",
      "    test time:                0.01266932487487793\n",
      "    epoch time:               0.07272553443908691\n",
      "    joint lr:                 0.01368634301897622\n",
      "epoch:  70 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 81.33%\n",
      "    train overall loss:       4.040385590659247\n",
      "    train cross_ent loss:     1.0391910208596125\n",
      "    test overall loss:        4.1020941734313965\n",
      "    test cross_ent loss:      1.1008888284365337\n",
      "    cluster loss:             2950.2666015625\n",
      "    separation loss:          8.281351407368978\n",
      "    avg separation loss:      25.853926340738933\n",
      "    l1_addon loss:            40.17076110839844\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05923199653625488\n",
      "    test time:                0.012656688690185547\n",
      "    epoch time:               0.07266449928283691\n",
      "    joint lr:                 0.012327708717078603\n",
      "epoch:  71 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 86.67%\n",
      "    train overall loss:       3.986682891845703\n",
      "    train cross_ent loss:     0.9854872624079386\n",
      "    test overall loss:        3.8424866994222007\n",
      "    test cross_ent loss:      0.8412786225477854\n",
      "    cluster loss:             2950.20751953125\n",
      "    separation loss:          8.089814186096191\n",
      "    avg separation loss:      23.810569127400715\n",
      "    l1_addon loss:            40.262168884277344\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.059326887130737305\n",
      "    test time:                0.012650728225708008\n",
      "    epoch time:               0.07277917861938477\n",
      "    joint lr:                 0.01099488846691703\n",
      "epoch:  72 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 79.67%\n",
      "    train overall loss:       4.133384545644124\n",
      "    train cross_ent loss:     1.1321776045693293\n",
      "    test overall loss:        4.112584352493286\n",
      "    test cross_ent loss:      1.11141304175059\n",
      "    cluster loss:             2950.2723795572915\n",
      "    separation loss:          7.555623531341553\n",
      "    avg separation loss:      20.428117752075195\n",
      "    l1_addon loss:            39.031211853027344\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.059126853942871094\n",
      "    test time:                0.012663125991821289\n",
      "    epoch time:               0.07256436347961426\n",
      "    joint lr:                 0.009687501850886984\n",
      "epoch:  73 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 86.33%\n",
      "    train overall loss:       3.858167780770196\n",
      "    train cross_ent loss:     0.8569794793923696\n",
      "    test overall loss:        3.66182804107666\n",
      "    test cross_ent loss:      0.6606247375408808\n",
      "    cluster loss:             2949.989013671875\n",
      "    separation loss:          7.063687324523926\n",
      "    avg separation loss:      20.861284891764324\n",
      "    l1_addon loss:            40.10135269165039\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.059154510498046875\n",
      "    test time:                0.012620925903320312\n",
      "    epoch time:               0.07253575325012207\n",
      "    joint lr:                 0.008405173478330853\n",
      "epoch:  74 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 89.00%\n",
      "    train overall loss:       3.832308769226074\n",
      "    train cross_ent loss:     0.8311149875322977\n",
      "    test overall loss:        3.702666680018107\n",
      "    test cross_ent loss:      0.7014510134855906\n",
      "    cluster loss:             2950.052978515625\n",
      "    separation loss:          7.197886943817139\n",
      "    avg separation loss:      20.30995496114095\n",
      "    l1_addon loss:            40.516929626464844\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05898261070251465\n",
      "    test time:                0.012634992599487305\n",
      "    epoch time:               0.07243537902832031\n",
      "    joint lr:                 0.007147532923040749\n",
      "epoch:  75 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 89.00%\n",
      "    train overall loss:       3.623629649480184\n",
      "    train cross_ent loss:     0.6224400897820791\n",
      "    test overall loss:        3.654740889867147\n",
      "    test cross_ent loss:      0.6535601665576299\n",
      "    cluster loss:             2949.861572265625\n",
      "    separation loss:          6.370901425679524\n",
      "    avg separation loss:      20.033545176188152\n",
      "    l1_addon loss:            39.349586486816406\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058979034423828125\n",
      "    test time:                0.012681961059570312\n",
      "    epoch time:               0.07246208190917969\n",
      "    joint lr:                 0.005914214661508615\n",
      "epoch:  76 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 88.00%\n",
      "    train overall loss:       3.481781323750814\n",
      "    train cross_ent loss:     0.4806000027391646\n",
      "    test overall loss:        3.48183012008667\n",
      "    test cross_ent loss:      0.48061584929625195\n",
      "    cluster loss:             2949.805908203125\n",
      "    separation loss:          5.8819343249003095\n",
      "    avg separation loss:      16.16754372914632\n",
      "    l1_addon loss:            40.46746063232422\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.059203386306762695\n",
      "    test time:                0.012645721435546875\n",
      "    epoch time:               0.0726022720336914\n",
      "    joint lr:                 0.004704858011914826\n",
      "epoch:  77 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 94.00%\n",
      "    train overall loss:       3.3900573783450656\n",
      "    train cross_ent loss:     0.3888642688592275\n",
      "    test overall loss:        3.350778500239054\n",
      "    test cross_ent loss:      0.3495783532659213\n",
      "    cluster loss:             2949.715087890625\n",
      "    separation loss:          5.33441178003947\n",
      "    avg separation loss:      15.679167111714682\n",
      "    l1_addon loss:            39.997154235839844\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058963775634765625\n",
      "    test time:                0.013115644454956055\n",
      "    epoch time:               0.07292819023132324\n",
      "    joint lr:                 0.0035191070738467612\n",
      "epoch:  78 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 92.00%\n",
      "    train overall loss:       3.2777418295542398\n",
      "    train cross_ent loss:     0.2765483632683754\n",
      "    test overall loss:        3.347738186518351\n",
      "    test cross_ent loss:      0.3465289721886317\n",
      "    cluster loss:             2949.681396484375\n",
      "    separation loss:          4.840250889460246\n",
      "    avg separation loss:      13.612335840861002\n",
      "    l1_addon loss:            40.30210494995117\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06189274787902832\n",
      "    test time:                0.01294088363647461\n",
      "    epoch time:               0.07559800148010254\n",
      "    joint lr:                 0.00235661066873886\n",
      "epoch:  79 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 94.00%\n",
      "    train overall loss:       3.2489412095811634\n",
      "    train cross_ent loss:     0.24773777524630228\n",
      "    test overall loss:        3.2821366786956787\n",
      "    test cross_ent loss:      0.2809473102291425\n",
      "    cluster loss:             2949.6415201822915\n",
      "    separation loss:          4.551586786905925\n",
      "    avg separation loss:      12.838295936584473\n",
      "    l1_addon loss:            39.6422233581543\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.061399221420288086\n",
      "    test time:                0.012758493423461914\n",
      "    epoch time:               0.07493758201599121\n",
      "    joint lr:                 0.001217022281025732\n",
      "epoch:  80 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 93.67%\n",
      "    train overall loss:       3.134061813354492\n",
      "    train cross_ent loss:     0.1328648337059551\n",
      "    test overall loss:        3.2659574349721274\n",
      "    test cross_ent loss:      0.26475361982981366\n",
      "    cluster loss:             2949.6363118489585\n",
      "    separation loss:          4.642170826594035\n",
      "    avg separation loss:      13.249123573303223\n",
      "    l1_addon loss:            40.119476318359375\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06147336959838867\n",
      "    test time:                0.0126190185546875\n",
      "    epoch time:               0.07481145858764648\n",
      "    joint lr:                 0.0001\n",
      "epoch:  81 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 93.67%\n",
      "    train overall loss:       3.1408345699310303\n",
      "    train cross_ent loss:     0.13963119188944498\n",
      "    test overall loss:        3.257182518641154\n",
      "    test cross_ent loss:      0.2559799626469612\n",
      "    cluster loss:             2949.6268717447915\n",
      "    separation loss:          4.628947416941325\n",
      "    avg separation loss:      13.249505678812662\n",
      "    l1_addon loss:            40.080501556396484\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.0615086555480957\n",
      "    test time:                0.012645959854125977\n",
      "    epoch time:               0.07490062713623047\n",
      "    joint lr:                 0.00228958707526664\n",
      "epoch:  82 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 94.67%\n",
      "    train overall loss:       3.1272539297739663\n",
      "    train cross_ent loss:     0.1260585474471251\n",
      "    test overall loss:        3.2530110677083335\n",
      "    test cross_ent loss:      0.2518116235733032\n",
      "    cluster loss:             2949.62548828125\n",
      "    separation loss:          4.246447483698527\n",
      "    avg separation loss:      11.839474360148111\n",
      "    l1_addon loss:            39.977264404296875\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06138777732849121\n",
      "    test time:                0.012684822082519531\n",
      "    epoch time:               0.07476091384887695\n",
      "    joint lr:                 0.004435382409027948\n",
      "epoch:  83 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 93.00%\n",
      "    train overall loss:       3.134276866912842\n",
      "    train cross_ent loss:     0.13307704942093956\n",
      "    test overall loss:        3.2806734244028726\n",
      "    test cross_ent loss:      0.27947068338592845\n",
      "    cluster loss:             2949.6097819010415\n",
      "    separation loss:          4.08937652905782\n",
      "    avg separation loss:      11.427666664123535\n",
      "    l1_addon loss:            40.086700439453125\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06119680404663086\n",
      "    test time:                0.012657642364501953\n",
      "    epoch time:               0.0745999813079834\n",
      "    joint lr:                 0.006538042877406532\n",
      "epoch:  84 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 93.00%\n",
      "    train overall loss:       3.2180439366234674\n",
      "    train cross_ent loss:     0.21684417542484072\n",
      "    test overall loss:        3.288220246632894\n",
      "    test cross_ent loss:      0.2870236237843831\n",
      "    cluster loss:             2949.6449381510415\n",
      "    separation loss:          3.9887208143870034\n",
      "    avg separation loss:      10.771631558736166\n",
      "    l1_addon loss:            39.87995147705078\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.060187578201293945\n",
      "    test time:                0.012130260467529297\n",
      "    epoch time:               0.07300114631652832\n",
      "    joint lr:                 0.008598216598176611\n",
      "epoch:  85 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 90.33%\n",
      "    train overall loss:       3.5365417533450656\n",
      "    train cross_ent loss:     0.5353455096483231\n",
      "    test overall loss:        3.413074254989624\n",
      "    test cross_ent loss:      0.4118817051251729\n",
      "    cluster loss:             2949.7064615885415\n",
      "    separation loss:          4.0781331062316895\n",
      "    avg separation loss:      10.811186154683432\n",
      "    l1_addon loss:            39.74433135986328\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06127810478210449\n",
      "    test time:                0.012190103530883789\n",
      "    epoch time:               0.07417702674865723\n",
      "    joint lr:                 0.010616543040243577\n",
      "epoch:  86 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 89.33%\n",
      "    train overall loss:       3.635815461476644\n",
      "    train cross_ent loss:     0.6346240341663361\n",
      "    test overall loss:        3.6052547295888266\n",
      "    test cross_ent loss:      0.6040497521559397\n",
      "    cluster loss:             2949.8751627604165\n",
      "    separation loss:          5.0517354011535645\n",
      "    avg separation loss:      12.556966781616211\n",
      "    l1_addon loss:            40.1583251953125\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06100273132324219\n",
      "    test time:                0.012635946273803711\n",
      "    epoch time:               0.07440996170043945\n",
      "    joint lr:                 0.012593653131809358\n",
      "epoch:  87 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 86.00%\n",
      "    train overall loss:       3.755179590649075\n",
      "    train cross_ent loss:     0.7539974517292447\n",
      "    test overall loss:        3.940997282663981\n",
      "    test cross_ent loss:      0.9397884408632914\n",
      "    cluster loss:             2950.1097819010415\n",
      "    separation loss:          6.679844220479329\n",
      "    avg separation loss:      16.570161819458008\n",
      "    l1_addon loss:            40.28602981567383\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.060773372650146484\n",
      "    test time:                0.012665987014770508\n",
      "    epoch time:               0.07414364814758301\n",
      "    joint lr:                 0.014530169367239798\n",
      "epoch:  88 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 80.67%\n",
      "    train overall loss:       3.954941511154175\n",
      "    train cross_ent loss:     0.9537594318389893\n",
      "    test overall loss:        4.0339445273081465\n",
      "    test cross_ent loss:      1.032751778761546\n",
      "    cluster loss:             2950.1702473958335\n",
      "    separation loss:          7.075387159983317\n",
      "    avg separation loss:      18.15358034769694\n",
      "    l1_addon loss:            39.75006866455078\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.061547040939331055\n",
      "    test time:                0.012687444686889648\n",
      "    epoch time:               0.07494521141052246\n",
      "    joint lr:                 0.01642670591264845\n",
      "epoch:  89 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 87.00%\n",
      "    train overall loss:       3.938877953423394\n",
      "    train cross_ent loss:     0.9376905891630385\n",
      "    test overall loss:        3.761558691660563\n",
      "    test cross_ent loss:      0.7603675325711569\n",
      "    cluster loss:             2950.124755859375\n",
      "    separation loss:          6.998471736907959\n",
      "    avg separation loss:      17.79677136739095\n",
      "    l1_addon loss:            39.697723388671875\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.0613856315612793\n",
      "    test time:                0.012645244598388672\n",
      "    epoch time:               0.07475686073303223\n",
      "    joint lr:                 0.018283868710212207\n",
      "epoch:  90 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 83.33%\n",
      "    train overall loss:       4.174622164832221\n",
      "    train cross_ent loss:     1.173425601588355\n",
      "    test overall loss:        4.14578104019165\n",
      "    test cross_ent loss:      1.1446035703023274\n",
      "    cluster loss:             2950.81298828125\n",
      "    separation loss:          9.433480898539225\n",
      "    avg separation loss:      23.77003796895345\n",
      "    l1_addon loss:            39.23710250854492\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06043076515197754\n",
      "    test time:                0.012730121612548828\n",
      "    epoch time:               0.07388734817504883\n",
      "    joint lr:                 0.020102255581233422\n",
      "epoch:  91 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 81.33%\n",
      "    train overall loss:       4.273605187733968\n",
      "    train cross_ent loss:     1.2723999818166096\n",
      "    test overall loss:        4.430411020914714\n",
      "    test cross_ent loss:      1.4291889667510986\n",
      "    cluster loss:             2951.5499674479165\n",
      "    separation loss:          11.767675081888834\n",
      "    avg separation loss:      28.292517344156902\n",
      "    l1_addon loss:            40.725460052490234\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06103372573852539\n",
      "    test time:                0.01266622543334961\n",
      "    epoch time:               0.07440471649169922\n",
      "    joint lr:                 0.018912121374150048\n",
      "epoch:  92 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 83.00%\n",
      "    train overall loss:       4.18944517771403\n",
      "    train cross_ent loss:     1.1882243421342638\n",
      "    test overall loss:        4.321309566497803\n",
      "    test cross_ent loss:      1.3200724522272747\n",
      "    cluster loss:             2951.973876953125\n",
      "    separation loss:          12.35413901011149\n",
      "    avg separation loss:      27.110326131184895\n",
      "    l1_addon loss:            41.22423553466797\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06098031997680664\n",
      "    test time:                0.012654542922973633\n",
      "    epoch time:               0.07433795928955078\n",
      "    joint lr:                 0.017743789625650205\n",
      "epoch:  93 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 79.00%\n",
      "    train overall loss:       4.1763777997758655\n",
      "    train cross_ent loss:     1.1751393013530307\n",
      "    test overall loss:        4.327866713205974\n",
      "    test cross_ent loss:      1.3266360759735107\n",
      "    cluster loss:             2952.4694010416665\n",
      "    separation loss:          13.332507451375326\n",
      "    avg separation loss:      27.85549481709798\n",
      "    l1_addon loss:            41.004695892333984\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06055927276611328\n",
      "    test time:                0.012666940689086914\n",
      "    epoch time:               0.07398509979248047\n",
      "    joint lr:                 0.01659694329998293\n",
      "epoch:  94 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 80.67%\n",
      "    train overall loss:       4.526487244500054\n",
      "    train cross_ent loss:     1.52523054016961\n",
      "    test overall loss:        4.100683768590291\n",
      "    test cross_ent loss:      1.0994236667950947\n",
      "    cluster loss:             2952.686767578125\n",
      "    separation loss:          14.487752278645834\n",
      "    avg separation loss:      29.458919525146484\n",
      "    l1_addon loss:            41.99125671386719\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06111788749694824\n",
      "    test time:                0.012680768966674805\n",
      "    epoch time:               0.07454824447631836\n",
      "    joint lr:                 0.01547126952186645\n",
      "epoch:  95 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 80.67%\n",
      "    train overall loss:       4.159045722749498\n",
      "    train cross_ent loss:     1.1577903363439772\n",
      "    test overall loss:        4.028619050979614\n",
      "    test cross_ent loss:      1.0273614923159282\n",
      "    cluster loss:             2952.7063802083335\n",
      "    separation loss:          14.310809771219889\n",
      "    avg separation loss:      29.378803888956707\n",
      "    l1_addon loss:            41.908538818359375\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06154203414916992\n",
      "    test time:                0.012667417526245117\n",
      "    epoch time:               0.07499861717224121\n",
      "    joint lr:                 0.014366459524982304\n",
      "epoch:  96 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 81.67%\n",
      "    train overall loss:       3.9371520943111844\n",
      "    train cross_ent loss:     0.9358961052364774\n",
      "    test overall loss:        3.8701459566752114\n",
      "    test cross_ent loss:      0.868886411190033\n",
      "    cluster loss:             2952.63818359375\n",
      "    separation loss:          13.407589276631674\n",
      "    avg separation loss:      26.149574915568035\n",
      "    l1_addon loss:            41.973724365234375\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06131100654602051\n",
      "    test time:                0.01268315315246582\n",
      "    epoch time:               0.07472681999206543\n",
      "    joint lr:                 0.013282208601083652\n",
      "epoch:  97 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 85.00%\n",
      "    train overall loss:       3.8798789183298745\n",
      "    train cross_ent loss:     0.8786228365368314\n",
      "    test overall loss:        4.092791398366292\n",
      "    test cross_ent loss:      1.0915672381718953\n",
      "    cluster loss:             2952.7806803385415\n",
      "    separation loss:          13.572259585062662\n",
      "    avg separation loss:      24.8625062306722\n",
      "    l1_addon loss:            40.79442596435547\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.0615391731262207\n",
      "    test time:                0.012625694274902344\n",
      "    epoch time:               0.07489967346191406\n",
      "    joint lr:                 0.012218216049710476\n",
      "epoch:  98 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 81.00%\n",
      "    train overall loss:       4.015764607323541\n",
      "    train cross_ent loss:     1.0145222147305806\n",
      "    test overall loss:        4.255794525146484\n",
      "    test cross_ent loss:      1.254515548547109\n",
      "    cluster loss:             2952.6803385416665\n",
      "    separation loss:          13.272464116414389\n",
      "    avg separation loss:      26.141231536865234\n",
      "    l1_addon loss:            42.62675094604492\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06117105484008789\n",
      "    test time:                0.012647867202758789\n",
      "    epoch time:               0.07458043098449707\n",
      "    joint lr:                 0.011174185128504639\n",
      "epoch:  99 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 80.33%\n",
      "    train overall loss:       3.9311367670694985\n",
      "    train cross_ent loss:     0.9298965798483955\n",
      "    test overall loss:        4.192233562469482\n",
      "    test cross_ent loss:      1.1910421053568523\n",
      "    cluster loss:             2952.68310546875\n",
      "    separation loss:          13.547815322875977\n",
      "    avg separation loss:      25.050919850667317\n",
      "    l1_addon loss:            39.70098876953125\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.061109066009521484\n",
      "    test time:                0.012664794921875\n",
      "    epoch time:               0.07450389862060547\n",
      "    joint lr:                 0.010149823004117963\n",
      "epoch: 100 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 87.67%\n",
      "    train overall loss:       3.9741536246405706\n",
      "    train cross_ent loss:     0.9729307823710971\n",
      "    test overall loss:        3.6849964459737143\n",
      "    test cross_ent loss:      0.683770477771759\n",
      "    cluster loss:             2952.216552734375\n",
      "    separation loss:          12.184552510579428\n",
      "    avg separation loss:      24.39443524678548\n",
      "    l1_addon loss:            40.858253479003906\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06089353561401367\n",
      "    test time:                0.012653827667236328\n",
      "    epoch time:               0.07427406311035156\n",
      "    joint lr:                 0.009144840703706159\n",
      "epoch: 101 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 90.33%\n",
      "    train overall loss:       3.6651993062761097\n",
      "    train cross_ent loss:     0.6639737155702379\n",
      "    test overall loss:        3.6789313157399497\n",
      "    test cross_ent loss:      0.6777212719122568\n",
      "    cluster loss:             2952.2298990885415\n",
      "    separation loss:          12.016327540079752\n",
      "    avg separation loss:      22.391656239827473\n",
      "    l1_addon loss:            40.325111389160156\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06089305877685547\n",
      "    test time:                0.01272439956665039\n",
      "    epoch time:               0.07435011863708496\n",
      "    joint lr:                 0.008158953067002189\n",
      "epoch: 102 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 87.00%\n",
      "    train overall loss:       3.524049891365899\n",
      "    train cross_ent loss:     0.5228270822101169\n",
      "    test overall loss:        3.5041943391164145\n",
      "    test cross_ent loss:      0.5029841611782709\n",
      "    cluster loss:             2952.0721842447915\n",
      "    separation loss:          11.292211532592773\n",
      "    avg separation loss:      21.346173604329426\n",
      "    l1_addon loss:            40.3307991027832\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06170034408569336\n",
      "    test time:                0.01266932487487793\n",
      "    epoch time:               0.07508993148803711\n",
      "    joint lr:                 0.0071918786989619305\n",
      "epoch: 103 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 90.67%\n",
      "    train overall loss:       3.45428638988071\n",
      "    train cross_ent loss:     0.4530627214246326\n",
      "    test overall loss:        3.4455788930257163\n",
      "    test cross_ent loss:      0.4443307891488075\n",
      "    cluster loss:             2951.94775390625\n",
      "    separation loss:          10.846666971842447\n",
      "    avg separation loss:      20.652598063151043\n",
      "    l1_addon loss:            41.595054626464844\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06148219108581543\n",
      "    test time:                0.012661457061767578\n",
      "    epoch time:               0.0748748779296875\n",
      "    joint lr:                 0.006243339922975775\n",
      "epoch: 104 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 89.67%\n",
      "    train overall loss:       3.3989339934455023\n",
      "    train cross_ent loss:     0.3977003080977334\n",
      "    test overall loss:        3.4307393232981362\n",
      "    test cross_ent loss:      0.4294896175463994\n",
      "    cluster loss:             2951.9248860677085\n",
      "    separation loss:          10.358617146809896\n",
      "    avg separation loss:      18.663492838541668\n",
      "    l1_addon loss:            41.65082550048828\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06146121025085449\n",
      "    test time:                0.01264190673828125\n",
      "    epoch time:               0.07485008239746094\n",
      "    joint lr:                 0.005313062734639446\n",
      "epoch: 105 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 93.67%\n",
      "    train overall loss:       3.357545985115899\n",
      "    train cross_ent loss:     0.35631418393717873\n",
      "    test overall loss:        3.3318862915039062\n",
      "    test cross_ent loss:      0.3306598737835884\n",
      "    cluster loss:             2951.8642578125\n",
      "    separation loss:          10.108426411946615\n",
      "    avg separation loss:      18.19001007080078\n",
      "    l1_addon loss:            40.87542724609375\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.061452627182006836\n",
      "    test time:                0.012613058090209961\n",
      "    epoch time:               0.0747833251953125\n",
      "    joint lr:                 0.004400776756077547\n",
      "epoch: 106 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       3.252658075756497\n",
      "    train cross_ent loss:     0.25142945183648\n",
      "    test overall loss:        3.2429332733154297\n",
      "    test cross_ent loss:      0.24170348172386488\n",
      "    cluster loss:             2951.8043619791665\n",
      "    separation loss:          9.941274960835775\n",
      "    avg separation loss:      17.812942504882812\n",
      "    l1_addon loss:            40.98261260986328\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.0612034797668457\n",
      "    test time:                0.012642383575439453\n",
      "    epoch time:               0.07458639144897461\n",
      "    joint lr:                 0.0035062151908134102\n",
      "epoch: 107 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 94.00%\n",
      "    train overall loss:       3.1257494025760226\n",
      "    train cross_ent loss:     0.1245164391067293\n",
      "    test overall loss:        3.2422834237416587\n",
      "    test cross_ent loss:      0.24105510612328848\n",
      "    cluster loss:             2951.7996419270835\n",
      "    separation loss:          9.731829007466635\n",
      "    avg separation loss:      17.081891377766926\n",
      "    l1_addon loss:            40.933773040771484\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06096243858337402\n",
      "    test time:                0.012686967849731445\n",
      "    epoch time:               0.0744173526763916\n",
      "    joint lr:                 0.0026291147791789593\n",
      "epoch: 108 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 94.00%\n",
      "    train overall loss:       3.0988765822516546\n",
      "    train cross_ent loss:     0.09764630140529738\n",
      "    test overall loss:        3.2235308488210044\n",
      "    test cross_ent loss:      0.22230179607868195\n",
      "    cluster loss:             2951.76953125\n",
      "    separation loss:          9.51943270365397\n",
      "    avg separation loss:      16.70689582824707\n",
      "    l1_addon loss:            40.9610595703125\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.060945749282836914\n",
      "    test time:                0.012664318084716797\n",
      "    epoch time:               0.07434844970703125\n",
      "    joint lr:                 0.001769215754258106\n",
      "epoch: 109 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       3.08099635442098\n",
      "    train cross_ent loss:     0.07976816760169135\n",
      "    test overall loss:        3.2026487986246743\n",
      "    test cross_ent loss:      0.2014214297135671\n",
      "    cluster loss:             2951.7613118489585\n",
      "    separation loss:          9.461110750834147\n",
      "    avg separation loss:      16.486522038777668\n",
      "    l1_addon loss:            40.907901763916016\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.060891151428222656\n",
      "    test time:                0.012641668319702148\n",
      "    epoch time:               0.07422852516174316\n",
      "    joint lr:                 0.0009262617983577627\n",
      "epoch: 110 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       3.0544745922088623\n",
      "    train cross_ent loss:     0.053248743216196694\n",
      "    test overall loss:        3.2068891525268555\n",
      "    test cross_ent loss:      0.20566179851690927\n",
      "    cluster loss:             2951.7665201822915\n",
      "    separation loss:          9.4171511332194\n",
      "    avg separation loss:      16.29910119374593\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06002235412597656\n",
      "    test time:                0.012663602828979492\n",
      "    epoch time:               0.07341933250427246\n",
      "    joint lr:                 0.0001\n",
      "epoch: 110 (PUSH) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       3.0544745922088623\n",
      "    train cross_ent loss:     0.053248743216196694\n",
      "    test overall loss:        3.1893018881479898\n",
      "    test cross_ent loss:      0.1880744956433773\n",
      "    cluster loss:             2949.3167317708335\n",
      "    separation loss:          2.7434701919555664\n",
      "    avg separation loss:      8.17701244354248\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.06002235412597656\n",
      "    test time:                0.012981653213500977\n",
      "    epoch time:               0.41595888137817383\n",
      "epoch: 110 (1/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       3.0706572797563343\n",
      "    train cross_ent loss:     0.07163218243254556\n",
      "    test overall loss:        3.1807123819986978\n",
      "    test cross_ent loss:      0.18428529302279154\n",
      "    cluster loss:             2949.31689453125\n",
      "    separation loss:          2.7524096171061196\n",
      "    avg separation loss:      8.225862185160318\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  2995.19970703125\n",
      "    train time:               0.024858951568603516\n",
      "    test time:                0.012627363204956055\n",
      "    epoch time:               0.03801417350769043\n",
      "    last layer lr:            0.0007599999999999978\n",
      "epoch: 110 (2/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       3.051629278394911\n",
      "    train cross_ent loss:     0.07004211967190106\n",
      "    test overall loss:        3.1471376419067383\n",
      "    test cross_ent loss:      0.18400432107349238\n",
      "    cluster loss:             2949.3169759114585\n",
      "    separation loss:          2.7372612953186035\n",
      "    avg separation loss:      8.170220057169596\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  2961.906005859375\n",
      "    train time:               0.024144649505615234\n",
      "    test time:                0.01257944107055664\n",
      "    epoch time:               0.037241458892822266\n",
      "    last layer lr:            0.0014200000000000013\n",
      "epoch: 110 (3/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       2.9972708225250244\n",
      "    train cross_ent loss:     0.06129498676293426\n",
      "    test overall loss:        3.080739657084147\n",
      "    test cross_ent loss:      0.17911972664296627\n",
      "    cluster loss:             2949.3173828125\n",
      "    separation loss:          2.7358973026275635\n",
      "    avg separation loss:      8.185307343800863\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  2900.392578125\n",
      "    train time:               0.024131059646606445\n",
      "    test time:                0.012580394744873047\n",
      "    epoch time:               0.03722357749938965\n",
      "    last layer lr:            0.0020799999999999985\n",
      "epoch: 110 (4/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       2.9432747628953724\n",
      "    train cross_ent loss:     0.0823182196666797\n",
      "    test overall loss:        2.9868125120798745\n",
      "    test cross_ent loss:      0.1765812455366055\n",
      "    cluster loss:             2949.3175455729165\n",
      "    separation loss:          2.748048941294352\n",
      "    avg separation loss:      8.228623231252035\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  2809.00390625\n",
      "    train time:               0.02417922019958496\n",
      "    test time:                0.01256871223449707\n",
      "    epoch time:               0.03726482391357422\n",
      "    last layer lr:            0.0027400000000000024\n",
      "epoch: 110 (5/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       2.816143353780111\n",
      "    train cross_ent loss:     0.05845359029869238\n",
      "    test overall loss:        2.8697309494018555\n",
      "    test cross_ent loss:      0.1783422908435265\n",
      "    cluster loss:             2949.3169759114585\n",
      "    separation loss:          2.737373193105062\n",
      "    avg separation loss:      8.182219664255777\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  2690.161376953125\n",
      "    train time:               0.024330854415893555\n",
      "    test time:                0.012583017349243164\n",
      "    epoch time:               0.03743290901184082\n",
      "    last layer lr:            0.0034\n",
      "epoch: 110 (6/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       2.6853813330332437\n",
      "    train cross_ent loss:     0.06008462711340851\n",
      "    test overall loss:        2.7266156673431396\n",
      "    test cross_ent loss:      0.18443201606472334\n",
      "    cluster loss:             2949.3170572916665\n",
      "    separation loss:          2.748847166697184\n",
      "    avg separation loss:      8.211690902709961\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  2540.956298828125\n",
      "    train time:               0.02421736717224121\n",
      "    test time:                0.012546539306640625\n",
      "    epoch time:               0.03727555274963379\n",
      "    last layer lr:            0.004059999999999998\n",
      "epoch: 110 (7/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       2.5283857186635337\n",
      "    train cross_ent loss:     0.0652517852269941\n",
      "    test overall loss:        2.55037784576416\n",
      "    test cross_ent loss:      0.18651175747315088\n",
      "    cluster loss:             2949.31640625\n",
      "    separation loss:          2.7403361002604165\n",
      "    avg separation loss:      8.165239016215006\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  2362.638916015625\n",
      "    train time:               0.02414226531982422\n",
      "    test time:                0.012570619583129883\n",
      "    epoch time:               0.03723573684692383\n",
      "    last layer lr:            0.004720000000000002\n",
      "epoch: 110 (8/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       2.3464094267951117\n",
      "    train cross_ent loss:     0.07553565750519435\n",
      "    test overall loss:        2.3506363232930503\n",
      "    test cross_ent loss:      0.19581298778454462\n",
      "    cluster loss:             2949.316650390625\n",
      "    separation loss:          2.7518386840820312\n",
      "    avg separation loss:      8.216065883636475\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  2153.595947265625\n",
      "    train time:               0.024180889129638672\n",
      "    test time:                0.012588977813720703\n",
      "    epoch time:               0.03728437423706055\n",
      "    last layer lr:            0.005379999999999999\n",
      "epoch: 110 (9/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       2.1423354943593345\n",
      "    train cross_ent loss:     0.09028487528363864\n",
      "    test overall loss:        2.124963084856669\n",
      "    test cross_ent loss:      0.1998794712126255\n",
      "    cluster loss:             2949.3173014322915\n",
      "    separation loss:          2.753416140874227\n",
      "    avg separation loss:      8.229461510976156\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  1923.8564453125\n",
      "    train time:               0.02423572540283203\n",
      "    test time:                0.01257634162902832\n",
      "    epoch time:               0.03733968734741211\n",
      "    last layer lr:            0.006040000000000003\n",
      "epoch: 110 (10/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       1.9020890129937067\n",
      "    train cross_ent loss:     0.09315119518174066\n",
      "    test overall loss:        1.8760964473088582\n",
      "    test cross_ent loss:      0.21020840977629027\n",
      "    cluster loss:             2949.317138671875\n",
      "    separation loss:          2.745502789815267\n",
      "    avg separation loss:      8.208142439524332\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  1664.660888671875\n",
      "    train time:               0.024149656295776367\n",
      "    test time:                0.012576818466186523\n",
      "    epoch time:               0.03724050521850586\n",
      "    last layer lr:            0.0067\n",
      "epoch: 110 (11/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       1.6364978949228923\n",
      "    train cross_ent loss:     0.09213016202880277\n",
      "    test overall loss:        1.6044073899586995\n",
      "    test cross_ent loss:      0.21400673811634383\n",
      "    cluster loss:             2949.3170572916665\n",
      "    separation loss:          2.7406596342722573\n",
      "    avg separation loss:      8.183899561564127\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  1389.173583984375\n",
      "    train time:               0.024160146713256836\n",
      "    test time:                0.012565374374389648\n",
      "    epoch time:               0.037241458892822266\n",
      "    last layer lr:            0.0073599999999999985\n",
      "epoch: 110 (12/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       1.3478796614540949\n",
      "    train cross_ent loss:     0.09697939745253986\n",
      "    test overall loss:        1.311409592628479\n",
      "    test cross_ent loss:      0.23510433857639632\n",
      "    cluster loss:             2949.3174641927085\n",
      "    separation loss:          2.742207129796346\n",
      "    avg separation loss:      8.194305896759033\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  1075.0782470703125\n",
      "    train time:               0.02425217628479004\n",
      "    test time:                0.012644052505493164\n",
      "    epoch time:               0.037407875061035156\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 110 (13/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       1.035478459464179\n",
      "    train cross_ent loss:     0.10640800495942433\n",
      "    test overall loss:        0.9952362179756165\n",
      "    test cross_ent loss:      0.2496498922506968\n",
      "    cluster loss:             2949.31787109375\n",
      "    separation loss:          2.7462169329325357\n",
      "    avg separation loss:      8.213930606842041\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  744.3592529296875\n",
      "    train time:               0.024399280548095703\n",
      "    test time:                0.012594461441040039\n",
      "    epoch time:               0.03751206398010254\n",
      "    last layer lr:            0.008679999999999998\n",
      "epoch: 110 (14/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.7009065018759834\n",
      "    train cross_ent loss:     0.11426809968219863\n",
      "    test overall loss:        0.6621053119500478\n",
      "    test cross_ent loss:      0.2599019557237625\n",
      "    cluster loss:             2949.31787109375\n",
      "    separation loss:          2.7628920873006186\n",
      "    avg separation loss:      8.27693239847819\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  400.976318359375\n",
      "    train time:               0.024144649505615234\n",
      "    test time:                0.01256561279296875\n",
      "    epoch time:               0.03722119331359863\n",
      "    last layer lr:            0.009340000000000003\n",
      "epoch: 110 (15/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.41751908262570697\n",
      "    train cross_ent loss:     0.12453143050273259\n",
      "    test overall loss:        0.4377273718516032\n",
      "    test cross_ent loss:      0.2550697724024455\n",
      "    cluster loss:             2949.3177897135415\n",
      "    separation loss:          2.752448081970215\n",
      "    avg separation loss:      8.241302649180094\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  181.43055725097656\n",
      "    train time:               0.024199962615966797\n",
      "    test time:                0.012602090835571289\n",
      "    epoch time:               0.03731656074523926\n",
      "    last layer lr:            0.01\n",
      "epoch: 110 (16/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.26474395394325256\n",
      "    train cross_ent loss:     0.12374792496363322\n",
      "    test overall loss:        0.33684414128462475\n",
      "    test cross_ent loss:      0.23409441113471985\n",
      "    cluster loss:             2949.3175455729165\n",
      "    separation loss:          2.7428433100382485\n",
      "    avg separation loss:      8.200777212778727\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  101.52267456054688\n",
      "    train time:               0.024201154708862305\n",
      "    test time:                0.012575864791870117\n",
      "    epoch time:               0.03729414939880371\n",
      "    last layer lr:            0.009604000000000001\n",
      "epoch: 110 (17/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.1889847293496132\n",
      "    train cross_ent loss:     0.10313139648901092\n",
      "    test overall loss:        0.27477369209130603\n",
      "    test cross_ent loss:      0.20932448779543242\n",
      "    cluster loss:             2949.3173014322915\n",
      "    separation loss:          2.7395801544189453\n",
      "    avg separation loss:      8.179956912994385\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  64.22215270996094\n",
      "    train time:               0.024315834045410156\n",
      "    test time:                0.012572765350341797\n",
      "    epoch time:               0.03740739822387695\n",
      "    last layer lr:            0.009208\n",
      "epoch: 110 (18/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.12808779130379358\n",
      "    train cross_ent loss:     0.07536159062551127\n",
      "    test overall loss:        0.23885610202948251\n",
      "    test cross_ent loss:      0.19984289755423865\n",
      "    cluster loss:             2949.3168131510415\n",
      "    separation loss:          2.7472547690073648\n",
      "    avg separation loss:      8.194003105163574\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  37.78615951538086\n",
      "    train time:               0.02439427375793457\n",
      "    test time:                0.012603521347045898\n",
      "    epoch time:               0.03751730918884277\n",
      "    last layer lr:            0.008812\n",
      "epoch: 110 (19/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.10667251216040717\n",
      "    train cross_ent loss:     0.07314184287356006\n",
      "    test overall loss:        0.22090563674767813\n",
      "    test cross_ent loss:      0.1938875230650107\n",
      "    cluster loss:             2949.318115234375\n",
      "    separation loss:          2.7561120986938477\n",
      "    avg separation loss:      8.224421819051107\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  25.79106330871582\n",
      "    train time:               0.025036096572875977\n",
      "    test time:                0.012920379638671875\n",
      "    epoch time:               0.03850913047790527\n",
      "    last layer lr:            0.008415999999999998\n",
      "epoch: 110 (20/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.09195857163932589\n",
      "    train cross_ent loss:     0.06807696177727646\n",
      "    test overall loss:        0.20592431724071503\n",
      "    test cross_ent loss:      0.1863336426516374\n",
      "    cluster loss:             2949.3177083333335\n",
      "    separation loss:          2.7466635704040527\n",
      "    avg separation loss:      8.206110000610352\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  18.363632202148438\n",
      "    train time:               0.0238339900970459\n",
      "    test time:                0.012596845626831055\n",
      "    epoch time:               0.036948204040527344\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 110 (21/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       0.08311125470532311\n",
      "    train cross_ent loss:     0.06420495195521249\n",
      "    test overall loss:        0.19798270364602408\n",
      "    test cross_ent loss:      0.18110369270046553\n",
      "    cluster loss:             2949.317626953125\n",
      "    separation loss:          2.751619895299276\n",
      "    avg separation loss:      8.226612567901611\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  15.65196418762207\n",
      "    train time:               0.023732662200927734\n",
      "    test time:                0.012581825256347656\n",
      "    epoch time:               0.036818504333496094\n",
      "    last layer lr:            0.007624000000000002\n",
      "epoch: 110 (22/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.07734164223074913\n",
      "    train cross_ent loss:     0.06200465001165867\n",
      "    test overall loss:        0.19175509115060171\n",
      "    test cross_ent loss:      0.1776023730635643\n",
      "    cluster loss:             2949.3177083333335\n",
      "    separation loss:          2.7533035278320312\n",
      "    avg separation loss:      8.238279978434244\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  12.925676345825195\n",
      "    train time:               0.027409791946411133\n",
      "    test time:                0.012597322463989258\n",
      "    epoch time:               0.04051375389099121\n",
      "    last layer lr:            0.007228000000000001\n",
      "epoch: 110 (23/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.0716002384821574\n",
      "    train cross_ent loss:     0.05750243924558163\n",
      "    test overall loss:        0.18787739425897598\n",
      "    test cross_ent loss:      0.17515816042820612\n",
      "    cluster loss:             2949.3174641927085\n",
      "    separation loss:          2.7462716102600098\n",
      "    avg separation loss:      8.19601821899414\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  11.492193222045898\n",
      "    train time:               0.023752689361572266\n",
      "    test time:                0.012669563293457031\n",
      "    epoch time:               0.03692626953125\n",
      "    last layer lr:            0.006832000000000001\n",
      "epoch: 110 (24/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.0948181872566541\n",
      "    train cross_ent loss:     0.08300341438088152\n",
      "    test overall loss:        0.1869551328321298\n",
      "    test cross_ent loss:      0.17413363854090372\n",
      "    cluster loss:             2949.3179524739585\n",
      "    separation loss:          2.7282326221466064\n",
      "    avg separation loss:      8.14317544301351\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  11.59445571899414\n",
      "    train time:               0.0237576961517334\n",
      "    test time:                0.012628555297851562\n",
      "    epoch time:               0.03688764572143555\n",
      "    last layer lr:            0.006436\n",
      "epoch: 110 (25/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.06889416318800715\n",
      "    train cross_ent loss:     0.05492332370744811\n",
      "    test overall loss:        0.1833844929933548\n",
      "    test cross_ent loss:      0.17114603271087012\n",
      "    cluster loss:             2949.3173014322915\n",
      "    separation loss:          2.7358744939168296\n",
      "    avg separation loss:      8.165544668833414\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  11.011415481567383\n",
      "    train time:               0.02382636070251465\n",
      "    test time:                0.012546777725219727\n",
      "    epoch time:               0.03688311576843262\n",
      "    last layer lr:            0.00604\n",
      "epoch: 110 (26/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       0.07081001872817676\n",
      "    train cross_ent loss:     0.05872220959928301\n",
      "    test overall loss:        0.17902414997418722\n",
      "    test cross_ent loss:      0.16820595661799112\n",
      "    cluster loss:             2949.3177083333335\n",
      "    separation loss:          2.75555419921875\n",
      "    avg separation loss:      8.242915630340576\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  9.591148376464844\n",
      "    train time:               0.02369856834411621\n",
      "    test time:                0.012552976608276367\n",
      "    epoch time:               0.036752939224243164\n",
      "    last layer lr:            0.005644000000000002\n",
      "epoch: 110 (27/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.06273091874188846\n",
      "    train cross_ent loss:     0.05262562337641915\n",
      "    test overall loss:        0.17604759335517883\n",
      "    test cross_ent loss:      0.16650955006480217\n",
      "    cluster loss:             2949.3177083333335\n",
      "    separation loss:          2.7600913047790527\n",
      "    avg separation loss:      8.252474149068197\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  8.31100082397461\n",
      "    train time:               0.023728609085083008\n",
      "    test time:                0.012575864791870117\n",
      "    epoch time:               0.036808013916015625\n",
      "    last layer lr:            0.005248\n",
      "epoch: 110 (28/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.05909626392854585\n",
      "    train cross_ent loss:     0.05057301858647002\n",
      "    test overall loss:        0.1727962133785089\n",
      "    test cross_ent loss:      0.16505059972405434\n",
      "    cluster loss:             2949.3173014322915\n",
      "    separation loss:          2.748732566833496\n",
      "    avg separation loss:      8.210369427998861\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  6.518570899963379\n",
      "    train time:               0.023669958114624023\n",
      "    test time:                0.012585163116455078\n",
      "    epoch time:               0.0367588996887207\n",
      "    last layer lr:            0.004852000000000001\n",
      "epoch: 110 (29/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.06898987831340896\n",
      "    train cross_ent loss:     0.061184212358461484\n",
      "    test overall loss:        0.17306135594844818\n",
      "    test cross_ent loss:      0.16527583574255308\n",
      "    cluster loss:             2949.3179524739585\n",
      "    separation loss:          2.753026803334554\n",
      "    avg separation loss:      8.20837116241455\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  6.558481216430664\n",
      "    train time:               0.02393198013305664\n",
      "    test time:                0.012581586837768555\n",
      "    epoch time:               0.03702282905578613\n",
      "    last layer lr:            0.004455999999999999\n",
      "epoch: 110 (30/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.06215589493513107\n",
      "    train cross_ent loss:     0.054245769770609006\n",
      "    test overall loss:        0.17123998204867044\n",
      "    test cross_ent loss:      0.16391263405481973\n",
      "    cluster loss:             2949.317138671875\n",
      "    separation loss:          2.7422983646392822\n",
      "    avg separation loss:      8.177163283030191\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  6.100310325622559\n",
      "    train time:               0.023721933364868164\n",
      "    test time:                0.012550830841064453\n",
      "    epoch time:               0.036777496337890625\n",
      "    last layer lr:            0.004060000000000001\n",
      "epoch: 110 (31/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.05330232882665263\n",
      "    train cross_ent loss:     0.046476754566861525\n",
      "    test overall loss:        0.1676702524224917\n",
      "    test cross_ent loss:      0.16162777319550514\n",
      "    cluster loss:             2949.3173014322915\n",
      "    separation loss:          2.7456342379252114\n",
      "    avg separation loss:      8.197836558024088\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  4.815442085266113\n",
      "    train time:               0.023669004440307617\n",
      "    test time:                0.012557506561279297\n",
      "    epoch time:               0.03672504425048828\n",
      "    last layer lr:            0.0036640000000000015\n",
      "epoch: 110 (32/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.06397042920192082\n",
      "    train cross_ent loss:     0.0583786710889803\n",
      "    test overall loss:        0.16512598966558775\n",
      "    test cross_ent loss:      0.15958561499913534\n",
      "    cluster loss:             2949.3168131510415\n",
      "    separation loss:          2.758289178212484\n",
      "    avg separation loss:      8.244370937347412\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  4.313331127166748\n",
      "    train time:               0.023679494857788086\n",
      "    test time:                0.012834548950195312\n",
      "    epoch time:               0.03701925277709961\n",
      "    last layer lr:            0.0032679999999999996\n",
      "epoch: 110 (33/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.06280230854948361\n",
      "    train cross_ent loss:     0.05673656923075517\n",
      "    test overall loss:        0.1652565784752369\n",
      "    test cross_ent loss:      0.15955722704529762\n",
      "    cluster loss:             2949.3174641927085\n",
      "    separation loss:          2.7627085049947104\n",
      "    avg separation loss:      8.249539057413736\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  4.47231388092041\n",
      "    train time:               0.023945331573486328\n",
      "    test time:                0.012614727020263672\n",
      "    epoch time:               0.037070274353027344\n",
      "    last layer lr:            0.002872000000000001\n",
      "epoch: 110 (34/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.06351262869106399\n",
      "    train cross_ent loss:     0.058236598347624145\n",
      "    test overall loss:        0.16370217874646187\n",
      "    test cross_ent loss:      0.15888561556736627\n",
      "    cluster loss:             2949.3172200520835\n",
      "    separation loss:          2.7567899227142334\n",
      "    avg separation loss:      8.231286843617758\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  3.5895309448242188\n",
      "    train time:               0.023726463317871094\n",
      "    test time:                0.012634515762329102\n",
      "    epoch time:               0.036861419677734375\n",
      "    last layer lr:            0.0024759999999999986\n",
      "epoch: 110 (35/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.058090428097380534\n",
      "    train cross_ent loss:     0.05334859465559324\n",
      "    test overall loss:        0.1625881977379322\n",
      "    test cross_ent loss:      0.15820403893788657\n",
      "    cluster loss:             2949.3168131510415\n",
      "    separation loss:          2.7493484814961753\n",
      "    avg separation loss:      8.205670833587646\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  3.157118320465088\n",
      "    train time:               0.02369546890258789\n",
      "    test time:                0.012564420700073242\n",
      "    epoch time:               0.03675675392150879\n",
      "    last layer lr:            0.0020800000000000003\n",
      "epoch: 110 (36/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.04769010821150409\n",
      "    train cross_ent loss:     0.04345521806842751\n",
      "    test overall loss:        0.16239412253101668\n",
      "    test cross_ent loss:      0.15844926362236342\n",
      "    cluster loss:             2949.3169759114585\n",
      "    separation loss:          2.7506779034932456\n",
      "    avg separation loss:      8.208234151204428\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  2.717822551727295\n",
      "    train time:               0.02370142936706543\n",
      "    test time:                0.012590885162353516\n",
      "    epoch time:               0.03679323196411133\n",
      "    last layer lr:            0.0016840000000000017\n",
      "epoch: 110 (37/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.05255104642775324\n",
      "    train cross_ent loss:     0.0488437180303865\n",
      "    test overall loss:        0.15975180392464003\n",
      "    test cross_ent loss:      0.1563249553243319\n",
      "    cluster loss:             2949.3172200520835\n",
      "    separation loss:          2.74979305267334\n",
      "    avg separation loss:      8.22386916478475\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  2.1998090744018555\n",
      "    train time:               0.0239717960357666\n",
      "    test time:                0.012582778930664062\n",
      "    epoch time:               0.03706192970275879\n",
      "    last layer lr:            0.0012879999999999994\n",
      "epoch: 110 (38/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.05221542322801219\n",
      "    train cross_ent loss:     0.04907419946458605\n",
      "    test overall loss:        0.15874874964356422\n",
      "    test cross_ent loss:      0.15585169568657875\n",
      "    cluster loss:             2949.3170572916665\n",
      "    separation loss:          2.760589917500814\n",
      "    avg separation loss:      8.246086120605469\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  1.670018196105957\n",
      "    train time:               0.023764848709106445\n",
      "    test time:                0.012543439865112305\n",
      "    epoch time:               0.03681445121765137\n",
      "    last layer lr:            0.0008920000000000009\n",
      "epoch: 110 (39/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.04549381178286341\n",
      "    train cross_ent loss:     0.042878557824426226\n",
      "    test overall loss:        0.1593435158332189\n",
      "    test cross_ent loss:      0.15696478448808193\n",
      "    cluster loss:             2949.3167317708335\n",
      "    separation loss:          2.7484747568766275\n",
      "    avg separation loss:      8.20085350672404\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  1.1516923904418945\n",
      "    train time:               0.023693561553955078\n",
      "    test time:                0.012546777725219727\n",
      "    epoch time:               0.03674459457397461\n",
      "    last layer lr:            0.0004959999999999986\n",
      "epoch: 110 (40/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.05925165189223157\n",
      "    train cross_ent loss:     0.05707618004331986\n",
      "    test overall loss:        0.1578381583094597\n",
      "    test cross_ent loss:      0.15576400607824326\n",
      "    cluster loss:             2949.3175455729165\n",
      "    separation loss:          2.754920721054077\n",
      "    avg separation loss:      8.246437549591064\n",
      "    l1_addon loss:            40.90126419067383\n",
      "    l1 loss:                  0.847114086151123\n",
      "    train time:               0.023717880249023438\n",
      "    test time:                0.012593746185302734\n",
      "    epoch time:               0.03681230545043945\n",
      "    last layer lr:            0.0001\n",
      "epoch: 111 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.04810478010525306\n",
      "    train cross_ent loss:     0.046030306878189244\n",
      "    test overall loss:        0.15890035405755043\n",
      "    test cross_ent loss:      0.1568257094671329\n",
      "    cluster loss:             2949.31689453125\n",
      "    separation loss:          2.7462944189707437\n",
      "    avg separation loss:      8.220041116078695\n",
      "    l1_addon loss:            40.91767120361328\n",
      "    l1 loss:                  0.847114086151123\n",
      "    train time:               0.05930829048156738\n",
      "    test time:                0.012707710266113281\n",
      "    epoch time:               0.07279038429260254\n",
      "    joint lr:                 0.0017196383771408863\n",
      "epoch: 112 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.03627840615808964\n",
      "    train cross_ent loss:     0.03420304310404592\n",
      "    test overall loss:        0.153982013463974\n",
      "    test cross_ent loss:      0.15190747318168482\n",
      "    cluster loss:             2949.3041178385415\n",
      "    separation loss:          2.673417409261068\n",
      "    avg separation loss:      8.065425554911295\n",
      "    l1_addon loss:            40.91425323486328\n",
      "    l1 loss:                  0.847114086151123\n",
      "    train time:               0.058873653411865234\n",
      "    test time:                0.012638568878173828\n",
      "    epoch time:               0.07229471206665039\n",
      "    joint lr:                 0.0033068839867389757\n",
      "epoch: 113 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.07884262274536821\n",
      "    train cross_ent loss:     0.07676916010677814\n",
      "    test overall loss:        0.15748177717129389\n",
      "    test cross_ent loss:      0.15541061821083227\n",
      "    cluster loss:             2949.2992350260415\n",
      "    separation loss:          2.6072566509246826\n",
      "    avg separation loss:      7.7754998207092285\n",
      "    l1_addon loss:            40.80162811279297\n",
      "    l1 loss:                  0.847114086151123\n",
      "    train time:               0.058843135833740234\n",
      "    test time:                0.012654781341552734\n",
      "    epoch time:               0.07230377197265625\n",
      "    joint lr:                 0.0048622227203073696\n",
      "epoch: 114 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 93.00%\n",
      "    train overall loss:       0.1912231780588627\n",
      "    train cross_ent loss:     0.18915216102161342\n",
      "    test overall loss:        0.2769107849647601\n",
      "    test cross_ent loss:      0.27482422937949497\n",
      "    cluster loss:             2949.4226888020835\n",
      "    separation loss:          3.0178373654683432\n",
      "    avg separation loss:      8.76746654510498\n",
      "    l1_addon loss:            41.3150749206543\n",
      "    l1 loss:                  0.847114086151123\n",
      "    train time:               0.05911135673522949\n",
      "    test time:                0.012649059295654297\n",
      "    epoch time:               0.07255434989929199\n",
      "    joint lr:                 0.00638613399080572\n",
      "epoch: 115 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.16590869261158836\n",
      "    train cross_ent loss:     0.16384210768673155\n",
      "    test overall loss:        0.23241156339645386\n",
      "    test cross_ent loss:      0.2303654352823893\n",
      "    cluster loss:             2949.4261067708335\n",
      "    separation loss:          3.079966942469279\n",
      "    avg separation loss:      8.063507239023844\n",
      "    l1_addon loss:            39.9672737121582\n",
      "    l1 loss:                  0.847114086151123\n",
      "    train time:               0.05930590629577637\n",
      "    test time:                0.012845516204833984\n",
      "    epoch time:               0.07297945022583008\n",
      "    joint lr:                 0.007879090813622073\n",
      "epoch: 116 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       0.3364397622644901\n",
      "    train cross_ent loss:     0.3344018595914046\n",
      "    test overall loss:        0.2885420123736064\n",
      "    test cross_ent loss:      0.2865095833937327\n",
      "    cluster loss:             2949.5525716145835\n",
      "    separation loss:          4.026351769765218\n",
      "    avg separation loss:      10.361631393432617\n",
      "    l1_addon loss:            39.51051330566406\n",
      "    l1 loss:                  0.847114086151123\n",
      "    train time:               0.059064388275146484\n",
      "    test time:                0.012704133987426758\n",
      "    epoch time:               0.07253575325012207\n",
      "    joint lr:                 0.009341559886583039\n",
      "epoch: 117 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.43153513471285504\n",
      "    train cross_ent loss:     0.4294954405890571\n",
      "    test overall loss:        0.45464510718981427\n",
      "    test cross_ent loss:      0.45258985956509906\n",
      "    cluster loss:             2949.6805013020835\n",
      "    separation loss:          4.355495611826579\n",
      "    avg separation loss:      11.052173296610514\n",
      "    l1_addon loss:            40.27187728881836\n",
      "    l1 loss:                  0.847114086151123\n",
      "    train time:               0.05886697769165039\n",
      "    test time:                0.012620687484741211\n",
      "    epoch time:               0.07229232788085938\n",
      "    joint lr:                 0.010774001669003403\n",
      "epoch: 118 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 89.67%\n",
      "    train overall loss:       0.524227499961853\n",
      "    train cross_ent loss:     0.5221898522641923\n",
      "    test overall loss:        0.6940258940060934\n",
      "    test cross_ent loss:      0.692010243733724\n",
      "    cluster loss:             2949.8778483072915\n",
      "    separation loss:          5.196812152862549\n",
      "    avg separation loss:      12.684354464213053\n",
      "    l1_addon loss:            38.95216369628906\n",
      "    l1 loss:                  0.847114086151123\n",
      "    train time:               0.05889177322387695\n",
      "    test time:                0.012655258178710938\n",
      "    epoch time:               0.07233142852783203\n",
      "    joint lr:                 0.012176870459786701\n",
      "epoch: 119 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.42264300253656173\n",
      "    train cross_ent loss:     0.42060084144274396\n",
      "    test overall loss:        0.47009362777074176\n",
      "    test cross_ent loss:      0.4680427511533101\n",
      "    cluster loss:             2949.900634765625\n",
      "    separation loss:          5.324261983235677\n",
      "    avg separation loss:      12.713109652201334\n",
      "    l1_addon loss:            40.12549591064453\n",
      "    l1 loss:                  0.847114086151123\n",
      "    train time:               0.058815956115722656\n",
      "    test time:                0.012642383575439453\n",
      "    epoch time:               0.07225584983825684\n",
      "    joint lr:                 0.013550614474587434\n",
      "epoch: 120 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 81.33%\n",
      "    train overall loss:       0.4568822847472297\n",
      "    train cross_ent loss:     0.454836153321796\n",
      "    test overall loss:        1.072708010673523\n",
      "    test cross_ent loss:      1.0706205169359844\n",
      "    cluster loss:             2950.2462565104165\n",
      "    separation loss:          5.690442403157552\n",
      "    avg separation loss:      13.637506484985352\n",
      "    l1_addon loss:            41.34715270996094\n",
      "    l1 loss:                  0.847114086151123\n",
      "    train time:               0.05902457237243652\n",
      "    test time:                0.012682914733886719\n",
      "    epoch time:               0.07247567176818848\n",
      "    joint lr:                 0.014895675922046181\n",
      "epoch: 121 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 84.33%\n",
      "    train overall loss:       0.8134038911925422\n",
      "    train cross_ent loss:     0.8113548689418368\n",
      "    test overall loss:        0.9500798185666403\n",
      "    test cross_ent loss:      0.9480517506599426\n",
      "    cluster loss:             2950.411865234375\n",
      "    separation loss:          6.743928750356038\n",
      "    avg separation loss:      14.64116382598877\n",
      "    l1_addon loss:            39.365535736083984\n",
      "    l1 loss:                  0.847114086151123\n",
      "    train time:               0.05881857872009277\n",
      "    test time:                0.012642383575439453\n",
      "    epoch time:               0.07221627235412598\n",
      "    joint lr:                 0.014015333204684437\n",
      "epoch: 122 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 89.00%\n",
      "    train overall loss:       0.750109980503718\n",
      "    train cross_ent loss:     0.7480525838004218\n",
      "    test overall loss:        0.7197332978248596\n",
      "    test cross_ent loss:      0.7176889777183533\n",
      "    cluster loss:             2950.2914225260415\n",
      "    separation loss:          6.762887477874756\n",
      "    avg separation loss:      15.41459592183431\n",
      "    l1_addon loss:            39.908203125\n",
      "    l1 loss:                  0.847114086151123\n",
      "    train time:               0.05900835990905762\n",
      "    test time:                0.01264190673828125\n",
      "    epoch time:               0.07247138023376465\n",
      "    joint lr:                 0.01315111777407772\n",
      "epoch: 123 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 87.67%\n",
      "    train overall loss:       0.7042150530550215\n",
      "    train cross_ent loss:     0.7021586861875322\n",
      "    test overall loss:        0.7762086192766825\n",
      "    test cross_ent loss:      0.7741318146387736\n",
      "    cluster loss:             2950.4911295572915\n",
      "    separation loss:          7.093364079793294\n",
      "    avg separation loss:      15.887839635213217\n",
      "    l1_addon loss:            40.98917770385742\n",
      "    l1 loss:                  0.847114086151123\n",
      "    train time:               0.059075117111206055\n",
      "    test time:                0.012631654739379883\n",
      "    epoch time:               0.07247042655944824\n",
      "    joint lr:                 0.012302795118762673\n",
      "epoch: 124 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 93.67%\n",
      "    train overall loss:       0.6319364739788903\n",
      "    train cross_ent loss:     0.6298730009131961\n",
      "    test overall loss:        0.6353074510892233\n",
      "    test cross_ent loss:      0.6332569320996603\n",
      "    cluster loss:             2950.5074055989585\n",
      "    separation loss:          7.394399483998616\n",
      "    avg separation loss:      17.122098286946613\n",
      "    l1_addon loss:            40.11319351196289\n",
      "    l1 loss:                  0.847114086151123\n",
      "    train time:               0.05891561508178711\n",
      "    test time:                0.0126190185546875\n",
      "    epoch time:               0.07234930992126465\n",
      "    joint lr:                 0.011470133804776505\n",
      "epoch: 125 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       0.5808748702208201\n",
      "    train cross_ent loss:     0.578811334239112\n",
      "    test overall loss:        0.45034579435984295\n",
      "    test cross_ent loss:      0.4482881824175517\n",
      "    cluster loss:             2950.4689127604165\n",
      "    separation loss:          7.075227578481038\n",
      "    avg separation loss:      16.17601267496745\n",
      "    l1_addon loss:            40.350467681884766\n",
      "    l1 loss:                  0.847114086151123\n",
      "    train time:               0.05936574935913086\n",
      "    test time:                0.012646913528442383\n",
      "    epoch time:               0.07279229164123535\n",
      "    joint lr:                 0.010652905437558197\n",
      "epoch: 126 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 89.00%\n",
      "    train overall loss:       0.4611210525035858\n",
      "    train cross_ent loss:     0.459054085943434\n",
      "    test overall loss:        0.7431611816088358\n",
      "    test cross_ent loss:      0.7410831848780314\n",
      "    cluster loss:             2950.5265299479165\n",
      "    separation loss:          6.909398873647054\n",
      "    avg separation loss:      15.583322525024414\n",
      "    l1_addon loss:            41.029842376708984\n",
      "    l1 loss:                  0.847114086151123\n",
      "    train time:               0.05896949768066406\n",
      "    test time:                0.012683868408203125\n",
      "    epoch time:               0.07242989540100098\n",
      "    joint lr:                 0.009850884624303774\n",
      "epoch: 127 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 93.00%\n",
      "    train overall loss:       0.48064956731266445\n",
      "    train cross_ent loss:     0.4785815311802758\n",
      "    test overall loss:        0.5820273955663046\n",
      "    test cross_ent loss:      0.5799573858579\n",
      "    cluster loss:             2950.4545084635415\n",
      "    separation loss:          6.553599834442139\n",
      "    avg separation loss:      14.876019159952799\n",
      "    l1_addon loss:            40.763694763183594\n",
      "    l1 loss:                  0.847114086151123\n",
      "    train time:               0.05887603759765625\n",
      "    test time:                0.012657403945922852\n",
      "    epoch time:               0.07233738899230957\n",
      "    joint lr:                 0.00906384893677068\n",
      "epoch: 128 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 94.00%\n",
      "    train overall loss:       0.5387392971250746\n",
      "    train cross_ent loss:     0.5366709364785088\n",
      "    test overall loss:        0.480240136384964\n",
      "    test cross_ent loss:      0.4781753520170848\n",
      "    cluster loss:             2950.421875\n",
      "    separation loss:          6.447030226389567\n",
      "    avg separation loss:      14.427570660909018\n",
      "    l1_addon loss:            40.58933639526367\n",
      "    l1 loss:                  0.847114086151123\n",
      "    train time:               0.05899858474731445\n",
      "    test time:                0.01266932487487793\n",
      "    epoch time:               0.07240724563598633\n",
      "    joint lr:                 0.00829157887452582\n",
      "epoch: 129 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 92.33%\n",
      "    train overall loss:       0.5268804017040465\n",
      "    train cross_ent loss:     0.5248132463958528\n",
      "    test overall loss:        0.5221115748087565\n",
      "    test cross_ent loss:      0.5200496117273966\n",
      "    cluster loss:             2950.390380859375\n",
      "    separation loss:          6.447487990061442\n",
      "    avg separation loss:      15.153806368509928\n",
      "    l1_addon loss:            40.49522018432617\n",
      "    l1 loss:                  0.847114086151123\n",
      "    train time:               0.05902981758117676\n",
      "    test time:                0.012644767761230469\n",
      "    epoch time:               0.07248187065124512\n",
      "    joint lr:                 0.007533857828632187\n",
      "epoch: 130 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 87.33%\n",
      "    train overall loss:       0.3797539903057946\n",
      "    train cross_ent loss:     0.37768525381882984\n",
      "    test overall loss:        0.6447208523750305\n",
      "    test cross_ent loss:      0.6426215767860413\n",
      "    cluster loss:             2950.4497884114585\n",
      "    separation loss:          6.391488075256348\n",
      "    avg separation loss:      14.927944819132486\n",
      "    l1_addon loss:            41.73925018310547\n",
      "    l1 loss:                  0.847114086151123\n",
      "    train time:               0.05893087387084961\n",
      "    test time:                0.012660741806030273\n",
      "    epoch time:               0.07240891456604004\n",
      "    joint lr:                 0.00679047204576897\n",
      "epoch: 131 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.4183689769771364\n",
      "    train cross_ent loss:     0.41629259950584835\n",
      "    test overall loss:        0.3626151978969574\n",
      "    test cross_ent loss:      0.36053118109703064\n",
      "    cluster loss:             2950.325927734375\n",
      "    separation loss:          6.037514527638753\n",
      "    avg separation loss:      14.092639605204264\n",
      "    l1_addon loss:            41.230369567871094\n",
      "    l1 loss:                  0.847114086151123\n",
      "    train time:               0.058866024017333984\n",
      "    test time:                0.012621402740478516\n",
      "    epoch time:               0.072296142578125\n",
      "    joint lr:                 0.006061210592780146\n",
      "epoch: 132 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.25012922452555764\n",
      "    train cross_ent loss:     0.24805656572182974\n",
      "    test overall loss:        0.3737959961096446\n",
      "    test cross_ent loss:      0.3717123369375865\n",
      "    cluster loss:             2950.2913411458335\n",
      "    separation loss:          5.987210591634114\n",
      "    avg separation loss:      13.822043418884277\n",
      "    l1_addon loss:            41.21856689453125\n",
      "    l1 loss:                  0.847114086151123\n",
      "    train time:               0.059148311614990234\n",
      "    test time:                0.012648344039916992\n",
      "    epoch time:               0.07256078720092773\n",
      "    joint lr:                 0.005345865321646531\n",
      "epoch: 133 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.16858240713675818\n",
      "    train cross_ent loss:     0.16651123596562278\n",
      "    test overall loss:        0.3653108974297841\n",
      "    test cross_ent loss:      0.36322574814160663\n",
      "    cluster loss:             2950.2079264322915\n",
      "    separation loss:          5.435049692789714\n",
      "    avg separation loss:      12.398218472798666\n",
      "    l1_addon loss:            41.2685661315918\n",
      "    l1 loss:                  0.847114086151123\n",
      "    train time:               0.05881237983703613\n",
      "    test time:                0.012650728225708008\n",
      "    epoch time:               0.07224130630493164\n",
      "    joint lr:                 0.00464423083487631\n",
      "epoch: 134 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.14355571899149153\n",
      "    train cross_ent loss:     0.14149210953878033\n",
      "    test overall loss:        0.27657489975293476\n",
      "    test cross_ent loss:      0.2744872371355693\n",
      "    cluster loss:             2950.2027180989585\n",
      "    separation loss:          5.363842010498047\n",
      "    avg separation loss:      12.45707098642985\n",
      "    l1_addon loss:            41.352088928222656\n",
      "    l1 loss:                  0.847114086151123\n",
      "    train time:               0.05886197090148926\n",
      "    test time:                0.012675762176513672\n",
      "    epoch time:               0.07234048843383789\n",
      "    joint lr:                 0.003956104451309328\n",
      "epoch: 135 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 94.67%\n",
      "    train overall loss:       0.13409345203803646\n",
      "    train cross_ent loss:     0.13202779036429194\n",
      "    test overall loss:        0.24166414638360342\n",
      "    test cross_ent loss:      0.23961621522903442\n",
      "    cluster loss:             2950.16259765625\n",
      "    separation loss:          5.275716940561931\n",
      "    avg separation loss:      11.384348551432291\n",
      "    l1_addon loss:            40.02741241455078\n",
      "    l1 loss:                  0.847114086151123\n",
      "    train time:               0.059053897857666016\n",
      "    test time:                0.01267552375793457\n",
      "    epoch time:               0.072509765625\n",
      "    joint lr:                 0.0032812861723301896\n",
      "epoch: 136 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.07189132873382834\n",
      "    train cross_ent loss:     0.06982195542918311\n",
      "    test overall loss:        0.19079677760601044\n",
      "    test cross_ent loss:      0.18873283763726553\n",
      "    cluster loss:             2950.0951334635415\n",
      "    separation loss:          4.950362205505371\n",
      "    avg separation loss:      10.897378285725912\n",
      "    l1_addon loss:            40.56104278564453\n",
      "    l1 loss:                  0.847114086151123\n",
      "    train time:               0.05892133712768555\n",
      "    test time:                0.012790441513061523\n",
      "    epoch time:               0.07252264022827148\n",
      "    joint lr:                 0.0026195786484855114\n",
      "epoch: 137 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.048748426139354706\n",
      "    train cross_ent loss:     0.046684341608650155\n",
      "    test overall loss:        0.1741748129328092\n",
      "    test cross_ent loss:      0.17211557924747467\n",
      "    cluster loss:             2950.087158203125\n",
      "    separation loss:          4.9146552085876465\n",
      "    avg separation loss:      10.763593355814615\n",
      "    l1_addon loss:            40.40376281738281\n",
      "    l1 loss:                  0.847114086151123\n",
      "    train time:               0.05890202522277832\n",
      "    test time:                0.012763023376464844\n",
      "    epoch time:               0.07244706153869629\n",
      "    joint lr:                 0.0019707871465004943\n",
      "epoch: 138 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.03670500963926315\n",
      "    train cross_ent loss:     0.03464994589901633\n",
      "    test overall loss:        0.15463436270753542\n",
      "    test cross_ent loss:      0.15257240210970244\n",
      "    cluster loss:             2950.0757649739585\n",
      "    separation loss:          4.872728665669759\n",
      "    avg separation loss:      10.7424685160319\n",
      "    l1_addon loss:            40.494834899902344\n",
      "    l1 loss:                  0.847114086151123\n",
      "    train time:               0.058632612228393555\n",
      "    test time:                0.012118101119995117\n",
      "    epoch time:               0.07152700424194336\n",
      "    joint lr:                 0.0013347195166903292\n",
      "epoch: 139 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.025241688825190067\n",
      "    train cross_ent loss:     0.023174961201018758\n",
      "    test overall loss:        0.16369316478570303\n",
      "    test cross_ent loss:      0.16162398954232535\n",
      "    cluster loss:             2950.0824381510415\n",
      "    separation loss:          4.838545004526774\n",
      "    avg separation loss:      10.742271105448404\n",
      "    l1_addon loss:            40.73540496826172\n",
      "    l1 loss:                  0.847114086151123\n",
      "    train time:               0.05803418159484863\n",
      "    test time:                0.01211237907409668\n",
      "    epoch time:               0.07094025611877441\n",
      "    joint lr:                 0.0007111861607617089\n",
      "epoch: 140 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.022341291834082868\n",
      "    train cross_ent loss:     0.020273612191279728\n",
      "    test overall loss:        0.1612525942424933\n",
      "    test cross_ent loss:      0.15918836866815886\n",
      "    cluster loss:             2950.0724283854165\n",
      "    separation loss:          4.793477376302083\n",
      "    avg separation loss:      10.548290252685547\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  0.847114086151123\n",
      "    train time:               0.05836939811706543\n",
      "    test time:                0.012168645858764648\n",
      "    epoch time:               0.0713047981262207\n",
      "    joint lr:                 0.0001\n",
      "epoch: 140 (PUSH) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.022341291834082868\n",
      "    train cross_ent loss:     0.020273612191279728\n",
      "    test overall loss:        0.17703187155226865\n",
      "    test cross_ent loss:      0.17496765467027822\n",
      "    cluster loss:             2949.3151041666665\n",
      "    separation loss:          2.809336026509603\n",
      "    avg separation loss:      7.908321062723796\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  0.847114086151123\n",
      "    train time:               0.05836939811706543\n",
      "    test time:                0.012478828430175781\n",
      "    epoch time:               0.37706446647644043\n",
      "epoch: 140 (1/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.030876959363619488\n",
      "    train cross_ent loss:     0.028998824974728957\n",
      "    test overall loss:        0.1743952346344789\n",
      "    test cross_ent loss:      0.17271029887100062\n",
      "    cluster loss:             2949.3151041666665\n",
      "    separation loss:          2.81819216410319\n",
      "    avg separation loss:      7.937158107757568\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  0.46782881021499634\n",
      "    train time:               0.022866249084472656\n",
      "    test time:                0.01209712028503418\n",
      "    epoch time:               0.03543972969055176\n",
      "    last layer lr:            0.0007599999999999978\n",
      "epoch: 140 (2/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.031104877177211974\n",
      "    train cross_ent loss:     0.028556930729084544\n",
      "    test overall loss:        0.17328977336486182\n",
      "    test cross_ent loss:      0.17066995861629644\n",
      "    cluster loss:             2949.3143717447915\n",
      "    separation loss:          2.8124265670776367\n",
      "    avg separation loss:      7.885104179382324\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  1.4027130603790283\n",
      "    train time:               0.022531509399414062\n",
      "    test time:                0.012045145034790039\n",
      "    epoch time:               0.03504681587219238\n",
      "    last layer lr:            0.0014199999999999955\n",
      "epoch: 140 (3/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.03341810032725334\n",
      "    train cross_ent loss:     0.03017855456305875\n",
      "    test overall loss:        0.17004840324322382\n",
      "    test cross_ent loss:      0.1667272305736939\n",
      "    cluster loss:             2949.314208984375\n",
      "    separation loss:          2.8130184014638266\n",
      "    avg separation loss:      7.895621458689372\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  2.1040658950805664\n",
      "    train time:               0.022486448287963867\n",
      "    test time:                0.01206660270690918\n",
      "    epoch time:               0.035042524337768555\n",
      "    last layer lr:            0.0020800000000000046\n",
      "epoch: 140 (4/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.03127648536529806\n",
      "    train cross_ent loss:     0.02747281775292423\n",
      "    test overall loss:        0.16825659076372781\n",
      "    test cross_ent loss:      0.16441443438331285\n",
      "    cluster loss:             2949.3141276041665\n",
      "    separation loss:          2.807212988535563\n",
      "    avg separation loss:      7.884798526763916\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  2.625053882598877\n",
      "    train time:               0.02247905731201172\n",
      "    test time:                0.01205587387084961\n",
      "    epoch time:               0.035006046295166016\n",
      "    last layer lr:            0.0027400000000000024\n",
      "epoch: 140 (5/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.03145175437546439\n",
      "    train cross_ent loss:     0.027410396219541628\n",
      "    test overall loss:        0.16926039134462675\n",
      "    test cross_ent loss:      0.16514009796082973\n",
      "    cluster loss:             2949.314697265625\n",
      "    separation loss:          2.803352435429891\n",
      "    avg separation loss:      7.882114728291829\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  2.9031896591186523\n",
      "    train time:               0.022652626037597656\n",
      "    test time:                0.012026548385620117\n",
      "    epoch time:               0.03514909744262695\n",
      "    last layer lr:            0.0034\n",
      "epoch: 140 (6/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       0.028321870395706758\n",
      "    train cross_ent loss:     0.023847831309669547\n",
      "    test overall loss:        0.16604118111232916\n",
      "    test cross_ent loss:      0.16136566052834192\n",
      "    cluster loss:             2949.314697265625\n",
      "    separation loss:          2.807578961054484\n",
      "    avg separation loss:      7.8941168785095215\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  3.4584062099456787\n",
      "    train time:               0.02249765396118164\n",
      "    test time:                0.012061595916748047\n",
      "    epoch time:               0.03502631187438965\n",
      "    last layer lr:            0.004059999999999998\n",
      "epoch: 140 (7/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       0.03211235410223404\n",
      "    train cross_ent loss:     0.02700446851344572\n",
      "    test overall loss:        0.1638622091462215\n",
      "    test cross_ent loss:      0.15865951341887316\n",
      "    cluster loss:             2949.314208984375\n",
      "    separation loss:          2.798410256703695\n",
      "    avg separation loss:      7.865226745605469\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  3.9855856895446777\n",
      "    train time:               0.022484779357910156\n",
      "    test time:                0.012116670608520508\n",
      "    epoch time:               0.03506779670715332\n",
      "    last layer lr:            0.004719999999999996\n",
      "epoch: 140 (8/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       0.0300204586237669\n",
      "    train cross_ent loss:     0.024284104195733864\n",
      "    test overall loss:        0.16274144997199377\n",
      "    test cross_ent loss:      0.15696313853065172\n",
      "    cluster loss:             2949.31396484375\n",
      "    separation loss:          2.796449343363444\n",
      "    avg separation loss:      7.852614084879558\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  4.561199188232422\n",
      "    train time:               0.02250957489013672\n",
      "    test time:                0.012049436569213867\n",
      "    epoch time:               0.03502821922302246\n",
      "    last layer lr:            0.0053800000000000054\n",
      "epoch: 140 (9/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       0.03120701935970121\n",
      "    train cross_ent loss:     0.025298581251667604\n",
      "    test overall loss:        0.16014848401149115\n",
      "    test cross_ent loss:      0.15386766257385412\n",
      "    cluster loss:             2949.31396484375\n",
      "    separation loss:          2.804216225941976\n",
      "    avg separation loss:      7.886921564737956\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  5.0637054443359375\n",
      "    train time:               0.02264714241027832\n",
      "    test time:                0.012042045593261719\n",
      "    epoch time:               0.035160064697265625\n",
      "    last layer lr:            0.006040000000000003\n",
      "epoch: 140 (10/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       0.031237972279389698\n",
      "    train cross_ent loss:     0.02491207079341014\n",
      "    test overall loss:        0.15929165172080198\n",
      "    test cross_ent loss:      0.15284141463538012\n",
      "    cluster loss:             2949.3134765625\n",
      "    separation loss:          2.7953575452168784\n",
      "    avg separation loss:      7.855615774790446\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  5.233128547668457\n",
      "    train time:               0.022507667541503906\n",
      "    test time:                0.012074947357177734\n",
      "    epoch time:               0.035054683685302734\n",
      "    last layer lr:            0.0067\n",
      "epoch: 140 (11/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       0.02666895671023263\n",
      "    train cross_ent loss:     0.019510345740450755\n",
      "    test overall loss:        0.156934787829717\n",
      "    test cross_ent loss:      0.14978273585438728\n",
      "    cluster loss:             2949.3134765625\n",
      "    separation loss:          2.8034454186757407\n",
      "    avg separation loss:      7.877601305643718\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  5.9349446296691895\n",
      "    train time:               0.02254176139831543\n",
      "    test time:                0.012033462524414062\n",
      "    epoch time:               0.03504204750061035\n",
      "    last layer lr:            0.0073599999999999985\n",
      "epoch: 140 (12/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.02820436076985465\n",
      "    train cross_ent loss:     0.020916610438790586\n",
      "    test overall loss:        0.15742469330628714\n",
      "    test cross_ent loss:      0.15008168667554855\n",
      "    cluster loss:             2949.3138020833335\n",
      "    separation loss:          2.797819137573242\n",
      "    avg separation loss:      7.86075496673584\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  6.125893592834473\n",
      "    train time:               0.02253270149230957\n",
      "    test time:                0.012066841125488281\n",
      "    epoch time:               0.03507065773010254\n",
      "    last layer lr:            0.008019999999999994\n",
      "epoch: 140 (13/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.030336894301904574\n",
      "    train cross_ent loss:     0.022488232081135113\n",
      "    test overall loss:        0.1554673525194327\n",
      "    test cross_ent loss:      0.1475121316810449\n",
      "    cluster loss:             2949.31396484375\n",
      "    separation loss:          2.8091960748036704\n",
      "    avg separation loss:      7.907530625661214\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  6.738109111785889\n",
      "    train time:               0.022739410400390625\n",
      "    test time:                0.012039661407470703\n",
      "    epoch time:               0.03524971008300781\n",
      "    last layer lr:            0.008680000000000005\n",
      "epoch: 140 (14/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       0.03635254440208276\n",
      "    train cross_ent loss:     0.02737988459153308\n",
      "    test overall loss:        0.15508478755752245\n",
      "    test cross_ent loss:      0.1463781725615263\n",
      "    cluster loss:             2949.3143717447915\n",
      "    separation loss:          2.816075086593628\n",
      "    avg separation loss:      7.928420066833496\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  7.489508152008057\n",
      "    train time:               0.022548198699951172\n",
      "    test time:                0.01203298568725586\n",
      "    epoch time:               0.0350489616394043\n",
      "    last layer lr:            0.009340000000000003\n",
      "epoch: 140 (15/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       0.023910369620554976\n",
      "    train cross_ent loss:     0.015353104151371453\n",
      "    test overall loss:        0.15500541652242342\n",
      "    test cross_ent loss:      0.1463935300707817\n",
      "    cluster loss:             2949.314208984375\n",
      "    separation loss:          2.808491071065267\n",
      "    avg separation loss:      7.90122922261556\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  7.394774913787842\n",
      "    train time:               0.022554397583007812\n",
      "    test time:                0.012078285217285156\n",
      "    epoch time:               0.035102128982543945\n",
      "    last layer lr:            0.01\n",
      "epoch: 140 (16/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       0.030587027159829933\n",
      "    train cross_ent loss:     0.021764419041574\n",
      "    test overall loss:        0.15266871949036917\n",
      "    test cross_ent loss:      0.1436252947896719\n",
      "    cluster loss:             2949.3146158854165\n",
      "    separation loss:          2.8186870416005454\n",
      "    avg separation loss:      7.9368720054626465\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  7.826315879821777\n",
      "    train time:               0.02253413200378418\n",
      "    test time:                0.012050867080688477\n",
      "    epoch time:               0.03505420684814453\n",
      "    last layer lr:            0.009604000000000001\n",
      "epoch: 140 (17/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.025254129742582638\n",
      "    train cross_ent loss:     0.016028865835525923\n",
      "    test overall loss:        0.15075144916772842\n",
      "    test cross_ent loss:      0.14158144034445286\n",
      "    cluster loss:             2949.31396484375\n",
      "    separation loss:          2.8158796628316245\n",
      "    avg separation loss:      7.909639199574788\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  7.95289421081543\n",
      "    train time:               0.022541522979736328\n",
      "    test time:                0.012022733688354492\n",
      "    epoch time:               0.03503680229187012\n",
      "    last layer lr:            0.009208000000000003\n",
      "epoch: 140 (18/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.028534242055482335\n",
      "    train cross_ent loss:     0.019779857248067856\n",
      "    test overall loss:        0.14849253247181574\n",
      "    test cross_ent loss:      0.13965638416508833\n",
      "    cluster loss:             2949.3140462239585\n",
      "    separation loss:          2.8133764266967773\n",
      "    avg separation loss:      7.9083147048950195\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  7.619035720825195\n",
      "    train time:               0.022493362426757812\n",
      "    test time:                0.012110233306884766\n",
      "    epoch time:               0.03507113456726074\n",
      "    last layer lr:            0.008811999999999997\n",
      "epoch: 140 (19/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.023223928382827178\n",
      "    train cross_ent loss:     0.014706687743051184\n",
      "    test overall loss:        0.1478379312902689\n",
      "    test cross_ent loss:      0.13956023131807646\n",
      "    cluster loss:             2949.3141276041665\n",
      "    separation loss:          2.8173086643218994\n",
      "    avg separation loss:      7.928614616394043\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  7.060591220855713\n",
      "    train time:               0.022494792938232422\n",
      "    test time:                0.012013435363769531\n",
      "    epoch time:               0.03498125076293945\n",
      "    last layer lr:            0.008415999999999998\n",
      "epoch: 140 (20/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.021871605784528785\n",
      "    train cross_ent loss:     0.013908866327255964\n",
      "    test overall loss:        0.1459749142328898\n",
      "    test cross_ent loss:      0.13813135959208012\n",
      "    cluster loss:             2949.313720703125\n",
      "    separation loss:          2.8116186459859214\n",
      "    avg separation loss:      7.911144733428955\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  6.6264448165893555\n",
      "    train time:               0.02280282974243164\n",
      "    test time:                0.012042760848999023\n",
      "    epoch time:               0.035315752029418945\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 140 (21/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.022223042841586802\n",
      "    train cross_ent loss:     0.014772100374102592\n",
      "    test overall loss:        0.14434606519838175\n",
      "    test cross_ent loss:      0.13699079491198063\n",
      "    cluster loss:             2949.3140462239585\n",
      "    separation loss:          2.8164480527242026\n",
      "    avg separation loss:      7.928475379943848\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  6.138155937194824\n",
      "    train time:               0.022671937942504883\n",
      "    test time:                0.012039422988891602\n",
      "    epoch time:               0.0351872444152832\n",
      "    last layer lr:            0.007624000000000002\n",
      "epoch: 140 (22/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.02125696837902069\n",
      "    train cross_ent loss:     0.014046950472725762\n",
      "    test overall loss:        0.1452580038458109\n",
      "    test cross_ent loss:      0.13829092433055243\n",
      "    cluster loss:             2949.3142903645835\n",
      "    separation loss:          2.811787207921346\n",
      "    avg separation loss:      7.907112121582031\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  5.749963760375977\n",
      "    train time:               0.02251148223876953\n",
      "    test time:                0.012059926986694336\n",
      "    epoch time:               0.03503847122192383\n",
      "    last layer lr:            0.0072280000000000035\n",
      "epoch: 140 (23/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.02889007930126455\n",
      "    train cross_ent loss:     0.02155983936972916\n",
      "    test overall loss:        0.14327521373828253\n",
      "    test cross_ent loss:      0.13582972871760526\n",
      "    cluster loss:             2949.3134765625\n",
      "    separation loss:          2.8054317633310952\n",
      "    avg separation loss:      7.868030389149983\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  6.2283759117126465\n",
      "    train time:               0.022493362426757812\n",
      "    test time:                0.012026786804199219\n",
      "    epoch time:               0.03498697280883789\n",
      "    last layer lr:            0.006831999999999998\n",
      "epoch: 140 (24/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.024132522857851453\n",
      "    train cross_ent loss:     0.017020617094304826\n",
      "    test overall loss:        0.14258892772098383\n",
      "    test cross_ent loss:      0.13579626257220903\n",
      "    cluster loss:             2949.3138020833335\n",
      "    separation loss:          2.8061551253000894\n",
      "    avg separation loss:      7.888615449269612\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  5.57555627822876\n",
      "    train time:               0.02284550666809082\n",
      "    test time:                0.012037515640258789\n",
      "    epoch time:               0.03535342216491699\n",
      "    last layer lr:            0.006436\n",
      "epoch: 140 (25/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.019855581120484404\n",
      "    train cross_ent loss:     0.01340507009687523\n",
      "    test overall loss:        0.14209296368062496\n",
      "    test cross_ent loss:      0.13578749261796474\n",
      "    cluster loss:             2949.31396484375\n",
      "    separation loss:          2.8020880222320557\n",
      "    avg separation loss:      7.865647633870442\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  5.088360786437988\n",
      "    train time:               0.022676706314086914\n",
      "    test time:                0.012028932571411133\n",
      "    epoch time:               0.035176992416381836\n",
      "    last layer lr:            0.00604\n",
      "epoch: 140 (26/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.019050423573288653\n",
      "    train cross_ent loss:     0.013029150975247225\n",
      "    test overall loss:        0.14037232721845308\n",
      "    test cross_ent loss:      0.13444965394834676\n",
      "    cluster loss:             2949.3140462239585\n",
      "    separation loss:          2.8157097498575845\n",
      "    avg separation loss:      7.928423086802165\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  4.705558776855469\n",
      "    train time:               0.0224912166595459\n",
      "    test time:                0.012035131454467773\n",
      "    epoch time:               0.034995317459106445\n",
      "    last layer lr:            0.005644000000000002\n",
      "epoch: 140 (27/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.019259136066668563\n",
      "    train cross_ent loss:     0.013626239003820552\n",
      "    test overall loss:        0.13914617709815502\n",
      "    test cross_ent loss:      0.1336539095888535\n",
      "    cluster loss:             2949.31494140625\n",
      "    separation loss:          2.8239376544952393\n",
      "    avg separation loss:      7.9429341952006025\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  4.275153160095215\n",
      "    train time:               0.022469520568847656\n",
      "    test time:                0.012054443359375\n",
      "    epoch time:               0.03499150276184082\n",
      "    last layer lr:            0.005248000000000003\n",
      "epoch: 140 (28/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.019433530357976753\n",
      "    train cross_ent loss:     0.014145817348940505\n",
      "    test overall loss:        0.13927073714633784\n",
      "    test cross_ent loss:      0.13408134753505388\n",
      "    cluster loss:             2949.3143717447915\n",
      "    separation loss:          2.819463014602661\n",
      "    avg separation loss:      7.935366153717041\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  3.972280502319336\n",
      "    train time:               0.02251720428466797\n",
      "    test time:                0.012029886245727539\n",
      "    epoch time:               0.0350193977355957\n",
      "    last layer lr:            0.004851999999999998\n",
      "epoch: 140 (29/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.019645102736022737\n",
      "    train cross_ent loss:     0.014631753063036336\n",
      "    test overall loss:        0.13734864753981432\n",
      "    test cross_ent loss:      0.13243975987037024\n",
      "    cluster loss:             2949.3133951822915\n",
      "    separation loss:          2.8069949944814048\n",
      "    avg separation loss:      7.878663698832194\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  3.6917738914489746\n",
      "    train time:               0.022669553756713867\n",
      "    test time:                0.012098312377929688\n",
      "    epoch time:               0.03523826599121094\n",
      "    last layer lr:            0.004455999999999999\n",
      "epoch: 140 (30/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.018576009819904964\n",
      "    train cross_ent loss:     0.013804618113984665\n",
      "    test overall loss:        0.13624325146277746\n",
      "    test cross_ent loss:      0.13155996489028135\n",
      "    cluster loss:             2949.3133951822915\n",
      "    separation loss:          2.803907632827759\n",
      "    avg separation loss:      7.859616120656331\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  3.466177463531494\n",
      "    train time:               0.022439002990722656\n",
      "    test time:                0.012034416198730469\n",
      "    epoch time:               0.0349431037902832\n",
      "    last layer lr:            0.004060000000000001\n",
      "epoch: 140 (31/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.019667356895903747\n",
      "    train cross_ent loss:     0.015060925287091069\n",
      "    test overall loss:        0.13641829478243986\n",
      "    test cross_ent loss:      0.1317429052044948\n",
      "    cluster loss:             2949.3135579427085\n",
      "    separation loss:          2.805041790008545\n",
      "    avg separation loss:      7.880239009857178\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  3.4582812786102295\n",
      "    train time:               0.022462844848632812\n",
      "    test time:                0.01202535629272461\n",
      "    epoch time:               0.03496551513671875\n",
      "    last layer lr:            0.0036640000000000015\n",
      "epoch: 140 (32/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.017952390739487276\n",
      "    train cross_ent loss:     0.013570589737759696\n",
      "    test overall loss:        0.13621901286145052\n",
      "    test cross_ent loss:      0.13189759974678358\n",
      "    cluster loss:             2949.3136393229165\n",
      "    separation loss:          2.8002156416575112\n",
      "    avg separation loss:      7.861612796783447\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  3.1043057441711426\n",
      "    train time:               0.02281022071838379\n",
      "    test time:                0.012092351913452148\n",
      "    epoch time:               0.0353851318359375\n",
      "    last layer lr:            0.003268000000000003\n",
      "epoch: 140 (33/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.016203911664585274\n",
      "    train cross_ent loss:     0.012128145382222202\n",
      "    test overall loss:        0.13433559673527876\n",
      "    test cross_ent loss:      0.13052385114133358\n",
      "    cluster loss:             2949.3136393229165\n",
      "    separation loss:          2.8115307490030923\n",
      "    avg separation loss:      7.910861968994141\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  2.594633102416992\n",
      "    train time:               0.02280592918395996\n",
      "    test time:                0.012060165405273438\n",
      "    epoch time:               0.03534722328186035\n",
      "    last layer lr:            0.002871999999999997\n",
      "epoch: 140 (34/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.015155516461365752\n",
      "    train cross_ent loss:     0.0115742234306203\n",
      "    test overall loss:        0.13451962545514107\n",
      "    test cross_ent loss:      0.13109858706593513\n",
      "    cluster loss:             2949.3134765625\n",
      "    separation loss:          2.804429848988851\n",
      "    avg separation loss:      7.868926048278809\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  2.2039284706115723\n",
      "    train time:               0.022526979446411133\n",
      "    test time:                0.0120391845703125\n",
      "    epoch time:               0.035034894943237305\n",
      "    last layer lr:            0.0024759999999999986\n",
      "epoch: 140 (35/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.017892492624620598\n",
      "    train cross_ent loss:     0.014585549994889233\n",
      "    test overall loss:        0.13455785376330218\n",
      "    test cross_ent loss:      0.13136805407702923\n",
      "    cluster loss:             2949.3141276041665\n",
      "    separation loss:          2.8061811129252114\n",
      "    avg separation loss:      7.888282934824626\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  1.9726855754852295\n",
      "    train time:               0.022915363311767578\n",
      "    test time:                0.012209177017211914\n",
      "    epoch time:               0.035593271255493164\n",
      "    last layer lr:            0.0020800000000000003\n",
      "epoch: 140 (36/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.017278303288751178\n",
      "    train cross_ent loss:     0.014216098468750715\n",
      "    test overall loss:        0.13453219396372637\n",
      "    test cross_ent loss:      0.13153996442755064\n",
      "    cluster loss:             2949.3140462239585\n",
      "    separation loss:          2.802457809448242\n",
      "    avg separation loss:      7.8714213371276855\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  1.775123119354248\n",
      "    train time:               0.02293086051940918\n",
      "    test time:                0.012253046035766602\n",
      "    epoch time:               0.035651445388793945\n",
      "    last layer lr:            0.0016840000000000017\n",
      "epoch: 140 (37/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.013304831304897865\n",
      "    train cross_ent loss:     0.010560249676927924\n",
      "    test overall loss:        0.1336195251593987\n",
      "    test cross_ent loss:      0.13102048138777414\n",
      "    cluster loss:             2949.314208984375\n",
      "    separation loss:          2.8129324913024902\n",
      "    avg separation loss:      7.902178764343262\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  1.3819291591644287\n",
      "    train time:               0.023051023483276367\n",
      "    test time:                0.01221323013305664\n",
      "    epoch time:               0.0357356071472168\n",
      "    last layer lr:            0.001288000000000003\n",
      "epoch: 140 (38/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.019608200579467747\n",
      "    train cross_ent loss:     0.017200051160115335\n",
      "    test overall loss:        0.1332257470736901\n",
      "    test cross_ent loss:      0.1308262006690105\n",
      "    cluster loss:             2949.31396484375\n",
      "    separation loss:          2.8090476989746094\n",
      "    avg separation loss:      7.8966294924418134\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  1.1824309825897217\n",
      "    train time:               0.022918224334716797\n",
      "    test time:                0.012228012084960938\n",
      "    epoch time:               0.035613059997558594\n",
      "    last layer lr:            0.0008919999999999973\n",
      "epoch: 140 (39/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.013576577934953902\n",
      "    train cross_ent loss:     0.011331819773962101\n",
      "    test overall loss:        0.13277813668052355\n",
      "    test cross_ent loss:      0.13069991519053778\n",
      "    cluster loss:             2949.313720703125\n",
      "    separation loss:          2.8131192525227866\n",
      "    avg separation loss:      7.911711692810059\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  0.8611131310462952\n",
      "    train time:               0.022960901260375977\n",
      "    test time:                0.012231111526489258\n",
      "    epoch time:               0.03566288948059082\n",
      "    last layer lr:            0.0004959999999999986\n",
      "epoch: 140 (40/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.020744536434196763\n",
      "    train cross_ent loss:     0.018875348433438275\n",
      "    test overall loss:        0.1326217483729124\n",
      "    test cross_ent loss:      0.13079562534888586\n",
      "    cluster loss:             2949.3143717447915\n",
      "    separation loss:          2.8215607007344565\n",
      "    avg separation loss:      7.940907796223958\n",
      "    l1_addon loss:            40.570308685302734\n",
      "    l1 loss:                  0.6090143918991089\n",
      "    train time:               0.022963523864746094\n",
      "    test time:                0.012320280075073242\n",
      "    epoch time:               0.0357515811920166\n",
      "    last layer lr:            0.0001\n",
      "epoch: 141 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.01803068697659506\n",
      "    train cross_ent loss:     0.016204903859438166\n",
      "    test overall loss:        0.1328924379001061\n",
      "    test cross_ent loss:      0.13106710277497768\n",
      "    cluster loss:             2949.3138834635415\n",
      "    separation loss:          2.803011894226074\n",
      "    avg separation loss:      7.873318513234456\n",
      "    l1_addon loss:            40.54420471191406\n",
      "    l1 loss:                  0.6090143918991089\n",
      "    train time:               0.06004452705383301\n",
      "    test time:                0.012328386306762695\n",
      "    epoch time:               0.07310700416564941\n",
      "    joint lr:                 0.001298047112325102\n",
      "epoch: 142 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.016438479535281658\n",
      "    train cross_ent loss:     0.014616687497537997\n",
      "    test overall loss:        0.1318784262984991\n",
      "    test cross_ent loss:      0.13005917333066463\n",
      "    cluster loss:             2949.3130696614585\n",
      "    separation loss:          2.803582191467285\n",
      "    avg separation loss:      7.7801408767700195\n",
      "    l1_addon loss:            40.34128952026367\n",
      "    l1 loss:                  0.6090143918991089\n",
      "    train time:               0.060089826583862305\n",
      "    test time:                0.012795686721801758\n",
      "    epoch time:               0.07402634620666504\n",
      "    joint lr:                 0.002472133282403701\n",
      "epoch: 143 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.010257375167889727\n",
      "    train cross_ent loss:     0.00843689877850314\n",
      "    test overall loss:        0.12301868200302124\n",
      "    test cross_ent loss:      0.12119628489017487\n",
      "    cluster loss:             2949.2975260416665\n",
      "    separation loss:          2.725309371948242\n",
      "    avg separation loss:      7.669522762298584\n",
      "    l1_addon loss:            40.44609451293945\n",
      "    l1 loss:                  0.6090143918991089\n",
      "    train time:               0.058327436447143555\n",
      "    test time:                0.012621164321899414\n",
      "    epoch time:               0.07185864448547363\n",
      "    joint lr:                 0.0036226179243694966\n",
      "epoch: 144 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.0059963721885449356\n",
      "    train cross_ent loss:     0.004173474826125635\n",
      "    test overall loss:        0.11908308230340481\n",
      "    test cross_ent loss:      0.11726025119423866\n",
      "    cluster loss:             2949.2906087239585\n",
      "    separation loss:          2.686426560084025\n",
      "    avg separation loss:      7.592440128326416\n",
      "    l1_addon loss:            40.460670471191406\n",
      "    l1 loss:                  0.6090143918991089\n",
      "    train time:               0.058007001876831055\n",
      "    test time:                0.012099027633666992\n",
      "    epoch time:               0.07083678245544434\n",
      "    joint lr:                 0.004749855660167736\n",
      "epoch: 145 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.0038784267898235056\n",
      "    train cross_ent loss:     0.0020570846326235267\n",
      "    test overall loss:        0.1215313250819842\n",
      "    test cross_ent loss:      0.11971101102729638\n",
      "    cluster loss:             2949.2853190104165\n",
      "    separation loss:          2.640509923299154\n",
      "    avg separation loss:      7.420685927073161\n",
      "    l1_addon loss:            40.376853942871094\n",
      "    l1 loss:                  0.6090143918991089\n",
      "    train time:               0.05815935134887695\n",
      "    test time:                0.012122392654418945\n",
      "    epoch time:               0.07100415229797363\n",
      "    joint lr:                 0.005854196379457574\n",
      "epoch: 146 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.0046251085586845875\n",
      "    train cross_ent loss:     0.0028058646065700385\n",
      "    test overall loss:        0.12184178518752257\n",
      "    test cross_ent loss:      0.12002178654074669\n",
      "    cluster loss:             2949.282470703125\n",
      "    separation loss:          2.6116642157236734\n",
      "    avg separation loss:      7.357237656911214\n",
      "    l1_addon loss:            40.366207122802734\n",
      "    l1 loss:                  0.6090143918991089\n",
      "    train time:               0.05813765525817871\n",
      "    test time:                0.012130975723266602\n",
      "    epoch time:               0.07103681564331055\n",
      "    joint lr:                 0.006935985298795627\n",
      "epoch: 147 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.004132174990243382\n",
      "    train cross_ent loss:     0.0023104362642495995\n",
      "    test overall loss:        0.10942850510279338\n",
      "    test cross_ent loss:      0.1076057640214761\n",
      "    cluster loss:             2949.2792154947915\n",
      "    separation loss:          2.6060665448506675\n",
      "    avg separation loss:      7.39775292078654\n",
      "    l1_addon loss:            40.457679748535156\n",
      "    l1 loss:                  0.6090143918991089\n",
      "    train time:               0.05833601951599121\n",
      "    test time:                0.012117147445678711\n",
      "    epoch time:               0.07122993469238281\n",
      "    joint lr:                 0.007995563020108943\n",
      "epoch: 148 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.0039310626064737635\n",
      "    train cross_ent loss:     0.0021093843647071887\n",
      "    test overall loss:        0.12963386562963328\n",
      "    test cross_ent loss:      0.12781563928971687\n",
      "    cluster loss:             2949.2818196614585\n",
      "    separation loss:          2.6036101977030435\n",
      "    avg separation loss:      7.3643418947855634\n",
      "    l1_addon loss:            40.307159423828125\n",
      "    l1 loss:                  0.6090143918991089\n",
      "    train time:               0.05803537368774414\n",
      "    test time:                0.01210927963256836\n",
      "    epoch time:               0.07087564468383789\n",
      "    joint lr:                 0.009033265588466115\n",
      "epoch: 149 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.00390232028439641\n",
      "    train cross_ent loss:     0.002085186696300904\n",
      "    test overall loss:        0.11276041530072689\n",
      "    test cross_ent loss:      0.11094198810557525\n",
      "    cluster loss:             2949.27783203125\n",
      "    separation loss:          2.5743581453959146\n",
      "    avg separation loss:      7.297656218210856\n",
      "    l1_addon loss:            40.31385040283203\n",
      "    l1 loss:                  0.6090143918991089\n",
      "    train time:               0.059323787689208984\n",
      "    test time:                0.012139320373535156\n",
      "    epoch time:               0.07222461700439453\n",
      "    joint lr:                 0.010049424549154131\n",
      "epoch: 150 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.005880050619857179\n",
      "    train cross_ent loss:     0.004058504030884554\n",
      "    test overall loss:        0.1164269878839453\n",
      "    test cross_ent loss:      0.11460938677191734\n",
      "    cluster loss:             2949.2750651041665\n",
      "    separation loss:          2.5285196701685586\n",
      "    avg separation loss:      7.1736297607421875\n",
      "    l1_addon loss:            40.286373138427734\n",
      "    l1 loss:                  0.6090143918991089\n",
      "    train time:               0.058275461196899414\n",
      "    test time:                0.012091398239135742\n",
      "    epoch time:               0.07114505767822266\n",
      "    joint lr:                 0.011044367004069541\n",
      "epoch: 151 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.0038707088420374524\n",
      "    train cross_ent loss:     0.002057835686072293\n",
      "    test overall loss:        0.127651064346234\n",
      "    test cross_ent loss:      0.1258356717104713\n",
      "    cluster loss:             2949.2818196614585\n",
      "    separation loss:          2.512648582458496\n",
      "    avg separation loss:      7.070727825164795\n",
      "    l1_addon loss:            40.21255111694336\n",
      "    l1 loss:                  0.6090143918991089\n",
      "    train time:               0.05825352668762207\n",
      "    test time:                0.012217521667480469\n",
      "    epoch time:               0.07128739356994629\n",
      "    joint lr:                 0.010393177167327405\n",
      "epoch: 152 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.005871759468896521\n",
      "    train cross_ent loss:     0.0040580993906284375\n",
      "    test overall loss:        0.12079795356839895\n",
      "    test cross_ent loss:      0.11898258607834578\n",
      "    cluster loss:             2949.2830403645835\n",
      "    separation loss:          2.510009249051412\n",
      "    avg separation loss:      7.022670269012451\n",
      "    l1_addon loss:            40.212013244628906\n",
      "    l1 loss:                  0.6090143918991089\n",
      "    train time:               0.05793190002441406\n",
      "    test time:                0.012144327163696289\n",
      "    epoch time:               0.07084202766418457\n",
      "    joint lr:                 0.009753916690619703\n",
      "epoch: 153 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       0.005627855658531189\n",
      "    train cross_ent loss:     0.0038122074717345336\n",
      "    test overall loss:        0.14055038491884866\n",
      "    test cross_ent loss:      0.1387406097104152\n",
      "    cluster loss:             2949.311767578125\n",
      "    separation loss:          2.5567071437835693\n",
      "    avg separation loss:      6.905460675557454\n",
      "    l1_addon loss:            40.02533721923828\n",
      "    l1 loss:                  0.6090143918991089\n",
      "    train time:               0.05832839012145996\n",
      "    test time:                0.012120723724365234\n",
      "    epoch time:               0.07118940353393555\n",
      "    joint lr:                 0.009126412105729424\n",
      "epoch: 154 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.009454053671409687\n",
      "    train cross_ent loss:     0.007642855673717956\n",
      "    test overall loss:        0.13560633268207312\n",
      "    test cross_ent loss:      0.13379236590117216\n",
      "    cluster loss:             2949.3208821614585\n",
      "    separation loss:          2.5434115727742515\n",
      "    avg separation loss:      6.96755313873291\n",
      "    l1_addon loss:            40.16532516479492\n",
      "    l1 loss:                  0.6090143918991089\n",
      "    train time:               0.05816960334777832\n",
      "    test time:                0.012098073959350586\n",
      "    epoch time:               0.07099032402038574\n",
      "    joint lr:                 0.008510492220867888\n",
      "epoch: 155 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.016968205829875335\n",
      "    train cross_ent loss:     0.015158086051491814\n",
      "    test overall loss:        0.16050099146862826\n",
      "    test cross_ent loss:      0.1586915117998918\n",
      "    cluster loss:             2949.3331705729165\n",
      "    separation loss:          2.579919974009196\n",
      "    avg separation loss:      6.894421259562175\n",
      "    l1_addon loss:            40.0156364440918\n",
      "    l1 loss:                  0.6090143918991089\n",
      "    train time:               0.05822324752807617\n",
      "    test time:                0.012154579162597656\n",
      "    epoch time:               0.07111191749572754\n",
      "    joint lr:                 0.00790598809249301\n",
      "epoch: 156 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.02890484355803993\n",
      "    train cross_ent loss:     0.02709236417690085\n",
      "    test overall loss:        0.12859134500225386\n",
      "    test cross_ent loss:      0.12677486116687456\n",
      "    cluster loss:             2949.3441569010415\n",
      "    separation loss:          2.6083523432413735\n",
      "    avg separation loss:      7.039543469746907\n",
      "    l1_addon loss:            40.24913024902344\n",
      "    l1 loss:                  0.6090143918991089\n",
      "    train time:               0.05803513526916504\n",
      "    test time:                0.01212930679321289\n",
      "    epoch time:               0.07094621658325195\n",
      "    joint lr:                 0.007312732997463544\n",
      "epoch: 157 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.04449137176076571\n",
      "    train cross_ent loss:     0.042675027804863125\n",
      "    test overall loss:        0.145055390894413\n",
      "    test cross_ent loss:      0.14323734243710837\n",
      "    cluster loss:             2949.347412109375\n",
      "    separation loss:          2.584462324778239\n",
      "    avg separation loss:      7.000024159749349\n",
      "    l1_addon loss:            40.301326751708984\n",
      "    l1 loss:                  0.6090143918991089\n",
      "    train time:               0.05822420120239258\n",
      "    test time:                0.012110233306884766\n",
      "    epoch time:               0.07106685638427734\n",
      "    joint lr:                 0.006730562405525418\n",
      "epoch: 158 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.060182445837805666\n",
      "    train cross_ent loss:     0.05836425530206826\n",
      "    test overall loss:        0.15637142521639666\n",
      "    test cross_ent loss:      0.15455512019495168\n",
      "    cluster loss:             2949.3638509114585\n",
      "    separation loss:          2.761179208755493\n",
      "    avg separation loss:      7.354631582895915\n",
      "    l1_addon loss:            40.243194580078125\n",
      "    l1 loss:                  0.6090143918991089\n",
      "    train time:               0.05852365493774414\n",
      "    test time:                0.012254476547241211\n",
      "    epoch time:               0.07155585289001465\n",
      "    joint lr:                 0.006159313952126306\n",
      "epoch: 159 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.05446802990304099\n",
      "    train cross_ent loss:     0.052651326896415815\n",
      "    test overall loss:        0.1521266313890616\n",
      "    test cross_ent loss:      0.15030783663193384\n",
      "    cluster loss:             2949.3829752604165\n",
      "    separation loss:          2.846630334854126\n",
      "    avg separation loss:      7.441978931427002\n",
      "    l1_addon loss:            40.32624053955078\n",
      "    l1 loss:                  0.6090143918991089\n",
      "    train time:               0.0582273006439209\n",
      "    test time:                0.012143135070800781\n",
      "    epoch time:               0.07113194465637207\n",
      "    joint lr:                 0.005598827411554625\n",
      "epoch: 160 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.03759382230540117\n",
      "    train cross_ent loss:     0.035783263130320445\n",
      "    test overall loss:        0.1725651075442632\n",
      "    test cross_ent loss:      0.17074342941244444\n",
      "    cluster loss:             2949.4180501302085\n",
      "    separation loss:          2.962873856226603\n",
      "    avg separation loss:      7.718137105305989\n",
      "    l1_addon loss:            40.42237854003906\n",
      "    l1 loss:                  0.6090143918991089\n",
      "    train time:               0.0581209659576416\n",
      "    test time:                0.012114763259887695\n",
      "    epoch time:               0.07100892066955566\n",
      "    joint lr:                 0.005048944670399165\n",
      "epoch: 161 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.03361395777513584\n",
      "    train cross_ent loss:     0.03179564420133829\n",
      "    test overall loss:        0.17046393205722174\n",
      "    test cross_ent loss:      0.16866136714816093\n",
      "    cluster loss:             2949.4146321614585\n",
      "    separation loss:          3.007712443669637\n",
      "    avg separation loss:      7.489660739898682\n",
      "    l1_addon loss:            39.78517150878906\n",
      "    l1 loss:                  0.6090143918991089\n",
      "    train time:               0.05823802947998047\n",
      "    test time:                0.012127399444580078\n",
      "    epoch time:               0.07112860679626465\n",
      "    joint lr:                 0.004509509701325646\n",
      "epoch: 162 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.0289606847282913\n",
      "    train cross_ent loss:     0.02714822940631873\n",
      "    test overall loss:        0.1730834444363912\n",
      "    test cross_ent loss:      0.17127282544970512\n",
      "    cluster loss:             2949.3985188802085\n",
      "    separation loss:          2.9101714293162027\n",
      "    avg separation loss:      7.430171807607015\n",
      "    l1_addon loss:            40.053627014160156\n",
      "    l1 loss:                  0.6090143918991089\n",
      "    train time:               0.05820584297180176\n",
      "    test time:                0.012202739715576172\n",
      "    epoch time:               0.07120418548583984\n",
      "    joint lr:                 0.00398036853716657\n",
      "epoch: 163 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.03520247573032975\n",
      "    train cross_ent loss:     0.03339864453300834\n",
      "    test overall loss:        0.16538518791397414\n",
      "    test cross_ent loss:      0.1635841354727745\n",
      "    cluster loss:             2949.4105631510415\n",
      "    separation loss:          2.9805548985799155\n",
      "    avg separation loss:      7.434602737426758\n",
      "    l1_addon loss:            39.734703063964844\n",
      "    l1 loss:                  0.6090143918991089\n",
      "    train time:               0.058203935623168945\n",
      "    test time:                0.012132883071899414\n",
      "    epoch time:               0.07109355926513672\n",
      "    joint lr:                 0.0034613692453205423\n",
      "epoch: 164 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.048928268978165254\n",
      "    train cross_ent loss:     0.04711560346186161\n",
      "    test overall loss:        0.15237350513537726\n",
      "    test cross_ent loss:      0.1505604044844707\n",
      "    cluster loss:             2949.3931477864585\n",
      "    separation loss:          2.8858320713043213\n",
      "    avg separation loss:      7.464420795440674\n",
      "    l1_addon loss:            40.13632583618164\n",
      "    l1 loss:                  0.6090143918991089\n",
      "    train time:               0.058116912841796875\n",
      "    test time:                0.012106895446777344\n",
      "    epoch time:               0.07094573974609375\n",
      "    joint lr:                 0.002952361902457719\n",
      "epoch: 165 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.010142423626449373\n",
      "    train cross_ent loss:     0.008334586940084895\n",
      "    test overall loss:        0.16302078838149706\n",
      "    test cross_ent loss:      0.16121670479575792\n",
      "    cluster loss:             2949.3975423177085\n",
      "    separation loss:          2.9723074436187744\n",
      "    avg separation loss:      7.472765286763509\n",
      "    l1_addon loss:            39.83562469482422\n",
      "    l1 loss:                  0.6090143918991089\n",
      "    train time:               0.0583646297454834\n",
      "    test time:                0.012129545211791992\n",
      "    epoch time:               0.07128477096557617\n",
      "    joint lr:                 0.0024531985695276076\n",
      "epoch: 166 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.013937117169714637\n",
      "    train cross_ent loss:     0.01212971212549342\n",
      "    test overall loss:        0.1351030357182026\n",
      "    test cross_ent loss:      0.1332894122848908\n",
      "    cluster loss:             2949.3707682291665\n",
      "    separation loss:          2.853580872217814\n",
      "    avg separation loss:      7.331101576487224\n",
      "    l1_addon loss:            40.153831481933594\n",
      "    l1 loss:                  0.6090143918991089\n",
      "    train time:               0.0581049919128418\n",
      "    test time:                0.012107133865356445\n",
      "    epoch time:               0.07097554206848145\n",
      "    joint lr:                 0.001963733267065865\n",
      "epoch: 167 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.00663562398403883\n",
      "    train cross_ent loss:     0.004821590807599326\n",
      "    test overall loss:        0.12861771757404009\n",
      "    test cross_ent loss:      0.12680369367202124\n",
      "    cluster loss:             2949.3662923177085\n",
      "    separation loss:          2.825630267461141\n",
      "    avg separation loss:      7.263138930002849\n",
      "    l1_addon loss:            40.16704559326172\n",
      "    l1 loss:                  0.6090143918991089\n",
      "    train time:               0.05825662612915039\n",
      "    test time:                0.012168645858764648\n",
      "    epoch time:               0.07119321823120117\n",
      "    joint lr:                 0.001483821950796405\n",
      "epoch: 168 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.005013572129731377\n",
      "    train cross_ent loss:     0.0032009092069024015\n",
      "    test overall loss:        0.1242200533548991\n",
      "    test cross_ent loss:      0.12240842667718728\n",
      "    cluster loss:             2949.3618977864585\n",
      "    separation loss:          2.826370636622111\n",
      "    avg separation loss:      7.227640151977539\n",
      "    l1_addon loss:            40.08727264404297\n",
      "    l1 loss:                  0.6090143918991089\n",
      "    train time:               0.058127403259277344\n",
      "    test time:                0.012089014053344727\n",
      "    epoch time:               0.07098841667175293\n",
      "    joint lr:                 0.0010133224875256274\n",
      "epoch: 169 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.004043844787196981\n",
      "    train cross_ent loss:     0.0022323918140803776\n",
      "    test overall loss:        0.12387062112490337\n",
      "    test cross_ent loss:      0.12205932537714641\n",
      "    cluster loss:             2949.3604329427085\n",
      "    separation loss:          2.8168946901957193\n",
      "    avg separation loss:      7.195580164591472\n",
      "    l1_addon loss:            40.07603454589844\n",
      "    l1 loss:                  0.6090143918991089\n",
      "    train time:               0.05815625190734863\n",
      "    test time:                0.012149572372436523\n",
      "    epoch time:               0.07108879089355469\n",
      "    joint lr:                 0.0005520946313251855\n",
      "epoch: 170 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.003589815848196546\n",
      "    train cross_ent loss:     0.0017785915018369753\n",
      "    test overall loss:        0.124558350071311\n",
      "    test cross_ent loss:      0.12274724679688613\n",
      "    cluster loss:             2949.3606770833335\n",
      "    separation loss:          2.817574977874756\n",
      "    avg separation loss:      7.209362506866455\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  0.6090143918991089\n",
      "    train time:               0.058110713958740234\n",
      "    test time:                0.012135505676269531\n",
      "    epoch time:               0.0709831714630127\n",
      "    joint lr:                 0.0001\n",
      "epoch: 170 (PUSH) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.003589815848196546\n",
      "    train cross_ent loss:     0.0017785915018369753\n",
      "    test overall loss:        0.13483517741163573\n",
      "    test cross_ent loss:      0.13302407413721085\n",
      "    cluster loss:             2949.3138834635415\n",
      "    separation loss:          2.505228598912557\n",
      "    avg separation loss:      6.7805813153584795\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  0.6090143918991089\n",
      "    train time:               0.058110713958740234\n",
      "    test time:                0.012408256530761719\n",
      "    epoch time:               0.39213085174560547\n",
      "epoch: 170 (1/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.013639925772117244\n",
      "    train cross_ent loss:     0.011982030390451351\n",
      "    test overall loss:        0.1342807567367951\n",
      "    test cross_ent loss:      0.13277572703858218\n",
      "    cluster loss:             2949.3135579427085\n",
      "    separation loss:          2.503260533014933\n",
      "    avg separation loss:      6.77394978205363\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  0.30293333530426025\n",
      "    train time:               0.0230252742767334\n",
      "    test time:                0.012190103530883789\n",
      "    epoch time:               0.03569149971008301\n",
      "    last layer lr:            0.0007599999999999978\n",
      "epoch: 170 (2/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.012676719265679518\n",
      "    train cross_ent loss:     0.010599508778088622\n",
      "    test overall loss:        0.13537664773563543\n",
      "    test cross_ent loss:      0.133413286258777\n",
      "    cluster loss:             2949.3133138020835\n",
      "    separation loss:          2.5023152033487954\n",
      "    avg separation loss:      6.767604033152263\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  0.7612683773040771\n",
      "    train time:               0.022551774978637695\n",
      "    test time:                0.012050390243530273\n",
      "    epoch time:               0.03508281707763672\n",
      "    last layer lr:            0.0014199999999999955\n",
      "epoch: 170 (3/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.015076718914012114\n",
      "    train cross_ent loss:     0.012800709344446659\n",
      "    test overall loss:        0.13538187245527902\n",
      "    test cross_ent loss:      0.1330849633862575\n",
      "    cluster loss:             2949.3142903645835\n",
      "    separation loss:          2.5071895519892373\n",
      "    avg separation loss:      6.797454198201497\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  1.0948162078857422\n",
      "    train time:               0.022475719451904297\n",
      "    test time:                0.012053966522216797\n",
      "    epoch time:               0.03499960899353027\n",
      "    last layer lr:            0.0020800000000000046\n",
      "epoch: 170 (4/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.013605009919653336\n",
      "    train cross_ent loss:     0.01091345606578721\n",
      "    test overall loss:        0.13505865881840387\n",
      "    test cross_ent loss:      0.13229042602082094\n",
      "    cluster loss:             2949.3136393229165\n",
      "    separation loss:          2.5049291451772056\n",
      "    avg separation loss:      6.776854356129964\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  1.5661394596099854\n",
      "    train time:               0.022646188735961914\n",
      "    test time:                0.012089967727661133\n",
      "    epoch time:               0.03523898124694824\n",
      "    last layer lr:            0.0027400000000000024\n",
      "epoch: 170 (5/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.01620247747956051\n",
      "    train cross_ent loss:     0.013082898351260357\n",
      "    test overall loss:        0.13592220718661943\n",
      "    test cross_ent loss:      0.13268743455410004\n",
      "    cluster loss:             2949.3136393229165\n",
      "    separation loss:          2.503896633783976\n",
      "    avg separation loss:      6.774125417073567\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  2.0326786041259766\n",
      "    train time:               0.02249312400817871\n",
      "    test time:                0.012084245681762695\n",
      "    epoch time:               0.03505563735961914\n",
      "    last layer lr:            0.0034\n",
      "epoch: 170 (6/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.01621278903136651\n",
      "    train cross_ent loss:     0.012686763269205889\n",
      "    test overall loss:        0.13515719398856163\n",
      "    test cross_ent loss:      0.1314136330038309\n",
      "    cluster loss:             2949.3133951822915\n",
      "    separation loss:          2.516119917233785\n",
      "    avg separation loss:      6.816723982493083\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  2.541473865509033\n",
      "    train time:               0.022516727447509766\n",
      "    test time:                0.012053966522216797\n",
      "    epoch time:               0.03504323959350586\n",
      "    last layer lr:            0.004059999999999998\n",
      "epoch: 170 (7/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.013213461575408777\n",
      "    train cross_ent loss:     0.009098481645600663\n",
      "    test overall loss:        0.13572155808409056\n",
      "    test cross_ent loss:      0.13159597913424173\n",
      "    cluster loss:             2949.313720703125\n",
      "    separation loss:          2.507171352704366\n",
      "    avg separation loss:      6.777273972829183\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  2.92348575592041\n",
      "    train time:               0.022688865661621094\n",
      "    test time:                0.012073993682861328\n",
      "    epoch time:               0.03525495529174805\n",
      "    last layer lr:            0.004719999999999996\n",
      "epoch: 170 (8/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.014802888760136234\n",
      "    train cross_ent loss:     0.010329129484792551\n",
      "    test overall loss:        0.13688525184988976\n",
      "    test cross_ent loss:      0.1322631345440944\n",
      "    cluster loss:             2949.3135579427085\n",
      "    separation loss:          2.498864730199178\n",
      "    avg separation loss:      6.745908260345459\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  3.420027732849121\n",
      "    train time:               0.022498607635498047\n",
      "    test time:                0.012068986892700195\n",
      "    epoch time:               0.03505063056945801\n",
      "    last layer lr:            0.0053800000000000054\n",
      "epoch: 170 (9/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.01623777796824773\n",
      "    train cross_ent loss:     0.011325923519002067\n",
      "    test overall loss:        0.1359457237025102\n",
      "    test cross_ent loss:      0.1307129735747973\n",
      "    cluster loss:             2949.3131510416665\n",
      "    separation loss:          2.505806088447571\n",
      "    avg separation loss:      6.772411664326985\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  4.030656814575195\n",
      "    train time:               0.02253580093383789\n",
      "    test time:                0.012036561965942383\n",
      "    epoch time:               0.035041093826293945\n",
      "    last layer lr:            0.006040000000000003\n",
      "epoch: 170 (10/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.018025115753213566\n",
      "    train cross_ent loss:     0.012457527530690035\n",
      "    test overall loss:        0.13586906840403876\n",
      "    test cross_ent loss:      0.12998451044162115\n",
      "    cluster loss:             2949.3136393229165\n",
      "    separation loss:          2.5041739543279014\n",
      "    avg separation loss:      6.7683234214782715\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  4.682466506958008\n",
      "    train time:               0.02269887924194336\n",
      "    test time:                0.012170076370239258\n",
      "    epoch time:               0.03538370132446289\n",
      "    last layer lr:            0.0067\n",
      "epoch: 170 (11/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.01783746263633172\n",
      "    train cross_ent loss:     0.011485388424868384\n",
      "    test overall loss:        0.1373355450729529\n",
      "    test cross_ent loss:      0.1309861739476522\n",
      "    cluster loss:             2949.314208984375\n",
      "    separation loss:          2.4925625721613565\n",
      "    avg separation loss:      6.727333386739095\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  5.14728307723999\n",
      "    train time:               0.022730112075805664\n",
      "    test time:                0.01216745376586914\n",
      "    epoch time:               0.03541445732116699\n",
      "    last layer lr:            0.0073599999999999985\n",
      "epoch: 170 (12/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.015347231075995497\n",
      "    train cross_ent loss:     0.008775980573975377\n",
      "    test overall loss:        0.13539043441414833\n",
      "    test cross_ent loss:      0.12888567273815474\n",
      "    cluster loss:             2949.3141276041665\n",
      "    separation loss:          2.5101746320724487\n",
      "    avg separation loss:      6.8043599128723145\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  5.302674293518066\n",
      "    train time:               0.022611379623413086\n",
      "    test time:                0.012052059173583984\n",
      "    epoch time:               0.03514814376831055\n",
      "    last layer lr:            0.008019999999999994\n",
      "epoch: 170 (13/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.018292862508032057\n",
      "    train cross_ent loss:     0.011414249686317312\n",
      "    test overall loss:        0.13678125043710074\n",
      "    test cross_ent loss:      0.12937215467294058\n",
      "    cluster loss:             2949.314697265625\n",
      "    separation loss:          2.4986687103907266\n",
      "    avg separation loss:      6.763017336527507\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  6.207005023956299\n",
      "    train time:               0.022504091262817383\n",
      "    test time:                0.012158393859863281\n",
      "    epoch time:               0.0351560115814209\n",
      "    last layer lr:            0.008680000000000005\n",
      "epoch: 170 (14/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.01875755325373676\n",
      "    train cross_ent loss:     0.011069099806870023\n",
      "    test overall loss:        0.135697981963555\n",
      "    test cross_ent loss:      0.12761925595502058\n",
      "    cluster loss:             2949.3135579427085\n",
      "    separation loss:          2.5077168941497803\n",
      "    avg separation loss:      6.7889297803243\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  6.876638412475586\n",
      "    train time:               0.022577524185180664\n",
      "    test time:                0.012061834335327148\n",
      "    epoch time:               0.035114288330078125\n",
      "    last layer lr:            0.009340000000000003\n",
      "epoch: 170 (15/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.01947731990367174\n",
      "    train cross_ent loss:     0.011202842773248753\n",
      "    test overall loss:        0.1344752348959446\n",
      "    test cross_ent loss:      0.1260892767459154\n",
      "    cluster loss:             2949.3133951822915\n",
      "    separation loss:          2.5142826636632285\n",
      "    avg separation loss:      6.80916166305542\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  7.183869361877441\n",
      "    train time:               0.02252197265625\n",
      "    test time:                0.012049674987792969\n",
      "    epoch time:               0.035051822662353516\n",
      "    last layer lr:            0.01\n",
      "epoch: 170 (16/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.016697151586413383\n",
      "    train cross_ent loss:     0.008136574644595385\n",
      "    test overall loss:        0.1362164057791233\n",
      "    test cross_ent loss:      0.12752683895329633\n",
      "    cluster loss:             2949.3138020833335\n",
      "    separation loss:          2.4989174604415894\n",
      "    avg separation loss:      6.757478396097819\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  7.487473487854004\n",
      "    train time:               0.022661685943603516\n",
      "    test time:                0.012055635452270508\n",
      "    epoch time:               0.035205841064453125\n",
      "    last layer lr:            0.009604000000000001\n",
      "epoch: 170 (17/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.01592850633379486\n",
      "    train cross_ent loss:     0.0075556910079386495\n",
      "    test overall loss:        0.13455224906404814\n",
      "    test cross_ent loss:      0.1261825809876124\n",
      "    cluster loss:             2949.3134765625\n",
      "    separation loss:          2.4989904165267944\n",
      "    avg separation loss:      6.7591807047526045\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  7.16757345199585\n",
      "    train time:               0.022530794143676758\n",
      "    test time:                0.012047529220581055\n",
      "    epoch time:               0.03504800796508789\n",
      "    last layer lr:            0.009208000000000003\n",
      "epoch: 170 (18/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.0161497150030401\n",
      "    train cross_ent loss:     0.008027457968435354\n",
      "    test overall loss:        0.1339002288877964\n",
      "    test cross_ent loss:      0.12590671082337698\n",
      "    cluster loss:             2949.3133951822915\n",
      "    separation loss:          2.4963191747665405\n",
      "    avg separation loss:      6.746634324391683\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  6.791422367095947\n",
      "    train time:               0.022484779357910156\n",
      "    test time:                0.01206827163696289\n",
      "    epoch time:               0.03503108024597168\n",
      "    last layer lr:            0.008811999999999997\n",
      "epoch: 170 (19/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.01723144172380368\n",
      "    train cross_ent loss:     0.0092906861876448\n",
      "    test overall loss:        0.13291275252898535\n",
      "    test cross_ent loss:      0.1250256858766079\n",
      "    cluster loss:             2949.3133138020835\n",
      "    separation loss:          2.4986719290415444\n",
      "    avg separation loss:      6.749186992645264\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  6.684975624084473\n",
      "    train time:               0.022534608840942383\n",
      "    test time:                0.012046575546264648\n",
      "    epoch time:               0.03506016731262207\n",
      "    last layer lr:            0.008415999999999998\n",
      "epoch: 170 (20/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.014003636315464973\n",
      "    train cross_ent loss:     0.006443092819406754\n",
      "    test overall loss:        0.13216583927472433\n",
      "    test cross_ent loss:      0.12480597508450349\n",
      "    cluster loss:             2949.3133951822915\n",
      "    separation loss:          2.5066062609354653\n",
      "    avg separation loss:      6.777289867401123\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  6.15777587890625\n",
      "    train time:               0.023259878158569336\n",
      "    test time:                0.012377738952636719\n",
      "    epoch time:               0.03612041473388672\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 170 (21/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.015782202180061076\n",
      "    train cross_ent loss:     0.008723836780215303\n",
      "    test overall loss:        0.1313894366224607\n",
      "    test cross_ent loss:      0.12430290629466374\n",
      "    cluster loss:             2949.3133138020835\n",
      "    separation loss:          2.508135517438253\n",
      "    avg separation loss:      6.798238436381022\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  5.88443660736084\n",
      "    train time:               0.02317976951599121\n",
      "    test time:                0.012369632720947266\n",
      "    epoch time:               0.03601837158203125\n",
      "    last layer lr:            0.007624000000000002\n",
      "epoch: 170 (22/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.013227606088750891\n",
      "    train cross_ent loss:     0.006334498084874617\n",
      "    test overall loss:        0.1299368515610695\n",
      "    test cross_ent loss:      0.12315735903879006\n",
      "    cluster loss:             2949.3131510416665\n",
      "    separation loss:          2.511748194694519\n",
      "    avg separation loss:      6.800113360087077\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  5.577400207519531\n",
      "    train time:               0.02333545684814453\n",
      "    test time:                0.012403726577758789\n",
      "    epoch time:               0.03622031211853027\n",
      "    last layer lr:            0.0072280000000000035\n",
      "epoch: 170 (23/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.013223057923217615\n",
      "    train cross_ent loss:     0.0065732755206732284\n",
      "    test overall loss:        0.13028581564625105\n",
      "    test cross_ent loss:      0.12362758815288544\n",
      "    cluster loss:             2949.3133138020835\n",
      "    separation loss:          2.5089005629221597\n",
      "    avg separation loss:      6.794259707132976\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  5.456137657165527\n",
      "    train time:               0.023186206817626953\n",
      "    test time:                0.012373208999633789\n",
      "    epoch time:               0.03604745864868164\n",
      "    last layer lr:            0.006831999999999998\n",
      "epoch: 170 (24/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.01231075202425321\n",
      "    train cross_ent loss:     0.005976866128750973\n",
      "    test overall loss:        0.13049166152874628\n",
      "    test cross_ent loss:      0.12440550637741883\n",
      "    cluster loss:             2949.3138834635415\n",
      "    separation loss:          2.503477931022644\n",
      "    avg separation loss:      6.778004328409831\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  4.884063720703125\n",
      "    train time:               0.023162126541137695\n",
      "    test time:                0.012485027313232422\n",
      "    epoch time:               0.03612852096557617\n",
      "    last layer lr:            0.006436\n",
      "epoch: 170 (25/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.013483492243621085\n",
      "    train cross_ent loss:     0.007484316825866699\n",
      "    test overall loss:        0.12972575798630714\n",
      "    test cross_ent loss:      0.12373674226303895\n",
      "    cluster loss:             2949.3138834635415\n",
      "    separation loss:          2.5054935614267984\n",
      "    avg separation loss:      6.770001729329427\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  4.786925315856934\n",
      "    train time:               0.023331880569458008\n",
      "    test time:                0.01241159439086914\n",
      "    epoch time:               0.0362391471862793\n",
      "    last layer lr:            0.00604\n",
      "epoch: 170 (26/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.012772058188501332\n",
      "    train cross_ent loss:     0.007033772074565705\n",
      "    test overall loss:        0.12964536994695663\n",
      "    test cross_ent loss:      0.123832231387496\n",
      "    cluster loss:             2949.3138834635415\n",
      "    separation loss:          2.5025750001271567\n",
      "    avg separation loss:      6.770439783732097\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  4.611048698425293\n",
      "    train time:               0.023183584213256836\n",
      "    test time:                0.012356042861938477\n",
      "    epoch time:               0.036010026931762695\n",
      "    last layer lr:            0.005644000000000002\n",
      "epoch: 170 (27/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.012510478962212801\n",
      "    train cross_ent loss:     0.007014905697562628\n",
      "    test overall loss:        0.1283768154680729\n",
      "    test cross_ent loss:      0.12299704800049464\n",
      "    cluster loss:             2949.313232421875\n",
      "    separation loss:          2.4989070494969687\n",
      "    avg separation loss:      6.749249617258708\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  4.177679061889648\n",
      "    train time:               0.023219823837280273\n",
      "    test time:                0.012389659881591797\n",
      "    epoch time:               0.03607535362243652\n",
      "    last layer lr:            0.005248000000000003\n",
      "epoch: 170 (28/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.012092977865702577\n",
      "    train cross_ent loss:     0.006846062192279432\n",
      "    test overall loss:        0.12898867204785347\n",
      "    test cross_ent loss:      0.1237640418112278\n",
      "    cluster loss:             2949.3136393229165\n",
      "    separation loss:          2.490987698237101\n",
      "    avg separation loss:      6.717703183492024\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  4.022538661956787\n",
      "    train time:               0.02337956428527832\n",
      "    test time:                0.012379646301269531\n",
      "    epoch time:               0.03624129295349121\n",
      "    last layer lr:            0.004851999999999998\n",
      "epoch: 170 (29/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.011110807303339243\n",
      "    train cross_ent loss:     0.006178186507895589\n",
      "    test overall loss:        0.12780122583111128\n",
      "    test cross_ent loss:      0.12311378121376038\n",
      "    cluster loss:             2949.3133138020835\n",
      "    separation loss:          2.4935984214146933\n",
      "    avg separation loss:      6.7275153795878095\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  3.485353946685791\n",
      "    train time:               0.023253202438354492\n",
      "    test time:                0.012382984161376953\n",
      "    epoch time:               0.0361175537109375\n",
      "    last layer lr:            0.004455999999999999\n",
      "epoch: 170 (30/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.012262888407955566\n",
      "    train cross_ent loss:     0.007648403200113939\n",
      "    test overall loss:        0.12681347380081812\n",
      "    test cross_ent loss:      0.1222246630738179\n",
      "    cluster loss:             2949.3134765625\n",
      "    separation loss:          2.5020457108815513\n",
      "    avg separation loss:      6.755324999491374\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  3.3867146968841553\n",
      "    train time:               0.023200035095214844\n",
      "    test time:                0.01237940788269043\n",
      "    epoch time:               0.0360867977142334\n",
      "    last layer lr:            0.004060000000000001\n",
      "epoch: 170 (31/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.011398758118351301\n",
      "    train cross_ent loss:     0.006970987939793203\n",
      "    test overall loss:        0.1274734896918138\n",
      "    test cross_ent loss:      0.12316711246967316\n",
      "    cluster loss:             2949.3135579427085\n",
      "    separation loss:          2.502038518587748\n",
      "    avg separation loss:      6.756180286407471\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  3.1042885780334473\n",
      "    train time:               0.023359298706054688\n",
      "    test time:                0.012387514114379883\n",
      "    epoch time:               0.036234378814697266\n",
      "    last layer lr:            0.0036640000000000015\n",
      "epoch: 170 (32/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.0116173573769629\n",
      "    train cross_ent loss:     0.007517761136922572\n",
      "    test overall loss:        0.1269539917508761\n",
      "    test cross_ent loss:      0.12301589921116829\n",
      "    cluster loss:             2949.3133951822915\n",
      "    separation loss:          2.5005027850468955\n",
      "    avg separation loss:      6.752806186676025\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  2.7359976768493652\n",
      "    train time:               0.023256778717041016\n",
      "    test time:                0.012373208999633789\n",
      "    epoch time:               0.03611445426940918\n",
      "    last layer lr:            0.003268000000000003\n",
      "epoch: 170 (33/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.01170061958125896\n",
      "    train cross_ent loss:     0.007879986867515577\n",
      "    test overall loss:        0.12547592694560686\n",
      "    test cross_ent loss:      0.12169374463458855\n",
      "    cluster loss:             2949.3125813802085\n",
      "    separation loss:          2.506347179412842\n",
      "    avg separation loss:      6.761185963948567\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  2.5800890922546387\n",
      "    train time:               0.023250579833984375\n",
      "    test time:                0.012381792068481445\n",
      "    epoch time:               0.03611302375793457\n",
      "    last layer lr:            0.002871999999999997\n",
      "epoch: 170 (34/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.0114601394161582\n",
      "    train cross_ent loss:     0.007823514991388138\n",
      "    test overall loss:        0.12475898365179698\n",
      "    test cross_ent loss:      0.12118030836184819\n",
      "    cluster loss:             2949.3129069010415\n",
      "    separation loss:          2.5056453148523965\n",
      "    avg separation loss:      6.783179918924968\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  2.3765790462493896\n",
      "    train time:               0.023420095443725586\n",
      "    test time:                0.012380123138427734\n",
      "    epoch time:               0.03628945350646973\n",
      "    last layer lr:            0.0024759999999999986\n",
      "epoch: 170 (35/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.013186140555060573\n",
      "    train cross_ent loss:     0.00983384835611408\n",
      "    test overall loss:        0.12450673927863438\n",
      "    test cross_ent loss:      0.12125160917639732\n",
      "    cluster loss:             2949.3133951822915\n",
      "    separation loss:          2.5052989721298218\n",
      "    avg separation loss:      6.785689036051433\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  2.053041934967041\n",
      "    train time:               0.023258447647094727\n",
      "    test time:                0.012473106384277344\n",
      "    epoch time:               0.03620028495788574\n",
      "    last layer lr:            0.0020800000000000003\n",
      "epoch: 170 (36/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.008695241995155811\n",
      "    train cross_ent loss:     0.005657039957845377\n",
      "    test overall loss:        0.12527201448877653\n",
      "    test cross_ent loss:      0.12245538147787254\n",
      "    cluster loss:             2949.3135579427085\n",
      "    separation loss:          2.498932441075643\n",
      "    avg separation loss:      6.752767880757649\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  1.614542007446289\n",
      "    train time:               0.0232546329498291\n",
      "    test time:                0.012381553649902344\n",
      "    epoch time:               0.03611397743225098\n",
      "    last layer lr:            0.0016840000000000017\n",
      "epoch: 170 (37/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.009823374915868044\n",
      "    train cross_ent loss:     0.007178707074167\n",
      "    test overall loss:        0.12347360948721568\n",
      "    test cross_ent loss:      0.1209343330313762\n",
      "    cluster loss:             2949.3131510416665\n",
      "    separation loss:          2.50918702284495\n",
      "    avg separation loss:      6.784992535909017\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  1.3371831178665161\n",
      "    train time:               0.023413658142089844\n",
      "    test time:                0.012388229370117188\n",
      "    epoch time:               0.036284685134887695\n",
      "    last layer lr:            0.001288000000000003\n",
      "epoch: 170 (38/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.009182801625380913\n",
      "    train cross_ent loss:     0.006830578152504232\n",
      "    test overall loss:        0.12304606164495151\n",
      "    test cross_ent loss:      0.12079494508604209\n",
      "    cluster loss:             2949.3130696614585\n",
      "    separation loss:          2.5156238079071045\n",
      "    avg separation loss:      6.80606730779012\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  1.0490214824676514\n",
      "    train time:               0.02322554588317871\n",
      "    test time:                0.012363195419311523\n",
      "    epoch time:               0.036069393157958984\n",
      "    last layer lr:            0.0008919999999999973\n",
      "epoch: 170 (39/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.011943268175754283\n",
      "    train cross_ent loss:     0.009875076615975963\n",
      "    test overall loss:        0.12375778642793496\n",
      "    test cross_ent loss:      0.12175908125936985\n",
      "    cluster loss:             2949.3125813802085\n",
      "    separation loss:          2.4997905095418296\n",
      "    avg separation loss:      6.747036139170329\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  0.7966086864471436\n",
      "    train time:               0.023276090621948242\n",
      "    test time:                0.012360811233520508\n",
      "    epoch time:               0.03612065315246582\n",
      "    last layer lr:            0.0004959999999999986\n",
      "epoch: 170 (40/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.008762155737107\n",
      "    train cross_ent loss:     0.006946855923160911\n",
      "    test overall loss:        0.1229462871948878\n",
      "    test cross_ent loss:      0.12122646843393643\n",
      "    cluster loss:             2949.31298828125\n",
      "    separation loss:          2.505650520324707\n",
      "    avg separation loss:      6.761462370554606\n",
      "    l1_addon loss:            40.06970977783203\n",
      "    l1 loss:                  0.5177286863327026\n",
      "    train time:               0.02354574203491211\n",
      "    test time:                0.012439250946044922\n",
      "    epoch time:               0.0364835262298584\n",
      "    last layer lr:            0.0001\n",
      "epoch: 171 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.007207562008665668\n",
      "    train cross_ent loss:     0.005487764512913095\n",
      "    test overall loss:        0.12285739742219448\n",
      "    test cross_ent loss:      0.12113764074941476\n",
      "    cluster loss:             2949.3133138020835\n",
      "    separation loss:          2.504521608352661\n",
      "    avg separation loss:      6.764132499694824\n",
      "    l1_addon loss:            40.06756591796875\n",
      "    l1 loss:                  0.5177286863327026\n",
      "    train time:               0.06089162826538086\n",
      "    test time:                0.012404680252075195\n",
      "    epoch time:               0.07415485382080078\n",
      "    joint lr:                 0.0009861958963236286\n",
      "epoch: 172 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.00988530833274126\n",
      "    train cross_ent loss:     0.008165736734453175\n",
      "    test overall loss:        0.11743139723936717\n",
      "    test cross_ent loss:      0.11571239680051804\n",
      "    cluster loss:             2949.3111165364585\n",
      "    separation loss:          2.4976388216018677\n",
      "    avg separation loss:      6.771085262298584\n",
      "    l1_addon loss:            40.04249572753906\n",
      "    l1 loss:                  0.5177286863327026\n",
      "    train time:               0.06058311462402344\n",
      "    test time:                0.012243270874023438\n",
      "    epoch time:               0.07357263565063477\n",
      "    joint lr:                 0.001854667874720785\n",
      "epoch: 173 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.005960836540907621\n",
      "    train cross_ent loss:     0.004245595016982406\n",
      "    test overall loss:        0.1103198720763127\n",
      "    test cross_ent loss:      0.10860687866806984\n",
      "    cluster loss:             2949.3046061197915\n",
      "    separation loss:          2.505123774210612\n",
      "    avg separation loss:      6.7482536633809405\n",
      "    l1_addon loss:            39.842185974121094\n",
      "    l1 loss:                  0.5177286863327026\n",
      "    train time:               0.05832242965698242\n",
      "    test time:                0.012100696563720703\n",
      "    epoch time:               0.0711512565612793\n",
      "    joint lr:                 0.0027056817939603655\n",
      "epoch: 174 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.00566027067705161\n",
      "    train cross_ent loss:     0.003947933398497601\n",
      "    test overall loss:        0.11074615083634853\n",
      "    test cross_ent loss:      0.10903299786150455\n",
      "    cluster loss:             2949.300048828125\n",
      "    separation loss:          2.487878402074178\n",
      "    avg separation loss:      6.737654844919841\n",
      "    l1_addon loss:            39.8475341796875\n",
      "    l1 loss:                  0.5177286863327026\n",
      "    train time:               0.058141231536865234\n",
      "    test time:                0.012130975723266602\n",
      "    epoch time:               0.07107090950012207\n",
      "    joint lr:                 0.003539499968027705\n",
      "epoch: 175 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.0034529101362244952\n",
      "    train cross_ent loss:     0.0017377171057483389\n",
      "    test overall loss:        0.11634120779732864\n",
      "    test cross_ent loss:      0.1146240873883168\n",
      "    cluster loss:             2949.2970377604165\n",
      "    separation loss:          2.443181117375692\n",
      "    avg separation loss:      6.664869467417399\n",
      "    l1_addon loss:            39.979759216308594\n",
      "    l1 loss:                  0.5177286863327026\n",
      "    train time:               0.05824995040893555\n",
      "    test time:                0.012117624282836914\n",
      "    epoch time:               0.0711209774017334\n",
      "    joint lr:                 0.00435638121043428\n",
      "epoch: 176 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.0032833028429498277\n",
      "    train cross_ent loss:     0.0015662421549980838\n",
      "    test overall loss:        0.11301636571685474\n",
      "    test cross_ent loss:      0.1113004715492328\n",
      "    cluster loss:             2949.2899576822915\n",
      "    separation loss:          2.4090072313944497\n",
      "    avg separation loss:      6.545921643575032\n",
      "    l1_addon loss:            39.938865661621094\n",
      "    l1 loss:                  0.5177286863327026\n",
      "    train time:               0.05807304382324219\n",
      "    test time:                0.012239217758178711\n",
      "    epoch time:               0.0710611343383789\n",
      "    joint lr:                 0.00515658087799592\n",
      "epoch: 177 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.0026292666896349853\n",
      "    train cross_ent loss:     0.000915183304136412\n",
      "    test overall loss:        0.10798873131473859\n",
      "    test cross_ent loss:      0.10627676732838154\n",
      "    cluster loss:             2949.283935546875\n",
      "    separation loss:          2.402298927307129\n",
      "    avg separation loss:      6.496574401855469\n",
      "    l1_addon loss:            39.807861328125\n",
      "    l1 loss:                  0.5177286863327026\n",
      "    train time:               0.05827498435974121\n",
      "    test time:                0.012151241302490234\n",
      "    epoch time:               0.07120394706726074\n",
      "    joint lr:                 0.005940350914085284\n",
      "epoch: 178 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.0029708411182380384\n",
      "    train cross_ent loss:     0.0012595224931525688\n",
      "    test overall loss:        0.10972937010228634\n",
      "    test cross_ent loss:      0.10801956119636695\n",
      "    cluster loss:             2949.2826334635415\n",
      "    separation loss:          2.4075756072998047\n",
      "    avg separation loss:      6.515937328338623\n",
      "    l1_addon loss:            39.73612976074219\n",
      "    l1 loss:                  0.5177286863327026\n",
      "    train time:               0.05809497833251953\n",
      "    test time:                0.012096643447875977\n",
      "    epoch time:               0.07096266746520996\n",
      "    joint lr:                 0.00670793989136506\n",
      "epoch: 179 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.0025511832856055764\n",
      "    train cross_ent loss:     0.0008429542326161431\n",
      "    test overall loss:        0.11046867817640305\n",
      "    test cross_ent loss:      0.10876150988042355\n",
      "    cluster loss:             2949.2835286458335\n",
      "    separation loss:          2.419843872388204\n",
      "    avg separation loss:      6.543557167053223\n",
      "    l1_addon loss:            39.648128509521484\n",
      "    l1 loss:                  0.5177286863327026\n",
      "    train time:               0.05822277069091797\n",
      "    test time:                0.012135744094848633\n",
      "    epoch time:               0.07116174697875977\n",
      "    joint lr:                 0.007459593054007833\n",
      "epoch: 180 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.0029125686269253492\n",
      "    train cross_ent loss:     0.0012056608926892902\n",
      "    test overall loss:        0.1116201647867759\n",
      "    test cross_ent loss:      0.10991199873387814\n",
      "    cluster loss:             2949.283203125\n",
      "    separation loss:          2.4165118932724\n",
      "    avg separation loss:      6.550097783406575\n",
      "    l1_addon loss:            39.681365966796875\n",
      "    l1 loss:                  0.5177286863327026\n",
      "    train time:               0.05804586410522461\n",
      "    test time:                0.012100458145141602\n",
      "    epoch time:               0.07088160514831543\n",
      "    joint lr:                 0.008195552359408614\n",
      "epoch: 181 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.00257391635225051\n",
      "    train cross_ent loss:     0.0008628010659271644\n",
      "    test overall loss:        0.10830609935025375\n",
      "    test cross_ent loss:      0.10659291129559278\n",
      "    cluster loss:             2949.2793782552085\n",
      "    separation loss:          2.3439207474390664\n",
      "    avg separation loss:      6.387446244557698\n",
      "    l1_addon loss:            39.8487548828125\n",
      "    l1 loss:                  0.5177286863327026\n",
      "    train time:               0.05825090408325195\n",
      "    test time:                0.012101173400878906\n",
      "    epoch time:               0.07104897499084473\n",
      "    joint lr:                 0.007713866994023813\n",
      "epoch: 182 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.003222988840813438\n",
      "    train cross_ent loss:     0.001509699110303902\n",
      "    test overall loss:        0.10695656264821689\n",
      "    test cross_ent loss:      0.10524765588343143\n",
      "    cluster loss:             2949.2764485677085\n",
      "    separation loss:          2.3410398165384927\n",
      "    avg separation loss:      6.365440209706624\n",
      "    l1_addon loss:            39.70595932006836\n",
      "    l1 loss:                  0.5177286863327026\n",
      "    train time:               0.05814838409423828\n",
      "    test time:                0.012095451354980469\n",
      "    epoch time:               0.0709531307220459\n",
      "    joint lr:                 0.007241005780710745\n",
      "epoch: 183 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.006234198123113149\n",
      "    train cross_ent loss:     0.004531071589250739\n",
      "    test overall loss:        0.11234233031670253\n",
      "    test cross_ent loss:      0.11063555038223664\n",
      "    cluster loss:             2949.2793782552085\n",
      "    separation loss:          2.3615547815958657\n",
      "    avg separation loss:      6.397007783253987\n",
      "    l1_addon loss:            39.635101318359375\n",
      "    l1 loss:                  0.5177286863327026\n",
      "    train time:               0.05825090408325195\n",
      "    test time:                0.012131929397583008\n",
      "    epoch time:               0.07119011878967285\n",
      "    joint lr:                 0.006776840404964548\n",
      "epoch: 184 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.006433564755651686\n",
      "    train cross_ent loss:     0.004720614341850806\n",
      "    test overall loss:        0.11288514547049999\n",
      "    test cross_ent loss:      0.11118252761662006\n",
      "    cluster loss:             2949.297607421875\n",
      "    separation loss:          2.4138569037119546\n",
      "    avg separation loss:      6.36616055170695\n",
      "    l1_addon loss:            39.49635696411133\n",
      "    l1 loss:                  0.5177286863327026\n",
      "    train time:               0.05808424949645996\n",
      "    test time:                0.012155771255493164\n",
      "    epoch time:               0.07105088233947754\n",
      "    joint lr:                 0.006321244236155204\n",
      "epoch: 185 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.00724372720449335\n",
      "    train cross_ent loss:     0.0055379109107889235\n",
      "    test overall loss:        0.11715560778975487\n",
      "    test cross_ent loss:      0.11544111991922061\n",
      "    cluster loss:             2949.3065592447915\n",
      "    separation loss:          2.425806164741516\n",
      "    avg separation loss:      6.459096749623616\n",
      "    l1_addon loss:            39.892051696777344\n",
      "    l1 loss:                  0.5177286863327026\n",
      "    train time:               0.05811905860900879\n",
      "    test time:                0.012162446975708008\n",
      "    epoch time:               0.07102370262145996\n",
      "    joint lr:                 0.00587409230668155\n",
      "epoch: 186 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.003646044060587883\n",
      "    train cross_ent loss:     0.0019335966305031131\n",
      "    test overall loss:        0.12062773729364078\n",
      "    test cross_ent loss:      0.11891830526292324\n",
      "    cluster loss:             2949.30517578125\n",
      "    separation loss:          2.4460970958073935\n",
      "    avg separation loss:      6.472386837005615\n",
      "    l1_addon loss:            39.72353744506836\n",
      "    l1 loss:                  0.5177286863327026\n",
      "    train time:               0.05799126625061035\n",
      "    test time:                0.01211404800415039\n",
      "    epoch time:               0.07091879844665527\n",
      "    joint lr:                 0.0054352612913737535\n",
      "epoch: 187 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.00537108438503411\n",
      "    train cross_ent loss:     0.003663815848995\n",
      "    test overall loss:        0.12014888040721416\n",
      "    test cross_ent loss:      0.11844088075061639\n",
      "    cluster loss:             2949.3043619791665\n",
      "    separation loss:          2.434164841969808\n",
      "    avg separation loss:      6.404721260070801\n",
      "    l1_addon loss:            39.67566680908203\n",
      "    l1 loss:                  0.5177286863327026\n",
      "    train time:               0.05825924873352051\n",
      "    test time:                0.012300491333007812\n",
      "    epoch time:               0.07134389877319336\n",
      "    joint lr:                 0.005004629487141445\n",
      "epoch: 188 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.0038980160218973956\n",
      "    train cross_ent loss:     0.002184666463613717\n",
      "    test overall loss:        0.11021694416801135\n",
      "    test cross_ent loss:      0.10850118348995845\n",
      "    cluster loss:             2949.3064778645835\n",
      "    separation loss:          2.3610548178354898\n",
      "    avg separation loss:      6.207010746002197\n",
      "    l1_addon loss:            39.93439865112305\n",
      "    l1 loss:                  0.5177286863327026\n",
      "    train time:               0.058016061782836914\n",
      "    test time:                0.01212310791015625\n",
      "    epoch time:               0.07088398933410645\n",
      "    joint lr:                 0.004582076792864645\n",
      "epoch: 189 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.003839339724638396\n",
      "    train cross_ent loss:     0.002126192370067454\n",
      "    test overall loss:        0.10973373427987099\n",
      "    test cross_ent loss:      0.10802344729502995\n",
      "    cluster loss:             2949.2999674479165\n",
      "    separation loss:          2.3374271790186563\n",
      "    avg separation loss:      6.106187502543132\n",
      "    l1_addon loss:            39.75205993652344\n",
      "    l1 loss:                  0.5177286863327026\n",
      "    train time:               0.058193206787109375\n",
      "    test time:                0.012128829956054688\n",
      "    epoch time:               0.07106900215148926\n",
      "    joint lr:                 0.004167484689524657\n",
      "epoch: 190 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.0034365784894261095\n",
      "    train cross_ent loss:     0.0017280627831092312\n",
      "    test overall loss:        0.11334647114078204\n",
      "    test cross_ent loss:      0.11163858510553837\n",
      "    cluster loss:             2949.29736328125\n",
      "    separation loss:          2.3467957178751626\n",
      "    avg separation loss:      6.14796257019043\n",
      "    l1_addon loss:            39.67200469970703\n",
      "    l1 loss:                  0.5177286863327026\n",
      "    train time:               0.05809926986694336\n",
      "    test time:                0.012112617492675781\n",
      "    epoch time:               0.07098746299743652\n",
      "    joint lr:                 0.003760736220572192\n",
      "epoch: 191 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.002668765787449148\n",
      "    train cross_ent loss:     0.0009600147960655806\n",
      "    test overall loss:        0.11086610580484073\n",
      "    test cross_ent loss:      0.1091562956571579\n",
      "    cluster loss:             2949.2936197916665\n",
      "    separation loss:          2.3271400133768716\n",
      "    avg separation loss:      6.110585530598958\n",
      "    l1_addon loss:            39.73616409301758\n",
      "    l1 loss:                  0.5177286863327026\n",
      "    train time:               0.05823254585266113\n",
      "    test time:                0.012145519256591797\n",
      "    epoch time:               0.07112693786621094\n",
      "    joint lr:                 0.0033617159725298235\n",
      "epoch: 192 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.002716517244051728\n",
      "    train cross_ent loss:     0.0010062708040802842\n",
      "    test overall loss:        0.1096522385875384\n",
      "    test cross_ent loss:      0.10794189758598804\n",
      "    cluster loss:             2949.2926432291665\n",
      "    separation loss:          2.313996195793152\n",
      "    avg separation loss:      6.081323623657227\n",
      "    l1_addon loss:            39.7537841796875\n",
      "    l1 loss:                  0.5177286863327026\n",
      "    train time:               0.05802655220031738\n",
      "    test time:                0.012102842330932617\n",
      "    epoch time:               0.07087206840515137\n",
      "    joint lr:                 0.002970310055826246\n",
      "epoch: 193 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.002753741056140926\n",
      "    train cross_ent loss:     0.0010435313613723135\n",
      "    test overall loss:        0.10922977204124133\n",
      "    test cross_ent loss:      0.10752032945553462\n",
      "    cluster loss:             2949.291259765625\n",
      "    separation loss:          2.3105834325154624\n",
      "    avg separation loss:      6.098236878712972\n",
      "    l1_addon loss:            39.72380065917969\n",
      "    l1 loss:                  0.5177286863327026\n",
      "    train time:               0.05862116813659668\n",
      "    test time:                0.012241840362548828\n",
      "    epoch time:               0.07163453102111816\n",
      "    joint lr:                 0.0025864060858594865\n",
      "epoch: 194 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.002541203077675568\n",
      "    train cross_ent loss:     0.0008332138531841338\n",
      "    test overall loss:        0.10964491156240304\n",
      "    test cross_ent loss:      0.10793851874768734\n",
      "    cluster loss:             2949.29052734375\n",
      "    separation loss:          2.319382985432943\n",
      "    avg separation loss:      6.087232271830241\n",
      "    l1_addon loss:            39.622276306152344\n",
      "    l1 loss:                  0.5177286863327026\n",
      "    train time:               0.05802321434020996\n",
      "    test time:                0.01212930679321289\n",
      "    epoch time:               0.07088112831115723\n",
      "    joint lr:                 0.00220989316428648\n",
      "epoch: 195 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.0021726707798532313\n",
      "    train cross_ent loss:     0.00046650986284172785\n",
      "    test overall loss:        0.11197714507579803\n",
      "    test cross_ent loss:      0.11027111982305844\n",
      "    cluster loss:             2949.2911783854165\n",
      "    separation loss:          2.3299603859583535\n",
      "    avg separation loss:      6.1373515129089355\n",
      "    l1_addon loss:            39.61000061035156\n",
      "    l1 loss:                  0.5177286863327026\n",
      "    train time:               0.0581357479095459\n",
      "    test time:                0.012103557586669922\n",
      "    epoch time:               0.0709848403930664\n",
      "    joint lr:                 0.0018406618605363474\n",
      "epoch: 196 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.002750019517002834\n",
      "    train cross_ent loss:     0.0010429262490813723\n",
      "    test overall loss:        0.11402735797067483\n",
      "    test cross_ent loss:      0.11231902738412221\n",
      "    cluster loss:             2949.29052734375\n",
      "    separation loss:          2.301299571990967\n",
      "    avg separation loss:      6.0961079597473145\n",
      "    l1_addon loss:            39.68684005737305\n",
      "    l1 loss:                  0.5177286863327026\n",
      "    train time:               0.05830264091491699\n",
      "    test time:                0.012157678604125977\n",
      "    epoch time:               0.07121634483337402\n",
      "    joint lr:                 0.001478604193544789\n",
      "epoch: 197 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.002868133752296368\n",
      "    train cross_ent loss:     0.0011595582440754192\n",
      "    test overall loss:        0.11373717213670413\n",
      "    test cross_ent loss:      0.11202892226477464\n",
      "    cluster loss:             2949.2899576822915\n",
      "    separation loss:          2.2908184925715127\n",
      "    avg separation loss:      6.06840976079305\n",
      "    l1_addon loss:            39.68403625488281\n",
      "    l1 loss:                  0.5177286863327026\n",
      "    train time:               0.05817103385925293\n",
      "    test time:                0.012166976928710938\n",
      "    epoch time:               0.07109189033508301\n",
      "    joint lr:                 0.0011236136137069992\n",
      "epoch: 198 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.00209611377471851\n",
      "    train cross_ent loss:     0.00038822663514616177\n",
      "    test overall loss:        0.11156158894300461\n",
      "    test cross_ent loss:      0.10985409406324227\n",
      "    cluster loss:             2949.2886555989585\n",
      "    separation loss:          2.292584776878357\n",
      "    avg separation loss:      6.064230442047119\n",
      "    l1_addon loss:            39.65897750854492\n",
      "    l1 loss:                  0.5177286863327026\n",
      "    train time:               0.05813026428222656\n",
      "    test time:                0.01219797134399414\n",
      "    epoch time:               0.07107067108154297\n",
      "    joint lr:                 0.0007755849850466195\n",
      "epoch: 199 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.002181004293055998\n",
      "    train cross_ent loss:     0.00047360505009742663\n",
      "    test overall loss:        0.1109777061889569\n",
      "    test cross_ent loss:      0.10927043575793505\n",
      "    cluster loss:             2949.2884928385415\n",
      "    separation loss:          2.300072431564331\n",
      "    avg separation loss:      6.0962904294331866\n",
      "    l1_addon loss:            39.651397705078125\n",
      "    l1 loss:                  0.5177286863327026\n",
      "    train time:               0.05810809135437012\n",
      "    test time:                0.012124300003051758\n",
      "    epoch time:               0.07101821899414062\n",
      "    joint lr:                 0.0004344145675980766\n",
      "epoch: 200 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.002275958308018744\n",
      "    train cross_ent loss:     0.0005687469367532887\n",
      "    test overall loss:        0.11163373415668805\n",
      "    test cross_ent loss:      0.10992659162729979\n",
      "    cluster loss:             2949.2884114583335\n",
      "    separation loss:          2.304274876912435\n",
      "    avg separation loss:      6.116902510325114\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  0.5177286863327026\n",
      "    train time:               0.05811047554016113\n",
      "    test time:                0.012122154235839844\n",
      "    epoch time:               0.07104182243347168\n",
      "    joint lr:                 0.0001\n",
      "epoch: 200 (PUSH) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.002275958308018744\n",
      "    train cross_ent loss:     0.0005687469367532887\n",
      "    test overall loss:        0.12711862474679947\n",
      "    test cross_ent loss:      0.12541148501137891\n",
      "    cluster loss:             2949.2952473958335\n",
      "    separation loss:          2.2179877758026123\n",
      "    avg separation loss:      5.968286355336507\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  0.5177286863327026\n",
      "    train time:               0.05811047554016113\n",
      "    test time:                0.012335062026977539\n",
      "    epoch time:               0.3580031394958496\n",
      "epoch: 200 (1/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.0063122328784730695\n",
      "    train cross_ent loss:     0.004793611639696691\n",
      "    test overall loss:        0.12625636905431747\n",
      "    test cross_ent loss:      0.12484335092206796\n",
      "    cluster loss:             2949.29638671875\n",
      "    separation loss:          2.2151094675064087\n",
      "    avg separation loss:      5.941276550292969\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  0.22360201179981232\n",
      "    train time:               0.0227968692779541\n",
      "    test time:                0.012078285217285156\n",
      "    epoch time:               0.035350799560546875\n",
      "    last layer lr:            0.0007600000000000095\n",
      "epoch: 200 (2/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.006699884465585153\n",
      "    train cross_ent loss:     0.004827404058434897\n",
      "    test overall loss:        0.1284057485560576\n",
      "    test cross_ent loss:      0.12658811608950296\n",
      "    cluster loss:             2949.2969563802085\n",
      "    separation loss:          2.214207132657369\n",
      "    avg separation loss:      5.9528961181640625\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  0.6282212734222412\n",
      "    train time:               0.022524356842041016\n",
      "    test time:                0.012063980102539062\n",
      "    epoch time:               0.03506207466125488\n",
      "    last layer lr:            0.0014199999999999955\n",
      "epoch: 200 (3/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.00571260316711333\n",
      "    train cross_ent loss:     0.003590261731814179\n",
      "    test overall loss:        0.12686524291833243\n",
      "    test cross_ent loss:      0.1247181153545777\n",
      "    cluster loss:             2949.29541015625\n",
      "    separation loss:          2.2156381209691367\n",
      "    avg separation loss:      5.95186710357666\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  0.9577164053916931\n",
      "    train time:               0.02246689796447754\n",
      "    test time:                0.012038469314575195\n",
      "    epoch time:               0.034993886947631836\n",
      "    last layer lr:            0.0020800000000000046\n",
      "epoch: 200 (4/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.006860784358448452\n",
      "    train cross_ent loss:     0.004399814513615436\n",
      "    test overall loss:        0.12893853088219961\n",
      "    test cross_ent loss:      0.12637843315800032\n",
      "    cluster loss:             2949.2960611979165\n",
      "    separation loss:          2.2178009351094565\n",
      "    avg separation loss:      5.958634535471599\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  1.370687484741211\n",
      "    train time:               0.0225985050201416\n",
      "    test time:                0.012031316757202148\n",
      "    epoch time:               0.03510880470275879\n",
      "    last layer lr:            0.0027399999999999907\n",
      "epoch: 200 (5/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.007021039879570405\n",
      "    train cross_ent loss:     0.004119887935101158\n",
      "    test overall loss:        0.1278712103764216\n",
      "    test cross_ent loss:      0.12491227065523465\n",
      "    cluster loss:             2949.295654296875\n",
      "    separation loss:          2.222981254259745\n",
      "    avg separation loss:      5.975574493408203\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  1.7695238590240479\n",
      "    train time:               0.02254033088684082\n",
      "    test time:                0.012024164199829102\n",
      "    epoch time:               0.03504824638366699\n",
      "    last layer lr:            0.0034\n",
      "epoch: 200 (6/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.006295349086738295\n",
      "    train cross_ent loss:     0.0029910480112044346\n",
      "    test overall loss:        0.12585311258832613\n",
      "    test cross_ent loss:      0.1225113794207573\n",
      "    cluster loss:             2949.2947591145835\n",
      "    separation loss:          2.216479937235514\n",
      "    avg separation loss:      5.935822010040283\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  2.1523208618164062\n",
      "    train time:               0.022526979446411133\n",
      "    test time:                0.012035369873046875\n",
      "    epoch time:               0.03505086898803711\n",
      "    last layer lr:            0.00406000000000001\n",
      "epoch: 200 (7/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.00847582488010327\n",
      "    train cross_ent loss:     0.004758211163183053\n",
      "    test overall loss:        0.12632534404595694\n",
      "    test cross_ent loss:      0.12243596402307351\n",
      "    cluster loss:             2949.2941080729165\n",
      "    separation loss:          2.2127527395884194\n",
      "    avg separation loss:      5.920763333638509\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  2.6999659538269043\n",
      "    train time:               0.022632598876953125\n",
      "    test time:                0.012052297592163086\n",
      "    epoch time:               0.035172462463378906\n",
      "    last layer lr:            0.004719999999999996\n",
      "epoch: 200 (8/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.008705476764589548\n",
      "    train cross_ent loss:     0.004433464517609941\n",
      "    test overall loss:        0.12739363312721252\n",
      "    test cross_ent loss:      0.12302219371000926\n",
      "    cluster loss:             2949.295166015625\n",
      "    separation loss:          2.2104291121164956\n",
      "    avg separation loss:      5.924108505249023\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  3.18202543258667\n",
      "    train time:               0.022518634796142578\n",
      "    test time:                0.012136220932006836\n",
      "    epoch time:               0.03513979911804199\n",
      "    last layer lr:            0.0053800000000000054\n",
      "epoch: 200 (9/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.010513560484266944\n",
      "    train cross_ent loss:     0.00575033148440222\n",
      "    test overall loss:        0.12676849588751793\n",
      "    test cross_ent loss:      0.12181416898965836\n",
      "    cluster loss:             2949.2954915364585\n",
      "    separation loss:          2.21000337600708\n",
      "    avg separation loss:      5.923007329305013\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  3.7649152278900146\n",
      "    train time:               0.022562503814697266\n",
      "    test time:                0.012272119522094727\n",
      "    epoch time:               0.03532266616821289\n",
      "    last layer lr:            0.0060399999999999916\n",
      "epoch: 200 (10/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.009846152996437417\n",
      "    train cross_ent loss:     0.004531089539846612\n",
      "    test overall loss:        0.12751254687706629\n",
      "    test cross_ent loss:      0.12202177941799164\n",
      "    cluster loss:             2949.2950032552085\n",
      "    separation loss:          2.2152715921401978\n",
      "    avg separation loss:      5.936877727508545\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  4.301355838775635\n",
      "    train time:               0.02267289161682129\n",
      "    test time:                0.012061595916748047\n",
      "    epoch time:               0.03520655632019043\n",
      "    last layer lr:            0.0067\n",
      "epoch: 200 (11/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.012002672017034557\n",
      "    train cross_ent loss:     0.006226551719009876\n",
      "    test overall loss:        0.12966206793983778\n",
      "    test cross_ent loss:      0.12350524961948395\n",
      "    cluster loss:             2949.2954915364585\n",
      "    separation loss:          2.2032787799835205\n",
      "    avg separation loss:      5.906638463338216\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  4.967403888702393\n",
      "    train time:               0.022501468658447266\n",
      "    test time:                0.012035608291625977\n",
      "    epoch time:               0.03502058982849121\n",
      "    last layer lr:            0.007360000000000011\n",
      "epoch: 200 (12/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.009729003947642114\n",
      "    train cross_ent loss:     0.003120841949971186\n",
      "    test overall loss:        0.12888838723301888\n",
      "    test cross_ent loss:      0.12215593581398328\n",
      "    cluster loss:             2949.2953287760415\n",
      "    separation loss:          2.209057410558065\n",
      "    avg separation loss:      5.917873064676921\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  5.543037414550781\n",
      "    train time:               0.022479534149169922\n",
      "    test time:                0.012023448944091797\n",
      "    epoch time:               0.034986257553100586\n",
      "    last layer lr:            0.008019999999999994\n",
      "epoch: 200 (13/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.010338865944908725\n",
      "    train cross_ent loss:     0.00351456506177783\n",
      "    test overall loss:        0.12811355044444403\n",
      "    test cross_ent loss:      0.12134883739054203\n",
      "    cluster loss:             2949.2958170572915\n",
      "    separation loss:          2.208818475405375\n",
      "    avg separation loss:      5.918504238128662\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  5.575300216674805\n",
      "    train time:               0.022736072540283203\n",
      "    test time:                0.012032032012939453\n",
      "    epoch time:               0.03524899482727051\n",
      "    last layer lr:            0.008680000000000005\n",
      "epoch: 200 (14/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.01048918596158425\n",
      "    train cross_ent loss:     0.0034065833315253258\n",
      "    test overall loss:        0.12687788034478822\n",
      "    test cross_ent loss:      0.11971327972908814\n",
      "    cluster loss:             2949.2955729166665\n",
      "    separation loss:          2.2219096422195435\n",
      "    avg separation loss:      5.964688142140706\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  5.975187301635742\n",
      "    train time:               0.023380279541015625\n",
      "    test time:                0.012125015258789062\n",
      "    epoch time:               0.03600811958312988\n",
      "    last layer lr:            0.00933999999999999\n",
      "epoch: 200 (15/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.012833939761751227\n",
      "    train cross_ent loss:     0.005321711547569268\n",
      "    test overall loss:        0.12757021437088648\n",
      "    test cross_ent loss:      0.11999344825744629\n",
      "    cluster loss:             2949.2955729166665\n",
      "    separation loss:          2.214263081550598\n",
      "    avg separation loss:      5.931881268819173\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  6.387352466583252\n",
      "    train time:               0.022549152374267578\n",
      "    test time:                0.012171506881713867\n",
      "    epoch time:               0.035212039947509766\n",
      "    last layer lr:            0.01\n",
      "epoch: 200 (16/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.010681492690410879\n",
      "    train cross_ent loss:     0.002756769044531716\n",
      "    test overall loss:        0.12788905824224153\n",
      "    test cross_ent loss:      0.11994571052491665\n",
      "    cluster loss:             2949.295166015625\n",
      "    separation loss:          2.2154799699783325\n",
      "    avg separation loss:      5.9352827072143555\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  6.75393009185791\n",
      "    train time:               0.02267742156982422\n",
      "    test time:                0.012371063232421875\n",
      "    epoch time:               0.03552722930908203\n",
      "    last layer lr:            0.009603999999999994\n",
      "epoch: 200 (17/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.01143123416437043\n",
      "    train cross_ent loss:     0.003508612849853105\n",
      "    test overall loss:        0.12725462391972542\n",
      "    test cross_ent loss:      0.1194380521774292\n",
      "    cluster loss:             2949.294921875\n",
      "    separation loss:          2.2090854247411094\n",
      "    avg separation loss:      5.910789171854655\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  6.62716007232666\n",
      "    train time:               0.023223876953125\n",
      "    test time:                0.012378931045532227\n",
      "    epoch time:               0.03608512878417969\n",
      "    last layer lr:            0.009208000000000003\n",
      "epoch: 200 (18/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.013604333934684595\n",
      "    train cross_ent loss:     0.005778832011856139\n",
      "    test overall loss:        0.1276751607656479\n",
      "    test cross_ent loss:      0.11991360535224278\n",
      "    cluster loss:             2949.2954915364585\n",
      "    separation loss:          2.2170710961023965\n",
      "    avg separation loss:      5.949199517567952\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  6.572141647338867\n",
      "    train time:               0.023164749145507812\n",
      "    test time:                0.01241159439086914\n",
      "    epoch time:               0.03605985641479492\n",
      "    last layer lr:            0.008811999999999997\n",
      "epoch: 200 (19/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.011186297258569134\n",
      "    train cross_ent loss:     0.0035004017991013825\n",
      "    test overall loss:        0.12709792827566466\n",
      "    test cross_ent loss:      0.11946979910135269\n",
      "    cluster loss:             2949.2950846354165\n",
      "    separation loss:          2.2274708350499473\n",
      "    avg separation loss:      5.980353037516276\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  6.438711643218994\n",
      "    train time:               0.023406028747558594\n",
      "    test time:                0.012514114379882812\n",
      "    epoch time:               0.03639793395996094\n",
      "    last layer lr:            0.008416000000000005\n",
      "epoch: 200 (20/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.009858552418235276\n",
      "    train cross_ent loss:     0.00254649629480102\n",
      "    test overall loss:        0.1274930958946546\n",
      "    test cross_ent loss:      0.12045460566878319\n",
      "    cluster loss:             2949.29541015625\n",
      "    separation loss:          2.221038500467936\n",
      "    avg separation loss:      5.964548746744792\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  5.849076271057129\n",
      "    train time:               0.023204326629638672\n",
      "    test time:                0.012359142303466797\n",
      "    epoch time:               0.03604769706726074\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 200 (21/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.010038772597908974\n",
      "    train cross_ent loss:     0.003147221390261418\n",
      "    test overall loss:        0.126835814366738\n",
      "    test cross_ent loss:      0.12004152312874794\n",
      "    cluster loss:             2949.294921875\n",
      "    separation loss:          2.2151615619659424\n",
      "    avg separation loss:      5.945341428120931\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  5.6048784255981445\n",
      "    train time:               0.02321600914001465\n",
      "    test time:                0.01241755485534668\n",
      "    epoch time:               0.03610992431640625\n",
      "    last layer lr:            0.007623999999999995\n",
      "epoch: 200 (22/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.01098190475669172\n",
      "    train cross_ent loss:     0.004374008664550881\n",
      "    test overall loss:        0.12774223710099855\n",
      "    test cross_ent loss:      0.121159378439188\n",
      "    cluster loss:             2949.295654296875\n",
      "    separation loss:          2.206865350405375\n",
      "    avg separation loss:      5.913598696390788\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  5.393445014953613\n",
      "    train time:               0.02336859703063965\n",
      "    test time:                0.01238560676574707\n",
      "    epoch time:               0.036232948303222656\n",
      "    last layer lr:            0.0072280000000000035\n",
      "epoch: 200 (23/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.010636481766899427\n",
      "    train cross_ent loss:     0.004309449978690181\n",
      "    test overall loss:        0.12912743911147118\n",
      "    test cross_ent loss:      0.12244764963785808\n",
      "    cluster loss:             2949.2963053385415\n",
      "    separation loss:          2.2061686913172402\n",
      "    avg separation loss:      5.910951296488444\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  5.490372180938721\n",
      "    train time:               0.02326202392578125\n",
      "    test time:                0.012387990951538086\n",
      "    epoch time:               0.03612685203552246\n",
      "    last layer lr:            0.006831999999999998\n",
      "epoch: 200 (24/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.009758813306689262\n",
      "    train cross_ent loss:     0.00326166660266204\n",
      "    test overall loss:        0.12630468855301538\n",
      "    test cross_ent loss:      0.12006493161122005\n",
      "    cluster loss:             2949.2953287760415\n",
      "    separation loss:          2.209027409553528\n",
      "    avg separation loss:      5.920914808909099\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  5.0503387451171875\n",
      "    train time:               0.02320122718811035\n",
      "    test time:                0.012448549270629883\n",
      "    epoch time:               0.03613543510437012\n",
      "    last layer lr:            0.006436000000000007\n",
      "epoch: 200 (25/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.009811180229816172\n",
      "    train cross_ent loss:     0.003762198418068389\n",
      "    test overall loss:        0.12681184088190398\n",
      "    test cross_ent loss:      0.12083270338674386\n",
      "    cluster loss:             2949.2958170572915\n",
      "    separation loss:          2.2092129786809287\n",
      "    avg separation loss:      5.93172550201416\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  4.789723873138428\n",
      "    train time:               0.02340245246887207\n",
      "    test time:                0.012424468994140625\n",
      "    epoch time:               0.03629875183105469\n",
      "    last layer lr:            0.00604\n",
      "epoch: 200 (26/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.009211828156063953\n",
      "    train cross_ent loss:     0.003536274281537367\n",
      "    test overall loss:        0.12642576669653258\n",
      "    test cross_ent loss:      0.12083403021097183\n",
      "    cluster loss:             2949.2960611979165\n",
      "    separation loss:          2.2143457730611167\n",
      "    avg separation loss:      5.9495517412821455\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  4.40231990814209\n",
      "    train time:               0.023205041885375977\n",
      "    test time:                0.012377738952636719\n",
      "    epoch time:               0.03606820106506348\n",
      "    last layer lr:            0.0056439999999999945\n",
      "epoch: 200 (27/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.007489807593325774\n",
      "    train cross_ent loss:     0.0021359151125782067\n",
      "    test overall loss:        0.12436329697569211\n",
      "    test cross_ent loss:      0.11911161616444588\n",
      "    cluster loss:             2949.2959798177085\n",
      "    separation loss:          2.2210684617360434\n",
      "    avg separation loss:      5.95980167388916\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  4.062272071838379\n",
      "    train time:               0.023200035095214844\n",
      "    test time:                0.012391090393066406\n",
      "    epoch time:               0.036069631576538086\n",
      "    last layer lr:            0.005248000000000003\n",
      "epoch: 200 (28/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.00759395274023215\n",
      "    train cross_ent loss:     0.0025740915896474486\n",
      "    test overall loss:        0.12398826082547505\n",
      "    test cross_ent loss:      0.11900848522782326\n",
      "    cluster loss:             2949.2955729166665\n",
      "    separation loss:          2.2170450687408447\n",
      "    avg separation loss:      5.94743283589681\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  3.7903592586517334\n",
      "    train time:               0.023324251174926758\n",
      "    test time:                0.012362241744995117\n",
      "    epoch time:               0.03618907928466797\n",
      "    last layer lr:            0.004851999999999998\n",
      "epoch: 200 (29/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.007527846273862653\n",
      "    train cross_ent loss:     0.0027697989135049284\n",
      "    test overall loss:        0.12316510205467542\n",
      "    test cross_ent loss:      0.11858955087761085\n",
      "    cluster loss:             2949.2953287760415\n",
      "    separation loss:          2.2208848794301352\n",
      "    avg separation loss:      5.9575653076171875\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  3.3861336708068848\n",
      "    train time:               0.023193836212158203\n",
      "    test time:                0.012353181838989258\n",
      "    epoch time:               0.036040306091308594\n",
      "    last layer lr:            0.004456000000000006\n",
      "epoch: 200 (30/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.007137097418308258\n",
      "    train cross_ent loss:     0.0026933017587806615\n",
      "    test overall loss:        0.12164560208717982\n",
      "    test cross_ent loss:      0.11724711706240971\n",
      "    cluster loss:             2949.2950032552085\n",
      "    separation loss:          2.2263302008310952\n",
      "    avg separation loss:      5.973723570505778\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  3.20906925201416\n",
      "    train time:               0.023205280303955078\n",
      "    test time:                0.012459516525268555\n",
      "    epoch time:               0.03614664077758789\n",
      "    last layer lr:            0.004060000000000001\n",
      "epoch: 200 (31/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.00884907946197523\n",
      "    train cross_ent loss:     0.004622605486979915\n",
      "    test overall loss:        0.1220533053080241\n",
      "    test cross_ent loss:      0.11777005903422832\n",
      "    cluster loss:             2949.2948404947915\n",
      "    separation loss:          2.2198301951090493\n",
      "    avg separation loss:      5.952399094899495\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  3.0938313007354736\n",
      "    train time:               0.02324390411376953\n",
      "    test time:                0.012398242950439453\n",
      "    epoch time:               0.03611612319946289\n",
      "    last layer lr:            0.0036639999999999945\n",
      "epoch: 200 (32/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.0070683286111387945\n",
      "    train cross_ent loss:     0.003037227459976243\n",
      "    test overall loss:        0.12278346717357635\n",
      "    test cross_ent loss:      0.11893788104255994\n",
      "    cluster loss:             2949.295166015625\n",
      "    separation loss:          2.21331254641215\n",
      "    avg separation loss:      5.938276608784993\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  2.6561737060546875\n",
      "    train time:               0.02319955825805664\n",
      "    test time:                0.01235198974609375\n",
      "    epoch time:               0.03603720664978027\n",
      "    last layer lr:            0.003268000000000003\n",
      "epoch: 200 (33/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.0070694501304792035\n",
      "    train cross_ent loss:     0.0033426208473328087\n",
      "    test overall loss:        0.12258591875433922\n",
      "    test cross_ent loss:      0.11889782051245372\n",
      "    cluster loss:             2949.2952473958335\n",
      "    separation loss:          2.213319102923075\n",
      "    avg separation loss:      5.943288962046306\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  2.4986841678619385\n",
      "    train time:               0.023186922073364258\n",
      "    test time:                0.012462377548217773\n",
      "    epoch time:               0.03614020347595215\n",
      "    last layer lr:            0.002871999999999997\n",
      "epoch: 200 (34/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.007011038613402181\n",
      "    train cross_ent loss:     0.0035408425093111065\n",
      "    test overall loss:        0.12421767165263493\n",
      "    test cross_ent loss:      0.12083100527524948\n",
      "    cluster loss:             2949.296142578125\n",
      "    separation loss:          2.2115378777186074\n",
      "    avg separation loss:      5.939911365509033\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  2.1972575187683105\n",
      "    train time:               0.023377418518066406\n",
      "    test time:                0.012400150299072266\n",
      "    epoch time:               0.036255598068237305\n",
      "    last layer lr:            0.0024760000000000055\n",
      "epoch: 200 (35/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.0069053153403931195\n",
      "    train cross_ent loss:     0.003746509448521667\n",
      "    test overall loss:        0.12147029613455136\n",
      "    test cross_ent loss:      0.11833237422009309\n",
      "    cluster loss:             2949.2948404947915\n",
      "    separation loss:          2.212821046511332\n",
      "    avg separation loss:      5.922891616821289\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  1.948509931564331\n",
      "    train time:               0.023169994354248047\n",
      "    test time:                0.012366056442260742\n",
      "    epoch time:               0.03602004051208496\n",
      "    last layer lr:            0.0020800000000000003\n",
      "epoch: 200 (36/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.005911665865116649\n",
      "    train cross_ent loss:     0.0029644943618526063\n",
      "    test overall loss:        0.12299335127075513\n",
      "    test cross_ent loss:      0.12021298582355182\n",
      "    cluster loss:             2949.2953287760415\n",
      "    separation loss:          2.205380360285441\n",
      "    avg separation loss:      5.902658780415853\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  1.5909534692764282\n",
      "    train time:               0.023246049880981445\n",
      "    test time:                0.012549638748168945\n",
      "    epoch time:               0.036292076110839844\n",
      "    last layer lr:            0.0016839999999999945\n",
      "epoch: 200 (37/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.009069813777589135\n",
      "    train cross_ent loss:     0.006336421511756877\n",
      "    test overall loss:        0.12275765215357144\n",
      "    test cross_ent loss:      0.1200591412683328\n",
      "    cluster loss:             2949.29541015625\n",
      "    separation loss:          2.2119232416152954\n",
      "    avg separation loss:      5.917500972747803\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  1.5090934038162231\n",
      "    train time:               0.023307085037231445\n",
      "    test time:                0.01241445541381836\n",
      "    epoch time:               0.03619050979614258\n",
      "    last layer lr:            0.001288000000000003\n",
      "epoch: 200 (38/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.0058973430035014944\n",
      "    train cross_ent loss:     0.0033895535291069085\n",
      "    test overall loss:        0.1231515035033226\n",
      "    test cross_ent loss:      0.12079243796567123\n",
      "    cluster loss:             2949.2953287760415\n",
      "    separation loss:          2.2087618509928384\n",
      "    avg separation loss:      5.9223402341206866\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  1.1696527004241943\n",
      "    train time:               0.02321910858154297\n",
      "    test time:                0.012391805648803711\n",
      "    epoch time:               0.03608083724975586\n",
      "    last layer lr:            0.0008919999999999973\n",
      "epoch: 200 (39/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.00533575290400121\n",
      "    train cross_ent loss:     0.003207055308545629\n",
      "    test overall loss:        0.12190187598268191\n",
      "    test cross_ent loss:      0.11990109644830227\n",
      "    cluster loss:             2949.29541015625\n",
      "    separation loss:          2.215028723080953\n",
      "    avg separation loss:      5.9408650398254395\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  0.811363697052002\n",
      "    train time:               0.023255109786987305\n",
      "    test time:                0.012409210205078125\n",
      "    epoch time:               0.03642892837524414\n",
      "    last layer lr:            0.0004960000000000057\n",
      "epoch: 200 (40/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.0058395211429645615\n",
      "    train cross_ent loss:     0.004047307353984151\n",
      "    test overall loss:        0.12246903280417125\n",
      "    test cross_ent loss:      0.12077265481154124\n",
      "    cluster loss:             2949.2955729166665\n",
      "    separation loss:          2.21470840771993\n",
      "    avg separation loss:      5.951766649881999\n",
      "    l1_addon loss:            39.647239685058594\n",
      "    l1 loss:                  0.506960391998291\n",
      "    train time:               0.023477792739868164\n",
      "    test time:                0.012376070022583008\n",
      "    epoch time:               0.03633236885070801\n",
      "    last layer lr:            0.0001\n",
      "Finished training in 30.58 seconds\n",
      "Last epoch test accu: 96.67%\n",
      "Done in 200 epochs, 43.34s\n",
      "Training for ArticularyWordRecognition, proto len 144, reception 0.25, features_lr 0.001, protos per class 10, l1_addon 3e-05\n",
      "Params: {\n",
      "    \"protos_per_class\": 10,\n",
      "    \"proto_features\": 32,\n",
      "    \"proto_len_latent\": 144,\n",
      "    \"features_lr\": 0.001,\n",
      "    \"num_classes\": 25,\n",
      "    \"coeffs\": {\n",
      "        \"crs_ent\": 1,\n",
      "        \"clst\": 0,\n",
      "        \"sep\": 0,\n",
      "        \"l1\": 0.001,\n",
      "        \"l1_addon\": 3e-05\n",
      "    },\n",
      "    \"num_warm_epochs\": 50,\n",
      "    \"push_start_epoch\": 110,\n",
      "    \"num_last_layer_epochs\": 40,\n",
      "    \"epochs\": 200\n",
      "}\n",
      "Training encoder\n",
      "epoch:   10/300 mse loss: 0.0403\n",
      "epoch:   20/300 mse loss: 0.0416\n",
      "epoch:   30/300 mse loss: 0.0413\n",
      "epoch:   40/300 mse loss: 0.0427\n",
      "epoch:   50/300 mse loss: 0.0530\n",
      "epoch:   60/300 mse loss: 0.0630\n",
      "epoch:   70/300 mse loss: 0.0642\n",
      "epoch:   80/300 mse loss: 0.0668\n",
      "epoch:   90/300 mse loss: 0.0811\n",
      "epoch:  100/300 mse loss: 0.0788\n",
      "epoch:  110/300 mse loss: 0.0754\n",
      "epoch:  120/300 mse loss: 0.0748\n",
      "epoch:  130/300 mse loss: 0.0767\n",
      "epoch:  140/300 mse loss: 0.0754\n",
      "epoch:  150/300 mse loss: 0.0752\n",
      "epoch:  160/300 mse loss: 0.0753\n",
      "epoch:  170/300 mse loss: 0.0736\n",
      "epoch:  180/300 mse loss: 0.0753\n",
      "epoch:  190/300 mse loss: 0.0772\n",
      "epoch:  200/300 mse loss: 0.0751\n",
      "epoch:  210/300 mse loss: 0.0742\n",
      "epoch:  220/300 mse loss: 0.0750\n",
      "epoch:  230/300 mse loss: 0.0745\n",
      "epoch:  240/300 mse loss: 0.0747\n",
      "epoch:  250/300 mse loss: 0.0753\n",
      "epoch:  260/300 mse loss: 0.0747\n",
      "epoch:  270/300 mse loss: 0.0744\n",
      "epoch:  280/300 mse loss: 0.0745\n",
      "epoch:  290/300 mse loss: 0.0742\n",
      "epoch:  300/300 mse loss: 0.0743\n",
      "Training ProtoTSNet\n",
      "Starting training\n",
      "epoch:   1 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 7.67%\n",
      "    train overall loss:       6.224376519521077\n",
      "    train cross_ent loss:     3.2188539769914417\n",
      "    test overall loss:        6.2239329020182295\n",
      "    test cross_ent loss:      3.218842347462972\n",
      "    cluster loss:             3361.2115885416665\n",
      "    separation loss:          1136.0731201171875\n",
      "    avg separation loss:      1156.5269775390625\n",
      "    l1_addon loss:            169.68043518066406\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04178166389465332\n",
      "    test time:                0.012183427810668945\n",
      "    epoch time:               0.054608821868896484\n",
      "epoch:   2 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 7.33%\n",
      "    train overall loss:       6.2235218154059515\n",
      "    train cross_ent loss:     3.218751245074802\n",
      "    test overall loss:        6.223156770070394\n",
      "    test cross_ent loss:      3.2187752723693848\n",
      "    cluster loss:             3378.3109537760415\n",
      "    separation loss:          1182.2550048828125\n",
      "    avg separation loss:      1216.9593912760417\n",
      "    l1_addon loss:            146.03289794921875\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.041202545166015625\n",
      "    test time:                0.012349605560302734\n",
      "    epoch time:               0.05420255661010742\n",
      "epoch:   3 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 8.00%\n",
      "    train overall loss:       6.2227181858486595\n",
      "    train cross_ent loss:     3.2186273203955755\n",
      "    test overall loss:        6.222394784291585\n",
      "    test cross_ent loss:      3.218656539916992\n",
      "    cluster loss:             3368.3060709635415\n",
      "    separation loss:          1161.6378173828125\n",
      "    avg separation loss:      1205.5189208984375\n",
      "    l1_addon loss:            124.59666442871094\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04631924629211426\n",
      "    test time:                0.01208806037902832\n",
      "    epoch time:               0.059058189392089844\n",
      "epoch:   4 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 8.67%\n",
      "    train overall loss:       6.221970081329346\n",
      "    train cross_ent loss:     3.218491898642646\n",
      "    test overall loss:        6.221661726633708\n",
      "    test cross_ent loss:      3.218489646911621\n",
      "    cluster loss:             3361.6612141927085\n",
      "    separation loss:          1147.216552734375\n",
      "    avg separation loss:      1206.12890625\n",
      "    l1_addon loss:            105.73123931884766\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04141426086425781\n",
      "    test time:                0.01840043067932129\n",
      "    epoch time:               0.060468435287475586\n",
      "epoch:   5 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 15.67%\n",
      "    train overall loss:       6.221305582258436\n",
      "    train cross_ent loss:     3.2183527416653104\n",
      "    test overall loss:        6.221002578735352\n",
      "    test cross_ent loss:      3.2183121045430503\n",
      "    cluster loss:             3352.91943359375\n",
      "    separation loss:          1130.9256184895833\n",
      "    avg separation loss:      1205.439208984375\n",
      "    l1_addon loss:            89.67017364501953\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.041233062744140625\n",
      "    test time:                0.012112617492675781\n",
      "    epoch time:               0.05401182174682617\n",
      "epoch:   6 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 28.67%\n",
      "    train overall loss:       6.22070492638482\n",
      "    train cross_ent loss:     3.2181966304779053\n",
      "    test overall loss:        6.220403989156087\n",
      "    test cross_ent loss:      3.2181053161621094\n",
      "    cluster loss:             3337.945068359375\n",
      "    separation loss:          1098.2095540364583\n",
      "    avg separation loss:      1182.1068929036458\n",
      "    l1_addon loss:            76.60637664794922\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04648947715759277\n",
      "    test time:                0.012091875076293945\n",
      "    epoch time:               0.05924081802368164\n",
      "epoch:   7 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 38.00%\n",
      "    train overall loss:       6.220168219672309\n",
      "    train cross_ent loss:     3.21800258424547\n",
      "    test overall loss:        6.219811916351318\n",
      "    test cross_ent loss:      3.2177873452504477\n",
      "    cluster loss:             3309.7601725260415\n",
      "    separation loss:          1026.377685546875\n",
      "    avg separation loss:      1121.5960286458333\n",
      "    l1_addon loss:            67.46903991699219\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.041350364685058594\n",
      "    test time:                0.012139081954956055\n",
      "    epoch time:               0.0541529655456543\n",
      "epoch:   8 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 41.67%\n",
      "    train overall loss:       6.219519138336182\n",
      "    train cross_ent loss:     3.21757091416253\n",
      "    test overall loss:        6.219166278839111\n",
      "    test cross_ent loss:      3.217289845148722\n",
      "    cluster loss:             3271.9322102864585\n",
      "    separation loss:          926.3365071614584\n",
      "    avg separation loss:      1043.197509765625\n",
      "    l1_addon loss:            62.54447555541992\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05006289482116699\n",
      "    test time:                0.01213836669921875\n",
      "    epoch time:               0.06285905838012695\n",
      "epoch:   9 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 54.67%\n",
      "    train overall loss:       6.218825022379558\n",
      "    train cross_ent loss:     3.2169961399502225\n",
      "    test overall loss:        6.218432426452637\n",
      "    test cross_ent loss:      3.216676394144694\n",
      "    cluster loss:             3240.0533854166665\n",
      "    separation loss:          847.2475382486979\n",
      "    avg separation loss:      975.4970906575521\n",
      "    l1_addon loss:            58.52489471435547\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04155874252319336\n",
      "    test time:                0.016950130462646484\n",
      "    epoch time:               0.05917525291442871\n",
      "epoch:  10 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 57.00%\n",
      "    train overall loss:       6.2180041737026635\n",
      "    train cross_ent loss:     3.2163177331288657\n",
      "    test overall loss:        6.217536608378093\n",
      "    test cross_ent loss:      3.2159390449523926\n",
      "    cluster loss:             3210.3086751302085\n",
      "    separation loss:          773.7828369140625\n",
      "    avg separation loss:      898.133544921875\n",
      "    l1_addon loss:            53.23985290527344\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.041240692138671875\n",
      "    test time:                0.012095928192138672\n",
      "    epoch time:               0.053999900817871094\n",
      "epoch:  11 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 60.67%\n",
      "    train overall loss:       6.216985013749865\n",
      "    train cross_ent loss:     3.215422021018134\n",
      "    test overall loss:        6.216324170430501\n",
      "    test cross_ent loss:      3.2147812048594155\n",
      "    cluster loss:             3173.78564453125\n",
      "    separation loss:          679.3636271158854\n",
      "    avg separation loss:      803.1085815429688\n",
      "    l1_addon loss:            51.418968200683594\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04561018943786621\n",
      "    test time:                0.012060880661010742\n",
      "    epoch time:               0.05833292007446289\n",
      "epoch:  12 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 64.67%\n",
      "    train overall loss:       6.215508672926161\n",
      "    train cross_ent loss:     3.2139956421322293\n",
      "    test overall loss:        6.21463410059611\n",
      "    test cross_ent loss:      3.213141759236654\n",
      "    cluster loss:             3142.353759765625\n",
      "    separation loss:          600.860595703125\n",
      "    avg separation loss:      722.2126871744791\n",
      "    l1_addon loss:            49.734031677246094\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04143667221069336\n",
      "    test time:                0.012135505676269531\n",
      "    epoch time:               0.05424380302429199\n",
      "epoch:  13 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 64.33%\n",
      "    train overall loss:       6.213711579640706\n",
      "    train cross_ent loss:     3.212274816301134\n",
      "    test overall loss:        6.212522506713867\n",
      "    test cross_ent loss:      3.2111314137776694\n",
      "    cluster loss:             3118.5939127604165\n",
      "    separation loss:          545.0559488932291\n",
      "    avg separation loss:      660.7269083658854\n",
      "    l1_addon loss:            46.36669921875\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04984927177429199\n",
      "    test time:                0.012088298797607422\n",
      "    epoch time:               0.0626058578491211\n",
      "epoch:  14 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 60.67%\n",
      "    train overall loss:       6.2115529378255205\n",
      "    train cross_ent loss:     3.210192839304606\n",
      "    test overall loss:        6.210154056549072\n",
      "    test cross_ent loss:      3.208827177683512\n",
      "    cluster loss:             3101.1543782552085\n",
      "    separation loss:          505.07689412434894\n",
      "    avg separation loss:      621.7627766927084\n",
      "    l1_addon loss:            44.22325897216797\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.041257381439208984\n",
      "    test time:                0.019945383071899414\n",
      "    epoch time:               0.06186723709106445\n",
      "epoch:  15 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 55.33%\n",
      "    train overall loss:       6.2090235286288795\n",
      "    train cross_ent loss:     3.2077099482218423\n",
      "    test overall loss:        6.207307497660319\n",
      "    test cross_ent loss:      3.2060139973958335\n",
      "    cluster loss:             3086.2880045572915\n",
      "    separation loss:          471.67218017578125\n",
      "    avg separation loss:      593.0005086263021\n",
      "    l1_addon loss:            43.11132049560547\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.041177988052368164\n",
      "    test time:                0.01210474967956543\n",
      "    epoch time:               0.05394172668457031\n",
      "epoch:  16 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 58.00%\n",
      "    train overall loss:       6.205983532799615\n",
      "    train cross_ent loss:     3.2046900855170355\n",
      "    test overall loss:        6.203503290812175\n",
      "    test cross_ent loss:      3.2021950085957847\n",
      "    cluster loss:             3071.2982584635415\n",
      "    separation loss:          435.31870524088544\n",
      "    avg separation loss:      563.6942138671875\n",
      "    l1_addon loss:            43.59306716918945\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04555058479309082\n",
      "    test time:                0.012130498886108398\n",
      "    epoch time:               0.05834841728210449\n",
      "epoch:  17 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 57.00%\n",
      "    train overall loss:       6.201971742841932\n",
      "    train cross_ent loss:     3.2006863488091364\n",
      "    test overall loss:        6.198743502298991\n",
      "    test cross_ent loss:      3.1974266370137534\n",
      "    cluster loss:             3057.5927734375\n",
      "    separation loss:          399.8872477213542\n",
      "    avg separation loss:      534.7710978190104\n",
      "    l1_addon loss:            43.89002227783203\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04143524169921875\n",
      "    test time:                0.01209878921508789\n",
      "    epoch time:               0.05418753623962402\n",
      "epoch:  18 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 54.00%\n",
      "    train overall loss:       6.196242014567058\n",
      "    train cross_ent loss:     3.1949501832326255\n",
      "    test overall loss:        6.191389083862305\n",
      "    test cross_ent loss:      3.190116802851359\n",
      "    cluster loss:             3043.859375\n",
      "    separation loss:          368.81226603190106\n",
      "    avg separation loss:      501.60439046223956\n",
      "    l1_addon loss:            42.40483856201172\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04590272903442383\n",
      "    test time:                0.012109756469726562\n",
      "    epoch time:               0.058624982833862305\n",
      "epoch:  19 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 56.33%\n",
      "    train overall loss:       6.18892404768202\n",
      "    train cross_ent loss:     3.187657435735067\n",
      "    test overall loss:        6.1818168958028155\n",
      "    test cross_ent loss:      3.180532614390055\n",
      "    cluster loss:             3030.2596028645835\n",
      "    separation loss:          327.84434000651044\n",
      "    avg separation loss:      462.0125427246094\n",
      "    l1_addon loss:            42.80382537841797\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04132795333862305\n",
      "    test time:                0.020751476287841797\n",
      "    epoch time:               0.06276512145996094\n",
      "epoch:  20 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 56.33%\n",
      "    train overall loss:       6.177641656663683\n",
      "    train cross_ent loss:     3.1763846344417996\n",
      "    test overall loss:        6.1689653396606445\n",
      "    test cross_ent loss:      3.16770339012146\n",
      "    cluster loss:             3018.498046875\n",
      "    separation loss:          295.2457682291667\n",
      "    avg separation loss:      427.65981038411456\n",
      "    l1_addon loss:            42.04913330078125\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.041582584381103516\n",
      "    test time:                0.01227116584777832\n",
      "    epoch time:               0.05451798439025879\n",
      "epoch:  21 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 59.00%\n",
      "    train overall loss:       6.16185548570421\n",
      "    train cross_ent loss:     3.160618464152018\n",
      "    test overall loss:        6.150490601857503\n",
      "    test cross_ent loss:      3.1492506663004556\n",
      "    cluster loss:             3007.34765625\n",
      "    separation loss:          259.7662302652995\n",
      "    avg separation loss:      390.6569519042969\n",
      "    l1_addon loss:            41.330623626708984\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04674792289733887\n",
      "    test time:                0.012096405029296875\n",
      "    epoch time:               0.05949902534484863\n",
      "epoch:  22 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 58.67%\n",
      "    train overall loss:       6.145032034979926\n",
      "    train cross_ent loss:     3.143827756245931\n",
      "    test overall loss:        6.131509304046631\n",
      "    test cross_ent loss:      3.130307912826538\n",
      "    cluster loss:             2998.5621744791665\n",
      "    separation loss:          231.47555541992188\n",
      "    avg separation loss:      356.4972635904948\n",
      "    l1_addon loss:            40.041473388671875\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04141068458557129\n",
      "    test time:                0.012117624282836914\n",
      "    epoch time:               0.054178476333618164\n",
      "epoch:  23 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 59.33%\n",
      "    train overall loss:       6.11621618270874\n",
      "    train cross_ent loss:     3.115028354856703\n",
      "    test overall loss:        6.106831232706706\n",
      "    test cross_ent loss:      3.1056580543518066\n",
      "    cluster loss:             2989.7788899739585\n",
      "    separation loss:          199.84746297200522\n",
      "    avg separation loss:      320.0235595703125\n",
      "    l1_addon loss:            39.09954071044922\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04614448547363281\n",
      "    test time:                0.012088298797607422\n",
      "    epoch time:               0.05889105796813965\n",
      "epoch:  24 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 61.00%\n",
      "    train overall loss:       6.096886210971409\n",
      "    train cross_ent loss:     3.0957389142778187\n",
      "    test overall loss:        6.08904234568278\n",
      "    test cross_ent loss:      3.087912162144979\n",
      "    cluster loss:             2983.8497721354165\n",
      "    separation loss:          177.36626688639322\n",
      "    avg separation loss:      294.89771525065106\n",
      "    l1_addon loss:            37.677528381347656\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04134368896484375\n",
      "    test time:                0.01976919174194336\n",
      "    epoch time:               0.06177663803100586\n",
      "epoch:  25 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 66.00%\n",
      "    train overall loss:       6.074219120873345\n",
      "    train cross_ent loss:     3.073095719019572\n",
      "    test overall loss:        6.074802398681641\n",
      "    test cross_ent loss:      3.073674996693929\n",
      "    cluster loss:             2978.345947265625\n",
      "    separation loss:          157.19151306152344\n",
      "    avg separation loss:      275.0568135579427\n",
      "    l1_addon loss:            37.574127197265625\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.041312456130981445\n",
      "    test time:                0.012174606323242188\n",
      "    epoch time:               0.05414605140686035\n",
      "epoch:  26 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 70.00%\n",
      "    train overall loss:       6.043236308627659\n",
      "    train cross_ent loss:     3.042131291495429\n",
      "    test overall loss:        6.054774761199951\n",
      "    test cross_ent loss:      3.053680658340454\n",
      "    cluster loss:             2973.716796875\n",
      "    separation loss:          139.9663340250651\n",
      "    avg separation loss:      252.29902140299478\n",
      "    l1_addon loss:            36.46139907836914\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.046180009841918945\n",
      "    test time:                0.012061834335327148\n",
      "    epoch time:               0.05891299247741699\n",
      "epoch:  27 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 73.00%\n",
      "    train overall loss:       6.018664942847358\n",
      "    train cross_ent loss:     3.0175855689578586\n",
      "    test overall loss:        6.036177794138591\n",
      "    test cross_ent loss:      3.0351032416025796\n",
      "    cluster loss:             2969.9290364583335\n",
      "    separation loss:          124.95977020263672\n",
      "    avg separation loss:      239.95049031575522\n",
      "    l1_addon loss:            35.80510711669922\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04129838943481445\n",
      "    test time:                0.01207590103149414\n",
      "    epoch time:               0.05403852462768555\n",
      "epoch:  28 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 72.00%\n",
      "    train overall loss:       5.997549162970649\n",
      "    train cross_ent loss:     2.996491061316596\n",
      "    test overall loss:        6.027550220489502\n",
      "    test cross_ent loss:      3.026510794957479\n",
      "    cluster loss:             2967.2696126302085\n",
      "    separation loss:          111.56506601969402\n",
      "    avg separation loss:      220.47224934895834\n",
      "    l1_addon loss:            34.63129806518555\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.045622825622558594\n",
      "    test time:                0.012277841567993164\n",
      "    epoch time:               0.058559417724609375\n",
      "epoch:  29 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 75.00%\n",
      "    train overall loss:       5.97209448284573\n",
      "    train cross_ent loss:     2.971060355504354\n",
      "    test overall loss:        6.015963713328044\n",
      "    test cross_ent loss:      3.0149315198262534\n",
      "    cluster loss:             2964.6402994791665\n",
      "    separation loss:          102.13656870524089\n",
      "    avg separation loss:      212.6241912841797\n",
      "    l1_addon loss:            34.394290924072266\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05380415916442871\n",
      "    test time:                0.01211857795715332\n",
      "    epoch time:               0.06658411026000977\n",
      "epoch:  30 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 78.33%\n",
      "    train overall loss:       5.944103611840142\n",
      "    train cross_ent loss:     2.943090968661838\n",
      "    test overall loss:        6.009133179982503\n",
      "    test cross_ent loss:      3.008101542790731\n",
      "    cluster loss:             2962.691162109375\n",
      "    separation loss:          93.45763397216797\n",
      "    avg separation loss:      203.32730611165366\n",
      "    l1_addon loss:            34.38780212402344\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04135322570800781\n",
      "    test time:                0.012088775634765625\n",
      "    epoch time:               0.054105520248413086\n",
      "epoch:  31 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 79.33%\n",
      "    train overall loss:       5.9196714825100365\n",
      "    train cross_ent loss:     2.918669647640652\n",
      "    test overall loss:        5.999913056691487\n",
      "    test cross_ent loss:      2.9988951683044434\n",
      "    cluster loss:             2961.3616536458335\n",
      "    separation loss:          86.9531478881836\n",
      "    avg separation loss:      195.87841288248697\n",
      "    l1_addon loss:            33.914207458496094\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.041187286376953125\n",
      "    test time:                0.012112855911254883\n",
      "    epoch time:               0.053986549377441406\n",
      "epoch:  32 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 79.33%\n",
      "    train overall loss:       5.905257489946154\n",
      "    train cross_ent loss:     2.9042750199635825\n",
      "    test overall loss:        5.990603446960449\n",
      "    test cross_ent loss:      2.98960812886556\n",
      "    cluster loss:             2960.1587727864585\n",
      "    separation loss:          82.51603698730469\n",
      "    avg separation loss:      189.06402079264322\n",
      "    l1_addon loss:            33.17546081542969\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.041268110275268555\n",
      "    test time:                0.012118101119995117\n",
      "    epoch time:               0.05404996871948242\n",
      "epoch:  33 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 79.00%\n",
      "    train overall loss:       5.885711881849501\n",
      "    train cross_ent loss:     2.88474440574646\n",
      "    test overall loss:        5.9769337972005205\n",
      "    test cross_ent loss:      2.9759618441263833\n",
      "    cluster loss:             2959.1424153645835\n",
      "    separation loss:          76.12380981445312\n",
      "    avg separation loss:      182.4792226155599\n",
      "    l1_addon loss:            32.397621154785156\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04127216339111328\n",
      "    test time:                0.012071847915649414\n",
      "    epoch time:               0.0540008544921875\n",
      "epoch:  34 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 78.00%\n",
      "    train overall loss:       5.875857988993327\n",
      "    train cross_ent loss:     2.874902089436849\n",
      "    test overall loss:        5.965004762013753\n",
      "    test cross_ent loss:      2.964064677556356\n",
      "    cluster loss:             2958.5855305989585\n",
      "    separation loss:          72.40702819824219\n",
      "    avg separation loss:      173.77349344889322\n",
      "    l1_addon loss:            31.330158233642578\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04288125038146973\n",
      "    test time:                0.012091636657714844\n",
      "    epoch time:               0.05563092231750488\n",
      "epoch:  35 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 77.33%\n",
      "    train overall loss:       5.845353285471599\n",
      "    train cross_ent loss:     2.8444178104400635\n",
      "    test overall loss:        5.958994070688884\n",
      "    test cross_ent loss:      2.958056926727295\n",
      "    cluster loss:             2958.0882161458335\n",
      "    separation loss:          70.33061091105144\n",
      "    avg separation loss:      169.8184611002604\n",
      "    l1_addon loss:            31.23372459411621\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04121279716491699\n",
      "    test time:                0.01208639144897461\n",
      "    epoch time:               0.05394434928894043\n",
      "epoch:  36 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 75.67%\n",
      "    train overall loss:       5.835247039794922\n",
      "    train cross_ent loss:     2.834312227037218\n",
      "    test overall loss:        5.949985186258952\n",
      "    test cross_ent loss:      2.949065605799357\n",
      "    cluster loss:             2957.9033203125\n",
      "    separation loss:          68.3352533976237\n",
      "    avg separation loss:      166.63645935058594\n",
      "    l1_addon loss:            30.648475646972656\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.042443275451660156\n",
      "    test time:                0.012180566787719727\n",
      "    epoch time:               0.05528569221496582\n",
      "epoch:  37 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 76.00%\n",
      "    train overall loss:       5.820078584882948\n",
      "    train cross_ent loss:     2.8191685676574707\n",
      "    test overall loss:        5.945416450500488\n",
      "    test cross_ent loss:      2.9445063273111978\n",
      "    cluster loss:             2957.8467610677085\n",
      "    separation loss:          66.00293477376302\n",
      "    avg separation loss:      164.04302469889322\n",
      "    l1_addon loss:            30.33437728881836\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.041283369064331055\n",
      "    test time:                0.020680904388427734\n",
      "    epoch time:               0.06277751922607422\n",
      "epoch:  38 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 74.33%\n",
      "    train overall loss:       5.827533139122857\n",
      "    train cross_ent loss:     2.8266296121809216\n",
      "    test overall loss:        5.968384742736816\n",
      "    test cross_ent loss:      2.9674552281697593\n",
      "    cluster loss:             2958.453857421875\n",
      "    separation loss:          66.51702117919922\n",
      "    avg separation loss:      167.0790812174479\n",
      "    l1_addon loss:            30.9721736907959\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.041085243225097656\n",
      "    test time:                0.012094259262084961\n",
      "    epoch time:               0.0538482666015625\n",
      "epoch:  39 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 75.00%\n",
      "    train overall loss:       5.793387677934435\n",
      "    train cross_ent loss:     2.792496813668145\n",
      "    test overall loss:        5.945114612579346\n",
      "    test cross_ent loss:      2.944202740987142\n",
      "    cluster loss:             2958.080078125\n",
      "    separation loss:          64.54154968261719\n",
      "    avg separation loss:      163.29210408528647\n",
      "    l1_addon loss:            30.387771606445312\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04122757911682129\n",
      "    test time:                0.012073516845703125\n",
      "    epoch time:               0.05396676063537598\n",
      "epoch:  40 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 74.67%\n",
      "    train overall loss:       5.773332754770915\n",
      "    train cross_ent loss:     2.7724455727471247\n",
      "    test overall loss:        5.989284674326579\n",
      "    test cross_ent loss:      2.9883413314819336\n",
      "    cluster loss:             2959.071044921875\n",
      "    separation loss:          66.917786916097\n",
      "    avg separation loss:      168.0676472981771\n",
      "    l1_addon loss:            31.442325592041016\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.041338205337524414\n",
      "    test time:                0.012097835540771484\n",
      "    epoch time:               0.05409574508666992\n",
      "epoch:  41 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 74.00%\n",
      "    train overall loss:       5.823036723666721\n",
      "    train cross_ent loss:     2.8221577538384333\n",
      "    test overall loss:        5.9535895983378095\n",
      "    test cross_ent loss:      2.9526847998301187\n",
      "    cluster loss:             2958.1873372395835\n",
      "    separation loss:          63.06006113688151\n",
      "    avg separation loss:      164.19454447428384\n",
      "    l1_addon loss:            30.147907257080078\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04143357276916504\n",
      "    test time:                0.01210165023803711\n",
      "    epoch time:               0.05419301986694336\n",
      "epoch:  42 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 73.00%\n",
      "    train overall loss:       5.76568963792589\n",
      "    train cross_ent loss:     2.764818880293104\n",
      "    test overall loss:        5.92651891708374\n",
      "    test cross_ent loss:      2.9256629149119058\n",
      "    cluster loss:             2957.2845865885415\n",
      "    separation loss:          60.743569691975914\n",
      "    avg separation loss:      153.2901357014974\n",
      "    l1_addon loss:            28.53240203857422\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.041290283203125\n",
      "    test time:                0.016483068466186523\n",
      "    epoch time:               0.058434247970581055\n",
      "epoch:  43 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 71.67%\n",
      "    train overall loss:       5.742584917280409\n",
      "    train cross_ent loss:     2.741728332307604\n",
      "    test overall loss:        5.921853224436442\n",
      "    test cross_ent loss:      2.9210124015808105\n",
      "    cluster loss:             2957.3623046875\n",
      "    separation loss:          60.310105641682945\n",
      "    avg separation loss:      151.8972625732422\n",
      "    l1_addon loss:            28.017831802368164\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04110097885131836\n",
      "    test time:                0.012110710144042969\n",
      "    epoch time:               0.053873538970947266\n",
      "epoch:  44 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 69.00%\n",
      "    train overall loss:       5.7356863551669655\n",
      "    train cross_ent loss:     2.7348271210988364\n",
      "    test overall loss:        5.930092970530192\n",
      "    test cross_ent loss:      2.929299831390381\n",
      "    cluster loss:             2957.8203125\n",
      "    separation loss:          61.10249455769857\n",
      "    avg separation loss:      149.43651326497397\n",
      "    l1_addon loss:            26.437721252441406\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04179692268371582\n",
      "    test time:                0.012095451354980469\n",
      "    epoch time:               0.05455732345581055\n",
      "epoch:  45 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 69.00%\n",
      "    train overall loss:       5.769924269782172\n",
      "    train cross_ent loss:     2.769077274534437\n",
      "    test overall loss:        5.919880708058675\n",
      "    test cross_ent loss:      2.9190823237101235\n",
      "    cluster loss:             2957.5552571614585\n",
      "    separation loss:          59.73112996419271\n",
      "    avg separation loss:      147.58033243815103\n",
      "    l1_addon loss:            26.605567932128906\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04149937629699707\n",
      "    test time:                0.012087821960449219\n",
      "    epoch time:               0.05427289009094238\n",
      "epoch:  46 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 70.00%\n",
      "    train overall loss:       5.705569638146295\n",
      "    train cross_ent loss:     2.704733239279853\n",
      "    test overall loss:        5.922436078389485\n",
      "    test cross_ent loss:      2.921581824620565\n",
      "    cluster loss:             2957.282958984375\n",
      "    separation loss:          57.977142333984375\n",
      "    avg separation loss:      149.06945292154947\n",
      "    l1_addon loss:            28.46796417236328\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04138040542602539\n",
      "    test time:                0.012109041213989258\n",
      "    epoch time:               0.05415630340576172\n",
      "epoch:  47 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 70.67%\n",
      "    train overall loss:       5.678768634796143\n",
      "    train cross_ent loss:     2.6779365804460316\n",
      "    test overall loss:        5.905749797821045\n",
      "    test cross_ent loss:      2.904914140701294\n",
      "    cluster loss:             2956.889892578125\n",
      "    separation loss:          57.29959615071615\n",
      "    avg separation loss:      147.9061279296875\n",
      "    l1_addon loss:            27.849977493286133\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04129314422607422\n",
      "    test time:                0.015157461166381836\n",
      "    epoch time:               0.05711174011230469\n",
      "epoch:  48 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 71.33%\n",
      "    train overall loss:       5.689582930670844\n",
      "    train cross_ent loss:     2.688759512371487\n",
      "    test overall loss:        5.906036376953125\n",
      "    test cross_ent loss:      2.905198891957601\n",
      "    cluster loss:             2957.0049641927085\n",
      "    separation loss:          56.156325022379555\n",
      "    avg separation loss:      147.22565714518228\n",
      "    l1_addon loss:            27.909908294677734\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.041220903396606445\n",
      "    test time:                0.012099266052246094\n",
      "    epoch time:               0.05398273468017578\n",
      "epoch:  49 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 71.00%\n",
      "    train overall loss:       5.669247097439236\n",
      "    train cross_ent loss:     2.668420765135023\n",
      "    test overall loss:        5.898618221282959\n",
      "    test cross_ent loss:      2.8977925777435303\n",
      "    cluster loss:             2956.7242838541665\n",
      "    separation loss:          54.80188878377279\n",
      "    avg separation loss:      143.21223958333334\n",
      "    l1_addon loss:            27.506526947021484\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.04140210151672363\n",
      "    test time:                0.012103796005249023\n",
      "    epoch time:               0.05416607856750488\n",
      "epoch:  50 (WARM) - ArticularyWordRecognition\n",
      "    test acc:                 69.67%\n",
      "    train overall loss:       5.644648181067573\n",
      "    train cross_ent loss:     2.6438324186537\n",
      "    test overall loss:        5.883123874664307\n",
      "    test cross_ent loss:      2.8823278745015464\n",
      "    cluster loss:             2956.4146321614585\n",
      "    separation loss:          53.53926467895508\n",
      "    avg separation loss:      138.1758270263672\n",
      "    l1_addon loss:            26.523500442504883\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.041162729263305664\n",
      "    test time:                0.012081384658813477\n",
      "    epoch time:               0.05390572547912598\n",
      "epoch:  51 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 73.00%\n",
      "    train overall loss:       5.729182614220513\n",
      "    train cross_ent loss:     2.7283840444352894\n",
      "    test overall loss:        5.98365052541097\n",
      "    test cross_ent loss:      2.982851505279541\n",
      "    cluster loss:             2958.8896484375\n",
      "    separation loss:          60.91686503092448\n",
      "    avg separation loss:      173.09678649902344\n",
      "    l1_addon loss:            26.624841690063477\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058269500732421875\n",
      "    test time:                0.012141704559326172\n",
      "    epoch time:               0.07118105888366699\n",
      "    joint lr:                 0.0030601000000000087\n",
      "epoch:  52 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 19.67%\n",
      "    train overall loss:       6.1374443372090655\n",
      "    train cross_ent loss:     3.136657820807563\n",
      "    test overall loss:        6.2180962562561035\n",
      "    test cross_ent loss:      3.217325290044149\n",
      "    cluster loss:             3173.4798990885415\n",
      "    separation loss:          502.0801188151042\n",
      "    avg separation loss:      919.9591878255209\n",
      "    l1_addon loss:            25.67821502685547\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05885744094848633\n",
      "    test time:                0.012119770050048828\n",
      "    epoch time:               0.07176423072814941\n",
      "    joint lr:                 0.005960997999999999\n",
      "epoch:  53 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 29.67%\n",
      "    train overall loss:       6.084165308210585\n",
      "    train cross_ent loss:     3.083400699827406\n",
      "    test overall loss:        6.214242617289226\n",
      "    test cross_ent loss:      3.21344526608785\n",
      "    cluster loss:             3112.7156575520835\n",
      "    separation loss:          372.3828125\n",
      "    avg separation loss:      811.3650309244791\n",
      "    l1_addon loss:            26.571712493896484\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05869936943054199\n",
      "    test time:                0.012168407440185547\n",
      "    epoch time:               0.07163262367248535\n",
      "    joint lr:                 0.008803582030000007\n",
      "epoch:  54 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 36.33%\n",
      "    train overall loss:       5.837924639383952\n",
      "    train cross_ent loss:     2.83713255988227\n",
      "    test overall loss:        6.210584958394368\n",
      "    test cross_ent loss:      3.2097736994425454\n",
      "    cluster loss:             3067.4498697916665\n",
      "    separation loss:          257.55091857910156\n",
      "    avg separation loss:      642.5787556966146\n",
      "    l1_addon loss:            27.030929565429688\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05841660499572754\n",
      "    test time:                0.012076616287231445\n",
      "    epoch time:               0.07124519348144531\n",
      "    joint lr:                 0.011588728279599995\n",
      "epoch:  55 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 41.00%\n",
      "    train overall loss:       5.566108756595188\n",
      "    train cross_ent loss:     2.5653097894456653\n",
      "    test overall loss:        6.196533203125\n",
      "    test cross_ent loss:      3.1956912676493325\n",
      "    cluster loss:             3009.124755859375\n",
      "    separation loss:          137.1322784423828\n",
      "    avg separation loss:      399.807373046875\n",
      "    l1_addon loss:            28.059307098388672\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.0589296817779541\n",
      "    test time:                0.012153863906860352\n",
      "    epoch time:               0.07186412811279297\n",
      "    joint lr:                 0.014317301246005004\n",
      "epoch:  56 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 67.67%\n",
      "    train overall loss:       5.505059189266628\n",
      "    train cross_ent loss:     2.5042290687561035\n",
      "    test overall loss:        6.119365851084392\n",
      "    test cross_ent loss:      3.1185160477956138\n",
      "    cluster loss:             2968.4178873697915\n",
      "    separation loss:          71.82856369018555\n",
      "    avg separation loss:      181.27788798014322\n",
      "    l1_addon loss:            28.32314109802246\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05861473083496094\n",
      "    test time:                0.012132644653320312\n",
      "    epoch time:               0.07151055335998535\n",
      "    joint lr:                 0.016990153880253933\n",
      "epoch:  57 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 72.67%\n",
      "    train overall loss:       5.227948930528429\n",
      "    train cross_ent loss:     2.227093882030911\n",
      "    test overall loss:        5.881049633026123\n",
      "    test cross_ent loss:      2.8801705837249756\n",
      "    cluster loss:             2955.9659830729165\n",
      "    separation loss:          36.368242263793945\n",
      "    avg separation loss:      100.81221771240234\n",
      "    l1_addon loss:            29.301021575927734\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05868864059448242\n",
      "    test time:                0.012313127517700195\n",
      "    epoch time:               0.07177519798278809\n",
      "    joint lr:                 0.019608127731693303\n",
      "epoch:  58 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 64.33%\n",
      "    train overall loss:       5.175717035929362\n",
      "    train cross_ent loss:     2.17482246292962\n",
      "    test overall loss:        5.963380495707194\n",
      "    test cross_ent loss:      2.962423245112101\n",
      "    cluster loss:             2957.62548828125\n",
      "    separation loss:          34.57407760620117\n",
      "    avg separation loss:      86.03432718912761\n",
      "    l1_addon loss:            31.903640747070312\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05861163139343262\n",
      "    test time:                0.012156486511230469\n",
      "    epoch time:               0.0715186595916748\n",
      "    joint lr:                 0.02217205309071584\n",
      "epoch:  59 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 55.67%\n",
      "    train overall loss:       5.279309961530897\n",
      "    train cross_ent loss:     2.2783612807591758\n",
      "    test overall loss:        5.917181173960368\n",
      "    test cross_ent loss:      2.9161787827809653\n",
      "    cluster loss:             2956.7386881510415\n",
      "    separation loss:          31.068796157836914\n",
      "    avg separation loss:      74.15629323323567\n",
      "    l1_addon loss:            33.410316467285156\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05856013298034668\n",
      "    test time:                0.012125730514526367\n",
      "    epoch time:               0.07143568992614746\n",
      "    joint lr:                 0.024682749129784777\n",
      "epoch:  60 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 68.67%\n",
      "    train overall loss:       5.126783900790745\n",
      "    train cross_ent loss:     2.125808596611023\n",
      "    test overall loss:        5.555142720540364\n",
      "    test cross_ent loss:      2.5541345278422036\n",
      "    cluster loss:             2952.6791178385415\n",
      "    separation loss:          21.624850591023762\n",
      "    avg separation loss:      51.349413553873696\n",
      "    l1_addon loss:            33.59800338745117\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.0585179328918457\n",
      "    test time:                0.012108564376831055\n",
      "    epoch time:               0.07134652137756348\n",
      "    joint lr:                 0.027141024042763244\n",
      "epoch:  61 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 62.67%\n",
      "    train overall loss:       5.104000621371799\n",
      "    train cross_ent loss:     2.102981779310438\n",
      "    test overall loss:        5.287420908610026\n",
      "    test cross_ent loss:      2.2864370346069336\n",
      "    cluster loss:             2952.3016764322915\n",
      "    separation loss:          19.71078109741211\n",
      "    avg separation loss:      44.35346984863281\n",
      "    l1_addon loss:            32.78618240356445\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05939507484436035\n",
      "    test time:                0.012190580368041992\n",
      "    epoch time:               0.07232928276062012\n",
      "    joint lr:                 0.025532083112218835\n",
      "epoch:  62 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 49.33%\n",
      "    train overall loss:       5.3080052799648705\n",
      "    train cross_ent loss:     2.3069527679019504\n",
      "    test overall loss:        5.961223602294922\n",
      "    test cross_ent loss:      2.9600756963094077\n",
      "    cluster loss:             2958.8302408854165\n",
      "    separation loss:          38.898241678873696\n",
      "    avg separation loss:      69.01277669270833\n",
      "    l1_addon loss:            38.25910949707031\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05873751640319824\n",
      "    test time:                0.012161016464233398\n",
      "    epoch time:               0.07169413566589355\n",
      "    joint lr:                 0.023952616897881036\n",
      "epoch:  63 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 63.33%\n",
      "    train overall loss:       5.661980734931098\n",
      "    train cross_ent loss:     2.660908725526598\n",
      "    test overall loss:        5.338167667388916\n",
      "    test cross_ent loss:      2.3370444774627686\n",
      "    cluster loss:             2953.464599609375\n",
      "    separation loss:          22.161027908325195\n",
      "    avg separation loss:      49.18210474650065\n",
      "    l1_addon loss:            37.42877197265625\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05856776237487793\n",
      "    test time:                0.012164115905761719\n",
      "    epoch time:               0.0715036392211914\n",
      "    joint lr:                 0.022402196799518763\n",
      "epoch:  64 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 75.33%\n",
      "    train overall loss:       5.222992049323188\n",
      "    train cross_ent loss:     2.221895032458835\n",
      "    test overall loss:        5.045899550120036\n",
      "    test cross_ent loss:      2.044806480407715\n",
      "    cluster loss:             2952.7784016927085\n",
      "    separation loss:          21.324488321940105\n",
      "    avg separation loss:      48.44488016764323\n",
      "    l1_addon loss:            36.42401123046875\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05852222442626953\n",
      "    test time:                0.012167930603027344\n",
      "    epoch time:               0.07147502899169922\n",
      "    joint lr:                 0.02088039984143395\n",
      "epoch:  65 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 73.33%\n",
      "    train overall loss:       4.707044919331868\n",
      "    train cross_ent loss:     1.7059117290708754\n",
      "    test overall loss:        4.497231801350911\n",
      "    test cross_ent loss:      1.4960895379384358\n",
      "    cluster loss:             2951.7149251302085\n",
      "    separation loss:          16.878039995829266\n",
      "    avg separation loss:      40.857643127441406\n",
      "    l1_addon loss:            38.06433868408203\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05868792533874512\n",
      "    test time:                0.012131452560424805\n",
      "    epoch time:               0.07158446311950684\n",
      "    joint lr:                 0.01938680860283089\n",
      "epoch:  66 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 68.33%\n",
      "    train overall loss:       4.626147005293104\n",
      "    train cross_ent loss:     1.6249826086892023\n",
      "    test overall loss:        4.689762592315674\n",
      "    test cross_ent loss:      1.6886173486709595\n",
      "    cluster loss:             2951.961181640625\n",
      "    separation loss:          15.617403030395508\n",
      "    avg separation loss:      34.1105105082194\n",
      "    l1_addon loss:            38.15625\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05849885940551758\n",
      "    test time:                0.012162923812866211\n",
      "    epoch time:               0.07140493392944336\n",
      "    joint lr:                 0.017921011149015745\n",
      "epoch:  67 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 67.00%\n",
      "    train overall loss:       4.654380851321751\n",
      "    train cross_ent loss:     1.6532015138202243\n",
      "    test overall loss:        4.959296226501465\n",
      "    test cross_ent loss:      1.958149512608846\n",
      "    cluster loss:             2952.3091634114585\n",
      "    separation loss:          15.300680796305338\n",
      "    avg separation loss:      30.90089734395345\n",
      "    l1_addon loss:            38.21148681640625\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05845022201538086\n",
      "    test time:                0.012192726135253906\n",
      "    epoch time:               0.0714564323425293\n",
      "    joint lr:                 0.016482600963416614\n",
      "epoch:  68 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 73.67%\n",
      "    train overall loss:       4.5534042252434626\n",
      "    train cross_ent loss:     1.5522371662987604\n",
      "    test overall loss:        4.255035479863484\n",
      "    test cross_ent loss:      1.253835380077362\n",
      "    cluster loss:             2951.1402994791665\n",
      "    separation loss:          12.608446756998697\n",
      "    avg separation loss:      27.402144114176433\n",
      "    l1_addon loss:            39.994041442871094\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05848217010498047\n",
      "    test time:                0.01216578483581543\n",
      "    epoch time:               0.07137489318847656\n",
      "    joint lr:                 0.015071176880414561\n",
      "epoch:  69 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 79.33%\n",
      "    train overall loss:       4.2382471561431885\n",
      "    train cross_ent loss:     1.237073540687561\n",
      "    test overall loss:        4.286362965901692\n",
      "    test cross_ent loss:      1.2852208216985066\n",
      "    cluster loss:             2951.0152994791665\n",
      "    separation loss:          11.136831919352213\n",
      "    avg separation loss:      24.4335994720459\n",
      "    l1_addon loss:            38.064788818359375\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05838131904602051\n",
      "    test time:                0.01211237907409668\n",
      "    epoch time:               0.07128143310546875\n",
      "    joint lr:                 0.01368634301897622\n",
      "epoch:  70 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 84.00%\n",
      "    train overall loss:       4.116424269146389\n",
      "    train cross_ent loss:     1.1152555015352037\n",
      "    test overall loss:        3.996553103129069\n",
      "    test cross_ent loss:      0.9953739643096924\n",
      "    cluster loss:             2950.4606119791665\n",
      "    separation loss:          8.853900909423828\n",
      "    avg separation loss:      21.154374440511067\n",
      "    l1_addon loss:            39.2970085144043\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.0582737922668457\n",
      "    test time:                0.012115716934204102\n",
      "    epoch time:               0.07108497619628906\n",
      "    joint lr:                 0.012327708717078603\n",
      "epoch:  71 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 90.67%\n",
      "    train overall loss:       3.9324480162726507\n",
      "    train cross_ent loss:     0.9312879509396024\n",
      "    test overall loss:        3.691482146581014\n",
      "    test cross_ent loss:      0.6903102596600851\n",
      "    cluster loss:             2950.27099609375\n",
      "    separation loss:          7.542577266693115\n",
      "    avg separation loss:      17.65870475769043\n",
      "    l1_addon loss:            39.05287170410156\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05823993682861328\n",
      "    test time:                0.012112617492675781\n",
      "    epoch time:               0.07111334800720215\n",
      "    joint lr:                 0.01099488846691703\n",
      "epoch:  72 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 90.00%\n",
      "    train overall loss:       3.6391347779168024\n",
      "    train cross_ent loss:     0.6379747788111368\n",
      "    test overall loss:        3.6466519037882485\n",
      "    test cross_ent loss:      0.6455209056536356\n",
      "    cluster loss:             2950.21728515625\n",
      "    separation loss:          6.85809326171875\n",
      "    avg separation loss:      15.671137809753418\n",
      "    l1_addon loss:            37.69401931762695\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05837845802307129\n",
      "    test time:                0.012108802795410156\n",
      "    epoch time:               0.07129263877868652\n",
      "    joint lr:                 0.009687501850886984\n",
      "epoch:  73 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 94.33%\n",
      "    train overall loss:       3.5481214788224964\n",
      "    train cross_ent loss:     0.5469724304146237\n",
      "    test overall loss:        3.5390880902608237\n",
      "    test cross_ent loss:      0.5379252831141154\n",
      "    cluster loss:             2950.064697265625\n",
      "    separation loss:          6.0373765627543134\n",
      "    avg separation loss:      13.348641077677408\n",
      "    l1_addon loss:            38.74808883666992\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05833148956298828\n",
      "    test time:                0.012111663818359375\n",
      "    epoch time:               0.07120442390441895\n",
      "    joint lr:                 0.008405173478330853\n",
      "epoch:  74 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       3.483132415347629\n",
      "    train cross_ent loss:     0.4819786416159736\n",
      "    test overall loss:        3.397474447886149\n",
      "    test cross_ent loss:      0.396324356396993\n",
      "    cluster loss:             2949.9593098958335\n",
      "    separation loss:          5.481528282165527\n",
      "    avg separation loss:      12.314068158467611\n",
      "    l1_addon loss:            38.33340835571289\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05816459655761719\n",
      "    test time:                0.012083768844604492\n",
      "    epoch time:               0.0710148811340332\n",
      "    joint lr:                 0.007147532923040749\n",
      "epoch:  75 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 93.00%\n",
      "    train overall loss:       3.334330028957791\n",
      "    train cross_ent loss:     0.3331763810581631\n",
      "    test overall loss:        3.451308091481527\n",
      "    test cross_ent loss:      0.45016393065452576\n",
      "    cluster loss:             2950.0005696614585\n",
      "    separation loss:          5.480292638142903\n",
      "    avg separation loss:      12.112284024556478\n",
      "    l1_addon loss:            38.12873077392578\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05817437171936035\n",
      "    test time:                0.012113094329833984\n",
      "    epoch time:               0.07106447219848633\n",
      "    joint lr:                 0.005914214661508615\n",
      "epoch:  76 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       3.390072822570801\n",
      "    train cross_ent loss:     0.3889190587732527\n",
      "    test overall loss:        3.278592665990194\n",
      "    test cross_ent loss:      0.27744680394728977\n",
      "    cluster loss:             2949.8976236979165\n",
      "    separation loss:          5.004026730855306\n",
      "    avg separation loss:      11.01582145690918\n",
      "    l1_addon loss:            38.18861770629883\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058089494705200195\n",
      "    test time:                0.0121002197265625\n",
      "    epoch time:               0.0709528923034668\n",
      "    joint lr:                 0.004704858011914826\n",
      "epoch:  77 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       3.2332469357384577\n",
      "    train cross_ent loss:     0.23209466536839804\n",
      "    test overall loss:        3.262737194697062\n",
      "    test cross_ent loss:      0.26159070680538815\n",
      "    cluster loss:             2949.8558756510415\n",
      "    separation loss:          4.694815397262573\n",
      "    avg separation loss:      10.121618270874023\n",
      "    l1_addon loss:            38.21329879760742\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05836009979248047\n",
      "    test time:                0.012115955352783203\n",
      "    epoch time:               0.07128691673278809\n",
      "    joint lr:                 0.0035191070738467612\n",
      "epoch:  78 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       3.1698943773905435\n",
      "    train cross_ent loss:     0.1687441716591517\n",
      "    test overall loss:        3.2128759225209556\n",
      "    test cross_ent loss:      0.2117188423871994\n",
      "    cluster loss:             2949.804443359375\n",
      "    separation loss:          4.422795057296753\n",
      "    avg separation loss:      9.677674611409506\n",
      "    l1_addon loss:            38.56132125854492\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05807328224182129\n",
      "    test time:                0.012125492095947266\n",
      "    epoch time:               0.07095170021057129\n",
      "    joint lr:                 0.00235661066873886\n",
      "epoch:  79 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       3.0916111204359265\n",
      "    train cross_ent loss:     0.09045584665404426\n",
      "    test overall loss:        3.195476452509562\n",
      "    test cross_ent loss:      0.1943267583847046\n",
      "    cluster loss:             2949.788330078125\n",
      "    separation loss:          4.288821856180827\n",
      "    avg separation loss:      9.441361427307129\n",
      "    l1_addon loss:            38.3133430480957\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058264732360839844\n",
      "    test time:                0.012358427047729492\n",
      "    epoch time:               0.0714108943939209\n",
      "    joint lr:                 0.001217022281025732\n",
      "epoch:  80 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       3.063878297805786\n",
      "    train cross_ent loss:     0.06272751444743739\n",
      "    test overall loss:        3.1840577125549316\n",
      "    test cross_ent loss:      0.18290401001771292\n",
      "    cluster loss:             2949.775146484375\n",
      "    separation loss:          4.216549714406331\n",
      "    avg separation loss:      9.20150057474772\n",
      "    l1_addon loss:            38.45254135131836\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058435916900634766\n",
      "    test time:                0.012115955352783203\n",
      "    epoch time:               0.07128429412841797\n",
      "    joint lr:                 0.0001\n",
      "epoch:  81 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       3.037162939707438\n",
      "    train cross_ent loss:     0.036008884819845356\n",
      "    test overall loss:        3.181809981664022\n",
      "    test cross_ent loss:      0.18065556635459265\n",
      "    cluster loss:             2949.7740071614585\n",
      "    separation loss:          4.210154453913371\n",
      "    avg separation loss:      9.173682848612467\n",
      "    l1_addon loss:            38.46984100341797\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05843353271484375\n",
      "    test time:                0.012115955352783203\n",
      "    epoch time:               0.07128691673278809\n",
      "    joint lr:                 0.00228958707526664\n",
      "epoch:  82 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       3.0402384334140353\n",
      "    train cross_ent loss:     0.03908646800037888\n",
      "    test overall loss:        3.1625595092773438\n",
      "    test cross_ent loss:      0.161406759172678\n",
      "    cluster loss:             2949.7621256510415\n",
      "    separation loss:          4.06669815381368\n",
      "    avg separation loss:      8.717992464701334\n",
      "    l1_addon loss:            38.41872024536133\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05879640579223633\n",
      "    test time:                0.01210641860961914\n",
      "    epoch time:               0.07168722152709961\n",
      "    joint lr:                 0.004435382409027948\n",
      "epoch:  83 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       3.059200392829047\n",
      "    train cross_ent loss:     0.058048793839083776\n",
      "    test overall loss:        3.1688807010650635\n",
      "    test cross_ent loss:      0.1677363303800424\n",
      "    cluster loss:             2949.7642415364585\n",
      "    separation loss:          3.9837040106455484\n",
      "    avg separation loss:      8.523677825927734\n",
      "    l1_addon loss:            38.138092041015625\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058368682861328125\n",
      "    test time:                0.012131929397583008\n",
      "    epoch time:               0.07126188278198242\n",
      "    joint lr:                 0.006538042877406532\n",
      "epoch:  84 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       3.0888365109761557\n",
      "    train cross_ent loss:     0.0876832836204105\n",
      "    test overall loss:        3.166930357615153\n",
      "    test cross_ent loss:      0.16578450923164686\n",
      "    cluster loss:             2949.7721354166665\n",
      "    separation loss:          3.9133822123209634\n",
      "    avg separation loss:      8.168612480163574\n",
      "    l1_addon loss:            38.18452835083008\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05846738815307617\n",
      "    test time:                0.012103080749511719\n",
      "    epoch time:               0.0713038444519043\n",
      "    joint lr:                 0.008598216598176611\n",
      "epoch:  85 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 93.67%\n",
      "    train overall loss:       3.1958019733428955\n",
      "    train cross_ent loss:     0.19464649591181013\n",
      "    test overall loss:        3.3947672049204507\n",
      "    test cross_ent loss:      0.3936361273129781\n",
      "    cluster loss:             2949.9283040364585\n",
      "    separation loss:          4.422205209732056\n",
      "    avg separation loss:      8.785222371419271\n",
      "    l1_addon loss:            37.69312286376953\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058281660079956055\n",
      "    test time:                0.012133598327636719\n",
      "    epoch time:               0.07117915153503418\n",
      "    joint lr:                 0.010616543040243577\n",
      "epoch:  86 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 83.33%\n",
      "    train overall loss:       3.807223293516371\n",
      "    train cross_ent loss:     0.8060730348030726\n",
      "    test overall loss:        4.044692595799764\n",
      "    test cross_ent loss:      1.043501079082489\n",
      "    cluster loss:             2950.4727376302085\n",
      "    separation loss:          6.798567295074463\n",
      "    avg separation loss:      13.48779296875\n",
      "    l1_addon loss:            39.71030044555664\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058220624923706055\n",
      "    test time:                0.012132406234741211\n",
      "    epoch time:               0.07108545303344727\n",
      "    joint lr:                 0.012593653131809358\n",
      "epoch:  87 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 91.67%\n",
      "    train overall loss:       4.013801839616564\n",
      "    train cross_ent loss:     1.0126512447992961\n",
      "    test overall loss:        3.834038257598877\n",
      "    test cross_ent loss:      0.8328673839569092\n",
      "    cluster loss:             2950.390625\n",
      "    separation loss:          7.886510372161865\n",
      "    avg separation loss:      17.20880381266276\n",
      "    l1_addon loss:            39.02107238769531\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05823540687561035\n",
      "    test time:                0.012122154235839844\n",
      "    epoch time:               0.07110929489135742\n",
      "    joint lr:                 0.014530169367239798\n",
      "epoch:  88 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 87.33%\n",
      "    train overall loss:       3.819605906804403\n",
      "    train cross_ent loss:     0.8184391458829244\n",
      "    test overall loss:        4.0210936069488525\n",
      "    test cross_ent loss:      1.0199238657951355\n",
      "    cluster loss:             2950.6025390625\n",
      "    separation loss:          8.872145652770996\n",
      "    avg separation loss:      19.06032117207845\n",
      "    l1_addon loss:            38.98529052734375\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05849480628967285\n",
      "    test time:                0.012101411819458008\n",
      "    epoch time:               0.07136178016662598\n",
      "    joint lr:                 0.01642670591264845\n",
      "epoch:  89 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 84.00%\n",
      "    train overall loss:       3.8599686092800565\n",
      "    train cross_ent loss:     0.8588058551152548\n",
      "    test overall loss:        4.144133408864339\n",
      "    test cross_ent loss:      1.1429552833239238\n",
      "    cluster loss:             2950.7579752604165\n",
      "    separation loss:          8.659898440043131\n",
      "    avg separation loss:      19.314107259114582\n",
      "    l1_addon loss:            39.26310729980469\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05838203430175781\n",
      "    test time:                0.012161731719970703\n",
      "    epoch time:               0.0713493824005127\n",
      "    joint lr:                 0.018283868710212207\n",
      "epoch:  90 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 90.00%\n",
      "    train overall loss:       4.007638772328694\n",
      "    train cross_ent loss:     1.0064773956934612\n",
      "    test overall loss:        4.1037678718566895\n",
      "    test cross_ent loss:      1.1025983889897664\n",
      "    cluster loss:             2951.091796875\n",
      "    separation loss:          9.457499821980795\n",
      "    avg separation loss:      19.346899668375652\n",
      "    l1_addon loss:            38.97267150878906\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058330535888671875\n",
      "    test time:                0.012183427810668945\n",
      "    epoch time:               0.07124447822570801\n",
      "    joint lr:                 0.020102255581233422\n",
      "epoch:  91 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 80.00%\n",
      "    train overall loss:       4.153515047497219\n",
      "    train cross_ent loss:     1.1523558961020575\n",
      "    test overall loss:        4.286797841389974\n",
      "    test cross_ent loss:      1.2856370608011882\n",
      "    cluster loss:             2951.5743001302085\n",
      "    separation loss:          10.982199668884277\n",
      "    avg separation loss:      21.30008888244629\n",
      "    l1_addon loss:            38.681095123291016\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058109283447265625\n",
      "    test time:                0.012123823165893555\n",
      "    epoch time:               0.07097244262695312\n",
      "    joint lr:                 0.018912121374150048\n",
      "epoch:  92 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 82.33%\n",
      "    train overall loss:       4.255797068277995\n",
      "    train cross_ent loss:     1.2546324597464666\n",
      "    test overall loss:        4.472818056742351\n",
      "    test cross_ent loss:      1.4716891845067341\n",
      "    cluster loss:             2952.12060546875\n",
      "    separation loss:          12.531968752543131\n",
      "    avg separation loss:      23.681848526000977\n",
      "    l1_addon loss:            37.61745071411133\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058171987533569336\n",
      "    test time:                0.012080669403076172\n",
      "    epoch time:               0.07102274894714355\n",
      "    joint lr:                 0.017743789625650205\n",
      "epoch:  93 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 74.00%\n",
      "    train overall loss:       4.588581032223171\n",
      "    train cross_ent loss:     1.5874228212568495\n",
      "    test overall loss:        4.897904237111409\n",
      "    test cross_ent loss:      1.896694262822469\n",
      "    cluster loss:             2953.1678059895835\n",
      "    separation loss:          15.626577059427897\n",
      "    avg separation loss:      29.082548141479492\n",
      "    l1_addon loss:            40.33094024658203\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05833172798156738\n",
      "    test time:                0.012119770050048828\n",
      "    epoch time:               0.07123208045959473\n",
      "    joint lr:                 0.01659694329998293\n",
      "epoch:  94 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 81.33%\n",
      "    train overall loss:       4.359113110436334\n",
      "    train cross_ent loss:     1.3579360644022624\n",
      "    test overall loss:        4.268524964650472\n",
      "    test cross_ent loss:      1.2673545678456624\n",
      "    cluster loss:             2952.9965006510415\n",
      "    separation loss:          14.51982593536377\n",
      "    avg separation loss:      26.84890874226888\n",
      "    l1_addon loss:            39.00013732910156\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05866384506225586\n",
      "    test time:                0.012146234512329102\n",
      "    epoch time:               0.07159948348999023\n",
      "    joint lr:                 0.01547126952186645\n",
      "epoch:  95 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 82.00%\n",
      "    train overall loss:       4.196948104434544\n",
      "    train cross_ent loss:     1.1957682569821675\n",
      "    test overall loss:        4.147446950276692\n",
      "    test cross_ent loss:      1.1462614138921101\n",
      "    cluster loss:             2952.9589029947915\n",
      "    separation loss:          14.123929023742676\n",
      "    avg separation loss:      25.428431193033855\n",
      "    l1_addon loss:            39.51723861694336\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05856966972351074\n",
      "    test time:                0.012125730514526367\n",
      "    epoch time:               0.07146239280700684\n",
      "    joint lr:                 0.014366459524982304\n",
      "epoch:  96 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 84.33%\n",
      "    train overall loss:       4.079772313435872\n",
      "    train cross_ent loss:     1.0785875187979803\n",
      "    test overall loss:        4.028207143147786\n",
      "    test cross_ent loss:      1.0270233551661174\n",
      "    cluster loss:             2952.8692220052085\n",
      "    separation loss:          13.649170557657877\n",
      "    avg separation loss:      24.67691167195638\n",
      "    l1_addon loss:            39.44911193847656\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05832648277282715\n",
      "    test time:                0.012122631072998047\n",
      "    epoch time:               0.07120633125305176\n",
      "    joint lr:                 0.013282208601083652\n",
      "epoch:  97 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 79.00%\n",
      "    train overall loss:       4.0503818723890515\n",
      "    train cross_ent loss:     1.049195455180274\n",
      "    test overall loss:        4.134350299835205\n",
      "    test cross_ent loss:      1.1331451733907063\n",
      "    cluster loss:             2952.923828125\n",
      "    separation loss:          13.421497027079264\n",
      "    avg separation loss:      23.686545689900715\n",
      "    l1_addon loss:            40.161476135253906\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058385372161865234\n",
      "    test time:                0.012366056442260742\n",
      "    epoch time:               0.07156777381896973\n",
      "    joint lr:                 0.012218216049710476\n",
      "epoch:  98 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 84.33%\n",
      "    train overall loss:       3.9115621778700085\n",
      "    train cross_ent loss:     0.910365190770891\n",
      "    test overall loss:        3.9381985664367676\n",
      "    test cross_ent loss:      0.9370179375012716\n",
      "    cluster loss:             2952.6172688802085\n",
      "    separation loss:          12.508600870768229\n",
      "    avg separation loss:      22.035877227783203\n",
      "    l1_addon loss:            39.3453369140625\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058807373046875\n",
      "    test time:                0.01265263557434082\n",
      "    epoch time:               0.0722815990447998\n",
      "    joint lr:                 0.011174185128504639\n",
      "epoch:  99 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 92.33%\n",
      "    train overall loss:       3.7749718030293784\n",
      "    train cross_ent loss:     0.7737821539243063\n",
      "    test overall loss:        3.6868871053059897\n",
      "    test cross_ent loss:      0.6856766939163208\n",
      "    cluster loss:             2952.5255533854165\n",
      "    separation loss:          12.160783767700195\n",
      "    avg separation loss:      21.291226704915363\n",
      "    l1_addon loss:            40.33905029296875\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05905032157897949\n",
      "    test time:                0.012649059295654297\n",
      "    epoch time:               0.07250118255615234\n",
      "    joint lr:                 0.010149823004117963\n",
      "epoch: 100 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       3.5356983873579235\n",
      "    train cross_ent loss:     0.534504257970386\n",
      "    test overall loss:        3.5117554664611816\n",
      "    test cross_ent loss:      0.5105578899383545\n",
      "    cluster loss:             2952.324462890625\n",
      "    separation loss:          11.416280746459961\n",
      "    avg separation loss:      19.449560165405273\n",
      "    l1_addon loss:            39.911842346191406\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.059148550033569336\n",
      "    test time:                0.012667655944824219\n",
      "    epoch time:               0.07262682914733887\n",
      "    joint lr:                 0.009144840703706159\n",
      "epoch: 101 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       3.418883800506592\n",
      "    train cross_ent loss:     0.41769121421708\n",
      "    test overall loss:        3.461473226547241\n",
      "    test cross_ent loss:      0.4602925976117452\n",
      "    cluster loss:             2952.209716796875\n",
      "    separation loss:          10.936065673828125\n",
      "    avg separation loss:      18.248382568359375\n",
      "    l1_addon loss:            39.34442138671875\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.059067726135253906\n",
      "    test time:                0.012763261795043945\n",
      "    epoch time:               0.07263326644897461\n",
      "    joint lr:                 0.008158953067002189\n",
      "epoch: 102 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       3.3660467995537653\n",
      "    train cross_ent loss:     0.36485803458425736\n",
      "    test overall loss:        3.4379378159840903\n",
      "    test cross_ent loss:      0.436746488014857\n",
      "    cluster loss:             2952.14697265625\n",
      "    separation loss:          10.589788436889648\n",
      "    avg separation loss:      17.87266222635905\n",
      "    l1_addon loss:            39.70363235473633\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05920577049255371\n",
      "    test time:                0.012642860412597656\n",
      "    epoch time:               0.07264924049377441\n",
      "    joint lr:                 0.0071918786989619305\n",
      "epoch: 103 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       3.250848478741116\n",
      "    train cross_ent loss:     0.24965779648886788\n",
      "    test overall loss:        3.2665228048960366\n",
      "    test cross_ent loss:      0.26533499360084534\n",
      "    cluster loss:             2952.0463053385415\n",
      "    separation loss:          10.266595522562662\n",
      "    avg separation loss:      16.957507451375324\n",
      "    l1_addon loss:            39.58893585205078\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05893421173095703\n",
      "    test time:                0.012647151947021484\n",
      "    epoch time:               0.0723721981048584\n",
      "    joint lr:                 0.006243339922975775\n",
      "epoch: 104 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       3.1927992237938776\n",
      "    train cross_ent loss:     0.19161264970898628\n",
      "    test overall loss:        3.277285893758138\n",
      "    test cross_ent loss:      0.2761055529117584\n",
      "    cluster loss:             2952.0172526041665\n",
      "    separation loss:          9.979708989461264\n",
      "    avg separation loss:      15.934993108113607\n",
      "    l1_addon loss:            39.33852767944336\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.059072256088256836\n",
      "    test time:                0.01262044906616211\n",
      "    epoch time:               0.07251858711242676\n",
      "    joint lr:                 0.005313062734639446\n",
      "epoch: 105 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       3.193642907672458\n",
      "    train cross_ent loss:     0.19245688079131973\n",
      "    test overall loss:        3.2610294818878174\n",
      "    test cross_ent loss:      0.2598569293816884\n",
      "    cluster loss:             2952.0045572916665\n",
      "    separation loss:          9.83163038889567\n",
      "    avg separation loss:      15.654413223266602\n",
      "    l1_addon loss:            39.073883056640625\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.0590052604675293\n",
      "    test time:                0.012683629989624023\n",
      "    epoch time:               0.07250595092773438\n",
      "    joint lr:                 0.004400776756077547\n",
      "epoch: 106 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       3.210774951510959\n",
      "    train cross_ent loss:     0.20959569265445074\n",
      "    test overall loss:        3.176667849222819\n",
      "    test cross_ent loss:      0.17548771823445955\n",
      "    cluster loss:             2951.9393717447915\n",
      "    separation loss:          9.706491152445475\n",
      "    avg separation loss:      15.627277692159018\n",
      "    l1_addon loss:            39.32763671875\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058945655822753906\n",
      "    test time:                0.012627601623535156\n",
      "    epoch time:               0.07238459587097168\n",
      "    joint lr:                 0.0035062151908134102\n",
      "epoch: 107 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 98.00%\n",
      "    train overall loss:       3.126120196448432\n",
      "    train cross_ent loss:     0.12495134232772721\n",
      "    test overall loss:        3.1850081284840903\n",
      "    test cross_ent loss:      0.18382192154725394\n",
      "    cluster loss:             2951.9375\n",
      "    separation loss:          9.62705135345459\n",
      "    avg separation loss:      15.214797973632812\n",
      "    l1_addon loss:            39.53178787231445\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05923867225646973\n",
      "    test time:                0.012666463851928711\n",
      "    epoch time:               0.07268905639648438\n",
      "    joint lr:                 0.0026291147791789593\n",
      "epoch: 108 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       3.0847911569807263\n",
      "    train cross_ent loss:     0.08360764880975087\n",
      "    test overall loss:        3.1715572675069175\n",
      "    test cross_ent loss:      0.17038684710860252\n",
      "    cluster loss:             2951.937255859375\n",
      "    separation loss:          9.591748237609863\n",
      "    avg separation loss:      15.083510716756185\n",
      "    l1_addon loss:            39.00387954711914\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05908036231994629\n",
      "    test time:                0.012642621994018555\n",
      "    epoch time:               0.07251620292663574\n",
      "    joint lr:                 0.001769215754258106\n",
      "epoch: 109 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       3.064729372660319\n",
      "    train cross_ent loss:     0.06355650681588385\n",
      "    test overall loss:        3.145628054936727\n",
      "    test cross_ent loss:      0.1444488267103831\n",
      "    cluster loss:             2951.8990071614585\n",
      "    separation loss:          9.515958150227865\n",
      "    avg separation loss:      15.052415529886881\n",
      "    l1_addon loss:            39.2969856262207\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.058974266052246094\n",
      "    test time:                0.012633800506591797\n",
      "    epoch time:               0.07242250442504883\n",
      "    joint lr:                 0.0009262617983577627\n",
      "epoch: 110 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       3.03267240524292\n",
      "    train cross_ent loss:     0.031494510256581836\n",
      "    test overall loss:        3.1378238995869956\n",
      "    test cross_ent loss:      0.1366480253636837\n",
      "    cluster loss:             2951.8929036458335\n",
      "    separation loss:          9.456453005472818\n",
      "    avg separation loss:      14.906362851460775\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05918574333190918\n",
      "    test time:                0.012647628784179688\n",
      "    epoch time:               0.07262778282165527\n",
      "    joint lr:                 0.0001\n",
      "epoch: 110 (PUSH) - ArticularyWordRecognition\n",
      "    test acc:                 94.33%\n",
      "    train overall loss:       3.03267240524292\n",
      "    train cross_ent loss:     0.031494510256581836\n",
      "    test overall loss:        3.209990660349528\n",
      "    test cross_ent loss:      0.20881471317261457\n",
      "    cluster loss:             2949.2766927083335\n",
      "    separation loss:          2.387356241544088\n",
      "    avg separation loss:      6.884775320688884\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  3000.0\n",
      "    train time:               0.05918574333190918\n",
      "    test time:                0.012980937957763672\n",
      "    epoch time:               0.37253236770629883\n",
      "epoch: 110 (1/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 94.33%\n",
      "    train overall loss:       3.042343166139391\n",
      "    train cross_ent loss:     0.04336073973940478\n",
      "    test overall loss:        3.2036871115366616\n",
      "    test cross_ent loss:      0.20739998016506433\n",
      "    cluster loss:             2949.2762858072915\n",
      "    separation loss:          2.3843061526616416\n",
      "    avg separation loss:      6.875453472137451\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  2995.111328125\n",
      "    train time:               0.024182558059692383\n",
      "    test time:                0.012645244598388672\n",
      "    epoch time:               0.03734183311462402\n",
      "    last layer lr:            0.0007599999999999978\n",
      "epoch: 110 (2/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 94.00%\n",
      "    train overall loss:       3.029693365097046\n",
      "    train cross_ent loss:     0.049488052932752505\n",
      "    test overall loss:        3.1710548400878906\n",
      "    test cross_ent loss:      0.21070528899629912\n",
      "    cluster loss:             2949.2771809895835\n",
      "    separation loss:          2.3765684763590493\n",
      "    avg separation loss:      6.841429392496745\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  2959.173828125\n",
      "    train time:               0.023803234100341797\n",
      "    test time:                0.012605905532836914\n",
      "    epoch time:               0.036930084228515625\n",
      "    last layer lr:            0.0014200000000000013\n",
      "epoch: 110 (3/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 94.33%\n",
      "    train overall loss:       2.980382760365804\n",
      "    train cross_ent loss:     0.04979391680616471\n",
      "    test overall loss:        3.097923517227173\n",
      "    test cross_ent loss:      0.20441475603729486\n",
      "    cluster loss:             2949.27734375\n",
      "    separation loss:          2.3786935011545816\n",
      "    avg separation loss:      6.851045926411946\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  2892.3330078125\n",
      "    train time:               0.02371382713317871\n",
      "    test time:                0.012644767761230469\n",
      "    epoch time:               0.0368654727935791\n",
      "    last layer lr:            0.0020799999999999985\n",
      "epoch: 110 (4/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 94.33%\n",
      "    train overall loss:       2.899094025293986\n",
      "    train cross_ent loss:     0.0477585643529892\n",
      "    test overall loss:        2.9950230916341147\n",
      "    test cross_ent loss:      0.1971374712884426\n",
      "    cluster loss:             2949.2766927083335\n",
      "    separation loss:          2.384720802307129\n",
      "    avg separation loss:      6.875326474507649\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  2796.7099609375\n",
      "    train time:               0.02372455596923828\n",
      "    test time:                0.012593507766723633\n",
      "    epoch time:               0.03682065010070801\n",
      "    last layer lr:            0.0027400000000000024\n",
      "epoch: 110 (5/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 94.33%\n",
      "    train overall loss:       2.795349597930908\n",
      "    train cross_ent loss:     0.05297273045612706\n",
      "    test overall loss:        2.8625059922536216\n",
      "    test cross_ent loss:      0.1897858390584588\n",
      "    cluster loss:             2949.2764485677085\n",
      "    separation loss:          2.3912723064422607\n",
      "    avg separation loss:      6.8975396156311035\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  2671.54443359375\n",
      "    train time:               0.023792266845703125\n",
      "    test time:                0.012589693069458008\n",
      "    epoch time:               0.036895036697387695\n",
      "    last layer lr:            0.0034\n",
      "epoch: 110 (6/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 94.67%\n",
      "    train overall loss:       2.657819774415758\n",
      "    train cross_ent loss:     0.05578890670504835\n",
      "    test overall loss:        2.707942326863607\n",
      "    test cross_ent loss:      0.19340585575749478\n",
      "    cluster loss:             2949.2769368489585\n",
      "    separation loss:          2.3781348864237466\n",
      "    avg separation loss:      6.850221157073975\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  2513.360595703125\n",
      "    train time:               0.02375316619873047\n",
      "    test time:                0.012596607208251953\n",
      "    epoch time:               0.03685283660888672\n",
      "    last layer lr:            0.004059999999999998\n",
      "epoch: 110 (7/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 94.00%\n",
      "    train overall loss:       2.4852355321248374\n",
      "    train cross_ent loss:     0.051246357046895556\n",
      "    test overall loss:        2.5317999521891275\n",
      "    test cross_ent loss:      0.19774121170242628\n",
      "    cluster loss:             2949.2770182291665\n",
      "    separation loss:          2.387923280398051\n",
      "    avg separation loss:      6.888022581736247\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  2332.883056640625\n",
      "    train time:               0.02251911163330078\n",
      "    test time:                0.012059211730957031\n",
      "    epoch time:               0.03505873680114746\n",
      "    last layer lr:            0.004720000000000002\n",
      "epoch: 110 (8/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 94.00%\n",
      "    train overall loss:       2.302231682671441\n",
      "    train cross_ent loss:     0.06308331909692949\n",
      "    test overall loss:        2.326951583226522\n",
      "    test cross_ent loss:      0.20543827830503383\n",
      "    cluster loss:             2949.2774251302085\n",
      "    separation loss:          2.3763139247894287\n",
      "    avg separation loss:      6.842857042948405\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  2120.337646484375\n",
      "    train time:               0.022543668746948242\n",
      "    test time:                0.012046337127685547\n",
      "    epoch time:               0.035066843032836914\n",
      "    last layer lr:            0.005379999999999999\n",
      "epoch: 110 (9/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 94.33%\n",
      "    train overall loss:       2.079157749811808\n",
      "    train cross_ent loss:     0.062708613773187\n",
      "    test overall loss:        2.095181147257487\n",
      "    test cross_ent loss:      0.2096175830811262\n",
      "    cluster loss:             2949.2775065104165\n",
      "    separation loss:          2.374424616495768\n",
      "    avg separation loss:      6.837681929270427\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  1884.387939453125\n",
      "    train time:               0.022881269454956055\n",
      "    test time:                0.012068510055541992\n",
      "    epoch time:               0.03542900085449219\n",
      "    last layer lr:            0.006040000000000003\n",
      "epoch: 110 (10/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 94.67%\n",
      "    train overall loss:       1.8272425068749323\n",
      "    train cross_ent loss:     0.06076021192388402\n",
      "    test overall loss:        1.834085464477539\n",
      "    test cross_ent loss:      0.21577303049465021\n",
      "    cluster loss:             2949.2770182291665\n",
      "    separation loss:          2.376391371091207\n",
      "    avg separation loss:      6.843249956766765\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  1617.1368408203125\n",
      "    train time:               0.022521018981933594\n",
      "    test time:                0.012074470520019531\n",
      "    epoch time:               0.035067081451416016\n",
      "    last layer lr:            0.0067\n",
      "epoch: 110 (11/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 94.67%\n",
      "    train overall loss:       1.57183039188385\n",
      "    train cross_ent loss:     0.08413855938447846\n",
      "    test overall loss:        1.537832776705424\n",
      "    test cross_ent loss:      0.21198146417737007\n",
      "    cluster loss:             2949.276611328125\n",
      "    separation loss:          2.381888747215271\n",
      "    avg separation loss:      6.863668918609619\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  1324.67578125\n",
      "    train time:               0.022481203079223633\n",
      "    test time:                0.01207590103149414\n",
      "    epoch time:               0.03502988815307617\n",
      "    last layer lr:            0.0073599999999999985\n",
      "epoch: 110 (12/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       1.2600540982352362\n",
      "    train cross_ent loss:     0.07400121870968077\n",
      "    test overall loss:        1.2303313414255779\n",
      "    test cross_ent loss:      0.21900072321295738\n",
      "    cluster loss:             2949.2769368489585\n",
      "    separation loss:          2.3733288447062173\n",
      "    avg separation loss:      6.83352518081665\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  1010.155029296875\n",
      "    train time:               0.022484779357910156\n",
      "    test time:                0.012219905853271484\n",
      "    epoch time:               0.035178184509277344\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 110 (13/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 94.33%\n",
      "    train overall loss:       0.9294119543499417\n",
      "    train cross_ent loss:     0.07088606390688154\n",
      "    test overall loss:        0.9079942504564921\n",
      "    test cross_ent loss:      0.24230518812934557\n",
      "    cluster loss:             2949.276611328125\n",
      "    separation loss:          2.3756882349650064\n",
      "    avg separation loss:      6.8469241460164385\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  664.5134887695312\n",
      "    train time:               0.02254962921142578\n",
      "    test time:                0.01207733154296875\n",
      "    epoch time:               0.03511929512023926\n",
      "    last layer lr:            0.008679999999999998\n",
      "epoch: 110 (14/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 94.67%\n",
      "    train overall loss:       0.6096126238505045\n",
      "    train cross_ent loss:     0.10345681756734848\n",
      "    test overall loss:        0.5664065380891165\n",
      "    test cross_ent loss:      0.2538818394144376\n",
      "    cluster loss:             2949.2769368489585\n",
      "    separation loss:          2.376283288002014\n",
      "    avg separation loss:      6.84687614440918\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  311.34918212890625\n",
      "    train time:               0.022537708282470703\n",
      "    test time:                0.012071847915649414\n",
      "    epoch time:               0.0350804328918457\n",
      "    last layer lr:            0.009340000000000003\n",
      "epoch: 110 (15/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.32033905055787826\n",
      "    train cross_ent loss:     0.10227125593357617\n",
      "    test overall loss:        0.3801695903142293\n",
      "    test cross_ent loss:      0.2384525015950203\n",
      "    cluster loss:             2949.2766927083335\n",
      "    separation loss:          2.377679189046224\n",
      "    avg separation loss:      6.851245403289795\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  140.5415496826172\n",
      "    train time:               0.02255392074584961\n",
      "    test time:                0.012079238891601562\n",
      "    epoch time:               0.03511238098144531\n",
      "    last layer lr:            0.01\n",
      "epoch: 110 (16/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.20709811647733053\n",
      "    train cross_ent loss:     0.09386253688070509\n",
      "    test overall loss:        0.30494041244188946\n",
      "    test cross_ent loss:      0.2151985839009285\n",
      "    cluster loss:             2949.2771809895835\n",
      "    separation loss:          2.3767696619033813\n",
      "    avg separation loss:      6.8447926839192705\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  88.5663070678711\n",
      "    train time:               0.022593021392822266\n",
      "    test time:                0.012102842330932617\n",
      "    epoch time:               0.035170793533325195\n",
      "    last layer lr:            0.009604000000000001\n",
      "epoch: 110 (17/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.15694496366712782\n",
      "    train cross_ent loss:     0.08046880923211575\n",
      "    test overall loss:        0.25175859530766803\n",
      "    test cross_ent loss:      0.19207365065813065\n",
      "    cluster loss:             2949.2774251302085\n",
      "    separation loss:          2.3813835779825845\n",
      "    avg separation loss:      6.860950311024983\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  58.509422302246094\n",
      "    train time:               0.02261185646057129\n",
      "    test time:                0.012117385864257812\n",
      "    epoch time:               0.035205841064453125\n",
      "    last layer lr:            0.009208\n",
      "epoch: 110 (18/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.10286485072639254\n",
      "    train cross_ent loss:     0.05114689138200548\n",
      "    test overall loss:        0.22189171860615411\n",
      "    test cross_ent loss:      0.18194274604320526\n",
      "    cluster loss:             2949.2769368489585\n",
      "    separation loss:          2.380345185597738\n",
      "    avg separation loss:      6.86698055267334\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  38.77345275878906\n",
      "    train time:               0.02255702018737793\n",
      "    test time:                0.012072086334228516\n",
      "    epoch time:               0.035120487213134766\n",
      "    last layer lr:            0.008812\n",
      "epoch: 110 (19/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.09675594336456722\n",
      "    train cross_ent loss:     0.0627825843791167\n",
      "    test overall loss:        0.21313259998957315\n",
      "    test cross_ent loss:      0.18539323036869368\n",
      "    cluster loss:             2949.2769368489585\n",
      "    separation loss:          2.3787025610605874\n",
      "    avg separation loss:      6.858347415924072\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  26.5638484954834\n",
      "    train time:               0.022526979446411133\n",
      "    test time:                0.012071847915649414\n",
      "    epoch time:               0.03507065773010254\n",
      "    last layer lr:            0.008415999999999998\n",
      "epoch: 110 (20/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.06561215221881866\n",
      "    train cross_ent loss:     0.041254562222295336\n",
      "    test overall loss:        0.20069570094347\n",
      "    test cross_ent loss:      0.17984096705913544\n",
      "    cluster loss:             2949.2767740885415\n",
      "    separation loss:          2.373725334803263\n",
      "    avg separation loss:      6.845537185668945\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  19.679208755493164\n",
      "    train time:               0.022504568099975586\n",
      "    test time:                0.012061595916748047\n",
      "    epoch time:               0.035036563873291016\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 110 (21/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.058200315882762275\n",
      "    train cross_ent loss:     0.03878702171560791\n",
      "    test overall loss:        0.20138380552331606\n",
      "    test cross_ent loss:      0.18406263614694277\n",
      "    cluster loss:             2949.27685546875\n",
      "    separation loss:          2.375710368156433\n",
      "    avg separation loss:      6.848199526468913\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  16.145645141601562\n",
      "    train time:               0.0225217342376709\n",
      "    test time:                0.012093067169189453\n",
      "    epoch time:               0.03508448600769043\n",
      "    last layer lr:            0.007624000000000002\n",
      "epoch: 110 (22/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.0539522050983376\n",
      "    train cross_ent loss:     0.03802316284014119\n",
      "    test overall loss:        0.19264487673838934\n",
      "    test cross_ent loss:      0.17755129064122835\n",
      "    cluster loss:             2949.2769368489585\n",
      "    separation loss:          2.374457836151123\n",
      "    avg separation loss:      6.843369642893474\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  13.918059349060059\n",
      "    train time:               0.022500276565551758\n",
      "    test time:                0.012050390243530273\n",
      "    epoch time:               0.03502011299133301\n",
      "    last layer lr:            0.007228000000000001\n",
      "epoch: 110 (23/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.05645158266027769\n",
      "    train cross_ent loss:     0.04107966429243485\n",
      "    test overall loss:        0.19130745778481165\n",
      "    test cross_ent loss:      0.1778143346309662\n",
      "    cluster loss:             2949.2770182291665\n",
      "    separation loss:          2.374327540397644\n",
      "    avg separation loss:      6.845630168914795\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  12.317605018615723\n",
      "    train time:               0.022537946701049805\n",
      "    test time:                0.012120962142944336\n",
      "    epoch time:               0.03513169288635254\n",
      "    last layer lr:            0.006832000000000001\n",
      "epoch: 110 (24/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.05468135037355953\n",
      "    train cross_ent loss:     0.04193468981732925\n",
      "    test overall loss:        0.18811969210704169\n",
      "    test cross_ent loss:      0.17585036406914392\n",
      "    cluster loss:             2949.2769368489585\n",
      "    separation loss:          2.382098396619161\n",
      "    avg separation loss:      6.872080167134603\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  11.093809127807617\n",
      "    train time:               0.022567272186279297\n",
      "    test time:                0.01204824447631836\n",
      "    epoch time:               0.03508448600769043\n",
      "    last layer lr:            0.006436\n",
      "epoch: 110 (25/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.07800084559453858\n",
      "    train cross_ent loss:     0.06536222311357658\n",
      "    test overall loss:        0.1891167052090168\n",
      "    test cross_ent loss:      0.1765948049724102\n",
      "    cluster loss:             2949.2777506510415\n",
      "    separation loss:          2.3879831234614053\n",
      "    avg separation loss:      6.878415107727051\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  11.3463773727417\n",
      "    train time:               0.02261805534362793\n",
      "    test time:                0.012065887451171875\n",
      "    epoch time:               0.03515267372131348\n",
      "    last layer lr:            0.00604\n",
      "epoch: 110 (26/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.05036231875419617\n",
      "    train cross_ent loss:     0.037102880577246346\n",
      "    test overall loss:        0.18536296238501868\n",
      "    test cross_ent loss:      0.17337324221928915\n",
      "    cluster loss:             2949.2771809895835\n",
      "    separation loss:          2.3804968198140464\n",
      "    avg separation loss:      6.8537594477335615\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  10.814197540283203\n",
      "    train time:               0.02248692512512207\n",
      "    test time:                0.01209115982055664\n",
      "    epoch time:               0.035044193267822266\n",
      "    last layer lr:            0.005644000000000002\n",
      "epoch: 110 (27/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.051074654070867434\n",
      "    train cross_ent loss:     0.03998540460856424\n",
      "    test overall loss:        0.1798479383190473\n",
      "    test cross_ent loss:      0.16977675879995027\n",
      "    cluster loss:             2949.2764485677085\n",
      "    separation loss:          2.3757898012797036\n",
      "    avg separation loss:      6.84393326441447\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  8.895652770996094\n",
      "    train time:               0.022488832473754883\n",
      "    test time:                0.01211857795715332\n",
      "    epoch time:               0.03507637977600098\n",
      "    last layer lr:            0.005248\n",
      "epoch: 110 (28/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.04894003892938296\n",
      "    train cross_ent loss:     0.03863585771371921\n",
      "    test overall loss:        0.17844857648015022\n",
      "    test cross_ent loss:      0.1680027296145757\n",
      "    cluster loss:             2949.2770182291665\n",
      "    separation loss:          2.377163569132487\n",
      "    avg separation loss:      6.847375233968099\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  9.2703218460083\n",
      "    train time:               0.022542953491210938\n",
      "    test time:                0.012065887451171875\n",
      "    epoch time:               0.0350801944732666\n",
      "    last layer lr:            0.004852000000000001\n",
      "epoch: 110 (29/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.03980206118689643\n",
      "    train cross_ent loss:     0.030114668214486703\n",
      "    test overall loss:        0.176262599726518\n",
      "    test cross_ent loss:      0.16723580410083136\n",
      "    cluster loss:             2949.2765299479165\n",
      "    separation loss:          2.3835326035817466\n",
      "    avg separation loss:      6.879808743794759\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  7.8512725830078125\n",
      "    train time:               0.022584199905395508\n",
      "    test time:                0.012057781219482422\n",
      "    epoch time:               0.03511333465576172\n",
      "    last layer lr:            0.004455999999999999\n",
      "epoch: 110 (30/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.04204998972515265\n",
      "    train cross_ent loss:     0.0336379191527764\n",
      "    test overall loss:        0.1745033139983813\n",
      "    test cross_ent loss:      0.16653203591704369\n",
      "    cluster loss:             2949.276611328125\n",
      "    separation loss:          2.384186307589213\n",
      "    avg separation loss:      6.877476851145427\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  6.795753002166748\n",
      "    train time:               0.022496461868286133\n",
      "    test time:                0.012077093124389648\n",
      "    epoch time:               0.03505229949951172\n",
      "    last layer lr:            0.004060000000000001\n",
      "epoch: 110 (31/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.0402884181174967\n",
      "    train cross_ent loss:     0.03271677034596602\n",
      "    test overall loss:        0.1727159544825554\n",
      "    test cross_ent loss:      0.16565553223093352\n",
      "    cluster loss:             2949.2762044270835\n",
      "    separation loss:          2.382062633832296\n",
      "    avg separation loss:      6.867647806803386\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  5.884897232055664\n",
      "    train time:               0.02253413200378418\n",
      "    test time:                0.012059211730957031\n",
      "    epoch time:               0.035062313079833984\n",
      "    last layer lr:            0.0036640000000000015\n",
      "epoch: 110 (32/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.04328849518464671\n",
      "    train cross_ent loss:     0.0363583370215363\n",
      "    test overall loss:        0.17143544678886732\n",
      "    test cross_ent loss:      0.16468363938232264\n",
      "    cluster loss:             2949.276611328125\n",
      "    separation loss:          2.3826472759246826\n",
      "    avg separation loss:      6.8719832102457685\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  5.576287269592285\n",
      "    train time:               0.022540569305419922\n",
      "    test time:                0.01206660270690918\n",
      "    epoch time:               0.03507637977600098\n",
      "    last layer lr:            0.0032679999999999996\n",
      "epoch: 110 (33/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.04127212199899885\n",
      "    train cross_ent loss:     0.0349592212587595\n",
      "    test overall loss:        0.17203245560328165\n",
      "    test cross_ent loss:      0.1656462624669075\n",
      "    cluster loss:             2949.2765299479165\n",
      "    separation loss:          2.3870431184768677\n",
      "    avg separation loss:      6.886706988016765\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  5.210674285888672\n",
      "    train time:               0.022641658782958984\n",
      "    test time:                0.01207280158996582\n",
      "    epoch time:               0.035193681716918945\n",
      "    last layer lr:            0.002872000000000001\n",
      "epoch: 110 (34/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.03570349390308062\n",
      "    train cross_ent loss:     0.029573488877051406\n",
      "    test overall loss:        0.1727800207833449\n",
      "    test cross_ent loss:      0.1669944946964582\n",
      "    cluster loss:             2949.2764485677085\n",
      "    separation loss:          2.3812721967697144\n",
      "    avg separation loss:      6.869970321655273\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  4.610006332397461\n",
      "    train time:               0.022538185119628906\n",
      "    test time:                0.012113332748413086\n",
      "    epoch time:               0.03512406349182129\n",
      "    last layer lr:            0.0024759999999999986\n",
      "epoch: 110 (35/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.036333787358469434\n",
      "    train cross_ent loss:     0.030717564539776906\n",
      "    test overall loss:        0.17015540475646654\n",
      "    test cross_ent loss:      0.16470175857345262\n",
      "    cluster loss:             2949.2763671875\n",
      "    separation loss:          2.3735456466674805\n",
      "    avg separation loss:      6.838402271270752\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  4.278123378753662\n",
      "    train time:               0.022479772567749023\n",
      "    test time:                0.012066841125488281\n",
      "    epoch time:               0.035013675689697266\n",
      "    last layer lr:            0.0020800000000000003\n",
      "epoch: 110 (36/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.035908139103816614\n",
      "    train cross_ent loss:     0.030843313990367785\n",
      "    test overall loss:        0.1689904729525248\n",
      "    test cross_ent loss:      0.1641867266347011\n",
      "    cluster loss:             2949.276611328125\n",
      "    separation loss:          2.3745736281077066\n",
      "    avg separation loss:      6.84445317586263\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  3.6282217502593994\n",
      "    train time:               0.022550582885742188\n",
      "    test time:                0.012075662612915039\n",
      "    epoch time:               0.035097599029541016\n",
      "    last layer lr:            0.0016840000000000017\n",
      "epoch: 110 (37/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.03731477488246229\n",
      "    train cross_ent loss:     0.03267452700270547\n",
      "    test overall loss:        0.16954283664623895\n",
      "    test cross_ent loss:      0.16515320849915346\n",
      "    cluster loss:             2949.2763671875\n",
      "    separation loss:          2.374097148577372\n",
      "    avg separation loss:      6.84335724512736\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  3.2141034603118896\n",
      "    train time:               0.022711515426635742\n",
      "    test time:                0.012079715728759766\n",
      "    epoch time:               0.0352630615234375\n",
      "    last layer lr:            0.0012879999999999994\n",
      "epoch: 110 (38/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.032807150234778724\n",
      "    train cross_ent loss:     0.02871004461000363\n",
      "    test overall loss:        0.16697207217415175\n",
      "    test cross_ent loss:      0.16305898254116377\n",
      "    cluster loss:             2949.2765299479165\n",
      "    separation loss:          2.3793477614720664\n",
      "    avg separation loss:      6.857450644175212\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  2.73756742477417\n",
      "    train time:               0.02261638641357422\n",
      "    test time:                0.01208186149597168\n",
      "    epoch time:               0.03517293930053711\n",
      "    last layer lr:            0.0008920000000000009\n",
      "epoch: 110 (39/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.03374583584566911\n",
      "    train cross_ent loss:     0.030087404366996553\n",
      "    test overall loss:        0.16804244245092073\n",
      "    test cross_ent loss:      0.16452064303060374\n",
      "    cluster loss:             2949.2770182291665\n",
      "    separation loss:          2.3795515298843384\n",
      "    avg separation loss:      6.853851159413655\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  2.346273183822632\n",
      "    train time:               0.02256488800048828\n",
      "    test time:                0.012079954147338867\n",
      "    epoch time:               0.03511762619018555\n",
      "    last layer lr:            0.0004959999999999986\n",
      "epoch: 110 (40/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.038521072620318994\n",
      "    train cross_ent loss:     0.03520965565823846\n",
      "    test overall loss:        0.16751551938553652\n",
      "    test cross_ent loss:      0.16427178929249445\n",
      "    cluster loss:             2949.277099609375\n",
      "    separation loss:          2.3757553100585938\n",
      "    avg separation loss:      6.840261618296306\n",
      "    l1_addon loss:            39.18411636352539\n",
      "    l1 loss:                  2.068208694458008\n",
      "    train time:               0.022540569305419922\n",
      "    test time:                0.012093305587768555\n",
      "    epoch time:               0.035100698471069336\n",
      "    last layer lr:            0.0001\n",
      "epoch: 111 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.034328755301733814\n",
      "    train cross_ent loss:     0.03108513096554412\n",
      "    test overall loss:        0.16552273680766424\n",
      "    test cross_ent loss:      0.1622790228575468\n",
      "    cluster loss:             2949.276123046875\n",
      "    separation loss:          2.3733927408854165\n",
      "    avg separation loss:      6.842065493265788\n",
      "    l1_addon loss:            39.18342590332031\n",
      "    l1 loss:                  2.068208694458008\n",
      "    train time:               0.05845236778259277\n",
      "    test time:                0.01212167739868164\n",
      "    epoch time:               0.07130670547485352\n",
      "    joint lr:                 0.0017196383771408863\n",
      "epoch: 112 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.03215278943793641\n",
      "    train cross_ent loss:     0.028907112052871123\n",
      "    test overall loss:        0.13950816417733827\n",
      "    test cross_ent loss:      0.13626257019738355\n",
      "    cluster loss:             2949.2692057291665\n",
      "    separation loss:          2.316156347592672\n",
      "    avg separation loss:      6.700246175130208\n",
      "    l1_addon loss:            39.24628448486328\n",
      "    l1 loss:                  2.068208694458008\n",
      "    train time:               0.05832028388977051\n",
      "    test time:                0.012167930603027344\n",
      "    epoch time:               0.0712735652923584\n",
      "    joint lr:                 0.0033068839867389757\n",
      "epoch: 113 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.0288058224444588\n",
      "    train cross_ent loss:     0.025562833477225568\n",
      "    test overall loss:        0.15192928227285543\n",
      "    test cross_ent loss:      0.14868658035993576\n",
      "    cluster loss:             2949.2765299479165\n",
      "    separation loss:          2.2992012898127236\n",
      "    avg separation loss:      6.54030195871989\n",
      "    l1_addon loss:            39.149818420410156\n",
      "    l1 loss:                  2.068208694458008\n",
      "    train time:               0.058498382568359375\n",
      "    test time:                0.012140989303588867\n",
      "    epoch time:               0.07143926620483398\n",
      "    joint lr:                 0.0048622227203073696\n",
      "epoch: 114 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.028363173724048667\n",
      "    train cross_ent loss:     0.02511469569678108\n",
      "    test overall loss:        0.12812992433706918\n",
      "    test cross_ent loss:      0.12488677725195885\n",
      "    cluster loss:             2949.2963053385415\n",
      "    separation loss:          2.324551502863566\n",
      "    avg separation loss:      6.460374673207601\n",
      "    l1_addon loss:            39.164520263671875\n",
      "    l1 loss:                  2.068208694458008\n",
      "    train time:               0.06222176551818848\n",
      "    test time:                0.012116193771362305\n",
      "    epoch time:               0.07510685920715332\n",
      "    joint lr:                 0.00638613399080572\n",
      "epoch: 115 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 98.00%\n",
      "    train overall loss:       0.05588220546229018\n",
      "    train cross_ent loss:     0.052641264939059816\n",
      "    test overall loss:        0.1561410129070282\n",
      "    test cross_ent loss:      0.15288488318522772\n",
      "    cluster loss:             2949.34814453125\n",
      "    separation loss:          2.5285469690958657\n",
      "    avg separation loss:      6.908167839050293\n",
      "    l1_addon loss:            39.59754943847656\n",
      "    l1 loss:                  2.068208694458008\n",
      "    train time:               0.058307647705078125\n",
      "    test time:                0.01219940185546875\n",
      "    epoch time:               0.07129788398742676\n",
      "    joint lr:                 0.007879090813622073\n",
      "epoch: 116 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.04960025391644902\n",
      "    train cross_ent loss:     0.0463578501302335\n",
      "    test overall loss:        0.18322279552618662\n",
      "    test cross_ent loss:      0.1799695466955503\n",
      "    cluster loss:             2949.3839518229165\n",
      "    separation loss:          2.641834100087484\n",
      "    avg separation loss:      6.826804320017497\n",
      "    l1_addon loss:            39.501304626464844\n",
      "    l1 loss:                  2.068208694458008\n",
      "    train time:               0.05840587615966797\n",
      "    test time:                0.01212167739868164\n",
      "    epoch time:               0.07128119468688965\n",
      "    joint lr:                 0.009341559886583039\n",
      "epoch: 117 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.05773482037087282\n",
      "    train cross_ent loss:     0.0544907973251409\n",
      "    test overall loss:        0.14074896772702536\n",
      "    test cross_ent loss:      0.13750732690095901\n",
      "    cluster loss:             2949.3653971354165\n",
      "    separation loss:          2.5983328024546304\n",
      "    avg separation loss:      6.578875382741292\n",
      "    l1_addon loss:            39.114418029785156\n",
      "    l1 loss:                  2.068208694458008\n",
      "    train time:               0.05861234664916992\n",
      "    test time:                0.012172698974609375\n",
      "    epoch time:               0.07152509689331055\n",
      "    joint lr:                 0.010774001669003403\n",
      "epoch: 118 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.09100747398204273\n",
      "    train cross_ent loss:     0.08776398354934321\n",
      "    test overall loss:        0.18464458733797073\n",
      "    test cross_ent loss:      0.18139513581991196\n",
      "    cluster loss:             2949.4212239583335\n",
      "    separation loss:          2.7335568269093833\n",
      "    avg separation loss:      6.6587192217508955\n",
      "    l1_addon loss:            39.37482833862305\n",
      "    l1 loss:                  2.068208694458008\n",
      "    train time:               0.05832481384277344\n",
      "    test time:                0.01263284683227539\n",
      "    epoch time:               0.07203459739685059\n",
      "    joint lr:                 0.012176870459786701\n",
      "epoch: 119 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.14863383935557473\n",
      "    train cross_ent loss:     0.14539651365743744\n",
      "    test overall loss:        0.21309267729520798\n",
      "    test cross_ent loss:      0.20986044531067213\n",
      "    cluster loss:             2949.447265625\n",
      "    separation loss:          2.7982774575551352\n",
      "    avg separation loss:      6.775707403818767\n",
      "    l1_addon loss:            38.80067443847656\n",
      "    l1 loss:                  2.068208694458008\n",
      "    train time:               0.058121681213378906\n",
      "    test time:                0.012699127197265625\n",
      "    epoch time:               0.07200217247009277\n",
      "    joint lr:                 0.013550614474587434\n",
      "epoch: 120 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 93.67%\n",
      "    train overall loss:       0.27991463906235164\n",
      "    train cross_ent loss:     0.2766860243346956\n",
      "    test overall loss:        0.3709571659564972\n",
      "    test cross_ent loss:      0.3677271803220113\n",
      "    cluster loss:             2949.6126302083335\n",
      "    separation loss:          3.5061883131663003\n",
      "    avg separation loss:      8.102556069691977\n",
      "    l1_addon loss:            38.725830078125\n",
      "    l1 loss:                  2.068208694458008\n",
      "    train time:               0.05860137939453125\n",
      "    test time:                0.012173652648925781\n",
      "    epoch time:               0.0715494155883789\n",
      "    joint lr:                 0.014895675922046181\n",
      "epoch: 121 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 92.33%\n",
      "    train overall loss:       0.5216131342781914\n",
      "    train cross_ent loss:     0.5183825724654727\n",
      "    test overall loss:        0.84529576698939\n",
      "    test cross_ent loss:      0.8420582214991251\n",
      "    cluster loss:             2950.1515299479165\n",
      "    separation loss:          5.5981753667195635\n",
      "    avg separation loss:      12.176371574401855\n",
      "    l1_addon loss:            38.97721862792969\n",
      "    l1 loss:                  2.068208694458008\n",
      "    train time:               0.0582127571105957\n",
      "    test time:                0.012119770050048828\n",
      "    epoch time:               0.07107424736022949\n",
      "    joint lr:                 0.014015333204684437\n",
      "epoch: 122 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 90.33%\n",
      "    train overall loss:       0.5639627277851105\n",
      "    train cross_ent loss:     0.5607298711935679\n",
      "    test overall loss:        0.9062778552373251\n",
      "    test cross_ent loss:      0.9030136664708456\n",
      "    cluster loss:             2950.427734375\n",
      "    separation loss:          6.664049943288167\n",
      "    avg separation loss:      13.478413899739584\n",
      "    l1_addon loss:            39.86566162109375\n",
      "    l1 loss:                  2.068208694458008\n",
      "    train time:               0.05823040008544922\n",
      "    test time:                0.012119054794311523\n",
      "    epoch time:               0.07109665870666504\n",
      "    joint lr:                 0.01315111777407772\n",
      "epoch: 123 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 92.00%\n",
      "    train overall loss:       0.5795547068119049\n",
      "    train cross_ent loss:     0.5763155586189694\n",
      "    test overall loss:        0.4822469154993693\n",
      "    test cross_ent loss:      0.4790145556131999\n",
      "    cluster loss:             2950.209228515625\n",
      "    separation loss:          5.966528256734212\n",
      "    avg separation loss:      12.32888094584147\n",
      "    l1_addon loss:            38.80500793457031\n",
      "    l1 loss:                  2.068208694458008\n",
      "    train time:               0.05849814414978027\n",
      "    test time:                0.012117624282836914\n",
      "    epoch time:               0.07138514518737793\n",
      "    joint lr:                 0.012302795118762673\n",
      "epoch: 124 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 91.00%\n",
      "    train overall loss:       0.5994808971881866\n",
      "    train cross_ent loss:     0.5962341494030423\n",
      "    test overall loss:        0.5493665287892023\n",
      "    test cross_ent loss:      0.546101450920105\n",
      "    cluster loss:             2950.3255208333335\n",
      "    separation loss:          6.240604559580485\n",
      "    avg separation loss:      12.432998657226562\n",
      "    l1_addon loss:            39.895545959472656\n",
      "    l1 loss:                  2.068208694458008\n",
      "    train time:               0.058449506759643555\n",
      "    test time:                0.012137889862060547\n",
      "    epoch time:               0.07139754295349121\n",
      "    joint lr:                 0.011470133804776505\n",
      "epoch: 125 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 86.67%\n",
      "    train overall loss:       0.55182217558225\n",
      "    train cross_ent loss:     0.5485651592413584\n",
      "    test overall loss:        0.5906457950671514\n",
      "    test cross_ent loss:      0.5874130576848984\n",
      "    cluster loss:             2950.3838704427085\n",
      "    separation loss:          6.395650863647461\n",
      "    avg separation loss:      12.737921078999838\n",
      "    l1_addon loss:            38.818115234375\n",
      "    l1 loss:                  2.068208694458008\n",
      "    train time:               0.0583653450012207\n",
      "    test time:                0.012175321578979492\n",
      "    epoch time:               0.0712594985961914\n",
      "    joint lr:                 0.010652905437558197\n",
      "epoch: 126 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 89.33%\n",
      "    train overall loss:       0.6965276797612509\n",
      "    train cross_ent loss:     0.6932644612259335\n",
      "    test overall loss:        0.6631438632806143\n",
      "    test cross_ent loss:      0.6598356068134308\n",
      "    cluster loss:             2950.4977213541665\n",
      "    separation loss:          7.156570593516032\n",
      "    avg separation loss:      14.793989181518555\n",
      "    l1_addon loss:            41.33534622192383\n",
      "    l1 loss:                  2.068208694458008\n",
      "    train time:               0.058608293533325195\n",
      "    test time:                0.012745380401611328\n",
      "    epoch time:               0.07225394248962402\n",
      "    joint lr:                 0.009850884624303774\n",
      "epoch: 127 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 90.67%\n",
      "    train overall loss:       0.49010153611501056\n",
      "    train cross_ent loss:     0.4868249860074785\n",
      "    test overall loss:        0.6056963205337524\n",
      "    test cross_ent loss:      0.6024473210175832\n",
      "    cluster loss:             2950.3851725260415\n",
      "    separation loss:          6.331549167633057\n",
      "    avg separation loss:      12.902193705240885\n",
      "    l1_addon loss:            39.359779357910156\n",
      "    l1 loss:                  2.068208694458008\n",
      "    train time:               0.05844402313232422\n",
      "    test time:                0.012667179107666016\n",
      "    epoch time:               0.07204461097717285\n",
      "    joint lr:                 0.00906384893677068\n",
      "epoch: 128 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 91.67%\n",
      "    train overall loss:       0.5160902324650023\n",
      "    train cross_ent loss:     0.5128223730458153\n",
      "    test overall loss:        0.3828798954685529\n",
      "    test cross_ent loss:      0.3796213169892629\n",
      "    cluster loss:             2950.2240397135415\n",
      "    separation loss:          5.688612937927246\n",
      "    avg separation loss:      11.684919357299805\n",
      "    l1_addon loss:            39.67866134643555\n",
      "    l1 loss:                  2.068208694458008\n",
      "    train time:               0.058669328689575195\n",
      "    test time:                0.012672901153564453\n",
      "    epoch time:               0.07227134704589844\n",
      "    joint lr:                 0.00829157887452582\n",
      "epoch: 129 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 92.33%\n",
      "    train overall loss:       0.3418877836730745\n",
      "    train cross_ent loss:     0.33862061964141\n",
      "    test overall loss:        0.30203071733315784\n",
      "    test cross_ent loss:      0.29875963429609936\n",
      "    cluster loss:             2950.1700846354165\n",
      "    separation loss:          5.622790018717448\n",
      "    avg separation loss:      11.79578971862793\n",
      "    l1_addon loss:            40.095489501953125\n",
      "    l1 loss:                  2.068208694458008\n",
      "    train time:               0.05857539176940918\n",
      "    test time:                0.012658357620239258\n",
      "    epoch time:               0.07221722602844238\n",
      "    joint lr:                 0.007533857828632187\n",
      "epoch: 130 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 94.67%\n",
      "    train overall loss:       0.256686806678772\n",
      "    train cross_ent loss:     0.2534184960855378\n",
      "    test overall loss:        0.278529812892278\n",
      "    test cross_ent loss:      0.27526312321424484\n",
      "    cluster loss:             2950.097900390625\n",
      "    separation loss:          5.248922189076741\n",
      "    avg separation loss:      10.91756820678711\n",
      "    l1_addon loss:            39.94938659667969\n",
      "    l1 loss:                  2.068208694458008\n",
      "    train time:               0.0583193302154541\n",
      "    test time:                0.01267099380493164\n",
      "    epoch time:               0.07195925712585449\n",
      "    joint lr:                 0.00679047204576897\n",
      "epoch: 131 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.18238782924082544\n",
      "    train cross_ent loss:     0.17912456641594568\n",
      "    test overall loss:        0.26411231855551404\n",
      "    test cross_ent loss:      0.26084241767724353\n",
      "    cluster loss:             2950.053466796875\n",
      "    separation loss:          4.909209092458089\n",
      "    avg separation loss:      10.555257161458334\n",
      "    l1_addon loss:            40.05650329589844\n",
      "    l1 loss:                  2.068208694458008\n",
      "    train time:               0.05843710899353027\n",
      "    test time:                0.012700557708740234\n",
      "    epoch time:               0.07211112976074219\n",
      "    joint lr:                 0.006061210592780146\n",
      "epoch: 132 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.10920425545838144\n",
      "    train cross_ent loss:     0.10594118759036064\n",
      "    test overall loss:        0.19636204714576402\n",
      "    test cross_ent loss:      0.1930979477862517\n",
      "    cluster loss:             2949.9785970052085\n",
      "    separation loss:          4.604069948196411\n",
      "    avg separation loss:      9.48342514038086\n",
      "    l1_addon loss:            39.863014221191406\n",
      "    l1 loss:                  2.068208694458008\n",
      "    train time:               0.05855154991149902\n",
      "    test time:                0.012642383575439453\n",
      "    epoch time:               0.07216930389404297\n",
      "    joint lr:                 0.005345865321646531\n",
      "epoch: 133 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.07798330444428656\n",
      "    train cross_ent loss:     0.07471622940566805\n",
      "    test overall loss:        0.20437935243050256\n",
      "    test cross_ent loss:      0.20111118257045746\n",
      "    cluster loss:             2949.982666015625\n",
      "    separation loss:          4.624518394470215\n",
      "    avg separation loss:      9.899064699808756\n",
      "    l1_addon loss:            39.99851989746094\n",
      "    l1 loss:                  2.068208694458008\n",
      "    train time:               0.058347463607788086\n",
      "    test time:                0.012624025344848633\n",
      "    epoch time:               0.07192277908325195\n",
      "    joint lr:                 0.00464423083487631\n",
      "epoch: 134 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.05254223673707909\n",
      "    train cross_ent loss:     0.04928285928650035\n",
      "    test overall loss:        0.16631321236491203\n",
      "    test cross_ent loss:      0.16306016966700554\n",
      "    cluster loss:             2949.940673828125\n",
      "    separation loss:          4.335468928019206\n",
      "    avg separation loss:      8.947525342305502\n",
      "    l1_addon loss:            39.49441146850586\n",
      "    l1 loss:                  2.068208694458008\n",
      "    train time:               0.05879378318786621\n",
      "    test time:                0.01215672492980957\n",
      "    epoch time:               0.0717167854309082\n",
      "    joint lr:                 0.003956104451309328\n",
      "epoch: 135 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.0370213831257489\n",
      "    train cross_ent loss:     0.03376526395893759\n",
      "    test overall loss:        0.1434528244038423\n",
      "    test cross_ent loss:      0.14019042129317918\n",
      "    cluster loss:             2949.9187825520835\n",
      "    separation loss:          4.243971427281697\n",
      "    avg separation loss:      8.826671918233236\n",
      "    l1_addon loss:            39.80662536621094\n",
      "    l1 loss:                  2.068208694458008\n",
      "    train time:               0.05849051475524902\n",
      "    test time:                0.012180566787719727\n",
      "    epoch time:               0.07148385047912598\n",
      "    joint lr:                 0.0032812861723301896\n",
      "epoch: 136 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.022331658543811903\n",
      "    train cross_ent loss:     0.019071568217542436\n",
      "    test overall loss:        0.12867552414536476\n",
      "    test cross_ent loss:      0.1254185779641072\n",
      "    cluster loss:             2949.8986002604165\n",
      "    separation loss:          4.123389561971028\n",
      "    avg separation loss:      8.517747561136881\n",
      "    l1_addon loss:            39.62457275390625\n",
      "    l1 loss:                  2.068208694458008\n",
      "    train time:               0.05836343765258789\n",
      "    test time:                0.012198925018310547\n",
      "    epoch time:               0.07134437561035156\n",
      "    joint lr:                 0.0026195786484855114\n",
      "epoch: 137 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.015059140717817677\n",
      "    train cross_ent loss:     0.01180561468936503\n",
      "    test overall loss:        0.12469037932654221\n",
      "    test cross_ent loss:      0.12143777062495549\n",
      "    cluster loss:             2949.8915201822915\n",
      "    separation loss:          4.052110195159912\n",
      "    avg separation loss:      8.339271863301596\n",
      "    l1_addon loss:            39.47990417480469\n",
      "    l1 loss:                  2.068208694458008\n",
      "    train time:               0.05848431587219238\n",
      "    test time:                0.012176036834716797\n",
      "    epoch time:               0.07145309448242188\n",
      "    joint lr:                 0.0019707871465004943\n",
      "epoch: 138 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.014801687767936124\n",
      "    train cross_ent loss:     0.011547181056812406\n",
      "    test overall loss:        0.1218636476745208\n",
      "    test cross_ent loss:      0.11860704235732555\n",
      "    cluster loss:             2949.8875325520835\n",
      "    separation loss:          4.035977284113566\n",
      "    avg separation loss:      8.310673713684082\n",
      "    l1_addon loss:            39.613304138183594\n",
      "    l1 loss:                  2.068208694458008\n",
      "    train time:               0.05865955352783203\n",
      "    test time:                0.012210369110107422\n",
      "    epoch time:               0.07166814804077148\n",
      "    joint lr:                 0.0013347195166903292\n",
      "epoch: 139 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.010050750492761532\n",
      "    train cross_ent loss:     0.006794361190663444\n",
      "    test overall loss:        0.11985611418883006\n",
      "    test cross_ent loss:      0.11659974977374077\n",
      "    cluster loss:             2949.8833821614585\n",
      "    separation loss:          3.995643456776937\n",
      "    avg separation loss:      8.173775672912598\n",
      "    l1_addon loss:            39.60514450073242\n",
      "    l1 loss:                  2.068208694458008\n",
      "    train time:               0.05818939208984375\n",
      "    test time:                0.01215505599975586\n",
      "    epoch time:               0.07113862037658691\n",
      "    joint lr:                 0.0007111861607617089\n",
      "epoch: 140 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.011754067925115427\n",
      "    train cross_ent loss:     0.008497555688437488\n",
      "    test overall loss:        0.1188311552007993\n",
      "    test cross_ent loss:      0.11557464053233464\n",
      "    cluster loss:             2949.8819173177085\n",
      "    separation loss:          3.993088642756144\n",
      "    avg separation loss:      8.172225952148438\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  2.068208694458008\n",
      "    train time:               0.0586698055267334\n",
      "    test time:                0.012106895446777344\n",
      "    epoch time:               0.07155418395996094\n",
      "    joint lr:                 0.0001\n",
      "epoch: 140 (PUSH) - ArticularyWordRecognition\n",
      "    test acc:                 94.67%\n",
      "    train overall loss:       0.011754067925115427\n",
      "    train cross_ent loss:     0.008497555688437488\n",
      "    test overall loss:        0.17418155943353972\n",
      "    test cross_ent loss:      0.17092503855625787\n",
      "    cluster loss:             2949.2681477864585\n",
      "    separation loss:          2.209218899408976\n",
      "    avg separation loss:      6.127950509389241\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  2.068208694458008\n",
      "    train time:               0.0586698055267334\n",
      "    test time:                0.01246500015258789\n",
      "    epoch time:               0.34061646461486816\n",
      "epoch: 140 (1/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 94.67%\n",
      "    train overall loss:       0.025868329116039805\n",
      "    train cross_ent loss:     0.02280995436012745\n",
      "    test overall loss:        0.17254450544714928\n",
      "    test cross_ent loss:      0.1696729895969232\n",
      "    cluster loss:             2949.2677408854165\n",
      "    separation loss:          2.2036661307017007\n",
      "    avg separation loss:      6.106973489125569\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  1.6832116842269897\n",
      "    train time:               0.02281928062438965\n",
      "    test time:                0.012125492095947266\n",
      "    epoch time:               0.03541851043701172\n",
      "    last layer lr:            0.0007599999999999978\n",
      "epoch: 140 (2/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 94.67%\n",
      "    train overall loss:       0.023919345086647406\n",
      "    train cross_ent loss:     0.020412548108854227\n",
      "    test overall loss:        0.1729856605331103\n",
      "    test cross_ent loss:      0.16957419738173485\n",
      "    cluster loss:             2949.2683919270835\n",
      "    separation loss:          2.2083933353424072\n",
      "    avg separation loss:      6.124183813730876\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  2.223151206970215\n",
      "    train time:               0.022571802139282227\n",
      "    test time:                0.01208043098449707\n",
      "    epoch time:               0.03513216972351074\n",
      "    last layer lr:            0.0014199999999999955\n",
      "epoch: 140 (3/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 94.67%\n",
      "    train overall loss:       0.024521083984937932\n",
      "    train cross_ent loss:     0.020624890716539487\n",
      "    test overall loss:        0.17314381152391434\n",
      "    test cross_ent loss:      0.16934430475036302\n",
      "    cluster loss:             2949.2685546875\n",
      "    separation loss:          2.206658959388733\n",
      "    avg separation loss:      6.112540562947591\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  2.6112003326416016\n",
      "    train time:               0.022588014602661133\n",
      "    test time:                0.01205301284790039\n",
      "    epoch time:               0.0351107120513916\n",
      "    last layer lr:            0.0020800000000000046\n",
      "epoch: 140 (4/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 94.67%\n",
      "    train overall loss:       0.024479720120628674\n",
      "    train cross_ent loss:     0.020335342217650678\n",
      "    test overall loss:        0.17285442103942236\n",
      "    test cross_ent loss:      0.1686603712538878\n",
      "    cluster loss:             2949.2681477864585\n",
      "    separation loss:          2.2060066064198813\n",
      "    avg separation loss:      6.11210298538208\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  3.005737781524658\n",
      "    train time:               0.022642850875854492\n",
      "    test time:                0.012078523635864258\n",
      "    epoch time:               0.03520345687866211\n",
      "    last layer lr:            0.0027400000000000024\n",
      "epoch: 140 (5/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.027490179985761642\n",
      "    train cross_ent loss:     0.022774019537286624\n",
      "    test overall loss:        0.17282778769731522\n",
      "    test cross_ent loss:      0.1679317206144333\n",
      "    cluster loss:             2949.268798828125\n",
      "    separation loss:          2.2114030917485556\n",
      "    avg separation loss:      6.131312211354573\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  3.707756996154785\n",
      "    train time:               0.022744178771972656\n",
      "    test time:                0.01208949089050293\n",
      "    epoch time:               0.035318613052368164\n",
      "    last layer lr:            0.0034\n",
      "epoch: 140 (6/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.03163170824862189\n",
      "    train cross_ent loss:     0.02604809682816267\n",
      "    test overall loss:        0.1728967477877935\n",
      "    test cross_ent loss:      0.1673443280160427\n",
      "    cluster loss:             2949.2686360677085\n",
      "    separation loss:          2.2098985513051352\n",
      "    avg separation loss:      6.113254547119141\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  4.364114761352539\n",
      "    train time:               0.022469758987426758\n",
      "    test time:                0.012087106704711914\n",
      "    epoch time:               0.03503680229187012\n",
      "    last layer lr:            0.004059999999999998\n",
      "epoch: 140 (7/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.023954661356078252\n",
      "    train cross_ent loss:     0.018010335612214275\n",
      "    test overall loss:        0.17054380103945732\n",
      "    test cross_ent loss:      0.1646796278655529\n",
      "    cluster loss:             2949.2683919270835\n",
      "    separation loss:          2.2092787822087607\n",
      "    avg separation loss:      6.121378421783447\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  4.675864219665527\n",
      "    train time:               0.022647857666015625\n",
      "    test time:                0.012134552001953125\n",
      "    epoch time:               0.03525114059448242\n",
      "    last layer lr:            0.004719999999999996\n",
      "epoch: 140 (8/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.031804026725391545\n",
      "    train cross_ent loss:     0.02544952540968855\n",
      "    test overall loss:        0.16938852767149606\n",
      "    test cross_ent loss:      0.16241500154137611\n",
      "    cluster loss:             2949.2691243489585\n",
      "    separation loss:          2.212048331896464\n",
      "    avg separation loss:      6.1458085378011065\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  5.785216331481934\n",
      "    train time:               0.023358821868896484\n",
      "    test time:                0.012200355529785156\n",
      "    epoch time:               0.03607797622680664\n",
      "    last layer lr:            0.0053800000000000054\n",
      "epoch: 140 (9/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.027087328127688833\n",
      "    train cross_ent loss:     0.01953063067048788\n",
      "    test overall loss:        0.1690622940659523\n",
      "    test cross_ent loss:      0.16187125320235887\n",
      "    cluster loss:             2949.2687174479165\n",
      "    separation loss:          2.2102774381637573\n",
      "    avg separation loss:      6.133828481038411\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  6.002734184265137\n",
      "    train time:               0.022858858108520508\n",
      "    test time:                0.012139558792114258\n",
      "    epoch time:               0.03548455238342285\n",
      "    last layer lr:            0.006040000000000003\n",
      "epoch: 140 (10/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.02926098679502805\n",
      "    train cross_ent loss:     0.021870009290675323\n",
      "    test overall loss:        0.16616244117418924\n",
      "    test cross_ent loss:      0.1589875022570292\n",
      "    cluster loss:             2949.26806640625\n",
      "    separation loss:          2.2063191334406533\n",
      "    avg separation loss:      6.121629238128662\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  5.986631870269775\n",
      "    train time:               0.02273845672607422\n",
      "    test time:                0.01209712028503418\n",
      "    epoch time:               0.035321950912475586\n",
      "    last layer lr:            0.0067\n",
      "epoch: 140 (11/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.0238686330202553\n",
      "    train cross_ent loss:     0.016491168437318668\n",
      "    test overall loss:        0.16506673271457353\n",
      "    test cross_ent loss:      0.15773032667736211\n",
      "    cluster loss:             2949.2686360677085\n",
      "    separation loss:          2.2024975617726645\n",
      "    avg separation loss:      6.118388811747233\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  6.148094177246094\n",
      "    train time:               0.022715091705322266\n",
      "    test time:                0.012097835540771484\n",
      "    epoch time:               0.035292863845825195\n",
      "    last layer lr:            0.0073599999999999985\n",
      "epoch: 140 (12/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.023000897115303412\n",
      "    train cross_ent loss:     0.015388519140995212\n",
      "    test overall loss:        0.16417771950364113\n",
      "    test cross_ent loss:      0.15634104857842127\n",
      "    cluster loss:             2949.26904296875\n",
      "    separation loss:          2.205920696258545\n",
      "    avg separation loss:      6.129122734069824\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  6.648364543914795\n",
      "    train time:               0.022968530654907227\n",
      "    test time:                0.012082815170288086\n",
      "    epoch time:               0.0355224609375\n",
      "    last layer lr:            0.008019999999999994\n",
      "epoch: 140 (13/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       0.029692132853799395\n",
      "    train cross_ent loss:     0.02157207438722253\n",
      "    test overall loss:        0.16372996444503465\n",
      "    test cross_ent loss:      0.15477952299018702\n",
      "    cluster loss:             2949.2684733072915\n",
      "    separation loss:          2.206611394882202\n",
      "    avg separation loss:      6.124068895975749\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  7.76213264465332\n",
      "    train time:               0.022887229919433594\n",
      "    test time:                0.012064933776855469\n",
      "    epoch time:               0.035425662994384766\n",
      "    last layer lr:            0.008680000000000005\n",
      "epoch: 140 (14/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.023644921369850636\n",
      "    train cross_ent loss:     0.014690710490362512\n",
      "    test overall loss:        0.16446983441710472\n",
      "    test cross_ent loss:      0.15486716913680235\n",
      "    cluster loss:             2949.2683919270835\n",
      "    separation loss:          2.2048444747924805\n",
      "    avg separation loss:      6.118773619333903\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  8.414356231689453\n",
      "    train time:               0.022701025009155273\n",
      "    test time:                0.01207280158996582\n",
      "    epoch time:               0.03524136543273926\n",
      "    last layer lr:            0.009340000000000003\n",
      "epoch: 140 (15/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.02813704912033346\n",
      "    train cross_ent loss:     0.01849141385820177\n",
      "    test overall loss:        0.16282655422886214\n",
      "    test cross_ent loss:      0.1531011319408814\n",
      "    cluster loss:             2949.2681477864585\n",
      "    separation loss:          2.2031010389328003\n",
      "    avg separation loss:      6.108291149139404\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  8.537114143371582\n",
      "    train time:               0.022735118865966797\n",
      "    test time:                0.012081384658813477\n",
      "    epoch time:               0.035284996032714844\n",
      "    last layer lr:            0.01\n",
      "epoch: 140 (16/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.023596047320299678\n",
      "    train cross_ent loss:     0.01410731797417005\n",
      "    test overall loss:        0.1626261348525683\n",
      "    test cross_ent loss:      0.15324171259999275\n",
      "    cluster loss:             2949.2683919270835\n",
      "    separation loss:          2.204042394955953\n",
      "    avg separation loss:      6.116977373758952\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  8.196111679077148\n",
      "    train time:               0.0227048397064209\n",
      "    test time:                0.012074470520019531\n",
      "    epoch time:               0.03527116775512695\n",
      "    last layer lr:            0.009604000000000001\n",
      "epoch: 140 (17/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.024444706737995148\n",
      "    train cross_ent loss:     0.015366402868595388\n",
      "    test overall loss:        0.16110460832715034\n",
      "    test cross_ent loss:      0.15161863962809244\n",
      "    cluster loss:             2949.2679036458335\n",
      "    separation loss:          2.2013978958129883\n",
      "    avg separation loss:      6.103517850240071\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  8.297662734985352\n",
      "    train time:               0.022696256637573242\n",
      "    test time:                0.012086868286132812\n",
      "    epoch time:               0.03525352478027344\n",
      "    last layer lr:            0.009208000000000003\n",
      "epoch: 140 (18/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.02611186427788602\n",
      "    train cross_ent loss:     0.01677979016676545\n",
      "    test overall loss:        0.15990158853431544\n",
      "    test cross_ent loss:      0.15090257860720158\n",
      "    cluster loss:             2949.2684733072915\n",
      "    separation loss:          2.2054564555486045\n",
      "    avg separation loss:      6.123416105906169\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  7.810698509216309\n",
      "    train time:               0.02268242835998535\n",
      "    test time:                0.012128829956054688\n",
      "    epoch time:               0.03528475761413574\n",
      "    last layer lr:            0.008811999999999997\n",
      "epoch: 140 (19/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.024526058075328667\n",
      "    train cross_ent loss:     0.015723070957594447\n",
      "    test overall loss:        0.1592500569919745\n",
      "    test cross_ent loss:      0.15017072794338068\n",
      "    cluster loss:             2949.2683919270835\n",
      "    separation loss:          2.2027918100357056\n",
      "    avg separation loss:      6.115714867909749\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  7.891021728515625\n",
      "    train time:               0.02274918556213379\n",
      "    test time:                0.012052536010742188\n",
      "    epoch time:               0.035276174545288086\n",
      "    last layer lr:            0.008415999999999998\n",
      "epoch: 140 (20/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.021378876227471564\n",
      "    train cross_ent loss:     0.01243402777860562\n",
      "    test overall loss:        0.16012483835220337\n",
      "    test cross_ent loss:      0.1508320358892282\n",
      "    cluster loss:             2949.2685546875\n",
      "    separation loss:          2.209701935450236\n",
      "    avg separation loss:      6.132851441701253\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  8.1044921875\n",
      "    train time:               0.024583816528320312\n",
      "    test time:                0.012674808502197266\n",
      "    epoch time:               0.037780046463012695\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 140 (21/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.02092223076356782\n",
      "    train cross_ent loss:     0.012459480100207858\n",
      "    test overall loss:        0.1580070580045382\n",
      "    test cross_ent loss:      0.14990661044915518\n",
      "    cluster loss:             2949.26806640625\n",
      "    separation loss:          2.1976101398468018\n",
      "    avg separation loss:      6.093210697174072\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  6.912136077880859\n",
      "    train time:               0.024180173873901367\n",
      "    test time:                0.012618541717529297\n",
      "    epoch time:               0.03731250762939453\n",
      "    last layer lr:            0.007624000000000002\n",
      "epoch: 140 (22/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.02603865021632777\n",
      "    train cross_ent loss:     0.017878306227632694\n",
      "    test overall loss:        0.15712626713017622\n",
      "    test cross_ent loss:      0.14912592247128487\n",
      "    cluster loss:             2949.2687174479165\n",
      "    separation loss:          2.207991043726603\n",
      "    avg separation loss:      6.1312252680460615\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  6.812038421630859\n",
      "    train time:               0.024080276489257812\n",
      "    test time:                0.012668371200561523\n",
      "    epoch time:               0.03726339340209961\n",
      "    last layer lr:            0.0072280000000000035\n",
      "epoch: 140 (23/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.019894259567889903\n",
      "    train cross_ent loss:     0.011799522261652682\n",
      "    test overall loss:        0.15574535665412745\n",
      "    test cross_ent loss:      0.14818329364061356\n",
      "    cluster loss:             2949.2686360677085\n",
      "    separation loss:          2.210157036781311\n",
      "    avg separation loss:      6.134209156036377\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  6.373754978179932\n",
      "    train time:               0.024242401123046875\n",
      "    test time:                0.012757301330566406\n",
      "    epoch time:               0.03750920295715332\n",
      "    last layer lr:            0.006831999999999998\n",
      "epoch: 140 (24/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.021661605168547895\n",
      "    train cross_ent loss:     0.01429301303707891\n",
      "    test overall loss:        0.153247211749355\n",
      "    test cross_ent loss:      0.14611108476916948\n",
      "    cluster loss:             2949.2682291666665\n",
      "    separation loss:          2.2080899477005005\n",
      "    avg separation loss:      6.126500129699707\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  5.947817802429199\n",
      "    train time:               0.024606704711914062\n",
      "    test time:                0.0127716064453125\n",
      "    epoch time:               0.03788566589355469\n",
      "    last layer lr:            0.006436\n",
      "epoch: 140 (25/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.0207714576067196\n",
      "    train cross_ent loss:     0.013745605428185727\n",
      "    test overall loss:        0.1533798643698295\n",
      "    test cross_ent loss:      0.14680135063827038\n",
      "    cluster loss:             2949.26806640625\n",
      "    separation loss:          2.202656944592794\n",
      "    avg separation loss:      6.102866172790527\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  5.3902106285095215\n",
      "    train time:               0.024210453033447266\n",
      "    test time:                0.012775659561157227\n",
      "    epoch time:               0.03748917579650879\n",
      "    last layer lr:            0.00604\n",
      "epoch: 140 (26/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.017723597379194364\n",
      "    train cross_ent loss:     0.01109373613467647\n",
      "    test overall loss:        0.1533887516707182\n",
      "    test cross_ent loss:      0.14694598751763502\n",
      "    cluster loss:             2949.2684733072915\n",
      "    separation loss:          2.2100548346837363\n",
      "    avg separation loss:      6.129150867462158\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  5.254459381103516\n",
      "    train time:               0.024538755416870117\n",
      "    test time:                0.012763023376464844\n",
      "    epoch time:               0.037805795669555664\n",
      "    last layer lr:            0.005644000000000002\n",
      "epoch: 140 (27/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.018155747921102576\n",
      "    train cross_ent loss:     0.012003160806165801\n",
      "    test overall loss:        0.15363238379359245\n",
      "    test cross_ent loss:      0.14763437025249004\n",
      "    cluster loss:             2949.2683919270835\n",
      "    separation loss:          2.2065853675206504\n",
      "    avg separation loss:      6.1168622970581055\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  4.809703350067139\n",
      "    train time:               0.02445840835571289\n",
      "    test time:                0.012805938720703125\n",
      "    epoch time:               0.03777265548706055\n",
      "    last layer lr:            0.005248000000000003\n",
      "epoch: 140 (28/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.02019806754671865\n",
      "    train cross_ent loss:     0.014584476283440987\n",
      "    test overall loss:        0.1514649869253238\n",
      "    test cross_ent loss:      0.14578443579375744\n",
      "    cluster loss:             2949.2685546875\n",
      "    separation loss:          2.20696751276652\n",
      "    avg separation loss:      6.119890530904134\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  4.492239952087402\n",
      "    train time:               0.02428722381591797\n",
      "    test time:                0.01280355453491211\n",
      "    epoch time:               0.03759455680847168\n",
      "    last layer lr:            0.004851999999999998\n",
      "epoch: 140 (29/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.018907066331141524\n",
      "    train cross_ent loss:     0.01278582950019174\n",
      "    test overall loss:        0.15127757315834364\n",
      "    test cross_ent loss:      0.14527291183670363\n",
      "    cluster loss:             2949.268310546875\n",
      "    separation loss:          2.208497484525045\n",
      "    avg separation loss:      6.1225714683532715\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  4.816354751586914\n",
      "    train time:               0.024291038513183594\n",
      "    test time:                0.012897253036499023\n",
      "    epoch time:               0.0376896858215332\n",
      "    last layer lr:            0.004455999999999999\n",
      "epoch: 140 (30/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.017150555323395465\n",
      "    train cross_ent loss:     0.011436309096299939\n",
      "    test overall loss:        0.15055539148549238\n",
      "    test cross_ent loss:      0.14525271579623222\n",
      "    cluster loss:             2949.2684733072915\n",
      "    separation loss:          2.205464323361715\n",
      "    avg separation loss:      6.116774082183838\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  4.114371299743652\n",
      "    train time:               0.024147510528564453\n",
      "    test time:                0.012425422668457031\n",
      "    epoch time:               0.03706502914428711\n",
      "    last layer lr:            0.004060000000000001\n",
      "epoch: 140 (31/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.018834618334141042\n",
      "    train cross_ent loss:     0.013649161491129134\n",
      "    test overall loss:        0.14985189276436964\n",
      "    test cross_ent loss:      0.14472926408052444\n",
      "    cluster loss:             2949.2685546875\n",
      "    separation loss:          2.207217534383138\n",
      "    avg separation loss:      6.129450639088948\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  3.934316873550415\n",
      "    train time:               0.02396416664123535\n",
      "    test time:                0.012845277786254883\n",
      "    epoch time:               0.037303924560546875\n",
      "    last layer lr:            0.0036640000000000015\n",
      "epoch: 140 (32/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.020268142740759585\n",
      "    train cross_ent loss:     0.015198160273333391\n",
      "    test overall loss:        0.15070866358776888\n",
      "    test cross_ent loss:      0.14564411528408527\n",
      "    cluster loss:             2949.2681477864585\n",
      "    separation loss:          2.204814592997233\n",
      "    avg separation loss:      6.121793270111084\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  3.8762450218200684\n",
      "    train time:               0.023194074630737305\n",
      "    test time:                0.012476921081542969\n",
      "    epoch time:               0.03615283966064453\n",
      "    last layer lr:            0.003268000000000003\n",
      "epoch: 140 (33/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.019407204973200958\n",
      "    train cross_ent loss:     0.014649255537531443\n",
      "    test overall loss:        0.14904913865029812\n",
      "    test cross_ent loss:      0.1446977642675241\n",
      "    cluster loss:             2949.268310546875\n",
      "    separation loss:          2.2102598349253335\n",
      "    avg separation loss:      6.127757549285889\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  3.163062334060669\n",
      "    train time:               0.02443528175354004\n",
      "    test time:                0.012332677841186523\n",
      "    epoch time:               0.03726387023925781\n",
      "    last layer lr:            0.002871999999999997\n",
      "epoch: 140 (34/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.020266566736002762\n",
      "    train cross_ent loss:     0.016183004818028875\n",
      "    test overall loss:        0.14844810341795286\n",
      "    test cross_ent loss:      0.14432602686186632\n",
      "    cluster loss:             2949.268798828125\n",
      "    separation loss:          2.2144545316696167\n",
      "    avg separation loss:      6.147875467936198\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  2.933767318725586\n",
      "    train time:               0.02369070053100586\n",
      "    test time:                0.012875080108642578\n",
      "    epoch time:               0.03709530830383301\n",
      "    last layer lr:            0.0024759999999999986\n",
      "epoch: 140 (35/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.01782239807976617\n",
      "    train cross_ent loss:     0.013885359331551526\n",
      "    test overall loss:        0.1485333926975727\n",
      "    test cross_ent loss:      0.14491451842089495\n",
      "    cluster loss:             2949.2685546875\n",
      "    separation loss:          2.2080372174580893\n",
      "    avg separation loss:      6.126675605773926\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  2.4305691719055176\n",
      "    train time:               0.02449798583984375\n",
      "    test time:                0.012933969497680664\n",
      "    epoch time:               0.03793835639953613\n",
      "    last layer lr:            0.0020800000000000003\n",
      "epoch: 140 (36/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.018903878931370046\n",
      "    train cross_ent loss:     0.01546125796933969\n",
      "    test overall loss:        0.14843331029017767\n",
      "    test cross_ent loss:      0.14510287096103033\n",
      "    cluster loss:             2949.2684733072915\n",
      "    separation loss:          2.2164955933888755\n",
      "    avg separation loss:      6.1561808586120605\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  2.1421327590942383\n",
      "    train time:               0.024504661560058594\n",
      "    test time:                0.012878656387329102\n",
      "    epoch time:               0.037889719009399414\n",
      "    last layer lr:            0.0016840000000000017\n",
      "epoch: 140 (37/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.019629975366923545\n",
      "    train cross_ent loss:     0.016277942107990384\n",
      "    test overall loss:        0.1479267260680596\n",
      "    test cross_ent loss:      0.14458082926770052\n",
      "    cluster loss:             2949.2684733072915\n",
      "    separation loss:          2.2076088190078735\n",
      "    avg separation loss:      6.123934268951416\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  2.157585382461548\n",
      "    train time:               0.02453017234802246\n",
      "    test time:                0.01293492317199707\n",
      "    epoch time:               0.0379643440246582\n",
      "    last layer lr:            0.001288000000000003\n",
      "epoch: 140 (38/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.01491573028680351\n",
      "    train cross_ent loss:     0.01201867067720741\n",
      "    test overall loss:        0.14742192067205906\n",
      "    test cross_ent loss:      0.14483064164717993\n",
      "    cluster loss:             2949.2677408854165\n",
      "    separation loss:          2.19866673151652\n",
      "    avg separation loss:      6.097643534342448\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  1.4029672145843506\n",
      "    train time:               0.024689912796020508\n",
      "    test time:                0.01291656494140625\n",
      "    epoch time:               0.038110971450805664\n",
      "    last layer lr:            0.0008919999999999973\n",
      "epoch: 140 (39/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.01274991138941712\n",
      "    train cross_ent loss:     0.010320082565562593\n",
      "    test overall loss:        0.14683345022300878\n",
      "    test cross_ent loss:      0.14455625725289187\n",
      "    cluster loss:             2949.2682291666665\n",
      "    separation loss:          2.2035340070724487\n",
      "    avg separation loss:      6.10858949025472\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  1.0888819694519043\n",
      "    train time:               0.02455282211303711\n",
      "    test time:                0.012931346893310547\n",
      "    epoch time:               0.03799581527709961\n",
      "    last layer lr:            0.0004959999999999986\n",
      "epoch: 140 (40/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.013162416716416677\n",
      "    train cross_ent loss:     0.011094748870366149\n",
      "    test overall loss:        0.14744257119794688\n",
      "    test cross_ent loss:      0.14552645136912665\n",
      "    cluster loss:             2949.267822265625\n",
      "    separation loss:          2.2001081307729087\n",
      "    avg separation loss:      6.1018500328063965\n",
      "    l1_addon loss:            39.61021423339844\n",
      "    l1 loss:                  0.7278169393539429\n",
      "    train time:               0.025757312774658203\n",
      "    test time:                0.012999296188354492\n",
      "    epoch time:               0.039258718490600586\n",
      "    last layer lr:            0.0001\n",
      "epoch: 141 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.02179741445514891\n",
      "    train cross_ent loss:     0.01988122162098686\n",
      "    test overall loss:        0.14675920829176903\n",
      "    test cross_ent loss:      0.14484291896224022\n",
      "    cluster loss:             2949.2687174479165\n",
      "    separation loss:          2.207369883855184\n",
      "    avg separation loss:      6.132089773813884\n",
      "    l1_addon loss:            39.615760803222656\n",
      "    l1 loss:                  0.7278169393539429\n",
      "    train time:               0.06415200233459473\n",
      "    test time:                0.012936115264892578\n",
      "    epoch time:               0.0779275894165039\n",
      "    joint lr:                 0.001298047112325102\n",
      "epoch: 142 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.012646932517074876\n",
      "    train cross_ent loss:     0.010730619801001417\n",
      "    test overall loss:        0.13866841606795788\n",
      "    test cross_ent loss:      0.13675217206279436\n",
      "    cluster loss:             2949.2666829427085\n",
      "    separation loss:          2.1965599854787192\n",
      "    avg separation loss:      6.1154100100199384\n",
      "    l1_addon loss:            39.61420440673828\n",
      "    l1 loss:                  0.7278169393539429\n",
      "    train time:               0.060028076171875\n",
      "    test time:                0.012686729431152344\n",
      "    epoch time:               0.07348799705505371\n",
      "    joint lr:                 0.002472133282403701\n",
      "epoch: 143 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.013722967511663834\n",
      "    train cross_ent loss:     0.011807956448238757\n",
      "    test overall loss:        0.12528631836175919\n",
      "    test cross_ent loss:      0.12337090944250424\n",
      "    cluster loss:             2949.2635091145835\n",
      "    separation loss:          2.149326284726461\n",
      "    avg separation loss:      5.93598477045695\n",
      "    l1_addon loss:            39.586299896240234\n",
      "    l1 loss:                  0.7278169393539429\n",
      "    train time:               0.06028318405151367\n",
      "    test time:                0.012605428695678711\n",
      "    epoch time:               0.07365584373474121\n",
      "    joint lr:                 0.0036226179243694966\n",
      "epoch: 144 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.0063548290895091165\n",
      "    train cross_ent loss:     0.004435586484356059\n",
      "    test overall loss:        0.1177136500676473\n",
      "    test cross_ent loss:      0.11579256442685922\n",
      "    cluster loss:             2949.26806640625\n",
      "    separation loss:          2.182690223058065\n",
      "    avg separation loss:      6.0111165046691895\n",
      "    l1_addon loss:            39.775455474853516\n",
      "    l1 loss:                  0.7278169393539429\n",
      "    train time:               0.05902743339538574\n",
      "    test time:                0.012690067291259766\n",
      "    epoch time:               0.0725088119506836\n",
      "    joint lr:                 0.004749855660167736\n",
      "epoch: 145 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.005003081039629049\n",
      "    train cross_ent loss:     0.0030843704913018476\n",
      "    test overall loss:        0.10934752101699512\n",
      "    test cross_ent loss:      0.10743197550376256\n",
      "    cluster loss:             2949.2626953125\n",
      "    separation loss:          2.151522914568583\n",
      "    avg separation loss:      5.958802541097005\n",
      "    l1_addon loss:            39.59098815917969\n",
      "    l1 loss:                  0.7278169393539429\n",
      "    train time:               0.05895853042602539\n",
      "    test time:                0.012642621994018555\n",
      "    epoch time:               0.0723724365234375\n",
      "    joint lr:                 0.005854196379457574\n",
      "epoch: 146 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.004095519013288949\n",
      "    train cross_ent loss:     0.002182031153804726\n",
      "    test overall loss:        0.10580141097307205\n",
      "    test cross_ent loss:      0.103888848486046\n",
      "    cluster loss:             2949.2581380208335\n",
      "    separation loss:          2.115798910458883\n",
      "    avg separation loss:      5.868733723958333\n",
      "    l1_addon loss:            39.491458892822266\n",
      "    l1 loss:                  0.7278169393539429\n",
      "    train time:               0.06075429916381836\n",
      "    test time:                0.012649297714233398\n",
      "    epoch time:               0.0741739273071289\n",
      "    joint lr:                 0.006935985298795627\n",
      "epoch: 147 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.006846086587756872\n",
      "    train cross_ent loss:     0.004930438823066652\n",
      "    test overall loss:        0.1055761044844985\n",
      "    test cross_ent loss:      0.10366127702097098\n",
      "    cluster loss:             2949.2548828125\n",
      "    separation loss:          2.1030105352401733\n",
      "    avg separation loss:      5.832492351531982\n",
      "    l1_addon loss:            39.56690979003906\n",
      "    l1 loss:                  0.7278169393539429\n",
      "    train time:               0.06092715263366699\n",
      "    test time:                0.013098716735839844\n",
      "    epoch time:               0.07476520538330078\n",
      "    joint lr:                 0.007995563020108943\n",
      "epoch: 148 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.010470241722133424\n",
      "    train cross_ent loss:     0.008560673876975974\n",
      "    test overall loss:        0.1115321818118294\n",
      "    test cross_ent loss:      0.10961998999118805\n",
      "    cluster loss:             2949.2529296875\n",
      "    separation loss:          2.0509161154429116\n",
      "    avg separation loss:      5.636372089385986\n",
      "    l1_addon loss:            39.479156494140625\n",
      "    l1 loss:                  0.7278169393539429\n",
      "    train time:               0.06170296669006348\n",
      "    test time:                0.012809991836547852\n",
      "    epoch time:               0.07528328895568848\n",
      "    joint lr:                 0.009033265588466115\n",
      "epoch: 149 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.025936775271677308\n",
      "    train cross_ent loss:     0.024028359847660694\n",
      "    test overall loss:        0.13139680897196135\n",
      "    test cross_ent loss:      0.12949072693785033\n",
      "    cluster loss:             2949.2978515625\n",
      "    separation loss:          2.1988757054011026\n",
      "    avg separation loss:      5.86026668548584\n",
      "    l1_addon loss:            39.275428771972656\n",
      "    l1 loss:                  0.7278169393539429\n",
      "    train time:               0.06175494194030762\n",
      "    test time:                0.012732267379760742\n",
      "    epoch time:               0.07520341873168945\n",
      "    joint lr:                 0.010049424549154131\n",
      "epoch: 150 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 94.67%\n",
      "    train overall loss:       0.06918219714942905\n",
      "    train cross_ent loss:     0.06727168496905102\n",
      "    test overall loss:        0.18554623797535896\n",
      "    test cross_ent loss:      0.18364833667874336\n",
      "    cluster loss:             2949.369384765625\n",
      "    separation loss:          2.5517005920410156\n",
      "    avg separation loss:      6.313326994578044\n",
      "    l1_addon loss:            39.002830505371094\n",
      "    l1 loss:                  0.7278169393539429\n",
      "    train time:               0.06174445152282715\n",
      "    test time:                0.012745380401611328\n",
      "    epoch time:               0.07523274421691895\n",
      "    joint lr:                 0.011044367004069541\n",
      "epoch: 151 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       0.16896516498592165\n",
      "    train cross_ent loss:     0.16705374005768034\n",
      "    test overall loss:        0.469740351041158\n",
      "    test cross_ent loss:      0.4678070346514384\n",
      "    cluster loss:             2949.6468098958335\n",
      "    separation loss:          3.7715555826822915\n",
      "    avg separation loss:      8.467196782430014\n",
      "    l1_addon loss:            40.18279266357422\n",
      "    l1 loss:                  0.7278169393539429\n",
      "    train time:               0.06333017349243164\n",
      "    test time:                0.012360811233520508\n",
      "    epoch time:               0.07651400566101074\n",
      "    joint lr:                 0.010393177167327405\n",
      "epoch: 152 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.23520906352334553\n",
      "    train cross_ent loss:     0.23328988336854511\n",
      "    test overall loss:        0.3102174897988637\n",
      "    test cross_ent loss:      0.3083130568265915\n",
      "    cluster loss:             2949.6631673177085\n",
      "    separation loss:          4.072022914886475\n",
      "    avg separation loss:      9.654698371887207\n",
      "    l1_addon loss:            39.22073745727539\n",
      "    l1 loss:                  0.7278169393539429\n",
      "    train time:               0.06064724922180176\n",
      "    test time:                0.012292861938476562\n",
      "    epoch time:               0.07366824150085449\n",
      "    joint lr:                 0.009753916690619703\n",
      "epoch: 153 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 93.67%\n",
      "    train overall loss:       0.2916562375095155\n",
      "    train cross_ent loss:     0.2897399945391549\n",
      "    test overall loss:        0.4718809525171916\n",
      "    test cross_ent loss:      0.4699602723121643\n",
      "    cluster loss:             2949.7847493489585\n",
      "    separation loss:          4.558596611022949\n",
      "    avg separation loss:      10.409184137980143\n",
      "    l1_addon loss:            39.76264190673828\n",
      "    l1 loss:                  0.7278169393539429\n",
      "    train time:               0.06107902526855469\n",
      "    test time:                0.012429237365722656\n",
      "    epoch time:               0.07422924041748047\n",
      "    joint lr:                 0.009126412105729424\n",
      "epoch: 154 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 94.33%\n",
      "    train overall loss:       0.3143100258376863\n",
      "    train cross_ent loss:     0.31240299675199723\n",
      "    test overall loss:        0.3752572139104207\n",
      "    test cross_ent loss:      0.37335636218388873\n",
      "    cluster loss:             2949.7921549479165\n",
      "    separation loss:          4.527931133906047\n",
      "    avg separation loss:      10.262543042500814\n",
      "    l1_addon loss:            39.10198974609375\n",
      "    l1 loss:                  0.7278169393539429\n",
      "    train time:               0.0619349479675293\n",
      "    test time:                0.013057231903076172\n",
      "    epoch time:               0.07571172714233398\n",
      "    joint lr:                 0.008510492220867888\n",
      "epoch: 155 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.32144169012705487\n",
      "    train cross_ent loss:     0.3195352935128742\n",
      "    test overall loss:        0.3839346170425415\n",
      "    test cross_ent loss:      0.38203340768814087\n",
      "    cluster loss:             2949.8260091145835\n",
      "    separation loss:          4.625097990036011\n",
      "    avg separation loss:      10.275287310282389\n",
      "    l1_addon loss:            39.113765716552734\n",
      "    l1 loss:                  0.7278169393539429\n",
      "    train time:               0.06027722358703613\n",
      "    test time:                0.012648820877075195\n",
      "    epoch time:               0.07369780540466309\n",
      "    joint lr:                 0.00790598809249301\n",
      "epoch: 156 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 94.33%\n",
      "    train overall loss:       0.24082559595505396\n",
      "    train cross_ent loss:     0.238918607433637\n",
      "    test overall loss:        0.3047095288832982\n",
      "    test cross_ent loss:      0.30280959109465283\n",
      "    cluster loss:             2949.714599609375\n",
      "    separation loss:          4.392345825831096\n",
      "    avg separation loss:      10.077713012695312\n",
      "    l1_addon loss:            39.071266174316406\n",
      "    l1 loss:                  0.7278169393539429\n",
      "    train time:               0.05973029136657715\n",
      "    test time:                0.012624025344848633\n",
      "    epoch time:               0.07316040992736816\n",
      "    joint lr:                 0.007312732997463544\n",
      "epoch: 157 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.15536557965808445\n",
      "    train cross_ent loss:     0.15345755798949134\n",
      "    test overall loss:        0.19481247663497925\n",
      "    test cross_ent loss:      0.1929038092494011\n",
      "    cluster loss:             2949.5839029947915\n",
      "    separation loss:          3.84751828511556\n",
      "    avg separation loss:      9.109976450602213\n",
      "    l1_addon loss:            39.361671447753906\n",
      "    l1 loss:                  0.7278169393539429\n",
      "    train time:               0.05898118019104004\n",
      "    test time:                0.012640237808227539\n",
      "    epoch time:               0.07239055633544922\n",
      "    joint lr:                 0.006730562405525418\n",
      "epoch: 158 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.08520835141340892\n",
      "    train cross_ent loss:     0.08329659617609447\n",
      "    test overall loss:        0.16126341000199318\n",
      "    test cross_ent loss:      0.15935528775056204\n",
      "    cluster loss:             2949.547607421875\n",
      "    separation loss:          3.6777143478393555\n",
      "    avg separation loss:      8.793675422668457\n",
      "    l1_addon loss:            39.34337615966797\n",
      "    l1 loss:                  0.7278169393539429\n",
      "    train time:               0.059126853942871094\n",
      "    test time:                0.012651920318603516\n",
      "    epoch time:               0.07255101203918457\n",
      "    joint lr:                 0.006159313952126306\n",
      "epoch: 159 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.044472837406728\n",
      "    train cross_ent loss:     0.04255521483719349\n",
      "    test overall loss:        0.15141164883971214\n",
      "    test cross_ent loss:      0.14950063452124596\n",
      "    cluster loss:             2949.5288899739585\n",
      "    separation loss:          3.488859494527181\n",
      "    avg separation loss:      8.268022537231445\n",
      "    l1_addon loss:            39.439937591552734\n",
      "    l1 loss:                  0.7278169393539429\n",
      "    train time:               0.059496402740478516\n",
      "    test time:                0.012611150741577148\n",
      "    epoch time:               0.07288002967834473\n",
      "    joint lr:                 0.005598827411554625\n",
      "epoch: 160 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.026007016396356955\n",
      "    train cross_ent loss:     0.024102173279970884\n",
      "    test overall loss:        0.1232034166653951\n",
      "    test cross_ent loss:      0.12129222229123116\n",
      "    cluster loss:             2949.4979654947915\n",
      "    separation loss:          3.353352944056193\n",
      "    avg separation loss:      8.049743175506592\n",
      "    l1_addon loss:            39.4459228515625\n",
      "    l1 loss:                  0.7278169393539429\n",
      "    train time:               0.06042885780334473\n",
      "    test time:                0.012726068496704102\n",
      "    epoch time:               0.07386040687561035\n",
      "    joint lr:                 0.005048944670399165\n",
      "epoch: 161 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.0175995744454364\n",
      "    train cross_ent loss:     0.01568835683994823\n",
      "    test overall loss:        0.11376677577694257\n",
      "    test cross_ent loss:      0.11186166231830914\n",
      "    cluster loss:             2949.4844563802085\n",
      "    separation loss:          3.2479220231374106\n",
      "    avg separation loss:      7.833734512329102\n",
      "    l1_addon loss:            39.243186950683594\n",
      "    l1 loss:                  0.7278169393539429\n",
      "    train time:               0.061808109283447266\n",
      "    test time:                0.012456893920898438\n",
      "    epoch time:               0.07494592666625977\n",
      "    joint lr:                 0.004509509701325646\n",
      "epoch: 162 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.00%\n",
      "    train overall loss:       0.009972922400467925\n",
      "    train cross_ent loss:     0.0080719369256662\n",
      "    test overall loss:        0.11186674733956654\n",
      "    test cross_ent loss:      0.10996501458187898\n",
      "    cluster loss:             2949.47265625\n",
      "    separation loss:          3.131232659022013\n",
      "    avg separation loss:      7.510586420694987\n",
      "    l1_addon loss:            39.1306037902832\n",
      "    l1 loss:                  0.7278169393539429\n",
      "    train time:               0.06211137771606445\n",
      "    test time:                0.012438058853149414\n",
      "    epoch time:               0.07528924942016602\n",
      "    joint lr:                 0.00398036853716657\n",
      "epoch: 163 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.007013774994346831\n",
      "    train cross_ent loss:     0.005109003098267648\n",
      "    test overall loss:        0.11125402276714642\n",
      "    test cross_ent loss:      0.10934701499839623\n",
      "    cluster loss:             2949.462158203125\n",
      "    separation loss:          3.0776856740315757\n",
      "    avg separation loss:      7.423914750417073\n",
      "    l1_addon loss:            39.306488037109375\n",
      "    l1 loss:                  0.7278169393539429\n",
      "    train time:               0.06135106086730957\n",
      "    test time:                0.012253761291503906\n",
      "    epoch time:               0.07432699203491211\n",
      "    joint lr:                 0.0034613692453205423\n",
      "epoch: 164 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.005568344715154833\n",
      "    train cross_ent loss:     0.0036615298207228384\n",
      "    test overall loss:        0.11137116762499015\n",
      "    test cross_ent loss:      0.10946554876863956\n",
      "    cluster loss:             2949.4583333333335\n",
      "    separation loss:          3.056490421295166\n",
      "    avg separation loss:      7.3926496505737305\n",
      "    l1_addon loss:            39.259986877441406\n",
      "    l1 loss:                  0.7278169393539429\n",
      "    train time:               0.06159496307373047\n",
      "    test time:                0.013112068176269531\n",
      "    epoch time:               0.07542824745178223\n",
      "    joint lr:                 0.002952361902457719\n",
      "epoch: 165 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.0054446133888430065\n",
      "    train cross_ent loss:     0.0035408589497415554\n",
      "    test overall loss:        0.108018908649683\n",
      "    test cross_ent loss:      0.10611723611752193\n",
      "    cluster loss:             2949.4545084635415\n",
      "    separation loss:          3.0216843287150064\n",
      "    avg separation loss:      7.298281033833821\n",
      "    l1_addon loss:            39.12856674194336\n",
      "    l1 loss:                  0.7278169393539429\n",
      "    train time:               0.062151432037353516\n",
      "    test time:                0.01306009292602539\n",
      "    epoch time:               0.07600569725036621\n",
      "    joint lr:                 0.0024531985695276076\n",
      "epoch: 166 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.00488081771052546\n",
      "    train cross_ent loss:     0.002980944907499684\n",
      "    test overall loss:        0.12516801555951437\n",
      "    test cross_ent loss:      0.12326965108513832\n",
      "    cluster loss:             2949.4574381510415\n",
      "    separation loss:          3.0168732007344565\n",
      "    avg separation loss:      7.267266273498535\n",
      "    l1_addon loss:            39.0183219909668\n",
      "    l1 loss:                  0.7278169393539429\n",
      "    train time:               0.06261348724365234\n",
      "    test time:                0.012833833694458008\n",
      "    epoch time:               0.07623434066772461\n",
      "    joint lr:                 0.001963733267065865\n",
      "epoch: 167 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.004751683833698432\n",
      "    train cross_ent loss:     0.002853346784831956\n",
      "    test overall loss:        0.11987709812819958\n",
      "    test cross_ent loss:      0.11797810718417168\n",
      "    cluster loss:             2949.4541015625\n",
      "    separation loss:          2.998974084854126\n",
      "    avg separation loss:      7.221780776977539\n",
      "    l1_addon loss:            39.039268493652344\n",
      "    l1 loss:                  0.7278169393539429\n",
      "    train time:               0.06194663047790527\n",
      "    test time:                0.012536048889160156\n",
      "    epoch time:               0.07534098625183105\n",
      "    joint lr:                 0.001483821950796405\n",
      "epoch: 168 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.0039012404676112863\n",
      "    train cross_ent loss:     0.0020016865002819234\n",
      "    test overall loss:        0.11149109217027824\n",
      "    test cross_ent loss:      0.10959101406236489\n",
      "    cluster loss:             2949.4502766927085\n",
      "    separation loss:          2.9802566369374595\n",
      "    avg separation loss:      7.191383520762126\n",
      "    l1_addon loss:            39.075439453125\n",
      "    l1 loss:                  0.7278169393539429\n",
      "    train time:               0.062371015548706055\n",
      "    test time:                0.012378931045532227\n",
      "    epoch time:               0.07562088966369629\n",
      "    joint lr:                 0.0010133224875256274\n",
      "epoch: 169 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.004216878674924374\n",
      "    train cross_ent loss:     0.002316616986516035\n",
      "    test overall loss:        0.10938975525399049\n",
      "    test cross_ent loss:      0.10748938036461671\n",
      "    cluster loss:             2949.4488932291665\n",
      "    separation loss:          2.9742696285247803\n",
      "    avg separation loss:      7.1764020919799805\n",
      "    l1_addon loss:            39.08525466918945\n",
      "    l1 loss:                  0.7278169393539429\n",
      "    train time:               0.06191754341125488\n",
      "    test time:                0.012840986251831055\n",
      "    epoch time:               0.07562398910522461\n",
      "    joint lr:                 0.0005520946313251855\n",
      "epoch: 170 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.67%\n",
      "    train overall loss:       0.00350891270985206\n",
      "    train cross_ent loss:     0.0016084461498798595\n",
      "    test overall loss:        0.10896708692113559\n",
      "    test cross_ent loss:      0.1070666058609883\n",
      "    cluster loss:             2949.4482421875\n",
      "    separation loss:          2.969060023625692\n",
      "    avg separation loss:      7.165441830952962\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  0.7278169393539429\n",
      "    train time:               0.062337398529052734\n",
      "    test time:                0.012866973876953125\n",
      "    epoch time:               0.0760352611541748\n",
      "    joint lr:                 0.0001\n",
      "epoch: 170 (PUSH) - ArticularyWordRecognition\n",
      "    test acc:                 94.67%\n",
      "    train overall loss:       0.00350891270985206\n",
      "    train cross_ent loss:     0.0016084461498798595\n",
      "    test overall loss:        0.19085625000298023\n",
      "    test cross_ent loss:      0.1889557739098867\n",
      "    cluster loss:             2949.2650553385415\n",
      "    separation loss:          2.2728966077168784\n",
      "    avg separation loss:      6.310371557871501\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  0.7278169393539429\n",
      "    train time:               0.062337398529052734\n",
      "    test time:                0.013020992279052734\n",
      "    epoch time:               0.40320897102355957\n",
      "epoch: 170 (1/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 94.67%\n",
      "    train overall loss:       0.019017710764374997\n",
      "    train cross_ent loss:     0.017316652099705405\n",
      "    test overall loss:        0.19232151036461195\n",
      "    test cross_ent loss:      0.19076841014126936\n",
      "    cluster loss:             2949.2652180989585\n",
      "    separation loss:          2.2755990823109946\n",
      "    avg separation loss:      6.320743083953857\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  0.380440890789032\n",
      "    train time:               0.024290084838867188\n",
      "    test time:                0.012327432632446289\n",
      "    epoch time:               0.03713393211364746\n",
      "    last layer lr:            0.0007599999999999978\n",
      "epoch: 170 (2/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 94.67%\n",
      "    train overall loss:       0.016068241662449308\n",
      "    train cross_ent loss:     0.013756732766826948\n",
      "    test overall loss:        0.19010294352968535\n",
      "    test cross_ent loss:      0.18775760817031065\n",
      "    cluster loss:             2949.2647298177085\n",
      "    separation loss:          2.27347993850708\n",
      "    avg separation loss:      6.309271812438965\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  1.1726758480072021\n",
      "    train time:               0.02531886100769043\n",
      "    test time:                0.012781381607055664\n",
      "    epoch time:               0.03868865966796875\n",
      "    last layer lr:            0.0014199999999999955\n",
      "epoch: 170 (3/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 94.33%\n",
      "    train overall loss:       0.02085013935963313\n",
      "    train cross_ent loss:     0.018119882559403777\n",
      "    test overall loss:        0.19119506515562534\n",
      "    test cross_ent loss:      0.18839161594708762\n",
      "    cluster loss:             2949.2649739583335\n",
      "    separation loss:          2.276890754699707\n",
      "    avg separation loss:      6.322982629140218\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  1.630790114402771\n",
      "    train time:               0.02545332908630371\n",
      "    test time:                0.012782573699951172\n",
      "    epoch time:               0.03884530067443848\n",
      "    last layer lr:            0.0020800000000000046\n",
      "epoch: 170 (4/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 94.67%\n",
      "    train overall loss:       0.01635891944169998\n",
      "    train cross_ent loss:     0.013317401520907879\n",
      "    test overall loss:        0.18237797170877457\n",
      "    test cross_ent loss:      0.17919041154285273\n",
      "    cluster loss:             2949.2648111979165\n",
      "    separation loss:          2.2757566372553506\n",
      "    avg separation loss:      6.320483366648356\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  2.014894485473633\n",
      "    train time:               0.025565624237060547\n",
      "    test time:                0.012542486190795898\n",
      "    epoch time:               0.03875112533569336\n",
      "    last layer lr:            0.0027400000000000024\n",
      "epoch: 170 (5/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 94.67%\n",
      "    train overall loss:       0.021871494646701548\n",
      "    train cross_ent loss:     0.018269647533694904\n",
      "    test overall loss:        0.18432660525043806\n",
      "    test cross_ent loss:      0.18042231847842535\n",
      "    cluster loss:             2949.264892578125\n",
      "    separation loss:          2.279764413833618\n",
      "    avg separation loss:      6.3355177243550616\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  2.7316274642944336\n",
      "    train time:               0.024612903594970703\n",
      "    test time:                0.012447834014892578\n",
      "    epoch time:               0.03764057159423828\n",
      "    last layer lr:            0.0034\n",
      "epoch: 170 (6/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 94.67%\n",
      "    train overall loss:       0.0169053730658359\n",
      "    train cross_ent loss:     0.012711855311257144\n",
      "    test overall loss:        0.18063018719355264\n",
      "    test cross_ent loss:      0.17647633701562881\n",
      "    cluster loss:             2949.2652180989585\n",
      "    separation loss:          2.280555486679077\n",
      "    avg separation loss:      6.333021958669026\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  2.981187343597412\n",
      "    train time:               0.024640798568725586\n",
      "    test time:                0.012404918670654297\n",
      "    epoch time:               0.03761935234069824\n",
      "    last layer lr:            0.004059999999999998\n",
      "epoch: 170 (7/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 94.67%\n",
      "    train overall loss:       0.023772438574168418\n",
      "    train cross_ent loss:     0.019304289650689397\n",
      "    test overall loss:        0.17691676629086336\n",
      "    test cross_ent loss:      0.1716390127936999\n",
      "    cluster loss:             2949.2655436197915\n",
      "    separation loss:          2.2815059423446655\n",
      "    avg separation loss:      6.345671494801839\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  4.105087757110596\n",
      "    train time:               0.024280548095703125\n",
      "    test time:                0.01226186752319336\n",
      "    epoch time:               0.03710627555847168\n",
      "    last layer lr:            0.004719999999999996\n",
      "epoch: 170 (8/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.01839786022901535\n",
      "    train cross_ent loss:     0.012133933474413224\n",
      "    test overall loss:        0.17778545804321766\n",
      "    test cross_ent loss:      0.17184165368477503\n",
      "    cluster loss:             2949.2652994791665\n",
      "    separation loss:          2.2802162965138755\n",
      "    avg separation loss:      6.332873821258545\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  4.771136283874512\n",
      "    train time:               0.02553105354309082\n",
      "    test time:                0.012250900268554688\n",
      "    epoch time:               0.038336753845214844\n",
      "    last layer lr:            0.0053800000000000054\n",
      "epoch: 170 (9/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.01770863330198659\n",
      "    train cross_ent loss:     0.01175023325615459\n",
      "    test overall loss:        0.17568857967853546\n",
      "    test cross_ent loss:      0.16982962936162949\n",
      "    cluster loss:             2949.2652994791665\n",
      "    separation loss:          2.2829434474309287\n",
      "    avg separation loss:      6.353140036265056\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  4.686282157897949\n",
      "    train time:               0.024936914443969727\n",
      "    test time:                0.012330770492553711\n",
      "    epoch time:               0.03783226013183594\n",
      "    last layer lr:            0.006040000000000003\n",
      "epoch: 170 (10/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.016070495980481308\n",
      "    train cross_ent loss:     0.010102892708447244\n",
      "    test overall loss:        0.1751080776254336\n",
      "    test cross_ent loss:      0.16925748251378536\n",
      "    cluster loss:             2949.2654622395835\n",
      "    separation loss:          2.2792624632517495\n",
      "    avg separation loss:      6.335163275400798\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  4.677935600280762\n",
      "    train time:               0.025645971298217773\n",
      "    test time:                0.012343645095825195\n",
      "    epoch time:               0.03856158256530762\n",
      "    last layer lr:            0.0067\n",
      "epoch: 170 (11/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 94.67%\n",
      "    train overall loss:       0.02228249878519111\n",
      "    train cross_ent loss:     0.015837827438695565\n",
      "    test overall loss:        0.174433176095287\n",
      "    test cross_ent loss:      0.16730943756798902\n",
      "    cluster loss:             2949.2652180989585\n",
      "    separation loss:          2.2809428373972573\n",
      "    avg separation loss:      6.3393754959106445\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  5.951071739196777\n",
      "    train time:               0.024311065673828125\n",
      "    test time:                0.012364625930786133\n",
      "    epoch time:               0.03724169731140137\n",
      "    last layer lr:            0.0073599999999999985\n",
      "epoch: 170 (12/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 94.67%\n",
      "    train overall loss:       0.026363672895563975\n",
      "    train cross_ent loss:     0.01914956643142634\n",
      "    test overall loss:        0.17082932653526464\n",
      "    test cross_ent loss:      0.16246692712108293\n",
      "    cluster loss:             2949.265380859375\n",
      "    separation loss:          2.2814642588297525\n",
      "    avg separation loss:      6.339290301005046\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  7.189736366271973\n",
      "    train time:               0.02462315559387207\n",
      "    test time:                0.012346267700195312\n",
      "    epoch time:               0.0375974178314209\n",
      "    last layer lr:            0.008019999999999994\n",
      "epoch: 170 (13/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       0.025631710059112973\n",
      "    train cross_ent loss:     0.015239453512347408\n",
      "    test overall loss:        0.16043541332085928\n",
      "    test cross_ent loss:      0.15028898852566877\n",
      "    cluster loss:             2949.2660319010415\n",
      "    separation loss:          2.282533327738444\n",
      "    avg separation loss:      6.349443594614665\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  8.973758697509766\n",
      "    train time:               0.024155855178833008\n",
      "    test time:                0.012415170669555664\n",
      "    epoch time:               0.03713703155517578\n",
      "    last layer lr:            0.008680000000000005\n",
      "epoch: 170 (14/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       0.023766787412265938\n",
      "    train cross_ent loss:     0.013610313698235486\n",
      "    test overall loss:        0.1592714867244164\n",
      "    test cross_ent loss:      0.14949465356767178\n",
      "    cluster loss:             2949.2655436197915\n",
      "    separation loss:          2.280934969584147\n",
      "    avg separation loss:      6.333071072896321\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  8.604169845581055\n",
      "    train time:               0.02498650550842285\n",
      "    test time:                0.012264490127563477\n",
      "    epoch time:               0.037839651107788086\n",
      "    last layer lr:            0.009340000000000003\n",
      "epoch: 170 (15/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.0203542523086071\n",
      "    train cross_ent loss:     0.01069984140081538\n",
      "    test overall loss:        0.16143256736298403\n",
      "    test cross_ent loss:      0.15188771889855465\n",
      "    cluster loss:             2949.265380859375\n",
      "    separation loss:          2.2824278672536216\n",
      "    avg separation loss:      6.335290749867757\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  8.372179985046387\n",
      "    train time:               0.025304794311523438\n",
      "    test time:                0.012762069702148438\n",
      "    epoch time:               0.038690805435180664\n",
      "    last layer lr:            0.01\n",
      "epoch: 170 (16/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.018974077370431688\n",
      "    train cross_ent loss:     0.009428161183475621\n",
      "    test overall loss:        0.16515019598106542\n",
      "    test cross_ent loss:      0.15565180778503418\n",
      "    cluster loss:             2949.265625\n",
      "    separation loss:          2.2847702900568643\n",
      "    avg separation loss:      6.350823084513347\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  8.325721740722656\n",
      "    train time:               0.02559685707092285\n",
      "    test time:                0.012793540954589844\n",
      "    epoch time:               0.038990020751953125\n",
      "    last layer lr:            0.009604000000000001\n",
      "epoch: 170 (17/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.020514963815609615\n",
      "    train cross_ent loss:     0.01121908152062032\n",
      "    test overall loss:        0.1649872021128734\n",
      "    test cross_ent loss:      0.15538021425406137\n",
      "    cluster loss:             2949.2657063802085\n",
      "    separation loss:          2.2835762898127236\n",
      "    avg separation loss:      6.3419210116068525\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  8.434320449829102\n",
      "    train time:               0.0252532958984375\n",
      "    test time:                0.012776374816894531\n",
      "    epoch time:               0.03861522674560547\n",
      "    last layer lr:            0.009208000000000003\n",
      "epoch: 170 (18/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.020179396805663902\n",
      "    train cross_ent loss:     0.010874171456735995\n",
      "    test overall loss:        0.16235931031405926\n",
      "    test cross_ent loss:      0.15354641185452542\n",
      "    cluster loss:             2949.265380859375\n",
      "    separation loss:          2.277778069178263\n",
      "    avg separation loss:      6.323826789855957\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  7.64023494720459\n",
      "    train time:               0.025439023971557617\n",
      "    test time:                0.01280069351196289\n",
      "    epoch time:               0.038837432861328125\n",
      "    last layer lr:            0.008811999999999997\n",
      "epoch: 170 (19/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.02075170021918085\n",
      "    train cross_ent loss:     0.011421186487293906\n",
      "    test overall loss:        0.1640646898498138\n",
      "    test cross_ent loss:      0.15493491074691215\n",
      "    cluster loss:             2949.2646484375\n",
      "    separation loss:          2.272414207458496\n",
      "    avg separation loss:      6.306851863861084\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  7.957115173339844\n",
      "    train time:               0.026122093200683594\n",
      "    test time:                0.013123750686645508\n",
      "    epoch time:               0.03984546661376953\n",
      "    last layer lr:            0.008415999999999998\n",
      "epoch: 170 (20/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.02020582536028491\n",
      "    train cross_ent loss:     0.01152001383403937\n",
      "    test overall loss:        0.16170576214790344\n",
      "    test cross_ent loss:      0.15335689298808575\n",
      "    cluster loss:             2949.2650553385415\n",
      "    separation loss:          2.277071714401245\n",
      "    avg separation loss:      6.3182220458984375\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  7.176205635070801\n",
      "    train time:               0.026381254196166992\n",
      "    test time:                0.013125419616699219\n",
      "    epoch time:               0.04007887840270996\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 170 (21/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.01793278091483646\n",
      "    train cross_ent loss:     0.009994865964270301\n",
      "    test overall loss:        0.16127193408707777\n",
      "    test cross_ent loss:      0.15345369403560957\n",
      "    cluster loss:             2949.2655436197915\n",
      "    separation loss:          2.2827559312184653\n",
      "    avg separation loss:      6.336928208669026\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  6.645578861236572\n",
      "    train time:               0.02572011947631836\n",
      "    test time:                0.01338815689086914\n",
      "    epoch time:               0.03970456123352051\n",
      "    last layer lr:            0.007624000000000002\n",
      "epoch: 170 (22/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.0190755779751473\n",
      "    train cross_ent loss:     0.011643840051773522\n",
      "    test overall loss:        0.16405082059403261\n",
      "    test cross_ent loss:      0.15684166736900806\n",
      "    cluster loss:             2949.2650553385415\n",
      "    separation loss:          2.2774388790130615\n",
      "    avg separation loss:      6.3235775629679365\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  6.036487102508545\n",
      "    train time:               0.02605915069580078\n",
      "    test time:                0.013124465942382812\n",
      "    epoch time:               0.03977346420288086\n",
      "    last layer lr:            0.0072280000000000035\n",
      "epoch: 170 (23/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.027634363517993026\n",
      "    train cross_ent loss:     0.020422745340814192\n",
      "    test overall loss:        0.16585520096123219\n",
      "    test cross_ent loss:      0.157343371771276\n",
      "    cluster loss:             2949.265625\n",
      "    separation loss:          2.2790300051371255\n",
      "    avg separation loss:      6.324711004892985\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  7.339166641235352\n",
      "    train time:               0.026540756225585938\n",
      "    test time:                0.012768983840942383\n",
      "    epoch time:               0.03989005088806152\n",
      "    last layer lr:            0.006831999999999998\n",
      "epoch: 170 (24/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.017669827056427796\n",
      "    train cross_ent loss:     0.008136735491765043\n",
      "    test overall loss:        0.16480657209952673\n",
      "    test cross_ent loss:      0.1561016719788313\n",
      "    cluster loss:             2949.2657063802085\n",
      "    separation loss:          2.279761870702108\n",
      "    avg separation loss:      6.324441909790039\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  7.53223180770874\n",
      "    train time:               0.027276992797851562\n",
      "    test time:                0.013039827346801758\n",
      "    epoch time:               0.0409245491027832\n",
      "    last layer lr:            0.006436\n",
      "epoch: 170 (25/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.01930901553067896\n",
      "    train cross_ent loss:     0.011517895489103265\n",
      "    test overall loss:        0.16086476917068163\n",
      "    test cross_ent loss:      0.15336118514339128\n",
      "    cluster loss:             2949.2655436197915\n",
      "    separation loss:          2.2832754850387573\n",
      "    avg separation loss:      6.345046838124593\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  6.330916404724121\n",
      "    train time:               0.0273129940032959\n",
      "    test time:                0.013130426406860352\n",
      "    epoch time:               0.041057586669921875\n",
      "    last layer lr:            0.00604\n",
      "epoch: 170 (26/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.019090533980892763\n",
      "    train cross_ent loss:     0.011478385060197778\n",
      "    test overall loss:        0.1624530665576458\n",
      "    test cross_ent loss:      0.15565633246054253\n",
      "    cluster loss:             2949.2655436197915\n",
      "    separation loss:          2.2843061288197837\n",
      "    avg separation loss:      6.3515268961588545\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  5.6240692138671875\n",
      "    train time:               0.026243925094604492\n",
      "    test time:                0.013145923614501953\n",
      "    epoch time:               0.03999781608581543\n",
      "    last layer lr:            0.005644000000000002\n",
      "epoch: 170 (27/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.01787767673118247\n",
      "    train cross_ent loss:     0.011206228919844661\n",
      "    test overall loss:        0.16168172222872576\n",
      "    test cross_ent loss:      0.1552749201655388\n",
      "    cluster loss:             2949.265625\n",
      "    separation loss:          2.282472809155782\n",
      "    avg separation loss:      6.348777612050374\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  5.2341413497924805\n",
      "    train time:               0.030807971954345703\n",
      "    test time:                0.013120174407958984\n",
      "    epoch time:               0.04454350471496582\n",
      "    last layer lr:            0.005248000000000003\n",
      "epoch: 170 (28/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.014470845874812868\n",
      "    train cross_ent loss:     0.008455582480463717\n",
      "    test overall loss:        0.1628113016486168\n",
      "    test cross_ent loss:      0.15712655056267977\n",
      "    cluster loss:             2949.265869140625\n",
      "    separation loss:          2.283008575439453\n",
      "    avg separation loss:      6.345305760701497\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  4.512088775634766\n",
      "    train time:               0.027560710906982422\n",
      "    test time:                0.013116121292114258\n",
      "    epoch time:               0.04129910469055176\n",
      "    last layer lr:            0.004851999999999998\n",
      "epoch: 170 (29/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.016078285459015105\n",
      "    train cross_ent loss:     0.010695782308984134\n",
      "    test overall loss:        0.16319648486872515\n",
      "    test cross_ent loss:      0.15772120064745346\n",
      "    cluster loss:             2949.2655436197915\n",
      "    separation loss:          2.279194792111715\n",
      "    avg separation loss:      6.3358964920043945\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  4.302618980407715\n",
      "    train time:               0.02598118782043457\n",
      "    test time:                0.01314091682434082\n",
      "    epoch time:               0.03973841667175293\n",
      "    last layer lr:            0.004455999999999999\n",
      "epoch: 170 (30/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.012482349450389544\n",
      "    train cross_ent loss:     0.007444414879298872\n",
      "    test overall loss:        0.16221576184034348\n",
      "    test cross_ent loss:      0.15737838142861924\n",
      "    cluster loss:             2949.2652994791665\n",
      "    separation loss:          2.2801016569137573\n",
      "    avg separation loss:      6.336694558461507\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  3.6647157669067383\n",
      "    train time:               0.02575969696044922\n",
      "    test time:                0.012970924377441406\n",
      "    epoch time:               0.03932547569274902\n",
      "    last layer lr:            0.004060000000000001\n",
      "epoch: 170 (31/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.013597279062701596\n",
      "    train cross_ent loss:     0.008972030805630816\n",
      "    test overall loss:        0.16102982560793558\n",
      "    test cross_ent loss:      0.15647847422709069\n",
      "    cluster loss:             2949.265380859375\n",
      "    separation loss:          2.2797462542851767\n",
      "    avg separation loss:      6.3306756019592285\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  3.3786842823028564\n",
      "    train time:               0.02597832679748535\n",
      "    test time:                0.012606620788574219\n",
      "    epoch time:               0.039138078689575195\n",
      "    last layer lr:            0.0036640000000000015\n",
      "epoch: 170 (32/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.011943214676446386\n",
      "    train cross_ent loss:     0.007674305945531362\n",
      "    test overall loss:        0.16082231452067694\n",
      "    test cross_ent loss:      0.15675122663378716\n",
      "    cluster loss:             2949.265380859375\n",
      "    separation loss:          2.2792754570643106\n",
      "    avg separation loss:      6.33186403910319\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  2.898423194885254\n",
      "    train time:               0.02492523193359375\n",
      "    test time:                0.012587785720825195\n",
      "    epoch time:               0.03806591033935547\n",
      "    last layer lr:            0.003268000000000003\n",
      "epoch: 170 (33/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.01076501804507441\n",
      "    train cross_ent loss:     0.006936168660306268\n",
      "    test overall loss:        0.15941683699687323\n",
      "    test cross_ent loss:      0.15574664964030185\n",
      "    cluster loss:             2949.2652180989585\n",
      "    separation loss:          2.2790242036183677\n",
      "    avg separation loss:      6.329012393951416\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  2.497523307800293\n",
      "    train time:               0.025171756744384766\n",
      "    test time:                0.012704849243164062\n",
      "    epoch time:               0.03843569755554199\n",
      "    last layer lr:            0.002871999999999997\n",
      "epoch: 170 (34/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.01345742473171817\n",
      "    train cross_ent loss:     0.009892920239104165\n",
      "    test overall loss:        0.15893522029121718\n",
      "    test cross_ent loss:      0.1554489421347777\n",
      "    cluster loss:             2949.2659505208335\n",
      "    separation loss:          2.285789132118225\n",
      "    avg separation loss:      6.351275444030762\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  2.3136157989501953\n",
      "    train time:               0.026937246322631836\n",
      "    test time:                0.012560606002807617\n",
      "    epoch time:               0.0400538444519043\n",
      "    last layer lr:            0.0024759999999999986\n",
      "epoch: 170 (35/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.011840062215924263\n",
      "    train cross_ent loss:     0.008527997130942013\n",
      "    test overall loss:        0.1592686716467142\n",
      "    test cross_ent loss:      0.15605070597181717\n",
      "    cluster loss:             2949.265625\n",
      "    separation loss:          2.2809271812438965\n",
      "    avg separation loss:      6.334257125854492\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  2.045299530029297\n",
      "    train time:               0.026640892028808594\n",
      "    test time:                0.013207435607910156\n",
      "    epoch time:               0.04046630859375\n",
      "    last layer lr:            0.0020800000000000003\n",
      "epoch: 170 (36/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.012037403053707547\n",
      "    train cross_ent loss:     0.008948866329673264\n",
      "    test overall loss:        0.16003750575085482\n",
      "    test cross_ent loss:      0.15698889115204415\n",
      "    cluster loss:             2949.264892578125\n",
      "    separation loss:          2.275631626447042\n",
      "    avg separation loss:      6.3221360842386884\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  1.8759489059448242\n",
      "    train time:               0.02682662010192871\n",
      "    test time:                0.013115882873535156\n",
      "    epoch time:               0.04058265686035156\n",
      "    last layer lr:            0.0016840000000000017\n",
      "epoch: 170 (37/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.010240808801932467\n",
      "    train cross_ent loss:     0.0074839521872086655\n",
      "    test overall loss:        0.15862937706212202\n",
      "    test cross_ent loss:      0.1560436338186264\n",
      "    cluster loss:             2949.265625\n",
      "    separation loss:          2.2800496021906533\n",
      "    avg separation loss:      6.338693141937256\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  1.4130839109420776\n",
      "    train time:               0.026370525360107422\n",
      "    test time:                0.013103723526000977\n",
      "    epoch time:               0.04007411003112793\n",
      "    last layer lr:            0.001288000000000003\n",
      "epoch: 170 (38/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.00980745255947113\n",
      "    train cross_ent loss:     0.007422985948829187\n",
      "    test overall loss:        0.15688130197425684\n",
      "    test cross_ent loss:      0.15462350317587456\n",
      "    cluster loss:             2949.265380859375\n",
      "    separation loss:          2.2813549439112344\n",
      "    avg separation loss:      6.339785734812419\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  1.0851396322250366\n",
      "    train time:               0.026269912719726562\n",
      "    test time:                0.013067007064819336\n",
      "    epoch time:               0.039948225021362305\n",
      "    last layer lr:            0.0008919999999999973\n",
      "epoch: 170 (39/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.010681390037967099\n",
      "    train cross_ent loss:     0.008613664449916946\n",
      "    test overall loss:        0.15588038973510265\n",
      "    test cross_ent loss:      0.15391532486925522\n",
      "    cluster loss:             2949.2649739583335\n",
      "    separation loss:          2.2795039415359497\n",
      "    avg separation loss:      6.329613208770752\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  0.7924044132232666\n",
      "    train time:               0.025749921798706055\n",
      "    test time:                0.012725353240966797\n",
      "    epoch time:               0.03904843330383301\n",
      "    last layer lr:            0.0004959999999999986\n",
      "epoch: 170 (40/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.010103702441685729\n",
      "    train cross_ent loss:     0.008324462454766035\n",
      "    test overall loss:        0.15622353181242943\n",
      "    test cross_ent loss:      0.1545361957202355\n",
      "    cluster loss:             2949.2649739583335\n",
      "    separation loss:          2.2764617204666138\n",
      "    avg separation loss:      6.323674360911052\n",
      "    l1_addon loss:            39.08893585205078\n",
      "    l1 loss:                  0.514674186706543\n",
      "    train time:               0.025790929794311523\n",
      "    test time:                0.012717247009277344\n",
      "    epoch time:               0.0391240119934082\n",
      "    last layer lr:            0.0001\n",
      "epoch: 171 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.33%\n",
      "    train overall loss:       0.009241778584611084\n",
      "    train cross_ent loss:     0.007554473044971625\n",
      "    test overall loss:        0.1549034435302019\n",
      "    test cross_ent loss:      0.15321617014706135\n",
      "    cluster loss:             2949.264892578125\n",
      "    separation loss:          2.2784272034962973\n",
      "    avg separation loss:      6.331349690755208\n",
      "    l1_addon loss:            39.086631774902344\n",
      "    l1 loss:                  0.514674186706543\n",
      "    train time:               0.06380748748779297\n",
      "    test time:                0.01277303695678711\n",
      "    epoch time:               0.07738280296325684\n",
      "    joint lr:                 0.0009861958963236286\n",
      "epoch: 172 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       0.009417571955256991\n",
      "    train cross_ent loss:     0.00773066403861675\n",
      "    test overall loss:        0.14831012611587843\n",
      "    test cross_ent loss:      0.14662331528961658\n",
      "    cluster loss:             2949.2623697916665\n",
      "    separation loss:          2.2652585903803506\n",
      "    avg separation loss:      6.277977466583252\n",
      "    l1_addon loss:            39.07120132446289\n",
      "    l1 loss:                  0.514674186706543\n",
      "    train time:               0.06189680099487305\n",
      "    test time:                0.012595891952514648\n",
      "    epoch time:               0.07529044151306152\n",
      "    joint lr:                 0.001854667874720785\n",
      "epoch: 173 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.00771399468390478\n",
      "    train cross_ent loss:     0.006027135247778561\n",
      "    test overall loss:        0.13887604574362436\n",
      "    test cross_ent loss:      0.1371893665442864\n",
      "    cluster loss:             2949.2600911458335\n",
      "    separation loss:          2.246824940045675\n",
      "    avg separation loss:      6.214137077331543\n",
      "    l1_addon loss:            39.066986083984375\n",
      "    l1 loss:                  0.514674186706543\n",
      "    train time:               0.06281781196594238\n",
      "    test time:                0.012965202331542969\n",
      "    epoch time:               0.0766303539276123\n",
      "    joint lr:                 0.0027056817939603655\n",
      "epoch: 174 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.007636230438947678\n",
      "    train cross_ent loss:     0.005949283872420589\n",
      "    test overall loss:        0.11461908121903737\n",
      "    test cross_ent loss:      0.1129319096604983\n",
      "    cluster loss:             2949.266845703125\n",
      "    separation loss:          2.2627644141515098\n",
      "    avg separation loss:      6.246091206868489\n",
      "    l1_addon loss:            39.0833854675293\n",
      "    l1 loss:                  0.514674186706543\n",
      "    train time:               0.0616304874420166\n",
      "    test time:                0.012879610061645508\n",
      "    epoch time:               0.0753030776977539\n",
      "    joint lr:                 0.003539499968027705\n",
      "epoch: 175 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.007931045360035367\n",
      "    train cross_ent loss:     0.0062452478774098884\n",
      "    test overall loss:        0.11736643935243289\n",
      "    test cross_ent loss:      0.11568230887254079\n",
      "    cluster loss:             2949.2752278645835\n",
      "    separation loss:          2.287410259246826\n",
      "    avg separation loss:      6.25118891398112\n",
      "    l1_addon loss:            38.981956481933594\n",
      "    l1 loss:                  0.514674186706543\n",
      "    train time:               0.06188654899597168\n",
      "    test time:                0.01284337043762207\n",
      "    epoch time:               0.07554078102111816\n",
      "    joint lr:                 0.00435638121043428\n",
      "epoch: 176 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 97.33%\n",
      "    train overall loss:       0.007509015500545502\n",
      "    train cross_ent loss:     0.0058224512160652215\n",
      "    test overall loss:        0.10589490520457427\n",
      "    test cross_ent loss:      0.10420475403467815\n",
      "    cluster loss:             2949.273681640625\n",
      "    separation loss:          2.2762097120285034\n",
      "    avg separation loss:      6.242403030395508\n",
      "    l1_addon loss:            39.18268585205078\n",
      "    l1 loss:                  0.514674186706543\n",
      "    train time:               0.06485438346862793\n",
      "    test time:                0.012976884841918945\n",
      "    epoch time:               0.07865500450134277\n",
      "    joint lr:                 0.00515658087799592\n",
      "epoch: 177 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.004884670359186\n",
      "    train cross_ent loss:     0.003196749525765578\n",
      "    test overall loss:        0.11200662578145663\n",
      "    test cross_ent loss:      0.11032367342462142\n",
      "    cluster loss:             2949.279541015625\n",
      "    separation loss:          2.263234535853068\n",
      "    avg separation loss:      6.1565853754679365\n",
      "    l1_addon loss:            38.9426155090332\n",
      "    l1 loss:                  0.514674186706543\n",
      "    train time:               0.06181454658508301\n",
      "    test time:                0.012874364852905273\n",
      "    epoch time:               0.075469970703125\n",
      "    joint lr:                 0.005940350914085284\n",
      "epoch: 178 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.0031879264085243144\n",
      "    train cross_ent loss:     0.0015065937509967221\n",
      "    test overall loss:        0.11235943126181762\n",
      "    test cross_ent loss:      0.1106785920759042\n",
      "    cluster loss:             2949.286865234375\n",
      "    separation loss:          2.2741967837015786\n",
      "    avg separation loss:      6.153392950693767\n",
      "    l1_addon loss:            38.87236785888672\n",
      "    l1 loss:                  0.514674186706543\n",
      "    train time:               0.06170988082885742\n",
      "    test time:                0.012349367141723633\n",
      "    epoch time:               0.07492470741271973\n",
      "    joint lr:                 0.00670793989136506\n",
      "epoch: 179 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.0030926536872155136\n",
      "    train cross_ent loss:     0.0014104124986463124\n",
      "    test overall loss:        0.10936670439938705\n",
      "    test cross_ent loss:      0.10768285983552535\n",
      "    cluster loss:             2949.2749837239585\n",
      "    separation loss:          2.2343393166859946\n",
      "    avg separation loss:      6.081977367401123\n",
      "    l1_addon loss:            38.972259521484375\n",
      "    l1 loss:                  0.514674186706543\n",
      "    train time:               0.06093597412109375\n",
      "    test time:                0.012742042541503906\n",
      "    epoch time:               0.074432373046875\n",
      "    joint lr:                 0.007459593054007833\n",
      "epoch: 180 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.0037107135220948192\n",
      "    train cross_ent loss:     0.002030066130424125\n",
      "    test overall loss:        0.10871639102697372\n",
      "    test cross_ent loss:      0.10703755108018716\n",
      "    cluster loss:             2949.2804361979165\n",
      "    separation loss:          2.239488403002421\n",
      "    avg separation loss:      6.053989728291829\n",
      "    l1_addon loss:            38.80556869506836\n",
      "    l1 loss:                  0.514674186706543\n",
      "    train time:               0.0619509220123291\n",
      "    test time:                0.012940406799316406\n",
      "    epoch time:               0.07569217681884766\n",
      "    joint lr:                 0.008195552359408614\n",
      "epoch: 181 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       0.003176817929165231\n",
      "    train cross_ent loss:     0.0014959092853435625\n",
      "    test overall loss:        0.11673229994873206\n",
      "    test cross_ent loss:      0.1150500023116668\n",
      "    cluster loss:             2949.2749837239585\n",
      "    separation loss:          2.2308302323023477\n",
      "    avg separation loss:      6.038559277852376\n",
      "    l1_addon loss:            38.92083740234375\n",
      "    l1 loss:                  0.514674186706543\n",
      "    train time:               0.06198716163635254\n",
      "    test time:                0.01282501220703125\n",
      "    epoch time:               0.07560062408447266\n",
      "    joint lr:                 0.007713866994023813\n",
      "epoch: 182 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 95.67%\n",
      "    train overall loss:       0.002746240934357047\n",
      "    train cross_ent loss:     0.0010650304288396405\n",
      "    test overall loss:        0.1154758104433616\n",
      "    test cross_ent loss:      0.11379652159909408\n",
      "    cluster loss:             2949.2696126302085\n",
      "    separation loss:          2.2080912987391152\n",
      "    avg separation loss:      5.976467291514079\n",
      "    l1_addon loss:            38.82063293457031\n",
      "    l1 loss:                  0.514674186706543\n",
      "    train time:               0.061089277267456055\n",
      "    test time:                0.012825489044189453\n",
      "    epoch time:               0.0747373104095459\n",
      "    joint lr:                 0.007241005780710745\n",
      "epoch: 183 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.0026368341512150234\n",
      "    train cross_ent loss:     0.0009588296169466856\n",
      "    test overall loss:        0.10870684248705705\n",
      "    test cross_ent loss:      0.10702879106005032\n",
      "    cluster loss:             2949.2687174479165\n",
      "    separation loss:          2.1971811056137085\n",
      "    avg separation loss:      5.9599080085754395\n",
      "    l1_addon loss:            38.77935028076172\n",
      "    l1 loss:                  0.514674186706543\n",
      "    train time:               0.0619816780090332\n",
      "    test time:                0.012858152389526367\n",
      "    epoch time:               0.07575321197509766\n",
      "    joint lr:                 0.006776840404964548\n",
      "epoch: 184 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.0026514250526411664\n",
      "    train cross_ent loss:     0.0009721301838807347\n",
      "    test overall loss:        0.10130611124138038\n",
      "    test cross_ent loss:      0.09962637474139531\n",
      "    cluster loss:             2949.2674153645835\n",
      "    separation loss:          2.178602933883667\n",
      "    avg separation loss:      5.91429869333903\n",
      "    l1_addon loss:            38.835601806640625\n",
      "    l1 loss:                  0.514674186706543\n",
      "    train time:               0.06309199333190918\n",
      "    test time:                0.01347041130065918\n",
      "    epoch time:               0.07735919952392578\n",
      "    joint lr:                 0.006321244236155204\n",
      "epoch: 185 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.0020896141132753757\n",
      "    train cross_ent loss:     0.0004115014291730606\n",
      "    test overall loss:        0.10337489781280358\n",
      "    test cross_ent loss:      0.10169842404623826\n",
      "    cluster loss:             2949.2662760416665\n",
      "    separation loss:          2.15182363986969\n",
      "    avg separation loss:      5.803290367126465\n",
      "    l1_addon loss:            38.726863861083984\n",
      "    l1 loss:                  0.514674186706543\n",
      "    train time:               0.06090068817138672\n",
      "    test time:                0.01282358169555664\n",
      "    epoch time:               0.07450270652770996\n",
      "    joint lr:                 0.00587409230668155\n",
      "epoch: 186 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.0024542992727624047\n",
      "    train cross_ent loss:     0.0007786806543461151\n",
      "    test overall loss:        0.10346882604062557\n",
      "    test cross_ent loss:      0.1017938597748677\n",
      "    cluster loss:             2949.2687174479165\n",
      "    separation loss:          2.1551257769266763\n",
      "    avg separation loss:      5.793905576070149\n",
      "    l1_addon loss:            38.67644500732422\n",
      "    l1 loss:                  0.514674186706543\n",
      "    train time:               0.06220698356628418\n",
      "    test time:                0.01251840591430664\n",
      "    epoch time:               0.07555580139160156\n",
      "    joint lr:                 0.0054352612913737535\n",
      "epoch: 187 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.0021596208163019684\n",
      "    train cross_ent loss:     0.0004846359354107537\n",
      "    test overall loss:        0.10132535981635253\n",
      "    test cross_ent loss:      0.09965026161322992\n",
      "    cluster loss:             2949.2666829427085\n",
      "    separation loss:          2.1518744627634683\n",
      "    avg separation loss:      5.806039969126384\n",
      "    l1_addon loss:            38.680763244628906\n",
      "    l1 loss:                  0.514674186706543\n",
      "    train time:               0.06109619140625\n",
      "    test time:                0.01241159439086914\n",
      "    epoch time:               0.07462739944458008\n",
      "    joint lr:                 0.005004629487141445\n",
      "epoch: 188 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.0021928640522269737\n",
      "    train cross_ent loss:     0.0005181074666325003\n",
      "    test overall loss:        0.10088859374324481\n",
      "    test cross_ent loss:      0.09921431137869756\n",
      "    cluster loss:             2949.26611328125\n",
      "    separation loss:          2.1533978382746377\n",
      "    avg separation loss:      5.832233746846517\n",
      "    l1_addon loss:            38.65376663208008\n",
      "    l1 loss:                  0.514674186706543\n",
      "    train time:               0.06113839149475098\n",
      "    test time:                0.012495040893554688\n",
      "    epoch time:               0.07444095611572266\n",
      "    joint lr:                 0.004582076792864645\n",
      "epoch: 189 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.0019841590352977314\n",
      "    train cross_ent loss:     0.0003100398623953677\n",
      "    test overall loss:        0.0997410515944163\n",
      "    test cross_ent loss:      0.09806721781690915\n",
      "    cluster loss:             2949.26513671875\n",
      "    separation loss:          2.1514388720194497\n",
      "    avg separation loss:      5.847685178120931\n",
      "    l1_addon loss:            38.638763427734375\n",
      "    l1 loss:                  0.514674186706543\n",
      "    train time:               0.0596165657043457\n",
      "    test time:                0.012241840362548828\n",
      "    epoch time:               0.0725393295288086\n",
      "    joint lr:                 0.004167484689524657\n",
      "epoch: 190 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.002089783639854027\n",
      "    train cross_ent loss:     0.00041632550386970653\n",
      "    test overall loss:        0.10072781207660834\n",
      "    test cross_ent loss:      0.09905460383743048\n",
      "    cluster loss:             2949.26416015625\n",
      "    separation loss:          2.141204516092936\n",
      "    avg separation loss:      5.814537366231282\n",
      "    l1_addon loss:            38.61790466308594\n",
      "    l1 loss:                  0.514674186706543\n",
      "    train time:               0.06012320518493652\n",
      "    test time:                0.012679100036621094\n",
      "    epoch time:               0.0736844539642334\n",
      "    joint lr:                 0.003760736220572192\n",
      "epoch: 191 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.0020795037530155647\n",
      "    train cross_ent loss:     0.00040625630451055866\n",
      "    test overall loss:        0.10110984990994136\n",
      "    test cross_ent loss:      0.09943683755894502\n",
      "    cluster loss:             2949.2633463541665\n",
      "    separation loss:          2.138601620992025\n",
      "    avg separation loss:      5.812475204467773\n",
      "    l1_addon loss:            38.611236572265625\n",
      "    l1 loss:                  0.514674186706543\n",
      "    train time:               0.05975008010864258\n",
      "    test time:                0.012732505798339844\n",
      "    epoch time:               0.07324624061584473\n",
      "    joint lr:                 0.0033617159725298235\n",
      "epoch: 192 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.001979006363803314\n",
      "    train cross_ent loss:     0.0003064663873778449\n",
      "    test overall loss:        0.10143936115006606\n",
      "    test cross_ent loss:      0.09976730061074097\n",
      "    cluster loss:             2949.2632649739585\n",
      "    separation loss:          2.134687582651774\n",
      "    avg separation loss:      5.797353585561116\n",
      "    l1_addon loss:            38.57964324951172\n",
      "    l1 loss:                  0.514674186706543\n",
      "    train time:               0.06134343147277832\n",
      "    test time:                0.01265406608581543\n",
      "    epoch time:               0.07468795776367188\n",
      "    joint lr:                 0.002970310055826246\n",
      "epoch: 193 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.0018990506262828906\n",
      "    train cross_ent loss:     0.00022712933585151203\n",
      "    test overall loss:        0.10071641579270363\n",
      "    test cross_ent loss:      0.09904468432068825\n",
      "    cluster loss:             2949.262939453125\n",
      "    separation loss:          2.1382598876953125\n",
      "    avg separation loss:      5.805437246958415\n",
      "    l1_addon loss:            38.56859588623047\n",
      "    l1 loss:                  0.514674186706543\n",
      "    train time:               0.060132741928100586\n",
      "    test time:                0.012681245803833008\n",
      "    epoch time:               0.07355856895446777\n",
      "    joint lr:                 0.0025864060858594865\n",
      "epoch: 194 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.0021444880791629353\n",
      "    train cross_ent loss:     0.000472757599911549\n",
      "    test overall loss:        0.09978019880751769\n",
      "    test cross_ent loss:      0.09810869116336107\n",
      "    cluster loss:             2949.2637532552085\n",
      "    separation loss:          2.1446719964345298\n",
      "    avg separation loss:      5.835854212443034\n",
      "    l1_addon loss:            38.56110763549805\n",
      "    l1 loss:                  0.514674186706543\n",
      "    train time:               0.06105971336364746\n",
      "    test time:                0.012641668319702148\n",
      "    epoch time:               0.0744016170501709\n",
      "    joint lr:                 0.00220989316428648\n",
      "epoch: 195 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.0019695496497054896\n",
      "    train cross_ent loss:     0.00029846266261301935\n",
      "    test overall loss:        0.09944205234448115\n",
      "    test cross_ent loss:      0.09777143597602844\n",
      "    cluster loss:             2949.2625325520835\n",
      "    separation loss:          2.13501246770223\n",
      "    avg separation loss:      5.799548308054606\n",
      "    l1_addon loss:            38.531585693359375\n",
      "    l1 loss:                  0.514674186706543\n",
      "    train time:               0.06061601638793945\n",
      "    test time:                0.012663841247558594\n",
      "    epoch time:               0.07396626472473145\n",
      "    joint lr:                 0.0018406618605363474\n",
      "epoch: 196 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.0019438983225781056\n",
      "    train cross_ent loss:     0.0002735645167477843\n",
      "    test overall loss:        0.10087145771831274\n",
      "    test cross_ent loss:      0.09920137810210387\n",
      "    cluster loss:             2949.2621256510415\n",
      "    separation loss:          2.1223868131637573\n",
      "    avg separation loss:      5.752083619435628\n",
      "    l1_addon loss:            38.51367950439453\n",
      "    l1 loss:                  0.514674186706543\n",
      "    train time:               0.06259465217590332\n",
      "    test time:                0.012991666793823242\n",
      "    epoch time:               0.07639646530151367\n",
      "    joint lr:                 0.001478604193544789\n",
      "epoch: 197 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.002008063046054708\n",
      "    train cross_ent loss:     0.0003380718586009203\n",
      "    test overall loss:        0.10134817752987146\n",
      "    test cross_ent loss:      0.09967830870300531\n",
      "    cluster loss:             2949.2618001302085\n",
      "    separation loss:          2.121084729830424\n",
      "    avg separation loss:      5.743017514546712\n",
      "    l1_addon loss:            38.50648498535156\n",
      "    l1 loss:                  0.514674186706543\n",
      "    train time:               0.05893898010253906\n",
      "    test time:                0.01267385482788086\n",
      "    epoch time:               0.07238459587097168\n",
      "    joint lr:                 0.0011236136137069992\n",
      "epoch: 198 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.0021790225938376454\n",
      "    train cross_ent loss:     0.0005092291232560658\n",
      "    test overall loss:        0.09927364966521661\n",
      "    test cross_ent loss:      0.09760404999057452\n",
      "    cluster loss:             2949.2615559895835\n",
      "    separation loss:          2.122642000516256\n",
      "    avg separation loss:      5.74753999710083\n",
      "    l1_addon loss:            38.497467041015625\n",
      "    l1 loss:                  0.514674186706543\n",
      "    train time:               0.059908151626586914\n",
      "    test time:                0.012764930725097656\n",
      "    epoch time:               0.07346940040588379\n",
      "    joint lr:                 0.0007755849850466195\n",
      "epoch: 199 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.0019682167201406425\n",
      "    train cross_ent loss:     0.00029883420130419027\n",
      "    test overall loss:        0.10058017385502656\n",
      "    test cross_ent loss:      0.09891100445141394\n",
      "    cluster loss:             2949.2613932291665\n",
      "    separation loss:          2.119744896888733\n",
      "    avg separation loss:      5.732422510782878\n",
      "    l1_addon loss:            38.48323059082031\n",
      "    l1 loss:                  0.514674186706543\n",
      "    train time:               0.05898785591125488\n",
      "    test time:                0.012668132781982422\n",
      "    epoch time:               0.07244062423706055\n",
      "    joint lr:                 0.0004344145675980766\n",
      "epoch: 200 (JOINT) - ArticularyWordRecognition\n",
      "    test acc:                 96.67%\n",
      "    train overall loss:       0.0018404921671996515\n",
      "    train cross_ent loss:     0.00017137262168236903\n",
      "    test overall loss:        0.10005076508969069\n",
      "    test cross_ent loss:      0.098381700925529\n",
      "    cluster loss:             2949.2613118489585\n",
      "    separation loss:          2.1213483810424805\n",
      "    avg separation loss:      5.744445164998372\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  0.514674186706543\n",
      "    train time:               0.059328317642211914\n",
      "    test time:                0.012610435485839844\n",
      "    epoch time:               0.07272577285766602\n",
      "    joint lr:                 0.0001\n",
      "epoch: 200 (PUSH) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.0018404921671996515\n",
      "    train cross_ent loss:     0.00017137262168236903\n",
      "    test overall loss:        0.13280713185667992\n",
      "    test cross_ent loss:      0.13113806707163653\n",
      "    cluster loss:             2949.2599283854165\n",
      "    separation loss:          2.0650339126586914\n",
      "    avg separation loss:      5.733352343241374\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  0.514674186706543\n",
      "    train time:               0.059328317642211914\n",
      "    test time:                0.012904644012451172\n",
      "    epoch time:               0.40265464782714844\n",
      "epoch: 200 (1/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.009063388117485575\n",
      "    train cross_ent loss:     0.007580867218267586\n",
      "    test overall loss:        0.1345661555727323\n",
      "    test cross_ent loss:      0.13318576974173388\n",
      "    cluster loss:             2949.2605794270835\n",
      "    separation loss:          2.0643372933069863\n",
      "    avg separation loss:      5.73254919052124\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  0.2259977161884308\n",
      "    train time:               0.024342775344848633\n",
      "    test time:                0.012664318084716797\n",
      "    epoch time:               0.03752303123474121\n",
      "    last layer lr:            0.0007600000000000095\n",
      "epoch: 200 (2/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.005582431072576178\n",
      "    train cross_ent loss:     0.003703329505191909\n",
      "    test overall loss:        0.13468691085775694\n",
      "    test cross_ent loss:      0.13285686820745468\n",
      "    cluster loss:             2949.260498046875\n",
      "    separation loss:          2.060944755872091\n",
      "    avg separation loss:      5.720285733540853\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  0.6756531596183777\n",
      "    train time:               0.026585102081298828\n",
      "    test time:                0.012613058090209961\n",
      "    epoch time:               0.03970694541931152\n",
      "    last layer lr:            0.0014199999999999955\n",
      "epoch: 200 (3/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.007993170525878668\n",
      "    train cross_ent loss:     0.005853504446956019\n",
      "    test overall loss:        0.13378573892017206\n",
      "    test cross_ent loss:      0.13153769200046858\n",
      "    cluster loss:             2949.26025390625\n",
      "    separation loss:          2.0655899047851562\n",
      "    avg separation loss:      5.7318902015686035\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  1.0936524868011475\n",
      "    train time:               0.024829864501953125\n",
      "    test time:                0.012631893157958984\n",
      "    epoch time:               0.03797721862792969\n",
      "    last layer lr:            0.0020800000000000046\n",
      "epoch: 200 (4/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.007386172449009286\n",
      "    train cross_ent loss:     0.004888802708592266\n",
      "    test overall loss:        0.13324147400756678\n",
      "    test cross_ent loss:      0.1306587023039659\n",
      "    cluster loss:             2949.26025390625\n",
      "    separation loss:          2.064365347226461\n",
      "    avg separation loss:      5.726403713226318\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  1.4283764362335205\n",
      "    train time:               0.024645566940307617\n",
      "    test time:                0.012566328048706055\n",
      "    epoch time:               0.03772687911987305\n",
      "    last layer lr:            0.0027399999999999907\n",
      "epoch: 200 (5/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.007512421761122014\n",
      "    train cross_ent loss:     0.004658062748300533\n",
      "    test overall loss:        0.13443397544324398\n",
      "    test cross_ent loss:      0.13153322724004587\n",
      "    cluster loss:             2949.26025390625\n",
      "    separation loss:          2.0645638704299927\n",
      "    avg separation loss:      5.72499418258667\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  1.7463536262512207\n",
      "    train time:               0.024363040924072266\n",
      "    test time:                0.012628793716430664\n",
      "    epoch time:               0.037508249282836914\n",
      "    last layer lr:            0.0034\n",
      "epoch: 200 (6/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.008321821430904998\n",
      "    train cross_ent loss:     0.005001086599400474\n",
      "    test overall loss:        0.13373520659903684\n",
      "    test cross_ent loss:      0.1303333460042874\n",
      "    cluster loss:             2949.2605794270835\n",
      "    separation loss:          2.0673862298329673\n",
      "    avg separation loss:      5.732999801635742\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  2.2474703788757324\n",
      "    train time:               0.024475574493408203\n",
      "    test time:                0.013159036636352539\n",
      "    epoch time:               0.03815102577209473\n",
      "    last layer lr:            0.00406000000000001\n",
      "epoch: 200 (7/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.009145896985299058\n",
      "    train cross_ent loss:     0.005339334317896929\n",
      "    test overall loss:        0.13462895589570203\n",
      "    test cross_ent loss:      0.13061219888428846\n",
      "    cluster loss:             2949.260986328125\n",
      "    separation loss:          2.0681869188944497\n",
      "    avg separation loss:      5.73226531346639\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  2.8623647689819336\n",
      "    train time:               0.024555683135986328\n",
      "    test time:                0.01261448860168457\n",
      "    epoch time:               0.03768420219421387\n",
      "    last layer lr:            0.004719999999999996\n",
      "epoch: 200 (8/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.008446944101403156\n",
      "    train cross_ent loss:     0.004189769375241465\n",
      "    test overall loss:        0.135920329640309\n",
      "    test cross_ent loss:      0.13146400141219297\n",
      "    cluster loss:             2949.2604166666665\n",
      "    separation loss:          2.064162254333496\n",
      "    avg separation loss:      5.72484016418457\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  3.301940441131592\n",
      "    train time:               0.029137134552001953\n",
      "    test time:                0.0126953125\n",
      "    epoch time:               0.0423433780670166\n",
      "    last layer lr:            0.0053800000000000054\n",
      "epoch: 200 (9/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.010941030302395424\n",
      "    train cross_ent loss:     0.006208944237894482\n",
      "    test overall loss:        0.13594681148727736\n",
      "    test cross_ent loss:      0.13094447987775007\n",
      "    cluster loss:             2949.26025390625\n",
      "    separation loss:          2.064850370089213\n",
      "    avg separation loss:      5.734720230102539\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  3.8479342460632324\n",
      "    train time:               0.024288415908813477\n",
      "    test time:                0.012578487396240234\n",
      "    epoch time:               0.03737783432006836\n",
      "    last layer lr:            0.0060399999999999916\n",
      "epoch: 200 (10/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.011328638117346499\n",
      "    train cross_ent loss:     0.005813797651272681\n",
      "    test overall loss:        0.13529692714413008\n",
      "    test cross_ent loss:      0.1296437376489242\n",
      "    cluster loss:             2949.26025390625\n",
      "    separation loss:          2.069341858228048\n",
      "    avg separation loss:      5.741915861765544\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  4.4988017082214355\n",
      "    train time:               0.02393794059753418\n",
      "    test time:                0.012564897537231445\n",
      "    epoch time:               0.03702139854431152\n",
      "    last layer lr:            0.0067\n",
      "epoch: 200 (11/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.012548365423248874\n",
      "    train cross_ent loss:     0.006721302330131746\n",
      "    test overall loss:        0.1367120419939359\n",
      "    test cross_ent loss:      0.13054485556979975\n",
      "    cluster loss:             2949.2604166666665\n",
      "    separation loss:          2.068278749783834\n",
      "    avg separation loss:      5.7391730944315595\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  5.012791633605957\n",
      "    train time:               0.024322986602783203\n",
      "    test time:                0.012588024139404297\n",
      "    epoch time:               0.03741645812988281\n",
      "    last layer lr:            0.007360000000000011\n",
      "epoch: 200 (12/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.011098974591328038\n",
      "    train cross_ent loss:     0.004431152573993636\n",
      "    test overall loss:        0.13690880748132864\n",
      "    test cross_ent loss:      0.13023614324629307\n",
      "    cluster loss:             2949.260009765625\n",
      "    separation loss:          2.0624630451202393\n",
      "    avg separation loss:      5.718271255493164\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  5.5182695388793945\n",
      "    train time:               0.0256803035736084\n",
      "    test time:                0.01265573501586914\n",
      "    epoch time:               0.03883934020996094\n",
      "    last layer lr:            0.008019999999999994\n",
      "epoch: 200 (13/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.012075015240245394\n",
      "    train cross_ent loss:     0.005150678580523365\n",
      "    test overall loss:        0.13774998423953852\n",
      "    test cross_ent loss:      0.13089139821628729\n",
      "    cluster loss:             2949.2599283854165\n",
      "    separation loss:          2.062590559323629\n",
      "    avg separation loss:      5.720686594645183\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  5.704193115234375\n",
      "    train time:               0.023976564407348633\n",
      "    test time:                0.012609243392944336\n",
      "    epoch time:               0.037094831466674805\n",
      "    last layer lr:            0.008680000000000005\n",
      "epoch: 200 (14/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.010536331114255719\n",
      "    train cross_ent loss:     0.0034851986112900907\n",
      "    test overall loss:        0.13900954090058804\n",
      "    test cross_ent loss:      0.1319382699827353\n",
      "    cluster loss:             2949.2603352864585\n",
      "    separation loss:          2.06097404162089\n",
      "    avg separation loss:      5.7176235516866045\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  5.916877746582031\n",
      "    train time:               0.02378368377685547\n",
      "    test time:                0.012583494186401367\n",
      "    epoch time:               0.036871910095214844\n",
      "    last layer lr:            0.00933999999999999\n",
      "epoch: 200 (15/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.011899985269539885\n",
      "    train cross_ent loss:     0.004318054972423447\n",
      "    test overall loss:        0.13883618575831255\n",
      "    test cross_ent loss:      0.13104287845393023\n",
      "    cluster loss:             2949.260009765625\n",
      "    separation loss:          2.0656153361002603\n",
      "    avg separation loss:      5.732804139455159\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  6.638915061950684\n",
      "    train time:               0.02616143226623535\n",
      "    test time:                0.01293635368347168\n",
      "    epoch time:               0.03960371017456055\n",
      "    last layer lr:            0.01\n",
      "epoch: 200 (16/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.012855986133217812\n",
      "    train cross_ent loss:     0.004997348309391075\n",
      "    test overall loss:        0.13901052810251713\n",
      "    test cross_ent loss:      0.1309735265870889\n",
      "    cluster loss:             2949.260498046875\n",
      "    separation loss:          2.0682162046432495\n",
      "    avg separation loss:      5.748158613840739\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  6.882610321044922\n",
      "    train time:               0.024739980697631836\n",
      "    test time:                0.012923002243041992\n",
      "    epoch time:               0.03817129135131836\n",
      "    last layer lr:            0.009603999999999994\n",
      "epoch: 200 (17/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.014140006051295333\n",
      "    train cross_ent loss:     0.006021103653539386\n",
      "    test overall loss:        0.1399754397571087\n",
      "    test cross_ent loss:      0.1313846999158462\n",
      "    cluster loss:             2949.2606608072915\n",
      "    separation loss:          2.063579559326172\n",
      "    avg separation loss:      5.733226776123047\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  7.436342239379883\n",
      "    train time:               0.024457693099975586\n",
      "    test time:                0.012915372848510742\n",
      "    epoch time:               0.03789210319519043\n",
      "    last layer lr:            0.009208000000000003\n",
      "epoch: 200 (18/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.012331882388227515\n",
      "    train cross_ent loss:     0.00374292424466047\n",
      "    test overall loss:        0.1385502809037765\n",
      "    test cross_ent loss:      0.130320622275273\n",
      "    cluster loss:             2949.2606608072915\n",
      "    separation loss:          2.0707754691441855\n",
      "    avg separation loss:      5.760406653086345\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  7.075268745422363\n",
      "    train time:               0.024533987045288086\n",
      "    test time:                0.013400554656982422\n",
      "    epoch time:               0.03844451904296875\n",
      "    last layer lr:            0.008811999999999997\n",
      "epoch: 200 (19/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.012492954110105833\n",
      "    train cross_ent loss:     0.004510340474856396\n",
      "    test overall loss:        0.13916672704120478\n",
      "    test cross_ent loss:      0.13135850181182226\n",
      "    cluster loss:             2949.2606608072915\n",
      "    separation loss:          2.0727292696634927\n",
      "    avg separation loss:      5.760802745819092\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  6.653837203979492\n",
      "    train time:               0.02476644515991211\n",
      "    test time:                0.013017654418945312\n",
      "    epoch time:               0.03828763961791992\n",
      "    last layer lr:            0.008416000000000005\n",
      "epoch: 200 (20/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.011797090992331505\n",
      "    train cross_ent loss:     0.004212516760970984\n",
      "    test overall loss:        0.13817669761677584\n",
      "    test cross_ent loss:      0.13065293865899244\n",
      "    cluster loss:             2949.2598470052085\n",
      "    separation loss:          2.0645118157068887\n",
      "    avg separation loss:      5.728507995605469\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  6.369365692138672\n",
      "    train time:               0.024557113647460938\n",
      "    test time:                0.012916803359985352\n",
      "    epoch time:               0.03797769546508789\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 200 (21/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.010978813697066572\n",
      "    train cross_ent loss:     0.0037508177726219096\n",
      "    test overall loss:        0.138190982863307\n",
      "    test cross_ent loss:      0.13101722051699957\n",
      "    cluster loss:             2949.260009765625\n",
      "    separation loss:          2.0637377500534058\n",
      "    avg separation loss:      5.731178283691406\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  6.019372463226318\n",
      "    train time:               0.024976015090942383\n",
      "    test time:                0.012945175170898438\n",
      "    epoch time:               0.03843092918395996\n",
      "    last layer lr:            0.007623999999999995\n",
      "epoch: 200 (22/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.011148741882708337\n",
      "    train cross_ent loss:     0.004145859003377457\n",
      "    test overall loss:        0.1367435430486997\n",
      "    test cross_ent loss:      0.12982597636679807\n",
      "    cluster loss:             2949.2604166666665\n",
      "    separation loss:          2.066470185915629\n",
      "    avg separation loss:      5.734947522481282\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  5.763176918029785\n",
      "    train time:               0.02472400665283203\n",
      "    test time:                0.012898683547973633\n",
      "    epoch time:               0.03813481330871582\n",
      "    last layer lr:            0.0072280000000000035\n",
      "epoch: 200 (23/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.009844257599777646\n",
      "    train cross_ent loss:     0.0032276496317030657\n",
      "    test overall loss:        0.1369463490943114\n",
      "    test cross_ent loss:      0.13033518133064112\n",
      "    cluster loss:             2949.2601725260415\n",
      "    separation loss:          2.0642442305882773\n",
      "    avg separation loss:      5.728385130564372\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  5.456775665283203\n",
      "    train time:               0.024536848068237305\n",
      "    test time:                0.012907743453979492\n",
      "    epoch time:               0.0379486083984375\n",
      "    last layer lr:            0.006831999999999998\n",
      "epoch: 200 (24/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.00865534542956286\n",
      "    train cross_ent loss:     0.0023844028797207605\n",
      "    test overall loss:        0.13545009680092335\n",
      "    test cross_ent loss:      0.12945731232563654\n",
      "    cluster loss:             2949.2604166666665\n",
      "    separation loss:          2.0656745433807373\n",
      "    avg separation loss:      5.731531620025635\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  4.83839225769043\n",
      "    train time:               0.024953126907348633\n",
      "    test time:                0.012972354888916016\n",
      "    epoch time:               0.03843426704406738\n",
      "    last layer lr:            0.006436000000000007\n",
      "epoch: 200 (25/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.008814370518343316\n",
      "    train cross_ent loss:     0.0030065381239789226\n",
      "    test overall loss:        0.13586529282232127\n",
      "    test cross_ent loss:      0.1301994826644659\n",
      "    cluster loss:             2949.260498046875\n",
      "    separation loss:          2.0690743128458657\n",
      "    avg separation loss:      5.742715517679851\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  4.5114216804504395\n",
      "    train time:               0.024809837341308594\n",
      "    test time:                0.012932538986206055\n",
      "    epoch time:               0.03825879096984863\n",
      "    last layer lr:            0.00604\n",
      "epoch: 200 (26/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.00990843198572596\n",
      "    train cross_ent loss:     0.00432441767770797\n",
      "    test overall loss:        0.13498939822117487\n",
      "    test cross_ent loss:      0.1293966956436634\n",
      "    cluster loss:             2949.26025390625\n",
      "    separation loss:          2.065693457921346\n",
      "    avg separation loss:      5.727604389190674\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  4.4383087158203125\n",
      "    train time:               0.02452397346496582\n",
      "    test time:                0.012921810150146484\n",
      "    epoch time:               0.03795027732849121\n",
      "    last layer lr:            0.0056439999999999945\n",
      "epoch: 200 (27/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.008804800920188427\n",
      "    train cross_ent loss:     0.0034725016319296425\n",
      "    test overall loss:        0.13509491520623365\n",
      "    test cross_ent loss:      0.12983987169961134\n",
      "    cluster loss:             2949.2603352864585\n",
      "    separation loss:          2.0669031143188477\n",
      "    avg separation loss:      5.731265068054199\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  4.10065221786499\n",
      "    train time:               0.025023698806762695\n",
      "    test time:                0.012946605682373047\n",
      "    epoch time:               0.038484811782836914\n",
      "    last layer lr:            0.005248000000000003\n",
      "epoch: 200 (28/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.00792447958762447\n",
      "    train cross_ent loss:     0.002853953547956836\n",
      "    test overall loss:        0.13498005581398806\n",
      "    test cross_ent loss:      0.1301400394489368\n",
      "    cluster loss:             2949.2603352864585\n",
      "    separation loss:          2.0649812618891397\n",
      "    avg separation loss:      5.732184251149495\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  3.685624122619629\n",
      "    train time:               0.024841785430908203\n",
      "    test time:                0.012971878051757812\n",
      "    epoch time:               0.03833580017089844\n",
      "    last layer lr:            0.004851999999999998\n",
      "epoch: 200 (29/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.009445151779800653\n",
      "    train cross_ent loss:     0.0047476268373429775\n",
      "    test overall loss:        0.1352164689451456\n",
      "    test cross_ent loss:      0.1305272982766231\n",
      "    cluster loss:             2949.2609049479165\n",
      "    separation loss:          2.06393826007843\n",
      "    avg separation loss:      5.723278681437175\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  3.5347766876220703\n",
      "    train time:               0.027095794677734375\n",
      "    test time:                0.012917518615722656\n",
      "    epoch time:               0.04053211212158203\n",
      "    last layer lr:            0.004456000000000006\n",
      "epoch: 200 (30/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.007329581357124779\n",
      "    train cross_ent loss:     0.0027650074205464786\n",
      "    test overall loss:        0.13401941830913225\n",
      "    test cross_ent loss:      0.12954749229053655\n",
      "    cluster loss:             2949.2601725260415\n",
      "    separation loss:          2.0652130047480264\n",
      "    avg separation loss:      5.732568899790446\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  3.317531108856201\n",
      "    train time:               0.025052785873413086\n",
      "    test time:                0.012981891632080078\n",
      "    epoch time:               0.038539886474609375\n",
      "    last layer lr:            0.004060000000000001\n",
      "epoch: 200 (31/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.008792197435266443\n",
      "    train cross_ent loss:     0.004512009993454235\n",
      "    test overall loss:        0.13399704111119112\n",
      "    test cross_ent loss:      0.12972467020154\n",
      "    cluster loss:             2949.2603352864585\n",
      "    separation loss:          2.0655014514923096\n",
      "    avg separation loss:      5.739763259887695\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  3.1179773807525635\n",
      "    train time:               0.02452850341796875\n",
      "    test time:                0.012903451919555664\n",
      "    epoch time:               0.037946224212646484\n",
      "    last layer lr:            0.0036639999999999945\n",
      "epoch: 200 (32/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.00%\n",
      "    train overall loss:       0.007137425864736239\n",
      "    train cross_ent loss:     0.003060978015936497\n",
      "    test overall loss:        0.1342438751210769\n",
      "    test cross_ent loss:      0.13029049398998419\n",
      "    cluster loss:             2949.260498046875\n",
      "    separation loss:          2.0678926706314087\n",
      "    avg separation loss:      5.735922495524089\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  2.7989864349365234\n",
      "    train time:               0.024486780166625977\n",
      "    test time:                0.012935400009155273\n",
      "    epoch time:               0.03793215751647949\n",
      "    last layer lr:            0.003268000000000003\n",
      "epoch: 200 (33/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.00679047591984272\n",
      "    train cross_ent loss:     0.0030412192184788487\n",
      "    test overall loss:        0.13292675403257212\n",
      "    test cross_ent loss:      0.12925822411974272\n",
      "    cluster loss:             2949.2606608072915\n",
      "    separation loss:          2.070879658063253\n",
      "    avg separation loss:      5.751095612843831\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  2.514133930206299\n",
      "    train time:               0.024897336959838867\n",
      "    test time:                0.012924432754516602\n",
      "    epoch time:               0.03833603858947754\n",
      "    last layer lr:            0.002871999999999997\n",
      "epoch: 200 (34/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.007729558274149895\n",
      "    train cross_ent loss:     0.004297400287921644\n",
      "    test overall loss:        0.13183675644298395\n",
      "    test cross_ent loss:      0.1285080766926209\n",
      "    cluster loss:             2949.260498046875\n",
      "    separation loss:          2.0702494780222573\n",
      "    avg separation loss:      5.747623602549235\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  2.174285411834717\n",
      "    train time:               0.024868011474609375\n",
      "    test time:                0.012914657592773438\n",
      "    epoch time:               0.03829479217529297\n",
      "    last layer lr:            0.0024760000000000055\n",
      "epoch: 200 (35/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.006465966295864847\n",
      "    train cross_ent loss:     0.003332853000352366\n",
      "    test overall loss:        0.13162453720966974\n",
      "    test cross_ent loss:      0.12857905278603235\n",
      "    cluster loss:             2949.2605794270835\n",
      "    separation loss:          2.0711569786071777\n",
      "    avg separation loss:      5.754445870717366\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  1.8910930156707764\n",
      "    train time:               0.02458047866821289\n",
      "    test time:                0.012916803359985352\n",
      "    epoch time:               0.03800368309020996\n",
      "    last layer lr:            0.0020800000000000003\n",
      "epoch: 200 (36/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.006556952837854624\n",
      "    train cross_ent loss:     0.0036734250800994537\n",
      "    test overall loss:        0.13184445599714914\n",
      "    test cross_ent loss:      0.12905336543917656\n",
      "    cluster loss:             2949.260498046875\n",
      "    separation loss:          2.067774176597595\n",
      "    avg separation loss:      5.736430644989014\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  1.63669753074646\n",
      "    train time:               0.024965524673461914\n",
      "    test time:                0.012913227081298828\n",
      "    epoch time:               0.038387298583984375\n",
      "    last layer lr:            0.0016839999999999945\n",
      "epoch: 200 (37/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.0072205085307359695\n",
      "    train cross_ent loss:     0.004607373596324275\n",
      "    test overall loss:        0.13207551588614783\n",
      "    test cross_ent loss:      0.12956796338160834\n",
      "    cluster loss:             2949.2607421875\n",
      "    separation loss:          2.0692943731943765\n",
      "    avg separation loss:      5.745223522186279\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  1.3531606197357178\n",
      "    train time:               0.026729583740234375\n",
      "    test time:                0.012904882431030273\n",
      "    epoch time:               0.04013872146606445\n",
      "    last layer lr:            0.001288000000000003\n",
      "epoch: 200 (38/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.004883423344128662\n",
      "    train cross_ent loss:     0.002565357581867526\n",
      "    test overall loss:        0.13056456111371517\n",
      "    test cross_ent loss:      0.1283551094432672\n",
      "    cluster loss:             2949.2601725260415\n",
      "    separation loss:          2.067446748415629\n",
      "    avg separation loss:      5.74196736017863\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  1.0550545454025269\n",
      "    train time:               0.024513721466064453\n",
      "    test time:                0.012902021408081055\n",
      "    epoch time:               0.03792071342468262\n",
      "    last layer lr:            0.0008919999999999973\n",
      "epoch: 200 (39/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.005821936919043462\n",
      "    train cross_ent loss:     0.0038005123755687643\n",
      "    test overall loss:        0.1306306030601263\n",
      "    test cross_ent loss:      0.1287033756573995\n",
      "    cluster loss:             2949.2603352864585\n",
      "    separation loss:          2.0706146558125815\n",
      "    avg separation loss:      5.748219013214111\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  0.7728368043899536\n",
      "    train time:               0.02499699592590332\n",
      "    test time:                0.012941360473632812\n",
      "    epoch time:               0.03844475746154785\n",
      "    last layer lr:            0.0004960000000000057\n",
      "epoch: 200 (40/40) (LAST_LAYER) - ArticularyWordRecognition\n",
      "    test acc:                 96.33%\n",
      "    train overall loss:       0.005811293143779039\n",
      "    train cross_ent loss:     0.004067760575304015\n",
      "    test overall loss:        0.1295087660352389\n",
      "    test cross_ent loss:      0.12784521405895552\n",
      "    cluster loss:             2949.2605794270835\n",
      "    separation loss:          2.0736641883850098\n",
      "    avg separation loss:      5.763351122538249\n",
      "    l1_addon loss:            38.47968292236328\n",
      "    l1 loss:                  0.5091629028320312\n",
      "    train time:               0.024718284606933594\n",
      "    test time:                0.012876749038696289\n",
      "    epoch time:               0.038102149963378906\n",
      "    last layer lr:            0.0001\n",
      "Finished training in 31.05 seconds\n",
      "Last epoch test accu: 96.33%\n",
      "Done in 200 epochs, 42.16s\n"
     ]
    }
   ],
   "source": [
    "experiment_name = \"HyperparameterOptimized\"\n",
    "\n",
    "best_params = pd.read_csv('best_params.csv', index_col=0)\n",
    "\n",
    "default_params = {\n",
    "    \"coeffs\": ProtoTSCoeffs(crs_ent=1, clst=0, sep=0, l1=1e-3, l1_addon=3e-5),\n",
    "    \"reception\": 0.25,\n",
    "    \"proto_len\": 5,\n",
    "    \"protos_per_class\": 10,\n",
    "    \"proto_features\": 32,\n",
    "    \"features_lr\": 1e-3,\n",
    "    \"push_start_epoch\": 110,\n",
    "    \"num_last_layer_epochs\": 40,\n",
    "}\n",
    "\n",
    "for run in range(1, 6):\n",
    "    for ds_name, dataset in all_ds.items():\n",
    "        ds_info = ds_get_info(dataset.name)\n",
    "\n",
    "        proto_len = int(best_params.loc[ds_name, 'proto_len'])\n",
    "        reception = float(best_params.loc[ds_name, 'reception'])\n",
    "        epochs = int(best_params.loc[ds_name, 'epochs'])\n",
    "        curr_experiment_dir = experiment_setup(f\"{experiment_name}/{dataset.name}/run-{run}\")\n",
    "\n",
    "        log, logclose = create_logger(curr_experiment_dir / \"log.txt\", display=True)\n",
    "\n",
    "        try:\n",
    "            if os.path.exists(curr_experiment_dir / 'models' / 'last-epoch.pth'):\n",
    "                print(f\"Skipping training for {dataset.name}, already done\")\n",
    "                continue\n",
    "\n",
    "            curr_link_path = Path.cwd() / 'experiments' / experiment_name / 'current'\n",
    "            if os.path.islink(curr_link_path):\n",
    "                os.unlink(curr_link_path)\n",
    "            os.symlink(curr_experiment_dir, curr_link_path)\n",
    "            \n",
    "            curr_log_link_path = Path.cwd() / 'experiments' / experiment_name / 'curr_log.txt'\n",
    "            if os.path.islink(curr_log_link_path):\n",
    "                os.unlink(curr_log_link_path)\n",
    "            os.symlink(curr_experiment_dir / 'log.txt', curr_log_link_path)\n",
    "            \n",
    "            features_lr = default_params[\"features_lr\"]\n",
    "\n",
    "            protos_per_class = default_params[\"protos_per_class\"]\n",
    "            proto_features = default_params[\"proto_features\"]\n",
    "            train_batch_size = 32\n",
    "            while train_batch_size > len(dataset.train.X) / 2:\n",
    "                train_batch_size //= 2\n",
    "            test_batch_size = 128\n",
    "            coeffs = default_params[\"coeffs\"]\n",
    "            padding = 'same'\n",
    "\n",
    "            push_start_epoch = default_params[\"push_start_epoch\"]\n",
    "            num_warm_epochs = 50\n",
    "            num_last_layer_epochs = default_params[\"num_last_layer_epochs\"]\n",
    "            push_epochs = range(push_start_epoch, 1000, 30)\n",
    "\n",
    "            params = {\n",
    "                \"protos_per_class\": protos_per_class,\n",
    "                \"proto_features\": proto_features,\n",
    "                \"proto_len_latent\": proto_len,\n",
    "                \"features_lr\": features_lr,\n",
    "                \"num_classes\": ds_info.num_classes,\n",
    "                \"protos_per_class\": protos_per_class,\n",
    "                \"coeffs\": coeffs._asdict(),\n",
    "                \"num_warm_epochs\": num_warm_epochs,\n",
    "                \"push_start_epoch\": push_start_epoch,\n",
    "                \"num_last_layer_epochs\": num_last_layer_epochs,\n",
    "                \"epochs\": epochs,\n",
    "            }\n",
    "            with open(curr_experiment_dir / \"params.json\", \"w\") as f:\n",
    "                json.dump(params, f, indent=4)\n",
    "\n",
    "            log(\n",
    "                f\"Training for {dataset.name}, proto len {proto_len}, reception {reception}, features_lr {features_lr}, protos per class {protos_per_class}, l1_addon {coeffs.l1_addon}\",\n",
    "                flush=True,\n",
    "                display=True\n",
    "            )\n",
    "            log(f'Params: {json.dumps(params, indent=4)}')\n",
    "            \n",
    "            whole_training_start = time.time()\n",
    "\n",
    "            log(f'Training encoder', flush=True, display=True)\n",
    "            autoencoder = PermutingConvAutoencoder(num_features=ds_info.features, latent_features=proto_features, reception_percent=reception, padding=padding)\n",
    "            train_ds = TSCDataset(dataset.train.X, dataset.train.y)\n",
    "            train_loader = torch.utils.data.DataLoader(dataset.train, batch_size=train_batch_size, shuffle=True)\n",
    "            test_loader = torch.utils.data.DataLoader(dataset.test, batch_size=test_batch_size)\n",
    "            train_autoencoder(autoencoder, train_loader, test_loader, device=device, log=log)\n",
    "            encoder = autoencoder.encoder\n",
    "\n",
    "            log(f'Training ProtoTSNet', flush=True, display=True)\n",
    "            trainer = train_prototsnet(\n",
    "                dataset,\n",
    "                curr_experiment_dir,\n",
    "                device,\n",
    "                encoder,\n",
    "                features_lr,\n",
    "                coeffs,\n",
    "                protos_per_class,\n",
    "                proto_features,\n",
    "                proto_len,\n",
    "                train_batch_size,\n",
    "                test_batch_size,\n",
    "                num_epochs=epochs,\n",
    "                num_warm_epochs=num_warm_epochs,\n",
    "                push_start_epoch=push_start_epoch,\n",
    "                push_epochs=push_epochs,\n",
    "                ds_info=ds_info,\n",
    "                num_last_layer_epochs=num_last_layer_epochs,\n",
    "                custom_checkpointers=[\n",
    "                    get_verbose_logger(dataset.name),\n",
    "                ],\n",
    "                log=log,\n",
    "            )\n",
    "\n",
    "            accu_test = trainer.latest_stat(\"accu_test\")\n",
    "            log(f'Last epoch test accu: {accu_test*100:.2f}%', display=True)\n",
    "            with open(curr_experiment_dir / \"test_accu.json\", \"w\") as f:\n",
    "                json.dump({\"value\": accu_test}, f, indent=4)\n",
    "            \n",
    "            ptsnet = trainer.ptsnet\n",
    "            confusion_matrix = torch.zeros(ptsnet.num_classes, ptsnet.num_classes)\n",
    "            for i, (image, label) in enumerate(test_loader):\n",
    "                output, _ = ptsnet(image.to(device))\n",
    "                confusion_matrix += multiclass_confusion_matrix(output.to('cpu'), label, num_classes=output.shape[1])\n",
    "            np.savetxt(curr_experiment_dir / 'confusion_matrix.txt', confusion_matrix.numpy(), fmt='%4d')\n",
    "\n",
    "            whole_training_end = time.time()\n",
    "            log(f\"Done in {trainer.curr_epoch - 1} epochs, {whole_training_end - whole_training_start:.2f}s\", display=True)\n",
    "        except Exception as e:\n",
    "            log(f\"Exception ocurred for {ds_name}: {e}\", display=True)\n",
    "            tb_str = traceback.format_tb(e.__traceback__)\n",
    "            log('\\n'.join(tb_str), display=True)\n",
    "        finally:\n",
    "            logclose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c735e16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for Libras, proto len 13, reception 0.9, features_lr 0.0001, protos per class 3, l1_addon 0.0001\n",
      "Params: {\n",
      "    \"protos_per_class\": 3,\n",
      "    \"proto_features\": 32,\n",
      "    \"proto_len_latent\": 13,\n",
      "    \"features_lr\": 0.0001,\n",
      "    \"num_classes\": 15,\n",
      "    \"coeffs\": {\n",
      "        \"crs_ent\": 1,\n",
      "        \"clst\": 0,\n",
      "        \"sep\": 0,\n",
      "        \"l1\": 0.001,\n",
      "        \"l1_addon\": 0.0001\n",
      "    },\n",
      "    \"num_warm_epochs\": 50,\n",
      "    \"push_start_epoch\": 110,\n",
      "    \"num_last_layer_epochs\": 40,\n",
      "    \"epochs\": 200\n",
      "}\n",
      "Training encoder\n",
      "epoch:   10/300 mse loss: 0.0065\n",
      "epoch:   20/300 mse loss: 0.0016\n",
      "epoch:   30/300 mse loss: 0.0008\n",
      "epoch:   40/300 mse loss: 0.0009\n",
      "epoch:   50/300 mse loss: 0.0007\n",
      "epoch:   60/300 mse loss: 0.0006\n",
      "epoch:   70/300 mse loss: 0.0007\n",
      "epoch:   80/300 mse loss: 0.0007\n",
      "epoch:   90/300 mse loss: 0.0009\n",
      "epoch:  100/300 mse loss: 0.0010\n",
      "epoch:  110/300 mse loss: 0.0006\n",
      "epoch:  120/300 mse loss: 0.0007\n",
      "epoch:  130/300 mse loss: 0.0007\n",
      "epoch:  140/300 mse loss: 0.0007\n",
      "epoch:  150/300 mse loss: 0.0007\n",
      "epoch:  160/300 mse loss: 0.0007\n",
      "epoch:  170/300 mse loss: 0.0007\n",
      "epoch:  180/300 mse loss: 0.0007\n",
      "epoch:  190/300 mse loss: 0.0007\n",
      "epoch:  200/300 mse loss: 0.0007\n",
      "epoch:  210/300 mse loss: 0.0008\n",
      "epoch:  220/300 mse loss: 0.0007\n",
      "epoch:  230/300 mse loss: 0.0008\n",
      "epoch:  240/300 mse loss: 0.0008\n",
      "epoch:  250/300 mse loss: 0.0007\n",
      "epoch:  260/300 mse loss: 0.0007\n",
      "epoch:  270/300 mse loss: 0.0008\n",
      "epoch:  280/300 mse loss: 0.0007\n",
      "epoch:  290/300 mse loss: 0.0008\n",
      "epoch:  300/300 mse loss: 0.0008\n",
      "Training ProtoTSNet\n",
      "Starting training\n",
      "epoch:   1 (WARM) - Libras\n",
      "    test acc:                 6.67%\n",
      "    train overall loss:       3.042051116625468\n",
      "    train cross_ent loss:     2.7080649932225547\n",
      "    test overall loss:        3.041056275367737\n",
      "    test cross_ent loss:      2.7080549001693726\n",
      "    cluster loss:             416.0\n",
      "    separation loss:          475.31996154785156\n",
      "    avg separation loss:      594.307373046875\n",
      "    l1_addon loss:            180.01234436035156\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017900705337524414\n",
      "    test time:                0.004403352737426758\n",
      "    epoch time:               0.022855281829833984\n",
      "epoch:   2 (WARM) - Libras\n",
      "    test acc:                 6.67%\n",
      "    train overall loss:       3.040084799130758\n",
      "    train cross_ent loss:     2.707746942838033\n",
      "    test overall loss:        3.0394999980926514\n",
      "    test cross_ent loss:      2.7080705165863037\n",
      "    cluster loss:             347.5613708496094\n",
      "    separation loss:          272.0902862548828\n",
      "    avg separation loss:      311.0633850097656\n",
      "    l1_addon loss:            164.2934112548828\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017320632934570312\n",
      "    test time:                0.004622697830200195\n",
      "    epoch time:               0.022487163543701172\n",
      "epoch:   3 (WARM) - Libras\n",
      "    test acc:                 5.00%\n",
      "    train overall loss:       3.0382667779922485\n",
      "    train cross_ent loss:     2.707452932993571\n",
      "    test overall loss:        3.0380297899246216\n",
      "    test cross_ent loss:      2.7080453634262085\n",
      "    cluster loss:             276.5121383666992\n",
      "    separation loss:          147.7726058959961\n",
      "    avg separation loss:      170.010986328125\n",
      "    l1_addon loss:            149.84332275390625\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017383098602294922\n",
      "    test time:                0.004339456558227539\n",
      "    epoch time:               0.02226424217224121\n",
      "epoch:   4 (WARM) - Libras\n",
      "    test acc:                 6.11%\n",
      "    train overall loss:       3.0366543531417847\n",
      "    train cross_ent loss:     2.707223415374756\n",
      "    test overall loss:        3.0365731716156006\n",
      "    test cross_ent loss:      2.707900285720825\n",
      "    cluster loss:             251.74373626708984\n",
      "    separation loss:          104.60440826416016\n",
      "    avg separation loss:      116.31082916259766\n",
      "    l1_addon loss:            136.72865295410156\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017304182052612305\n",
      "    test time:                0.004630565643310547\n",
      "    epoch time:               0.022475719451904297\n",
      "epoch:   5 (WARM) - Libras\n",
      "    test acc:                 4.44%\n",
      "    train overall loss:       3.035147468249003\n",
      "    train cross_ent loss:     2.7069841225941977\n",
      "    test overall loss:        3.035163402557373\n",
      "    test cross_ent loss:      2.707700490951538\n",
      "    cluster loss:             247.40872955322266\n",
      "    separation loss:          97.16201400756836\n",
      "    avg separation loss:      106.26104736328125\n",
      "    l1_addon loss:            124.62834167480469\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017359256744384766\n",
      "    test time:                0.004467010498046875\n",
      "    epoch time:               0.02236652374267578\n",
      "epoch:   6 (WARM) - Libras\n",
      "    test acc:                 16.11%\n",
      "    train overall loss:       3.0338151852289834\n",
      "    train cross_ent loss:     2.706824779510498\n",
      "    test overall loss:        3.033642530441284\n",
      "    test cross_ent loss:      2.707292079925537\n",
      "    cluster loss:             246.21761322021484\n",
      "    separation loss:          95.09600830078125\n",
      "    avg separation loss:      105.82391738891602\n",
      "    l1_addon loss:            113.50313568115234\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.01725602149963379\n",
      "    test time:                0.004405498504638672\n",
      "    epoch time:               0.02220320701599121\n",
      "epoch:   7 (WARM) - Libras\n",
      "    test acc:                 13.89%\n",
      "    train overall loss:       3.0323745807011924\n",
      "    train cross_ent loss:     2.7064449389775596\n",
      "    test overall loss:        3.0322604179382324\n",
      "    test cross_ent loss:      2.7068915367126465\n",
      "    cluster loss:             244.92027282714844\n",
      "    separation loss:          93.09332275390625\n",
      "    avg separation loss:      104.67466735839844\n",
      "    l1_addon loss:            103.6888427734375\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017280101776123047\n",
      "    test time:                0.005225419998168945\n",
      "    epoch time:               0.023044586181640625\n",
      "epoch:   8 (WARM) - Libras\n",
      "    test acc:                 16.67%\n",
      "    train overall loss:       3.031110167503357\n",
      "    train cross_ent loss:     2.7061042388280234\n",
      "    test overall loss:        3.0309559106826782\n",
      "    test cross_ent loss:      2.7064303159713745\n",
      "    cluster loss:             242.46820068359375\n",
      "    separation loss:          89.42123413085938\n",
      "    avg separation loss:      101.65641784667969\n",
      "    l1_addon loss:            95.2560043334961\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017278671264648438\n",
      "    test time:                0.0043795108795166016\n",
      "    epoch time:               0.022207260131835938\n",
      "epoch:   9 (WARM) - Libras\n",
      "    test acc:                 19.44%\n",
      "    train overall loss:       3.029922366142273\n",
      "    train cross_ent loss:     2.705704927444458\n",
      "    test overall loss:        3.0295804738998413\n",
      "    test cross_ent loss:      2.7057732343673706\n",
      "    cluster loss:             239.3990478515625\n",
      "    separation loss:          83.93764114379883\n",
      "    avg separation loss:      97.1258316040039\n",
      "    l1_addon loss:            88.07087707519531\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017858505249023438\n",
      "    test time:                0.004408121109008789\n",
      "    epoch time:               0.02280902862548828\n",
      "epoch:  10 (WARM) - Libras\n",
      "    test acc:                 21.67%\n",
      "    train overall loss:       3.028676470120748\n",
      "    train cross_ent loss:     2.705118735631307\n",
      "    test overall loss:        3.0282610654830933\n",
      "    test cross_ent loss:      2.705025792121887\n",
      "    cluster loss:             236.49437713623047\n",
      "    separation loss:          78.16729736328125\n",
      "    avg separation loss:      92.68313217163086\n",
      "    l1_addon loss:            82.35301208496094\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017706871032714844\n",
      "    test time:                0.004397869110107422\n",
      "    epoch time:               0.02265000343322754\n",
      "epoch:  11 (WARM) - Libras\n",
      "    test acc:                 26.11%\n",
      "    train overall loss:       3.027189016342163\n",
      "    train cross_ent loss:     2.704159696896871\n",
      "    test overall loss:        3.0269802808761597\n",
      "    test cross_ent loss:      2.7042235136032104\n",
      "    cluster loss:             233.56134033203125\n",
      "    separation loss:          73.16166687011719\n",
      "    avg separation loss:      88.38519287109375\n",
      "    l1_addon loss:            77.56802368164062\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017123937606811523\n",
      "    test time:                0.0044019222259521484\n",
      "    epoch time:               0.02207207679748535\n",
      "epoch:  12 (WARM) - Libras\n",
      "    test acc:                 26.11%\n",
      "    train overall loss:       3.025650064150492\n",
      "    train cross_ent loss:     2.703065196673075\n",
      "    test overall loss:        3.025579810142517\n",
      "    test cross_ent loss:      2.703236937522888\n",
      "    cluster loss:             230.77542877197266\n",
      "    separation loss:          68.43626022338867\n",
      "    avg separation loss:      84.41946029663086\n",
      "    l1_addon loss:            73.42811584472656\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017205476760864258\n",
      "    test time:                0.004395961761474609\n",
      "    epoch time:               0.02214360237121582\n",
      "epoch:  13 (WARM) - Libras\n",
      "    test acc:                 29.44%\n",
      "    train overall loss:       3.0241672595342\n",
      "    train cross_ent loss:     2.7019606033960977\n",
      "    test overall loss:        3.024053454399109\n",
      "    test cross_ent loss:      2.7020360231399536\n",
      "    cluster loss:             227.71612548828125\n",
      "    separation loss:          62.879905700683594\n",
      "    avg separation loss:      80.26774597167969\n",
      "    l1_addon loss:            70.17340850830078\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017244338989257812\n",
      "    test time:                0.004393100738525391\n",
      "    epoch time:               0.022181034088134766\n",
      "epoch:  14 (WARM) - Libras\n",
      "    test acc:                 33.33%\n",
      "    train overall loss:       3.0219132900238037\n",
      "    train cross_ent loss:     2.7000135580698648\n",
      "    test overall loss:        3.0218361616134644\n",
      "    test cross_ent loss:      2.7000924348831177\n",
      "    cluster loss:             224.35665893554688\n",
      "    separation loss:          56.579355239868164\n",
      "    avg separation loss:      75.27338409423828\n",
      "    l1_addon loss:            67.4371109008789\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.01718449592590332\n",
      "    test time:                0.004415273666381836\n",
      "    epoch time:               0.022135496139526367\n",
      "epoch:  15 (WARM) - Libras\n",
      "    test acc:                 35.56%\n",
      "    train overall loss:       3.0190338691075644\n",
      "    train cross_ent loss:     2.697362939516703\n",
      "    test overall loss:        3.0197160243988037\n",
      "    test cross_ent loss:      2.6981449127197266\n",
      "    cluster loss:             222.02489471435547\n",
      "    separation loss:          52.67866516113281\n",
      "    avg separation loss:      71.42817687988281\n",
      "    l1_addon loss:            65.70944213867188\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017313480377197266\n",
      "    test time:                0.004755735397338867\n",
      "    epoch time:               0.022611141204833984\n",
      "epoch:  16 (WARM) - Libras\n",
      "    test acc:                 36.67%\n",
      "    train overall loss:       3.0168424050013223\n",
      "    train cross_ent loss:     2.695357879002889\n",
      "    test overall loss:        3.0174813270568848\n",
      "    test cross_ent loss:      2.696072578430176\n",
      "    cluster loss:             219.98182678222656\n",
      "    separation loss:          49.77872276306152\n",
      "    avg separation loss:      68.04859924316406\n",
      "    l1_addon loss:            64.08778381347656\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017225980758666992\n",
      "    test time:                0.004347324371337891\n",
      "    epoch time:               0.022109508514404297\n",
      "epoch:  17 (WARM) - Libras\n",
      "    test acc:                 34.44%\n",
      "    train overall loss:       3.013530174891154\n",
      "    train cross_ent loss:     2.6921769777933755\n",
      "    test overall loss:        3.014695882797241\n",
      "    test cross_ent loss:      2.6934101581573486\n",
      "    cluster loss:             217.8876953125\n",
      "    separation loss:          46.42317581176758\n",
      "    avg separation loss:      65.07321166992188\n",
      "    l1_addon loss:            62.85658264160156\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.01790332794189453\n",
      "    test time:                0.004395246505737305\n",
      "    epoch time:               0.022837162017822266\n",
      "epoch:  18 (WARM) - Libras\n",
      "    test acc:                 35.00%\n",
      "    train overall loss:       3.0094709396362305\n",
      "    train cross_ent loss:     2.6881808042526245\n",
      "    test overall loss:        3.011539936065674\n",
      "    test cross_ent loss:      2.690258741378784\n",
      "    cluster loss:             215.87088012695312\n",
      "    separation loss:          43.29706382751465\n",
      "    avg separation loss:      61.74526405334473\n",
      "    l1_addon loss:            62.81128692626953\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.01799178123474121\n",
      "    test time:                0.004422187805175781\n",
      "    epoch time:               0.0229489803314209\n",
      "epoch:  19 (WARM) - Libras\n",
      "    test acc:                 35.00%\n",
      "    train overall loss:       3.004540125528971\n",
      "    train cross_ent loss:     2.683277209599813\n",
      "    test overall loss:        3.0071825981140137\n",
      "    test cross_ent loss:      2.685915946960449\n",
      "    cluster loss:             213.69955444335938\n",
      "    separation loss:          39.886003494262695\n",
      "    avg separation loss:      57.75898551940918\n",
      "    l1_addon loss:            62.665733337402344\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017530441284179688\n",
      "    test time:                0.004351377487182617\n",
      "    epoch time:               0.0224151611328125\n",
      "epoch:  20 (WARM) - Libras\n",
      "    test acc:                 40.56%\n",
      "    train overall loss:       2.998254974683126\n",
      "    train cross_ent loss:     2.6769136985143027\n",
      "    test overall loss:        3.001809597015381\n",
      "    test cross_ent loss:      2.680391311645508\n",
      "    cluster loss:             211.36016082763672\n",
      "    separation loss:          35.92951774597168\n",
      "    avg separation loss:      53.888689041137695\n",
      "    l1_addon loss:            64.1832046508789\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.01727128028869629\n",
      "    test time:                0.004366159439086914\n",
      "    epoch time:               0.02218151092529297\n",
      "epoch:  21 (WARM) - Libras\n",
      "    test acc:                 41.11%\n",
      "    train overall loss:       2.9910389184951782\n",
      "    train cross_ent loss:     2.669660488764445\n",
      "    test overall loss:        2.9957469701766968\n",
      "    test cross_ent loss:      2.67439067363739\n",
      "    cluster loss:             209.89744567871094\n",
      "    separation loss:          33.279197692871094\n",
      "    avg separation loss:      51.513389587402344\n",
      "    l1_addon loss:            63.56208038330078\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017297029495239258\n",
      "    test time:                0.004363536834716797\n",
      "    epoch time:               0.02219247817993164\n",
      "epoch:  22 (WARM) - Libras\n",
      "    test acc:                 41.67%\n",
      "    train overall loss:       2.982347289721171\n",
      "    train cross_ent loss:     2.6609389781951904\n",
      "    test overall loss:        2.987783432006836\n",
      "    test cross_ent loss:      2.6662540435791016\n",
      "    cluster loss:             208.23223114013672\n",
      "    separation loss:          30.46365737915039\n",
      "    avg separation loss:      48.81199264526367\n",
      "    l1_addon loss:            65.2939453125\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017247438430786133\n",
      "    test time:                0.0043566226959228516\n",
      "    epoch time:               0.022136449813842773\n",
      "epoch:  23 (WARM) - Libras\n",
      "    test acc:                 41.67%\n",
      "    train overall loss:       2.969383955001831\n",
      "    train cross_ent loss:     2.6478086709976196\n",
      "    test overall loss:        2.9781492948532104\n",
      "    test cross_ent loss:      2.6565979719161987\n",
      "    cluster loss:             206.71005249023438\n",
      "    separation loss:          27.77772808074951\n",
      "    avg separation loss:      46.35676383972168\n",
      "    l1_addon loss:            65.51150512695312\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.01732921600341797\n",
      "    test time:                0.004382610321044922\n",
      "    epoch time:               0.02224874496459961\n",
      "epoch:  24 (WARM) - Libras\n",
      "    test acc:                 41.11%\n",
      "    train overall loss:       2.954154888788859\n",
      "    train cross_ent loss:     2.632585088411967\n",
      "    test overall loss:        2.966015577316284\n",
      "    test cross_ent loss:      2.644423484802246\n",
      "    cluster loss:             205.2159538269043\n",
      "    separation loss:          25.19883441925049\n",
      "    avg separation loss:      43.46980094909668\n",
      "    l1_addon loss:            65.92007446289062\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017312288284301758\n",
      "    test time:                0.004464387893676758\n",
      "    epoch time:               0.02231121063232422\n",
      "epoch:  25 (WARM) - Libras\n",
      "    test acc:                 42.22%\n",
      "    train overall loss:       2.9320250749588013\n",
      "    train cross_ent loss:     2.6104208628336587\n",
      "    test overall loss:        2.9509516954421997\n",
      "    test cross_ent loss:      2.629271388053894\n",
      "    cluster loss:             203.84967041015625\n",
      "    separation loss:          22.697463035583496\n",
      "    avg separation loss:      40.78790855407715\n",
      "    l1_addon loss:            66.8017578125\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017375469207763672\n",
      "    test time:                0.00445556640625\n",
      "    epoch time:               0.022368669509887695\n",
      "epoch:  26 (WARM) - Libras\n",
      "    test acc:                 43.89%\n",
      "    train overall loss:       2.9058961868286133\n",
      "    train cross_ent loss:     2.584152340888977\n",
      "    test overall loss:        2.934437394142151\n",
      "    test cross_ent loss:      2.6126760244369507\n",
      "    cluster loss:             202.6273536682129\n",
      "    separation loss:          20.538891792297363\n",
      "    avg separation loss:      38.58481979370117\n",
      "    l1_addon loss:            67.61332702636719\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017426252365112305\n",
      "    test time:                0.005724191665649414\n",
      "    epoch time:               0.02368783950805664\n",
      "epoch:  27 (WARM) - Libras\n",
      "    test acc:                 41.11%\n",
      "    train overall loss:       2.8809808492660522\n",
      "    train cross_ent loss:     2.559238314628601\n",
      "    test overall loss:        2.909932017326355\n",
      "    test cross_ent loss:      2.5882147550582886\n",
      "    cluster loss:             201.57675552368164\n",
      "    separation loss:          18.33790874481201\n",
      "    avg separation loss:      36.30721855163574\n",
      "    l1_addon loss:            67.1727523803711\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017493724822998047\n",
      "    test time:                0.004382610321044922\n",
      "    epoch time:               0.022415637969970703\n",
      "epoch:  28 (WARM) - Libras\n",
      "    test acc:                 43.33%\n",
      "    train overall loss:       2.828124721844991\n",
      "    train cross_ent loss:     2.5063764254252114\n",
      "    test overall loss:        2.873490333557129\n",
      "    test cross_ent loss:      2.551661968231201\n",
      "    cluster loss:             200.35153579711914\n",
      "    separation loss:          15.918609619140625\n",
      "    avg separation loss:      33.11526107788086\n",
      "    l1_addon loss:            68.28341674804688\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017346620559692383\n",
      "    test time:                0.004393100738525391\n",
      "    epoch time:               0.022276878356933594\n",
      "epoch:  29 (WARM) - Libras\n",
      "    test acc:                 44.44%\n",
      "    train overall loss:       2.7709720929463706\n",
      "    train cross_ent loss:     2.449110746383667\n",
      "    test overall loss:        2.8450270891189575\n",
      "    test cross_ent loss:      2.523176074028015\n",
      "    cluster loss:             199.4738540649414\n",
      "    separation loss:          14.033848285675049\n",
      "    avg separation loss:      30.9514217376709\n",
      "    l1_addon loss:            68.50840759277344\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.0172579288482666\n",
      "    test time:                0.004349708557128906\n",
      "    epoch time:               0.02214527130126953\n",
      "epoch:  30 (WARM) - Libras\n",
      "    test acc:                 43.33%\n",
      "    train overall loss:       2.7180577913920083\n",
      "    train cross_ent loss:     2.3961782455444336\n",
      "    test overall loss:        2.805576801300049\n",
      "    test cross_ent loss:      2.483729600906372\n",
      "    cluster loss:             198.68708038330078\n",
      "    separation loss:          12.63346242904663\n",
      "    avg separation loss:      28.649065017700195\n",
      "    l1_addon loss:            68.47223663330078\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.01737236976623535\n",
      "    test time:                0.004399538040161133\n",
      "    epoch time:               0.022305965423583984\n",
      "epoch:  31 (WARM) - Libras\n",
      "    test acc:                 45.56%\n",
      "    train overall loss:       2.6686782042185464\n",
      "    train cross_ent loss:     2.346841017405192\n",
      "    test overall loss:        2.770121693611145\n",
      "    test cross_ent loss:      2.4483104944229126\n",
      "    cluster loss:             198.10315322875977\n",
      "    separation loss:          11.187122821807861\n",
      "    avg separation loss:      26.79784107208252\n",
      "    l1_addon loss:            68.11065673828125\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.01733112335205078\n",
      "    test time:                0.004362583160400391\n",
      "    epoch time:               0.022232532501220703\n",
      "epoch:  32 (WARM) - Libras\n",
      "    test acc:                 48.89%\n",
      "    train overall loss:       2.57637890179952\n",
      "    train cross_ent loss:     2.254509925842285\n",
      "    test overall loss:        2.699804663658142\n",
      "    test cross_ent loss:      2.37789523601532\n",
      "    cluster loss:             197.34815216064453\n",
      "    separation loss:          9.544477939605713\n",
      "    avg separation loss:      24.709259033203125\n",
      "    l1_addon loss:            69.09489440917969\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.01730513572692871\n",
      "    test time:                0.004348039627075195\n",
      "    epoch time:               0.022187232971191406\n",
      "epoch:  33 (WARM) - Libras\n",
      "    test acc:                 49.44%\n",
      "    train overall loss:       2.489474336306254\n",
      "    train cross_ent loss:     2.1676179567972818\n",
      "    test overall loss:        2.6407878398895264\n",
      "    test cross_ent loss:      2.318913698196411\n",
      "    cluster loss:             196.86724853515625\n",
      "    separation loss:          8.436790227890015\n",
      "    avg separation loss:      23.255151748657227\n",
      "    l1_addon loss:            68.74169921875\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017323970794677734\n",
      "    test time:                0.0043947696685791016\n",
      "    epoch time:               0.022256851196289062\n",
      "epoch:  34 (WARM) - Libras\n",
      "    test acc:                 51.11%\n",
      "    train overall loss:       2.3996702432632446\n",
      "    train cross_ent loss:     2.0777990023295083\n",
      "    test overall loss:        2.573964238166809\n",
      "    test cross_ent loss:      2.252109169960022\n",
      "    cluster loss:             196.4029197692871\n",
      "    separation loss:          7.46247935295105\n",
      "    avg separation loss:      21.483108520507812\n",
      "    l1_addon loss:            68.55128479003906\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017713308334350586\n",
      "    test time:                0.005124807357788086\n",
      "    epoch time:               0.023374319076538086\n",
      "epoch:  35 (WARM) - Libras\n",
      "    test acc:                 51.67%\n",
      "    train overall loss:       2.3166572650273642\n",
      "    train cross_ent loss:     1.9948372840881348\n",
      "    test overall loss:        2.5388554334640503\n",
      "    test cross_ent loss:      2.2171281576156616\n",
      "    cluster loss:             196.18613052368164\n",
      "    separation loss:          6.994292974472046\n",
      "    avg separation loss:      20.331965446472168\n",
      "    l1_addon loss:            67.27267456054688\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017437219619750977\n",
      "    test time:                0.00443577766418457\n",
      "    epoch time:               0.02241206169128418\n",
      "epoch:  36 (WARM) - Libras\n",
      "    test acc:                 54.44%\n",
      "    train overall loss:       2.311587691307068\n",
      "    train cross_ent loss:     1.9898115992546082\n",
      "    test overall loss:        2.4909034967422485\n",
      "    test cross_ent loss:      2.1691192388534546\n",
      "    cluster loss:             195.89623260498047\n",
      "    separation loss:          6.187890529632568\n",
      "    avg separation loss:      18.951129913330078\n",
      "    l1_addon loss:            67.8415756225586\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017310380935668945\n",
      "    test time:                0.0043866634368896484\n",
      "    epoch time:               0.022232532501220703\n",
      "epoch:  37 (WARM) - Libras\n",
      "    test acc:                 55.56%\n",
      "    train overall loss:       2.263717452685038\n",
      "    train cross_ent loss:     1.9420097867647808\n",
      "    test overall loss:        2.4382317066192627\n",
      "    test cross_ent loss:      2.116591691970825\n",
      "    cluster loss:             195.64568328857422\n",
      "    separation loss:          5.6691670417785645\n",
      "    avg separation loss:      17.878878593444824\n",
      "    l1_addon loss:            66.40071105957031\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017375469207763672\n",
      "    test time:                0.00437617301940918\n",
      "    epoch time:               0.022286415100097656\n",
      "epoch:  38 (WARM) - Libras\n",
      "    test acc:                 59.44%\n",
      "    train overall loss:       2.2044247587521872\n",
      "    train cross_ent loss:     1.8828114072481792\n",
      "    test overall loss:        2.4158822298049927\n",
      "    test cross_ent loss:      2.0943013429641724\n",
      "    cluster loss:             195.51899337768555\n",
      "    separation loss:          5.32371187210083\n",
      "    avg separation loss:      16.756254196166992\n",
      "    l1_addon loss:            65.80818176269531\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.01738142967224121\n",
      "    test time:                0.0043773651123046875\n",
      "    epoch time:               0.022291898727416992\n",
      "epoch:  39 (WARM) - Libras\n",
      "    test acc:                 58.89%\n",
      "    train overall loss:       2.1281579534212747\n",
      "    train cross_ent loss:     1.8066139817237854\n",
      "    test overall loss:        2.378606915473938\n",
      "    test cross_ent loss:      2.0570985078811646\n",
      "    cluster loss:             195.38654708862305\n",
      "    separation loss:          4.929648160934448\n",
      "    avg separation loss:      15.894944190979004\n",
      "    l1_addon loss:            65.08402252197266\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.01736164093017578\n",
      "    test time:                0.004376888275146484\n",
      "    epoch time:               0.02229166030883789\n",
      "epoch:  40 (WARM) - Libras\n",
      "    test acc:                 58.89%\n",
      "    train overall loss:       2.1100977460543313\n",
      "    train cross_ent loss:     1.7886013984680176\n",
      "    test overall loss:        2.3581658601760864\n",
      "    test cross_ent loss:      2.036666750907898\n",
      "    cluster loss:             195.28363800048828\n",
      "    separation loss:          4.525568842887878\n",
      "    avg separation loss:      14.907759666442871\n",
      "    l1_addon loss:            64.9915771484375\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017363786697387695\n",
      "    test time:                0.004448413848876953\n",
      "    epoch time:               0.0223538875579834\n",
      "epoch:  41 (WARM) - Libras\n",
      "    test acc:                 61.11%\n",
      "    train overall loss:       2.1053925355275473\n",
      "    train cross_ent loss:     1.7839356064796448\n",
      "    test overall loss:        2.3176770210266113\n",
      "    test cross_ent loss:      1.996286153793335\n",
      "    cluster loss:             195.18307876586914\n",
      "    separation loss:          4.31062114238739\n",
      "    avg separation loss:      14.534801483154297\n",
      "    l1_addon loss:            63.908203125\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.01738715171813965\n",
      "    test time:                0.004389524459838867\n",
      "    epoch time:               0.022316932678222656\n",
      "epoch:  42 (WARM) - Libras\n",
      "    test acc:                 59.44%\n",
      "    train overall loss:       2.0793474117914834\n",
      "    train cross_ent loss:     1.7579826712608337\n",
      "    test overall loss:        2.295801043510437\n",
      "    test cross_ent loss:      1.9745180010795593\n",
      "    cluster loss:             195.1112174987793\n",
      "    separation loss:          4.089378714561462\n",
      "    avg separation loss:      13.6132230758667\n",
      "    l1_addon loss:            62.831573486328125\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017601490020751953\n",
      "    test time:                0.0043888092041015625\n",
      "    epoch time:               0.022528409957885742\n",
      "epoch:  43 (WARM) - Libras\n",
      "    test acc:                 59.44%\n",
      "    train overall loss:       2.096855580806732\n",
      "    train cross_ent loss:     1.77556977669398\n",
      "    test overall loss:        2.2620294094085693\n",
      "    test cross_ent loss:      1.9407058954238892\n",
      "    cluster loss:             194.99314880371094\n",
      "    separation loss:          3.7579421997070312\n",
      "    avg separation loss:      12.886900424957275\n",
      "    l1_addon loss:            63.236328125\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017611980438232422\n",
      "    test time:                0.004397153854370117\n",
      "    epoch time:               0.022543907165527344\n",
      "epoch:  44 (WARM) - Libras\n",
      "    test acc:                 59.44%\n",
      "    train overall loss:       1.9882380366325378\n",
      "    train cross_ent loss:     1.6669728755950928\n",
      "    test overall loss:        2.236002206802368\n",
      "    test cross_ent loss:      1.9148229360580444\n",
      "    cluster loss:             194.96126556396484\n",
      "    separation loss:          3.713917374610901\n",
      "    avg separation loss:      12.596835613250732\n",
      "    l1_addon loss:            61.792457580566406\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017409563064575195\n",
      "    test time:                0.004383563995361328\n",
      "    epoch time:               0.022330760955810547\n",
      "epoch:  45 (WARM) - Libras\n",
      "    test acc:                 61.11%\n",
      "    train overall loss:       1.987438678741455\n",
      "    train cross_ent loss:     1.6662385662396748\n",
      "    test overall loss:        2.2001781463623047\n",
      "    test cross_ent loss:      1.8789222240447998\n",
      "    cluster loss:             194.87887954711914\n",
      "    separation loss:          3.363836407661438\n",
      "    avg separation loss:      11.966087818145752\n",
      "    l1_addon loss:            62.558406829833984\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017464637756347656\n",
      "    test time:                0.004419088363647461\n",
      "    epoch time:               0.022417545318603516\n",
      "epoch:  46 (WARM) - Libras\n",
      "    test acc:                 61.67%\n",
      "    train overall loss:       1.9477643569310505\n",
      "    train cross_ent loss:     1.6265710989634197\n",
      "    test overall loss:        2.1822030544281006\n",
      "    test cross_ent loss:      1.8610246181488037\n",
      "    cluster loss:             194.8605194091797\n",
      "    separation loss:          3.293379545211792\n",
      "    avg separation loss:      11.57709789276123\n",
      "    l1_addon loss:            61.784141540527344\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017386198043823242\n",
      "    test time:                0.004370927810668945\n",
      "    epoch time:               0.022300243377685547\n",
      "epoch:  47 (WARM) - Libras\n",
      "    test acc:                 62.22%\n",
      "    train overall loss:       1.937827467918396\n",
      "    train cross_ent loss:     1.616639216740926\n",
      "    test overall loss:        2.156559467315674\n",
      "    test cross_ent loss:      1.8354602456092834\n",
      "    cluster loss:             194.82608032226562\n",
      "    separation loss:          3.239342212677002\n",
      "    avg separation loss:      11.331271171569824\n",
      "    l1_addon loss:            60.9910888671875\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017392635345458984\n",
      "    test time:                0.004380226135253906\n",
      "    epoch time:               0.022307634353637695\n",
      "epoch:  48 (WARM) - Libras\n",
      "    test acc:                 62.22%\n",
      "    train overall loss:       1.8708311319351196\n",
      "    train cross_ent loss:     1.5497394601504009\n",
      "    test overall loss:        2.135954976081848\n",
      "    test cross_ent loss:      1.814849317073822\n",
      "    cluster loss:             194.7876739501953\n",
      "    separation loss:          3.11518394947052\n",
      "    avg separation loss:      10.904481410980225\n",
      "    l1_addon loss:            61.05693054199219\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.01742410659790039\n",
      "    test time:                0.00439143180847168\n",
      "    epoch time:               0.02235102653503418\n",
      "epoch:  49 (WARM) - Libras\n",
      "    test acc:                 61.11%\n",
      "    train overall loss:       1.8806541164716084\n",
      "    train cross_ent loss:     1.5596010287602742\n",
      "    test overall loss:        2.1402833461761475\n",
      "    test cross_ent loss:      1.8192529678344727\n",
      "    cluster loss:             194.7795753479004\n",
      "    separation loss:          3.0600556135177612\n",
      "    avg separation loss:      10.606249809265137\n",
      "    l1_addon loss:            60.303714752197266\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.01739501953125\n",
      "    test time:                0.004349946975708008\n",
      "    epoch time:               0.02228093147277832\n",
      "epoch:  50 (WARM) - Libras\n",
      "    test acc:                 61.67%\n",
      "    train overall loss:       1.9365153312683105\n",
      "    train cross_ent loss:     1.6154772241910298\n",
      "    test overall loss:        2.103541135787964\n",
      "    test cross_ent loss:      1.782576084136963\n",
      "    cluster loss:             194.73429107666016\n",
      "    separation loss:          3.0071001052856445\n",
      "    avg separation loss:      10.267982482910156\n",
      "    l1_addon loss:            59.64957809448242\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.01745891571044922\n",
      "    test time:                0.004401445388793945\n",
      "    epoch time:               0.022397756576538086\n",
      "epoch:  51 (JOINT) - Libras\n",
      "    test acc:                 52.78%\n",
      "    train overall loss:       2.043708582719167\n",
      "    train cross_ent loss:     1.7227419416109722\n",
      "    test overall loss:        2.543573498725891\n",
      "    test cross_ent loss:      2.2226086854934692\n",
      "    cluster loss:             195.4350700378418\n",
      "    separation loss:          3.7231767177581787\n",
      "    avg separation loss:      12.337089538574219\n",
      "    l1_addon loss:            59.6468391418457\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.027709484100341797\n",
      "    test time:                0.005975961685180664\n",
      "    epoch time:               0.03429722785949707\n",
      "    joint lr:                 0.0030601000000000087\n",
      "epoch:  52 (JOINT) - Libras\n",
      "    test acc:                 13.33%\n",
      "    train overall loss:       2.8333340883255005\n",
      "    train cross_ent loss:     2.512408494949341\n",
      "    test overall loss:        3.0235968828201294\n",
      "    test cross_ent loss:      2.70271098613739\n",
      "    cluster loss:             220.02023315429688\n",
      "    separation loss:          30.763547897338867\n",
      "    avg separation loss:      144.44386672973633\n",
      "    l1_addon loss:            58.858123779296875\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.02656722068786621\n",
      "    test time:                0.004389047622680664\n",
      "    epoch time:               0.03155684471130371\n",
      "    joint lr:                 0.005960997999999999\n",
      "epoch:  53 (JOINT) - Libras\n",
      "    test acc:                 13.89%\n",
      "    train overall loss:       2.956806500752767\n",
      "    train cross_ent loss:     2.635938048362732\n",
      "    test overall loss:        3.0247544050216675\n",
      "    test cross_ent loss:      2.703896403312683\n",
      "    cluster loss:             221.5412826538086\n",
      "    separation loss:          36.58796310424805\n",
      "    avg separation loss:      112.00250625610352\n",
      "    l1_addon loss:            58.58013916015625\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.026062488555908203\n",
      "    test time:                0.00447392463684082\n",
      "    epoch time:               0.031163454055786133\n",
      "    joint lr:                 0.008803582030000007\n",
      "epoch:  54 (JOINT) - Libras\n",
      "    test acc:                 18.33%\n",
      "    train overall loss:       2.914475758870443\n",
      "    train cross_ent loss:     2.593609094619751\n",
      "    test overall loss:        3.0197924375534058\n",
      "    test cross_ent loss:      2.6989325284957886\n",
      "    cluster loss:             209.9509048461914\n",
      "    separation loss:          20.541897773742676\n",
      "    avg separation loss:      60.80012321472168\n",
      "    l1_addon loss:            58.59825134277344\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.026357173919677734\n",
      "    test time:                0.004551887512207031\n",
      "    epoch time:               0.03151392936706543\n",
      "    joint lr:                 0.011588728279599995\n",
      "epoch:  55 (JOINT) - Libras\n",
      "    test acc:                 19.44%\n",
      "    train overall loss:       2.881107489267985\n",
      "    train cross_ent loss:     2.5602510372797647\n",
      "    test overall loss:        3.028075695037842\n",
      "    test cross_ent loss:      2.7071988582611084\n",
      "    cluster loss:             225.35740661621094\n",
      "    separation loss:          35.616455078125\n",
      "    avg separation loss:      137.63098526000977\n",
      "    l1_addon loss:            58.766693115234375\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.02635979652404785\n",
      "    test time:                0.0044803619384765625\n",
      "    epoch time:               0.03144550323486328\n",
      "    joint lr:                 0.014317301246005004\n",
      "epoch:  56 (JOINT) - Libras\n",
      "    test acc:                 16.11%\n",
      "    train overall loss:       2.827609896659851\n",
      "    train cross_ent loss:     2.5066393613815308\n",
      "    test overall loss:        3.0289456844329834\n",
      "    test cross_ent loss:      2.7078609466552734\n",
      "    cluster loss:             233.5093765258789\n",
      "    separation loss:          49.19538688659668\n",
      "    avg separation loss:      144.2396469116211\n",
      "    l1_addon loss:            60.84602355957031\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.02645111083984375\n",
      "    test time:                0.00439143180847168\n",
      "    epoch time:               0.031441688537597656\n",
      "    joint lr:                 0.016990153880253933\n",
      "epoch:  57 (JOINT) - Libras\n",
      "    test acc:                 12.22%\n",
      "    train overall loss:       2.7318125565846763\n",
      "    train cross_ent loss:     2.4108486572901406\n",
      "    test overall loss:        3.0291351079940796\n",
      "    test cross_ent loss:      2.7082310914993286\n",
      "    cluster loss:             238.56989288330078\n",
      "    separation loss:          56.92486000061035\n",
      "    avg separation loss:      139.4297103881836\n",
      "    l1_addon loss:            59.039615631103516\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.026159286499023438\n",
      "    test time:                0.004385709762573242\n",
      "    epoch time:               0.031140565872192383\n",
      "    joint lr:                 0.019608127731693303\n",
      "epoch:  58 (JOINT) - Libras\n",
      "    test acc:                 13.33%\n",
      "    train overall loss:       2.537739555040995\n",
      "    train cross_ent loss:     2.2169076999028525\n",
      "    test overall loss:        3.014000177383423\n",
      "    test cross_ent loss:      2.6933717727661133\n",
      "    cluster loss:             204.0303726196289\n",
      "    separation loss:          12.35930585861206\n",
      "    avg separation loss:      43.37693977355957\n",
      "    l1_addon loss:            56.28456115722656\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.026038646697998047\n",
      "    test time:                0.0043680667877197266\n",
      "    epoch time:               0.03099966049194336\n",
      "    joint lr:                 0.02217205309071584\n",
      "epoch:  59 (JOINT) - Libras\n",
      "    test acc:                 9.44%\n",
      "    train overall loss:       2.5374062856038413\n",
      "    train cross_ent loss:     2.2166688442230225\n",
      "    test overall loss:        3.027954339981079\n",
      "    test cross_ent loss:      2.707104444503784\n",
      "    cluster loss:             217.69668579101562\n",
      "    separation loss:          30.570039749145508\n",
      "    avg separation loss:      78.19646453857422\n",
      "    l1_addon loss:            58.499542236328125\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.026216745376586914\n",
      "    test time:                0.004475116729736328\n",
      "    epoch time:               0.03129768371582031\n",
      "    joint lr:                 0.024682749129784777\n",
      "epoch:  60 (JOINT) - Libras\n",
      "    test acc:                 16.11%\n",
      "    train overall loss:       2.428121328353882\n",
      "    train cross_ent loss:     2.1071888407071433\n",
      "    test overall loss:        3.0171478986740112\n",
      "    test cross_ent loss:      2.6961740255355835\n",
      "    cluster loss:             213.11676788330078\n",
      "    separation loss:          17.397746086120605\n",
      "    avg separation loss:      68.86430358886719\n",
      "    l1_addon loss:            59.737281799316406\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.026242733001708984\n",
      "    test time:                0.004361867904663086\n",
      "    epoch time:               0.03120899200439453\n",
      "    joint lr:                 0.027141024042763244\n",
      "epoch:  61 (JOINT) - Libras\n",
      "    test acc:                 22.22%\n",
      "    train overall loss:       2.317588766415914\n",
      "    train cross_ent loss:     1.9965489705403645\n",
      "    test overall loss:        2.9938786029815674\n",
      "    test cross_ent loss:      2.672635555267334\n",
      "    cluster loss:             201.55170440673828\n",
      "    separation loss:          9.302756547927856\n",
      "    avg separation loss:      35.281450271606445\n",
      "    l1_addon loss:            62.42893981933594\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.026050090789794922\n",
      "    test time:                0.004462242126464844\n",
      "    epoch time:               0.031121015548706055\n",
      "    joint lr:                 0.025532083112218835\n",
      "epoch:  62 (JOINT) - Libras\n",
      "    test acc:                 18.89%\n",
      "    train overall loss:       2.2900481621424356\n",
      "    train cross_ent loss:     1.9686928192774455\n",
      "    test overall loss:        2.998784899711609\n",
      "    test cross_ent loss:      2.6773282289505005\n",
      "    cluster loss:             204.02986526489258\n",
      "    separation loss:          13.492332935333252\n",
      "    avg separation loss:      43.09226989746094\n",
      "    l1_addon loss:            64.566162109375\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.026193618774414062\n",
      "    test time:                0.004453182220458984\n",
      "    epoch time:               0.03125190734863281\n",
      "    joint lr:                 0.023952616897881036\n",
      "epoch:  63 (JOINT) - Libras\n",
      "    test acc:                 15.00%\n",
      "    train overall loss:       2.1940813859303794\n",
      "    train cross_ent loss:     1.8725666801134746\n",
      "    test overall loss:        3.0181496143341064\n",
      "    test cross_ent loss:      2.6965408325195312\n",
      "    cluster loss:             207.8868179321289\n",
      "    separation loss:          18.410127639770508\n",
      "    avg separation loss:      49.58123970031738\n",
      "    l1_addon loss:            66.08677673339844\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.026227712631225586\n",
      "    test time:                0.004462242126464844\n",
      "    epoch time:               0.03129458427429199\n",
      "    joint lr:                 0.022402196799518763\n",
      "epoch:  64 (JOINT) - Libras\n",
      "    test acc:                 35.56%\n",
      "    train overall loss:       1.9516586065292358\n",
      "    train cross_ent loss:     1.629963755607605\n",
      "    test overall loss:        2.825234889984131\n",
      "    test cross_ent loss:      2.5033957958221436\n",
      "    cluster loss:             196.24564361572266\n",
      "    separation loss:          4.717771530151367\n",
      "    avg separation loss:      17.60269260406494\n",
      "    l1_addon loss:            68.39077758789062\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.026156902313232422\n",
      "    test time:                0.0073184967041015625\n",
      "    epoch time:               0.034081459045410156\n",
      "    joint lr:                 0.02088039984143395\n",
      "epoch:  65 (JOINT) - Libras\n",
      "    test acc:                 38.33%\n",
      "    train overall loss:       1.84251469373703\n",
      "    train cross_ent loss:     1.52062060435613\n",
      "    test overall loss:        2.801947832107544\n",
      "    test cross_ent loss:      2.4799697399139404\n",
      "    cluster loss:             196.11047744750977\n",
      "    separation loss:          3.8110350370407104\n",
      "    avg separation loss:      15.877528190612793\n",
      "    l1_addon loss:            69.77944946289062\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.026192903518676758\n",
      "    test time:                0.004471540451049805\n",
      "    epoch time:               0.03127336502075195\n",
      "    joint lr:                 0.01938680860283089\n",
      "epoch:  66 (JOINT) - Libras\n",
      "    test acc:                 30.00%\n",
      "    train overall loss:       1.6980329155921936\n",
      "    train cross_ent loss:     1.3760529259840648\n",
      "    test overall loss:        2.8609148263931274\n",
      "    test cross_ent loss:      2.5389689207077026\n",
      "    cluster loss:             196.2799186706543\n",
      "    separation loss:          3.752931833267212\n",
      "    avg separation loss:      14.068386554718018\n",
      "    l1_addon loss:            69.45921325683594\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.026362895965576172\n",
      "    test time:                0.004387378692626953\n",
      "    epoch time:               0.03134012222290039\n",
      "    joint lr:                 0.017921011149015745\n",
      "epoch:  67 (JOINT) - Libras\n",
      "    test acc:                 55.56%\n",
      "    train overall loss:       1.6910327871640523\n",
      "    train cross_ent loss:     1.369007448355357\n",
      "    test overall loss:        2.410263180732727\n",
      "    test cross_ent loss:      2.0881733298301697\n",
      "    cluster loss:             195.01131439208984\n",
      "    separation loss:          2.4714601039886475\n",
      "    avg separation loss:      8.719144105911255\n",
      "    l1_addon loss:            70.89839172363281\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.026325225830078125\n",
      "    test time:                0.004477977752685547\n",
      "    epoch time:               0.03142118453979492\n",
      "    joint lr:                 0.016482600963416614\n",
      "epoch:  68 (JOINT) - Libras\n",
      "    test acc:                 41.67%\n",
      "    train overall loss:       1.530241866906484\n",
      "    train cross_ent loss:     1.208124925692876\n",
      "    test overall loss:        2.7333576679229736\n",
      "    test cross_ent loss:      2.411346435546875\n",
      "    cluster loss:             195.6155014038086\n",
      "    separation loss:          3.001176357269287\n",
      "    avg separation loss:      10.102718353271484\n",
      "    l1_addon loss:            70.11143493652344\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.026198863983154297\n",
      "    test time:                0.0043888092041015625\n",
      "    epoch time:               0.031189680099487305\n",
      "    joint lr:                 0.015071176880414561\n",
      "epoch:  69 (JOINT) - Libras\n",
      "    test acc:                 60.56%\n",
      "    train overall loss:       1.7603277961413066\n",
      "    train cross_ent loss:     1.4381800293922424\n",
      "    test overall loss:        2.34776771068573\n",
      "    test cross_ent loss:      2.025627076625824\n",
      "    cluster loss:             194.8869857788086\n",
      "    separation loss:          2.4555617570877075\n",
      "    avg separation loss:      9.172733783721924\n",
      "    l1_addon loss:            71.40702819824219\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.026471614837646484\n",
      "    test time:                0.004412174224853516\n",
      "    epoch time:               0.03148603439331055\n",
      "    joint lr:                 0.01368634301897622\n",
      "epoch:  70 (JOINT) - Libras\n",
      "    test acc:                 56.67%\n",
      "    train overall loss:       1.4980745514233906\n",
      "    train cross_ent loss:     1.1758735378583272\n",
      "    test overall loss:        2.108963370323181\n",
      "    test cross_ent loss:      1.7868749499320984\n",
      "    cluster loss:             194.54547119140625\n",
      "    separation loss:          2.0329630970954895\n",
      "    avg separation loss:      8.183422088623047\n",
      "    l1_addon loss:            70.88384246826172\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.026385068893432617\n",
      "    test time:                0.004363298416137695\n",
      "    epoch time:               0.03134608268737793\n",
      "    joint lr:                 0.012327708717078603\n",
      "epoch:  71 (JOINT) - Libras\n",
      "    test acc:                 41.67%\n",
      "    train overall loss:       1.45246026913325\n",
      "    train cross_ent loss:     1.1303118268648784\n",
      "    test overall loss:        2.6066126823425293\n",
      "    test cross_ent loss:      2.2844114303588867\n",
      "    cluster loss:             195.2295379638672\n",
      "    separation loss:          2.563985228538513\n",
      "    avg separation loss:      9.969627857208252\n",
      "    l1_addon loss:            72.011474609375\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.02625441551208496\n",
      "    test time:                0.004370212554931641\n",
      "    epoch time:               0.031212568283081055\n",
      "    joint lr:                 0.01099488846691703\n",
      "epoch:  72 (JOINT) - Libras\n",
      "    test acc:                 63.33%\n",
      "    train overall loss:       1.415822426478068\n",
      "    train cross_ent loss:     1.0936144292354584\n",
      "    test overall loss:        2.0473268032073975\n",
      "    test cross_ent loss:      1.7251631617546082\n",
      "    cluster loss:             194.58756256103516\n",
      "    separation loss:          1.8699758648872375\n",
      "    avg separation loss:      7.025542497634888\n",
      "    l1_addon loss:            71.63607788085938\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.026359081268310547\n",
      "    test time:                0.004381656646728516\n",
      "    epoch time:               0.0313420295715332\n",
      "    joint lr:                 0.009687501850886984\n",
      "epoch:  73 (JOINT) - Libras\n",
      "    test acc:                 57.22%\n",
      "    train overall loss:       1.2234109441439311\n",
      "    train cross_ent loss:     0.9012062052885691\n",
      "    test overall loss:        2.09377658367157\n",
      "    test cross_ent loss:      1.7715798616409302\n",
      "    cluster loss:             194.5913429260254\n",
      "    separation loss:          1.7930437326431274\n",
      "    avg separation loss:      6.795296669006348\n",
      "    l1_addon loss:            71.96772766113281\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.026390552520751953\n",
      "    test time:                0.004460811614990234\n",
      "    epoch time:               0.03145432472229004\n",
      "    joint lr:                 0.008405173478330853\n",
      "epoch:  74 (JOINT) - Libras\n",
      "    test acc:                 67.22%\n",
      "    train overall loss:       1.3247693181037903\n",
      "    train cross_ent loss:     1.0025320549805958\n",
      "    test overall loss:        1.9927063584327698\n",
      "    test cross_ent loss:      1.670521318912506\n",
      "    cluster loss:             194.52339935302734\n",
      "    separation loss:          1.7180616855621338\n",
      "    avg separation loss:      6.674171447753906\n",
      "    l1_addon loss:            71.84966278076172\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.026434659957885742\n",
      "    test time:                0.00446629524230957\n",
      "    epoch time:               0.03149819374084473\n",
      "    joint lr:                 0.007147532923040749\n",
      "epoch:  75 (JOINT) - Libras\n",
      "    test acc:                 71.11%\n",
      "    train overall loss:       1.1251337627569835\n",
      "    train cross_ent loss:     0.8028942147890726\n",
      "    test overall loss:        1.5472286939620972\n",
      "    test cross_ent loss:      1.224997639656067\n",
      "    cluster loss:             194.3213005065918\n",
      "    separation loss:          1.2895938754081726\n",
      "    avg separation loss:      5.955916404724121\n",
      "    l1_addon loss:            72.31041717529297\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.026076555252075195\n",
      "    test time:                0.0044651031494140625\n",
      "    epoch time:               0.031145572662353516\n",
      "    joint lr:                 0.005914214661508615\n",
      "epoch:  76 (JOINT) - Libras\n",
      "    test acc:                 68.89%\n",
      "    train overall loss:       1.0695810914039612\n",
      "    train cross_ent loss:     0.7474357783794403\n",
      "    test overall loss:        1.518060564994812\n",
      "    test cross_ent loss:      1.195915937423706\n",
      "    cluster loss:             194.31615447998047\n",
      "    separation loss:          1.1502448618412018\n",
      "    avg separation loss:      5.644279956817627\n",
      "    l1_addon loss:            71.44552612304688\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.026397228240966797\n",
      "    test time:                0.004401445388793945\n",
      "    epoch time:               0.031354427337646484\n",
      "    joint lr:                 0.004704858011914826\n",
      "epoch:  77 (JOINT) - Libras\n",
      "    test acc:                 72.22%\n",
      "    train overall loss:       1.0315849085648854\n",
      "    train cross_ent loss:     0.7094231893618902\n",
      "    test overall loss:        1.5198453664779663\n",
      "    test cross_ent loss:      1.197702169418335\n",
      "    cluster loss:             194.3142967224121\n",
      "    separation loss:          1.2110595703125\n",
      "    avg separation loss:      5.514737129211426\n",
      "    l1_addon loss:            71.43156433105469\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.026245832443237305\n",
      "    test time:                0.004360198974609375\n",
      "    epoch time:               0.031220436096191406\n",
      "    joint lr:                 0.0035191070738467612\n",
      "epoch:  78 (JOINT) - Libras\n",
      "    test acc:                 69.44%\n",
      "    train overall loss:       0.9297492603460947\n",
      "    train cross_ent loss:     0.6076061377922694\n",
      "    test overall loss:        1.520262897014618\n",
      "    test cross_ent loss:      1.1981167197227478\n",
      "    cluster loss:             194.2973518371582\n",
      "    separation loss:          1.1416883766651154\n",
      "    avg separation loss:      5.585172414779663\n",
      "    l1_addon loss:            71.46080017089844\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.026349306106567383\n",
      "    test time:                0.004404306411743164\n",
      "    epoch time:               0.031351566314697266\n",
      "    joint lr:                 0.00235661066873886\n",
      "epoch:  79 (JOINT) - Libras\n",
      "    test acc:                 75.00%\n",
      "    train overall loss:       0.8689756989479065\n",
      "    train cross_ent loss:     0.5468406428893408\n",
      "    test overall loss:        1.2877020239830017\n",
      "    test cross_ent loss:      0.9655638933181763\n",
      "    cluster loss:             194.25305938720703\n",
      "    separation loss:          1.1216956675052643\n",
      "    avg separation loss:      5.321313858032227\n",
      "    l1_addon loss:            71.38165283203125\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.02714705467224121\n",
      "    test time:                0.00439000129699707\n",
      "    epoch time:               0.03213691711425781\n",
      "    joint lr:                 0.001217022281025732\n",
      "epoch:  80 (JOINT) - Libras\n",
      "    test acc:                 75.56%\n",
      "    train overall loss:       0.8878687570492426\n",
      "    train cross_ent loss:     0.565724881986777\n",
      "    test overall loss:        1.2626946568489075\n",
      "    test cross_ent loss:      0.9405402839183807\n",
      "    cluster loss:             194.2372589111328\n",
      "    separation loss:          1.088871955871582\n",
      "    avg separation loss:      5.221479654312134\n",
      "    l1_addon loss:            71.54367065429688\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.02641439437866211\n",
      "    test time:                0.0044710636138916016\n",
      "    epoch time:               0.03149247169494629\n",
      "    joint lr:                 0.0001\n",
      "epoch:  81 (JOINT) - Libras\n",
      "    test acc:                 76.67%\n",
      "    train overall loss:       0.838429868221283\n",
      "    train cross_ent loss:     0.5162757138411204\n",
      "    test overall loss:        1.2491537928581238\n",
      "    test cross_ent loss:      0.9270004034042358\n",
      "    cluster loss:             194.23772811889648\n",
      "    separation loss:          1.096647173166275\n",
      "    avg separation loss:      5.252880334854126\n",
      "    l1_addon loss:            71.53388214111328\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.02648615837097168\n",
      "    test time:                0.004773855209350586\n",
      "    epoch time:               0.031862735748291016\n",
      "    joint lr:                 0.00228958707526664\n",
      "epoch:  82 (JOINT) - Libras\n",
      "    test acc:                 76.67%\n",
      "    train overall loss:       0.8165853718916575\n",
      "    train cross_ent loss:     0.494438573718071\n",
      "    test overall loss:        1.225046694278717\n",
      "    test cross_ent loss:      0.9029098153114319\n",
      "    cluster loss:             194.24298095703125\n",
      "    separation loss:          1.1051523983478546\n",
      "    avg separation loss:      5.009005308151245\n",
      "    l1_addon loss:            71.36798095703125\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.026232242584228516\n",
      "    test time:                0.004398822784423828\n",
      "    epoch time:               0.03122854232788086\n",
      "    joint lr:                 0.004435382409027948\n",
      "epoch:  83 (JOINT) - Libras\n",
      "    test acc:                 75.00%\n",
      "    train overall loss:       0.9381098747253418\n",
      "    train cross_ent loss:     0.615971677005291\n",
      "    test overall loss:        1.3810455203056335\n",
      "    test cross_ent loss:      1.0588437020778656\n",
      "    cluster loss:             194.2672996520996\n",
      "    separation loss:          1.1304501593112946\n",
      "    avg separation loss:      5.212082147598267\n",
      "    l1_addon loss:            72.01848602294922\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.026068687438964844\n",
      "    test time:                0.00568079948425293\n",
      "    epoch time:               0.03235626220703125\n",
      "    joint lr:                 0.006538042877406532\n",
      "epoch:  84 (JOINT) - Libras\n",
      "    test acc:                 72.22%\n",
      "    train overall loss:       0.9394310414791107\n",
      "    train cross_ent loss:     0.6172964970270792\n",
      "    test overall loss:        1.4138368964195251\n",
      "    test cross_ent loss:      1.0917479395866394\n",
      "    cluster loss:             194.2852897644043\n",
      "    separation loss:          1.083334356546402\n",
      "    avg separation loss:      4.583989858627319\n",
      "    l1_addon loss:            70.88877868652344\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.026187896728515625\n",
      "    test time:                0.004513263702392578\n",
      "    epoch time:               0.031304359436035156\n",
      "    joint lr:                 0.008598216598176611\n",
      "epoch:  85 (JOINT) - Libras\n",
      "    test acc:                 30.56%\n",
      "    train overall loss:       1.1507857938607533\n",
      "    train cross_ent loss:     0.8286122183005015\n",
      "    test overall loss:        2.6006431579589844\n",
      "    test cross_ent loss:      2.2785286903381348\n",
      "    cluster loss:             194.75029754638672\n",
      "    separation loss:          1.5603488683700562\n",
      "    avg separation loss:      5.123926639556885\n",
      "    l1_addon loss:            71.14448547363281\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.026244163513183594\n",
      "    test time:                0.0044558048248291016\n",
      "    epoch time:               0.03130626678466797\n",
      "    joint lr:                 0.010616543040243577\n",
      "epoch:  86 (JOINT) - Libras\n",
      "    test acc:                 36.11%\n",
      "    train overall loss:       1.2320513824621837\n",
      "    train cross_ent loss:     0.9098491867383321\n",
      "    test overall loss:        2.4429800510406494\n",
      "    test cross_ent loss:      2.120835065841675\n",
      "    cluster loss:             194.62128448486328\n",
      "    separation loss:          1.2648844718933105\n",
      "    avg separation loss:      4.59837007522583\n",
      "    l1_addon loss:            71.44903564453125\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.02617025375366211\n",
      "    test time:                0.005013465881347656\n",
      "    epoch time:               0.031794071197509766\n",
      "    joint lr:                 0.012593653131809358\n",
      "epoch:  87 (JOINT) - Libras\n",
      "    test acc:                 62.78%\n",
      "    train overall loss:       1.1320362289746602\n",
      "    train cross_ent loss:     0.8099414507548014\n",
      "    test overall loss:        1.7942863702774048\n",
      "    test cross_ent loss:      1.4722132682800293\n",
      "    cluster loss:             194.42995834350586\n",
      "    separation loss:          1.2195360660552979\n",
      "    avg separation loss:      4.913816690444946\n",
      "    l1_addon loss:            70.73085021972656\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.02629232406616211\n",
      "    test time:                0.004487514495849609\n",
      "    epoch time:               0.03139090538024902\n",
      "    joint lr:                 0.014530169367239798\n",
      "epoch:  88 (JOINT) - Libras\n",
      "    test acc:                 38.33%\n",
      "    train overall loss:       1.2129233876864116\n",
      "    train cross_ent loss:     0.8908078372478485\n",
      "    test overall loss:        2.5142918825149536\n",
      "    test cross_ent loss:      2.192365288734436\n",
      "    cluster loss:             194.65735626220703\n",
      "    separation loss:          1.512228786945343\n",
      "    avg separation loss:      4.996967077255249\n",
      "    l1_addon loss:            69.26469421386719\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.02632737159729004\n",
      "    test time:                0.004399538040161133\n",
      "    epoch time:               0.03131580352783203\n",
      "    joint lr:                 0.01642670591264845\n",
      "epoch:  89 (JOINT) - Libras\n",
      "    test acc:                 42.78%\n",
      "    train overall loss:       1.236206849416097\n",
      "    train cross_ent loss:     0.9141179422537485\n",
      "    test overall loss:        2.4527595043182373\n",
      "    test cross_ent loss:      2.1305742263793945\n",
      "    cluster loss:             194.7835578918457\n",
      "    separation loss:          1.5497799515724182\n",
      "    avg separation loss:      5.548137187957764\n",
      "    l1_addon loss:            71.85303497314453\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.026256322860717773\n",
      "    test time:                0.004490375518798828\n",
      "    epoch time:               0.031358957290649414\n",
      "    joint lr:                 0.018283868710212207\n",
      "epoch:  90 (JOINT) - Libras\n",
      "    test acc:                 58.33%\n",
      "    train overall loss:       1.2915854652722676\n",
      "    train cross_ent loss:     0.9693995316823324\n",
      "    test overall loss:        2.2001153230667114\n",
      "    test cross_ent loss:      1.8777976036071777\n",
      "    cluster loss:             194.68397521972656\n",
      "    separation loss:          1.5174313187599182\n",
      "    avg separation loss:      5.344512462615967\n",
      "    l1_addon loss:            73.1779556274414\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.026639938354492188\n",
      "    test time:                0.0044748783111572266\n",
      "    epoch time:               0.03173232078552246\n",
      "    joint lr:                 0.020102255581233422\n",
      "epoch:  91 (JOINT) - Libras\n",
      "    test acc:                 51.11%\n",
      "    train overall loss:       1.3593538999557495\n",
      "    train cross_ent loss:     1.037068208058675\n",
      "    test overall loss:        2.2771413326263428\n",
      "    test cross_ent loss:      1.9548187851905823\n",
      "    cluster loss:             194.66143798828125\n",
      "    separation loss:          1.565402626991272\n",
      "    avg separation loss:      5.738638162612915\n",
      "    l1_addon loss:            73.22599792480469\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.027293920516967773\n",
      "    test time:                0.004364728927612305\n",
      "    epoch time:               0.032217979431152344\n",
      "    joint lr:                 0.018912121374150048\n",
      "epoch:  92 (JOINT) - Libras\n",
      "    test acc:                 62.78%\n",
      "    train overall loss:       1.3279201587041218\n",
      "    train cross_ent loss:     1.005592256784439\n",
      "    test overall loss:        1.922822892665863\n",
      "    test cross_ent loss:      1.6004354357719421\n",
      "    cluster loss:             194.5603485107422\n",
      "    separation loss:          1.3985213041305542\n",
      "    avg separation loss:      4.976222991943359\n",
      "    l1_addon loss:            73.87387084960938\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.029039859771728516\n",
      "    test time:                0.009180068969726562\n",
      "    epoch time:               0.03883862495422363\n",
      "    joint lr:                 0.017743789625650205\n",
      "epoch:  93 (JOINT) - Libras\n",
      "    test acc:                 51.11%\n",
      "    train overall loss:       1.2375573913256328\n",
      "    train cross_ent loss:     0.9151344001293182\n",
      "    test overall loss:        2.220118761062622\n",
      "    test cross_ent loss:      1.8976824879646301\n",
      "    cluster loss:             194.5698356628418\n",
      "    separation loss:          1.493594765663147\n",
      "    avg separation loss:      5.33360743522644\n",
      "    l1_addon loss:            74.36190795898438\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.02625894546508789\n",
      "    test time:                0.0044705867767333984\n",
      "    epoch time:               0.03134870529174805\n",
      "    joint lr:                 0.01659694329998293\n",
      "epoch:  94 (JOINT) - Libras\n",
      "    test acc:                 58.89%\n",
      "    train overall loss:       1.241249014933904\n",
      "    train cross_ent loss:     0.9188091655572256\n",
      "    test overall loss:        2.0807536840438843\n",
      "    test cross_ent loss:      1.7583029866218567\n",
      "    cluster loss:             194.52264404296875\n",
      "    separation loss:          1.5771973133087158\n",
      "    avg separation loss:      5.847121953964233\n",
      "    l1_addon loss:            74.50679779052734\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.02657032012939453\n",
      "    test time:                0.004439830780029297\n",
      "    epoch time:               0.03161740303039551\n",
      "    joint lr:                 0.01547126952186645\n",
      "epoch:  95 (JOINT) - Libras\n",
      "    test acc:                 33.33%\n",
      "    train overall loss:       1.1740455826123555\n",
      "    train cross_ent loss:     0.8516024549802145\n",
      "    test overall loss:        2.5435158014297485\n",
      "    test cross_ent loss:      2.2209538221359253\n",
      "    cluster loss:             194.9430923461914\n",
      "    separation loss:          1.5391116738319397\n",
      "    avg separation loss:      6.261085510253906\n",
      "    l1_addon loss:            75.6190185546875\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.028116226196289062\n",
      "    test time:                0.008374452590942383\n",
      "    epoch time:               0.037073373794555664\n",
      "    joint lr:                 0.014366459524982304\n",
      "epoch:  96 (JOINT) - Libras\n",
      "    test acc:                 55.56%\n",
      "    train overall loss:       1.1341869433720906\n",
      "    train cross_ent loss:     0.8116902758677801\n",
      "    test overall loss:        1.8905539512634277\n",
      "    test cross_ent loss:      1.5682257413864136\n",
      "    cluster loss:             194.36278915405273\n",
      "    separation loss:          1.2195465564727783\n",
      "    avg separation loss:      4.969492197036743\n",
      "    l1_addon loss:            73.28179931640625\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.026848316192626953\n",
      "    test time:                0.004385471343994141\n",
      "    epoch time:               0.03182673454284668\n",
      "    joint lr:                 0.013282208601083652\n",
      "epoch:  97 (JOINT) - Libras\n",
      "    test acc:                 61.67%\n",
      "    train overall loss:       1.2763185501098633\n",
      "    train cross_ent loss:     0.9538494547208151\n",
      "    test overall loss:        1.6814953088760376\n",
      "    test cross_ent loss:      1.359101414680481\n",
      "    cluster loss:             194.36784744262695\n",
      "    separation loss:          1.318560779094696\n",
      "    avg separation loss:      4.853067874908447\n",
      "    l1_addon loss:            73.93787384033203\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.027078628540039062\n",
      "    test time:                0.004470348358154297\n",
      "    epoch time:               0.032164812088012695\n",
      "    joint lr:                 0.012218216049710476\n",
      "epoch:  98 (JOINT) - Libras\n",
      "    test acc:                 53.89%\n",
      "    train overall loss:       1.1471609671910603\n",
      "    train cross_ent loss:     0.824761708577474\n",
      "    test overall loss:        2.343971014022827\n",
      "    test cross_ent loss:      2.0213851928710938\n",
      "    cluster loss:             194.90282821655273\n",
      "    separation loss:          1.9327785968780518\n",
      "    avg separation loss:      6.382045269012451\n",
      "    l1_addon loss:            75.85704803466797\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.026621580123901367\n",
      "    test time:                0.00448298454284668\n",
      "    epoch time:               0.031733036041259766\n",
      "    joint lr:                 0.011174185128504639\n",
      "epoch:  99 (JOINT) - Libras\n",
      "    test acc:                 73.89%\n",
      "    train overall loss:       1.0831193228562672\n",
      "    train cross_ent loss:     0.7606461346149445\n",
      "    test overall loss:        1.5311363339424133\n",
      "    test cross_ent loss:      1.2087013125419617\n",
      "    cluster loss:             194.3234748840332\n",
      "    separation loss:          1.2333296537399292\n",
      "    avg separation loss:      4.710431814193726\n",
      "    l1_addon loss:            74.34910583496094\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.027489900588989258\n",
      "    test time:                0.004456281661987305\n",
      "    epoch time:               0.032559871673583984\n",
      "    joint lr:                 0.010149823004117963\n",
      "epoch: 100 (JOINT) - Libras\n",
      "    test acc:                 66.11%\n",
      "    train overall loss:       0.9124805629253387\n",
      "    train cross_ent loss:     0.5899879559874535\n",
      "    test overall loss:        1.5278560519218445\n",
      "    test cross_ent loss:      1.2053722739219666\n",
      "    cluster loss:             194.36157989501953\n",
      "    separation loss:          1.137028694152832\n",
      "    avg separation loss:      4.551496505737305\n",
      "    l1_addon loss:            74.83758544921875\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.02901172637939453\n",
      "    test time:                0.004389762878417969\n",
      "    epoch time:               0.03397321701049805\n",
      "    joint lr:                 0.009144840703706159\n",
      "epoch: 101 (JOINT) - Libras\n",
      "    test acc:                 78.33%\n",
      "    train overall loss:       0.9408983488877615\n",
      "    train cross_ent loss:     0.618392750620842\n",
      "    test overall loss:        1.2684215903282166\n",
      "    test cross_ent loss:      0.94589564204216\n",
      "    cluster loss:             194.2720069885254\n",
      "    separation loss:          1.0621348321437836\n",
      "    avg separation loss:      4.426316499710083\n",
      "    l1_addon loss:            75.25894165039062\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.029446840286254883\n",
      "    test time:                0.004419565200805664\n",
      "    epoch time:               0.03443408012390137\n",
      "    joint lr:                 0.008158953067002189\n",
      "epoch: 102 (JOINT) - Libras\n",
      "    test acc:                 77.78%\n",
      "    train overall loss:       0.8227749069531759\n",
      "    train cross_ent loss:     0.5003013660510381\n",
      "    test overall loss:        1.2428604364395142\n",
      "    test cross_ent loss:      0.9204804301261902\n",
      "    cluster loss:             194.24412536621094\n",
      "    separation loss:          0.9864430725574493\n",
      "    avg separation loss:      4.19200325012207\n",
      "    l1_addon loss:            73.80000305175781\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.028942346572875977\n",
      "    test time:                0.0044138431549072266\n",
      "    epoch time:               0.03392601013183594\n",
      "    joint lr:                 0.0071918786989619305\n",
      "epoch: 103 (JOINT) - Libras\n",
      "    test acc:                 82.22%\n",
      "    train overall loss:       0.7599935233592987\n",
      "    train cross_ent loss:     0.4375675867001216\n",
      "    test overall loss:        1.1117743849754333\n",
      "    test cross_ent loss:      0.7892758250236511\n",
      "    cluster loss:             194.2560272216797\n",
      "    separation loss:          0.9813737869262695\n",
      "    avg separation loss:      4.189584374427795\n",
      "    l1_addon loss:            74.98542785644531\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.02900552749633789\n",
      "    test time:                0.0044097900390625\n",
      "    epoch time:               0.03397870063781738\n",
      "    joint lr:                 0.006243339922975775\n",
      "epoch: 104 (JOINT) - Libras\n",
      "    test acc:                 75.56%\n",
      "    train overall loss:       0.7789924740791321\n",
      "    train cross_ent loss:     0.45653697351614636\n",
      "    test overall loss:        1.2028558850288391\n",
      "    test cross_ent loss:      0.880466878414154\n",
      "    cluster loss:             194.226806640625\n",
      "    separation loss:          0.9540717303752899\n",
      "    avg separation loss:      4.059869050979614\n",
      "    l1_addon loss:            73.88912200927734\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.028808116912841797\n",
      "    test time:                0.004407644271850586\n",
      "    epoch time:               0.03378582000732422\n",
      "    joint lr:                 0.005313062734639446\n",
      "epoch: 105 (JOINT) - Libras\n",
      "    test acc:                 81.11%\n",
      "    train overall loss:       0.7812610864639282\n",
      "    train cross_ent loss:     0.4588401069243749\n",
      "    test overall loss:        1.03417307138443\n",
      "    test cross_ent loss:      0.7117210030555725\n",
      "    cluster loss:             194.22232818603516\n",
      "    separation loss:          0.87675341963768\n",
      "    avg separation loss:      3.932126998901367\n",
      "    l1_addon loss:            74.51982116699219\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.028768301010131836\n",
      "    test time:                0.004481077194213867\n",
      "    epoch time:               0.03381466865539551\n",
      "    joint lr:                 0.004400776756077547\n",
      "epoch: 106 (JOINT) - Libras\n",
      "    test acc:                 79.44%\n",
      "    train overall loss:       0.7927524546782175\n",
      "    train cross_ent loss:     0.4703037366271019\n",
      "    test overall loss:        1.0886623859405518\n",
      "    test cross_ent loss:      0.7662119269371033\n",
      "    cluster loss:             194.22354888916016\n",
      "    separation loss:          0.8402137160301208\n",
      "    avg separation loss:      3.960116147994995\n",
      "    l1_addon loss:            74.50473022460938\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.02962779998779297\n",
      "    test time:                0.004442930221557617\n",
      "    epoch time:               0.03464388847351074\n",
      "    joint lr:                 0.0035062151908134102\n",
      "epoch: 107 (JOINT) - Libras\n",
      "    test acc:                 79.44%\n",
      "    train overall loss:       0.7187769412994385\n",
      "    train cross_ent loss:     0.3963260700305303\n",
      "    test overall loss:        1.0412399172782898\n",
      "    test cross_ent loss:      0.7188185155391693\n",
      "    cluster loss:             194.2217140197754\n",
      "    separation loss:          0.825054943561554\n",
      "    avg separation loss:      3.8482381105422974\n",
      "    l1_addon loss:            74.21401977539062\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.026654481887817383\n",
      "    test time:                0.00452876091003418\n",
      "    epoch time:               0.03180098533630371\n",
      "    joint lr:                 0.0026291147791789593\n",
      "epoch: 108 (JOINT) - Libras\n",
      "    test acc:                 80.56%\n",
      "    train overall loss:       0.7058141132195791\n",
      "    train cross_ent loss:     0.3834071010351181\n",
      "    test overall loss:        1.0605462491512299\n",
      "    test cross_ent loss:      0.7381430864334106\n",
      "    cluster loss:             194.21759414672852\n",
      "    separation loss:          0.8158555924892426\n",
      "    avg separation loss:      3.7129966020584106\n",
      "    l1_addon loss:            74.0318832397461\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.029012441635131836\n",
      "    test time:                0.0044176578521728516\n",
      "    epoch time:               0.033998966217041016\n",
      "    joint lr:                 0.001769215754258106\n",
      "epoch: 109 (JOINT) - Libras\n",
      "    test acc:                 81.67%\n",
      "    train overall loss:       0.6888703058163325\n",
      "    train cross_ent loss:     0.3664654990037282\n",
      "    test overall loss:        1.0252430438995361\n",
      "    test cross_ent loss:      0.7028442919254303\n",
      "    cluster loss:             194.2196807861328\n",
      "    separation loss:          0.8260650932788849\n",
      "    avg separation loss:      3.7119261026382446\n",
      "    l1_addon loss:            73.98736572265625\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.02947378158569336\n",
      "    test time:                0.004602909088134766\n",
      "    epoch time:               0.03497910499572754\n",
      "    joint lr:                 0.0009262617983577627\n",
      "epoch: 110 (JOINT) - Libras\n",
      "    test acc:                 82.78%\n",
      "    train overall loss:       0.6788904170195261\n",
      "    train cross_ent loss:     0.3564951668183009\n",
      "    test overall loss:        0.9748998880386353\n",
      "    test cross_ent loss:      0.6525051593780518\n",
      "    cluster loss:             194.2119026184082\n",
      "    separation loss:          0.8165578544139862\n",
      "    avg separation loss:      3.736768364906311\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.029401779174804688\n",
      "    test time:                0.004433631896972656\n",
      "    epoch time:               0.03440380096435547\n",
      "    joint lr:                 0.0001\n",
      "epoch: 110 (PUSH) - Libras\n",
      "    test acc:                 77.78%\n",
      "    train overall loss:       0.6788904170195261\n",
      "    train cross_ent loss:     0.3564951668183009\n",
      "    test overall loss:        1.214644730091095\n",
      "    test cross_ent loss:      0.8922500312328339\n",
      "    cluster loss:             194.2013931274414\n",
      "    separation loss:          0.7761077880859375\n",
      "    avg separation loss:      3.750686287879944\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.029401779174804688\n",
      "    test time:                0.004467010498046875\n",
      "    epoch time:               0.06412672996520996\n",
      "epoch: 110 (1/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 78.33%\n",
      "    train overall loss:       0.782773474852244\n",
      "    train cross_ent loss:     0.4603637605905533\n",
      "    test overall loss:        1.2200864553451538\n",
      "    test cross_ent loss:      0.8976662456989288\n",
      "    cluster loss:             194.20211029052734\n",
      "    separation loss:          0.7755805253982544\n",
      "    avg separation loss:      3.7475333213806152\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  315.0255126953125\n",
      "    train time:               0.012502908706665039\n",
      "    test time:                0.00442194938659668\n",
      "    epoch time:               0.017401456832885742\n",
      "    last layer lr:            0.0007599999999999978\n",
      "epoch: 110 (2/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 77.78%\n",
      "    train overall loss:       0.802043209473292\n",
      "    train cross_ent loss:     0.47961710890134174\n",
      "    test overall loss:        1.2132589221000671\n",
      "    test cross_ent loss:      0.8908464908599854\n",
      "    cluster loss:             194.20273971557617\n",
      "    separation loss:          0.7757426202297211\n",
      "    avg separation loss:      3.7495346069335938\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  315.0177001953125\n",
      "    train time:               0.012388229370117188\n",
      "    test time:                0.004427433013916016\n",
      "    epoch time:               0.017290592193603516\n",
      "    last layer lr:            0.0014200000000000013\n",
      "epoch: 110 (3/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 78.33%\n",
      "    train overall loss:       0.7368664344151815\n",
      "    train cross_ent loss:     0.41445442537466687\n",
      "    test overall loss:        1.2046899795532227\n",
      "    test cross_ent loss:      0.8822742998600006\n",
      "    cluster loss:             194.20325088500977\n",
      "    separation loss:          0.7756727635860443\n",
      "    avg separation loss:      3.7478338479995728\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  315.0209655761719\n",
      "    train time:               0.012377262115478516\n",
      "    test time:                0.004483938217163086\n",
      "    epoch time:               0.017336606979370117\n",
      "    last layer lr:            0.0020799999999999985\n",
      "epoch: 110 (4/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 78.89%\n",
      "    train overall loss:       0.761128822962443\n",
      "    train cross_ent loss:     0.4387365902463595\n",
      "    test overall loss:        1.186621069908142\n",
      "    test cross_ent loss:      0.8642590045928955\n",
      "    cluster loss:             194.20328521728516\n",
      "    separation loss:          0.77642822265625\n",
      "    avg separation loss:      3.7409605979919434\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  314.9674072265625\n",
      "    train time:               0.012341022491455078\n",
      "    test time:                0.00447392463684082\n",
      "    epoch time:               0.01728987693786621\n",
      "    last layer lr:            0.0027400000000000024\n",
      "epoch: 110 (5/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 78.33%\n",
      "    train overall loss:       0.796791285276413\n",
      "    train cross_ent loss:     0.4744247496128082\n",
      "    test overall loss:        1.1637007594108582\n",
      "    test cross_ent loss:      0.841402530670166\n",
      "    cluster loss:             194.2032012939453\n",
      "    separation loss:          0.7728363275527954\n",
      "    avg separation loss:      3.745668649673462\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  314.903564453125\n",
      "    train time:               0.012345314025878906\n",
      "    test time:                0.004506587982177734\n",
      "    epoch time:               0.017327308654785156\n",
      "    last layer lr:            0.0034\n",
      "epoch: 110 (6/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 78.89%\n",
      "    train overall loss:       0.7582133909066519\n",
      "    train cross_ent loss:     0.4360526402791341\n",
      "    test overall loss:        1.1480160355567932\n",
      "    test cross_ent loss:      0.8260324895381927\n",
      "    cluster loss:             194.20363998413086\n",
      "    separation loss:          0.7766523659229279\n",
      "    avg separation loss:      3.746970057487488\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  314.5888671875\n",
      "    train time:               0.012334585189819336\n",
      "    test time:                0.004443645477294922\n",
      "    epoch time:               0.017282485961914062\n",
      "    last layer lr:            0.004059999999999998\n",
      "epoch: 110 (7/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 78.89%\n",
      "    train overall loss:       0.6831034719944\n",
      "    train cross_ent loss:     0.36133040487766266\n",
      "    test overall loss:        1.127331554889679\n",
      "    test cross_ent loss:      0.8057853877544403\n",
      "    cluster loss:             194.20335388183594\n",
      "    separation loss:          0.7761576473712921\n",
      "    avg separation loss:      3.7499382495880127\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  314.1514587402344\n",
      "    train time:               0.012868404388427734\n",
      "    test time:                0.004464387893676758\n",
      "    epoch time:               0.017812252044677734\n",
      "    last layer lr:            0.004720000000000002\n",
      "epoch: 110 (8/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 78.89%\n",
      "    train overall loss:       0.6792949636777242\n",
      "    train cross_ent loss:     0.3579399933417638\n",
      "    test overall loss:        1.1053206324577332\n",
      "    test cross_ent loss:      0.7843097150325775\n",
      "    cluster loss:             194.2033920288086\n",
      "    separation loss:          0.7757826149463654\n",
      "    avg separation loss:      3.7564268112182617\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  313.6162414550781\n",
      "    train time:               0.012386083602905273\n",
      "    test time:                0.004665374755859375\n",
      "    epoch time:               0.017535924911499023\n",
      "    last layer lr:            0.005379999999999999\n",
      "epoch: 110 (9/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 79.44%\n",
      "    train overall loss:       0.68010742465655\n",
      "    train cross_ent loss:     0.35954126218954724\n",
      "    test overall loss:        1.0843977332115173\n",
      "    test cross_ent loss:      0.7644971609115601\n",
      "    cluster loss:             194.2032241821289\n",
      "    separation loss:          0.7739810943603516\n",
      "    avg separation loss:      3.752266049385071\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  312.505859375\n",
      "    train time:               0.012348651885986328\n",
      "    test time:                0.004457712173461914\n",
      "    epoch time:               0.017281532287597656\n",
      "    last layer lr:            0.006040000000000003\n",
      "epoch: 110 (10/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 79.44%\n",
      "    train overall loss:       0.6887590487798055\n",
      "    train cross_ent loss:     0.3693212966124217\n",
      "    test overall loss:        1.0654114484786987\n",
      "    test cross_ent loss:      0.7467471063137054\n",
      "    cluster loss:             194.20299530029297\n",
      "    separation loss:          0.7714362442493439\n",
      "    avg separation loss:      3.737996220588684\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  311.2696838378906\n",
      "    train time:               0.012349128723144531\n",
      "    test time:                0.004457712173461914\n",
      "    epoch time:               0.017328262329101562\n",
      "    last layer lr:            0.0067\n",
      "epoch: 110 (11/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 79.44%\n",
      "    train overall loss:       0.6537893215815226\n",
      "    train cross_ent loss:     0.3357744887471199\n",
      "    test overall loss:        1.0510656833648682\n",
      "    test cross_ent loss:      0.734128326177597\n",
      "    cluster loss:             194.2029571533203\n",
      "    separation loss:          0.773421585559845\n",
      "    avg separation loss:      3.744429588317871\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  309.54266357421875\n",
      "    train time:               0.012357950210571289\n",
      "    test time:                0.004813432693481445\n",
      "    epoch time:               0.017647743225097656\n",
      "    last layer lr:            0.0073599999999999985\n",
      "epoch: 110 (12/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 80.00%\n",
      "    train overall loss:       0.6525072952111562\n",
      "    train cross_ent loss:     0.3364236628015836\n",
      "    test overall loss:        1.0298893451690674\n",
      "    test cross_ent loss:      0.7151935994625092\n",
      "    cluster loss:             194.20318222045898\n",
      "    separation loss:          0.774202823638916\n",
      "    avg separation loss:      3.745274543762207\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  307.3010559082031\n",
      "    train time:               0.012320280075073242\n",
      "    test time:                0.0044438838958740234\n",
      "    epoch time:               0.017241239547729492\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 110 (13/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 79.44%\n",
      "    train overall loss:       0.6300356090068817\n",
      "    train cross_ent loss:     0.3165000379085541\n",
      "    test overall loss:        1.0133739113807678\n",
      "    test cross_ent loss:      0.7014691233634949\n",
      "    cluster loss:             194.2036895751953\n",
      "    separation loss:          0.7754245698451996\n",
      "    avg separation loss:      3.7527735233306885\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  304.5101318359375\n",
      "    train time:               0.012344837188720703\n",
      "    test time:                0.004427671432495117\n",
      "    epoch time:               0.01724720001220703\n",
      "    last layer lr:            0.008679999999999998\n",
      "epoch: 110 (14/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 79.44%\n",
      "    train overall loss:       0.6364754637082418\n",
      "    train cross_ent loss:     0.3258621369798978\n",
      "    test overall loss:        0.999424010515213\n",
      "    test cross_ent loss:      0.6904229819774628\n",
      "    cluster loss:             194.2038688659668\n",
      "    separation loss:          0.7757511138916016\n",
      "    avg separation loss:      3.7514196634292603\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  301.6063537597656\n",
      "    train time:               0.01235342025756836\n",
      "    test time:                0.004440784454345703\n",
      "    epoch time:               0.01726841926574707\n",
      "    last layer lr:            0.009340000000000003\n",
      "epoch: 110 (15/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 80.00%\n",
      "    train overall loss:       0.6155565977096558\n",
      "    train cross_ent loss:     0.30755727738142014\n",
      "    test overall loss:        0.9772399663925171\n",
      "    test cross_ent loss:      0.6709360480308533\n",
      "    cluster loss:             194.20373916625977\n",
      "    separation loss:          0.77476367354393\n",
      "    avg separation loss:      3.74245023727417\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  298.90924072265625\n",
      "    train time:               0.01234126091003418\n",
      "    test time:                0.004479408264160156\n",
      "    epoch time:               0.01729726791381836\n",
      "    last layer lr:            0.01\n",
      "epoch: 110 (16/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 80.56%\n",
      "    train overall loss:       0.5882056554158529\n",
      "    train cross_ent loss:     0.2830667272210121\n",
      "    test overall loss:        0.9540548026561737\n",
      "    test cross_ent loss:      0.6507693231105804\n",
      "    cluster loss:             194.2036247253418\n",
      "    separation loss:          0.7759870886802673\n",
      "    avg separation loss:      3.752475142478943\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  295.89080810546875\n",
      "    train time:               0.012340545654296875\n",
      "    test time:                0.004544496536254883\n",
      "    epoch time:               0.017360210418701172\n",
      "    last layer lr:            0.009604000000000001\n",
      "epoch: 110 (17/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 80.56%\n",
      "    train overall loss:       0.6073715090751648\n",
      "    train cross_ent loss:     0.3052910342812538\n",
      "    test overall loss:        0.9389965534210205\n",
      "    test cross_ent loss:      0.6390295326709747\n",
      "    cluster loss:             194.2033233642578\n",
      "    separation loss:          0.7744741141796112\n",
      "    avg separation loss:      3.7528269290924072\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  292.57232666015625\n",
      "    train time:               0.01232600212097168\n",
      "    test time:                0.004445075988769531\n",
      "    epoch time:               0.01728510856628418\n",
      "    last layer lr:            0.009208\n",
      "epoch: 110 (18/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 80.56%\n",
      "    train overall loss:       0.5639134844144186\n",
      "    train cross_ent loss:     0.26553372542063397\n",
      "    test overall loss:        0.921348512172699\n",
      "    test cross_ent loss:      0.6252935528755188\n",
      "    cluster loss:             194.2030906677246\n",
      "    separation loss:          0.7728081941604614\n",
      "    avg separation loss:      3.74010694026947\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  288.6602478027344\n",
      "    train time:               0.012318134307861328\n",
      "    test time:                0.00442194938659668\n",
      "    epoch time:               0.01722407341003418\n",
      "    last layer lr:            0.008812\n",
      "epoch: 110 (19/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 80.56%\n",
      "    train overall loss:       0.5789479116598765\n",
      "    train cross_ent loss:     0.284623634070158\n",
      "    test overall loss:        0.900486171245575\n",
      "    test cross_ent loss:      0.6083815693855286\n",
      "    cluster loss:             194.20305633544922\n",
      "    separation loss:          0.7727600336074829\n",
      "    avg separation loss:      3.738685727119446\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  284.70989990234375\n",
      "    train time:               0.012322187423706055\n",
      "    test time:                0.004424333572387695\n",
      "    epoch time:               0.017228126525878906\n",
      "    last layer lr:            0.008415999999999998\n",
      "epoch: 110 (20/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 81.11%\n",
      "    train overall loss:       0.5695198178291321\n",
      "    train cross_ent loss:     0.2787507325410843\n",
      "    test overall loss:        0.8972658812999725\n",
      "    test cross_ent loss:      0.6083747446537018\n",
      "    cluster loss:             194.20269393920898\n",
      "    separation loss:          0.7729645073413849\n",
      "    avg separation loss:      3.736645221710205\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  281.4964599609375\n",
      "    train time:               0.01234745979309082\n",
      "    test time:                0.004426002502441406\n",
      "    epoch time:               0.01724839210510254\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 110 (21/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 81.67%\n",
      "    train overall loss:       0.5382926712433497\n",
      "    train cross_ent loss:     0.25077737619479495\n",
      "    test overall loss:        0.8927722573280334\n",
      "    test cross_ent loss:      0.6072112619876862\n",
      "    cluster loss:             194.20280838012695\n",
      "    separation loss:          0.7735432982444763\n",
      "    avg separation loss:      3.7374987602233887\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  278.16632080078125\n",
      "    train time:               0.0123291015625\n",
      "    test time:                0.004441022872924805\n",
      "    epoch time:               0.017243385314941406\n",
      "    last layer lr:            0.007624000000000002\n",
      "epoch: 110 (22/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 83.33%\n",
      "    train overall loss:       0.5476249853769938\n",
      "    train cross_ent loss:     0.26330756147702533\n",
      "    test overall loss:        0.8866104483604431\n",
      "    test cross_ent loss:      0.6041947603225708\n",
      "    cluster loss:             194.20330047607422\n",
      "    separation loss:          0.7747195959091187\n",
      "    avg separation loss:      3.74779736995697\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  275.02099609375\n",
      "    train time:               0.012334823608398438\n",
      "    test time:                0.004453420639038086\n",
      "    epoch time:               0.01726365089416504\n",
      "    last layer lr:            0.007228000000000001\n",
      "epoch: 110 (23/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 82.78%\n",
      "    train overall loss:       0.5327599396308264\n",
      "    train cross_ent loss:     0.2517392784357071\n",
      "    test overall loss:        0.8824337720870972\n",
      "    test cross_ent loss:      0.6034472286701202\n",
      "    cluster loss:             194.20332717895508\n",
      "    separation loss:          0.7734110653400421\n",
      "    avg separation loss:      3.7402687072753906\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  271.59185791015625\n",
      "    train time:               0.01233816146850586\n",
      "    test time:                0.004443645477294922\n",
      "    epoch time:               0.01725912094116211\n",
      "    last layer lr:            0.006832000000000001\n",
      "epoch: 110 (24/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 83.33%\n",
      "    train overall loss:       0.5322637408971786\n",
      "    train cross_ent loss:     0.2546812022725741\n",
      "    test overall loss:        0.8730103671550751\n",
      "    test cross_ent loss:      0.5974765717983246\n",
      "    cluster loss:             194.20355224609375\n",
      "    separation loss:          0.7748019695281982\n",
      "    avg separation loss:      3.7477757930755615\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  268.13909912109375\n",
      "    train time:               0.012356281280517578\n",
      "    test time:                0.004420280456542969\n",
      "    epoch time:               0.01725006103515625\n",
      "    last layer lr:            0.006436\n",
      "epoch: 110 (25/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 82.78%\n",
      "    train overall loss:       0.5345084170500437\n",
      "    train cross_ent loss:     0.2603894496957461\n",
      "    test overall loss:        0.8679048120975494\n",
      "    test cross_ent loss:      0.5958805978298187\n",
      "    cluster loss:             194.2034149169922\n",
      "    separation loss:          0.7741241753101349\n",
      "    avg separation loss:      3.746710777282715\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  264.6295166015625\n",
      "    train time:               0.012329339981079102\n",
      "    test time:                0.004429817199707031\n",
      "    epoch time:               0.01723313331604004\n",
      "    last layer lr:            0.00604\n",
      "epoch: 110 (26/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 83.33%\n",
      "    train overall loss:       0.49390122294425964\n",
      "    train cross_ent loss:     0.22317702447374663\n",
      "    test overall loss:        0.8653436601161957\n",
      "    test cross_ent loss:      0.5965286791324615\n",
      "    cluster loss:             194.20361328125\n",
      "    separation loss:          0.7732703387737274\n",
      "    avg separation loss:      3.744549512863159\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  261.4202880859375\n",
      "    train time:               0.012376546859741211\n",
      "    test time:                0.004476308822631836\n",
      "    epoch time:               0.017330408096313477\n",
      "    last layer lr:            0.005644000000000002\n",
      "epoch: 110 (27/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 83.89%\n",
      "    train overall loss:       0.5109631965557734\n",
      "    train cross_ent loss:     0.2435166910290718\n",
      "    test overall loss:        0.8554631471633911\n",
      "    test cross_ent loss:      0.5898669958114624\n",
      "    cluster loss:             194.20329666137695\n",
      "    separation loss:          0.7733025550842285\n",
      "    avg separation loss:      3.7435320615768433\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  258.2014465332031\n",
      "    train time:               0.01234292984008789\n",
      "    test time:                0.004539966583251953\n",
      "    epoch time:               0.017358064651489258\n",
      "    last layer lr:            0.005248\n",
      "epoch: 110 (28/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 83.89%\n",
      "    train overall loss:       0.5227770109971365\n",
      "    train cross_ent loss:     0.25853319466114044\n",
      "    test overall loss:        0.848090410232544\n",
      "    test cross_ent loss:      0.5855801999568939\n",
      "    cluster loss:             194.20312881469727\n",
      "    separation loss:          0.7707011103630066\n",
      "    avg separation loss:      3.7383058071136475\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  255.11553955078125\n",
      "    train time:               0.012352943420410156\n",
      "    test time:                0.004465818405151367\n",
      "    epoch time:               0.01729106903076172\n",
      "    last layer lr:            0.004852000000000001\n",
      "epoch: 110 (29/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 83.33%\n",
      "    train overall loss:       0.49535249173641205\n",
      "    train cross_ent loss:     0.23393922423322996\n",
      "    test overall loss:        0.848024308681488\n",
      "    test cross_ent loss:      0.5880643725395203\n",
      "    cluster loss:             194.20357131958008\n",
      "    separation loss:          0.7719041705131531\n",
      "    avg separation loss:      3.7483030557632446\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  252.5652618408203\n",
      "    train time:               0.012344121932983398\n",
      "    test time:                0.004422187805175781\n",
      "    epoch time:               0.017239093780517578\n",
      "    last layer lr:            0.004455999999999999\n",
      "epoch: 110 (30/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 82.78%\n",
      "    train overall loss:       0.5121336827675501\n",
      "    train cross_ent loss:     0.2531762296954791\n",
      "    test overall loss:        0.8349144160747528\n",
      "    test cross_ent loss:      0.5773142278194427\n",
      "    cluster loss:             194.20413970947266\n",
      "    separation loss:          0.772216796875\n",
      "    avg separation loss:      3.754067897796631\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  250.20550537109375\n",
      "    train time:               0.012359619140625\n",
      "    test time:                0.004439830780029297\n",
      "    epoch time:               0.017271995544433594\n",
      "    last layer lr:            0.004060000000000001\n",
      "epoch: 110 (31/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 83.89%\n",
      "    train overall loss:       0.5108644962310791\n",
      "    train cross_ent loss:     0.25415132691462833\n",
      "    test overall loss:        0.8263378143310547\n",
      "    test cross_ent loss:      0.5708696246147156\n",
      "    cluster loss:             194.2035369873047\n",
      "    separation loss:          0.7729885876178741\n",
      "    avg separation loss:      3.7509965896606445\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  248.073486328125\n",
      "    train time:               0.012337446212768555\n",
      "    test time:                0.005056142807006836\n",
      "    epoch time:               0.0178680419921875\n",
      "    last layer lr:            0.0036640000000000015\n",
      "epoch: 110 (32/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 83.89%\n",
      "    train overall loss:       0.49761853118737537\n",
      "    train cross_ent loss:     0.24301793922980627\n",
      "    test overall loss:        0.8208855390548706\n",
      "    test cross_ent loss:      0.5674671530723572\n",
      "    cluster loss:             194.2037010192871\n",
      "    separation loss:          0.7699761688709259\n",
      "    avg separation loss:      3.7435522079467773\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  246.02371215820312\n",
      "    train time:               0.012559890747070312\n",
      "    test time:                0.00443577766418457\n",
      "    epoch time:               0.017469167709350586\n",
      "    last layer lr:            0.0032679999999999996\n",
      "epoch: 110 (33/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 83.89%\n",
      "    train overall loss:       0.4879050652186076\n",
      "    train cross_ent loss:     0.2351666527489821\n",
      "    test overall loss:        0.8172472715377808\n",
      "    test cross_ent loss:      0.5654845833778381\n",
      "    cluster loss:             194.20339584350586\n",
      "    separation loss:          0.7703762650489807\n",
      "    avg separation loss:      3.747097611427307\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  244.36801147460938\n",
      "    train time:               0.01237797737121582\n",
      "    test time:                0.004457950592041016\n",
      "    epoch time:               0.017308712005615234\n",
      "    last layer lr:            0.002872000000000001\n",
      "epoch: 110 (34/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 83.89%\n",
      "    train overall loss:       0.511280799905459\n",
      "    train cross_ent loss:     0.2602257380882899\n",
      "    test overall loss:        0.8185173869132996\n",
      "    test cross_ent loss:      0.5684079229831696\n",
      "    cluster loss:             194.20383071899414\n",
      "    separation loss:          0.7747111022472382\n",
      "    avg separation loss:      3.7595252990722656\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  242.71478271484375\n",
      "    train time:               0.012348175048828125\n",
      "    test time:                0.004431962966918945\n",
      "    epoch time:               0.017253398895263672\n",
      "    last layer lr:            0.0024759999999999986\n",
      "epoch: 110 (35/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 84.44%\n",
      "    train overall loss:       0.5313712259133657\n",
      "    train cross_ent loss:     0.281805823246638\n",
      "    test overall loss:        0.8149625360965729\n",
      "    test cross_ent loss:      0.5661750733852386\n",
      "    cluster loss:             194.20331954956055\n",
      "    separation loss:          0.7732188105583191\n",
      "    avg separation loss:      3.750185251235962\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  241.39279174804688\n",
      "    train time:               0.012358665466308594\n",
      "    test time:                0.00446319580078125\n",
      "    epoch time:               0.017319679260253906\n",
      "    last layer lr:            0.0020800000000000003\n",
      "epoch: 110 (36/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 84.44%\n",
      "    train overall loss:       0.5054924090703329\n",
      "    train cross_ent loss:     0.25714916239182156\n",
      "    test overall loss:        0.8118160963058472\n",
      "    test cross_ent loss:      0.5641096234321594\n",
      "    cluster loss:             194.20341873168945\n",
      "    separation loss:          0.7759898006916046\n",
      "    avg separation loss:      3.754756450653076\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  240.311767578125\n",
      "    train time:               0.012334585189819336\n",
      "    test time:                0.004424333572387695\n",
      "    epoch time:               0.017231225967407227\n",
      "    last layer lr:            0.0016840000000000017\n",
      "epoch: 110 (37/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 84.44%\n",
      "    train overall loss:       0.49448782205581665\n",
      "    train cross_ent loss:     0.24714822694659233\n",
      "    test overall loss:        0.8108279705047607\n",
      "    test cross_ent loss:      0.5640256404876709\n",
      "    cluster loss:             194.20340728759766\n",
      "    separation loss:          0.7758249938488007\n",
      "    avg separation loss:      3.753785490989685\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  239.40768432617188\n",
      "    train time:               0.012859582901000977\n",
      "    test time:                0.004481792449951172\n",
      "    epoch time:               0.017824649810791016\n",
      "    last layer lr:            0.0012879999999999994\n",
      "epoch: 110 (38/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 83.89%\n",
      "    train overall loss:       0.47099311649799347\n",
      "    train cross_ent loss:     0.22447948902845383\n",
      "    test overall loss:        0.8078301548957825\n",
      "    test cross_ent loss:      0.5617195963859558\n",
      "    cluster loss:             194.20344161987305\n",
      "    separation loss:          0.7767330706119537\n",
      "    avg separation loss:      3.747779130935669\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  238.71585083007812\n",
      "    train time:               0.01234889030456543\n",
      "    test time:                0.004559040069580078\n",
      "    epoch time:               0.01739025115966797\n",
      "    last layer lr:            0.0008920000000000009\n",
      "epoch: 110 (39/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 84.44%\n",
      "    train overall loss:       0.46429124971230823\n",
      "    train cross_ent loss:     0.218385332574447\n",
      "    test overall loss:        0.8096949458122253\n",
      "    test cross_ent loss:      0.564076840877533\n",
      "    cluster loss:             194.20326232910156\n",
      "    separation loss:          0.7757667005062103\n",
      "    avg separation loss:      3.743578553199768\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  238.2234344482422\n",
      "    train time:               0.012331724166870117\n",
      "    test time:                0.004440784454345703\n",
      "    epoch time:               0.017252206802368164\n",
      "    last layer lr:            0.0004959999999999986\n",
      "epoch: 110 (40/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 83.89%\n",
      "    train overall loss:       0.48200226326783496\n",
      "    train cross_ent loss:     0.23649793366591135\n",
      "    test overall loss:        0.8092794716358185\n",
      "    test cross_ent loss:      0.5639356672763824\n",
      "    cluster loss:             194.2034797668457\n",
      "    separation loss:          0.774926096200943\n",
      "    avg separation loss:      3.749961495399475\n",
      "    l1_addon loss:            73.94671630859375\n",
      "    l1 loss:                  237.94912719726562\n",
      "    train time:               0.012332916259765625\n",
      "    test time:                0.004477500915527344\n",
      "    epoch time:               0.017283916473388672\n",
      "    last layer lr:            0.0001\n",
      "epoch: 111 (JOINT) - Libras\n",
      "    test acc:                 84.44%\n",
      "    train overall loss:       0.48045658071835834\n",
      "    train cross_ent loss:     0.23511259444057941\n",
      "    test overall loss:        0.7994906604290009\n",
      "    test cross_ent loss:      0.5541470944881439\n",
      "    cluster loss:             194.2045135498047\n",
      "    separation loss:          0.7725765705108643\n",
      "    avg separation loss:      3.7470531463623047\n",
      "    l1_addon loss:            73.94419860839844\n",
      "    l1 loss:                  237.94912719726562\n",
      "    train time:               0.029287338256835938\n",
      "    test time:                0.00447392463684082\n",
      "    epoch time:               0.03431582450866699\n",
      "    joint lr:                 0.0017196383771408863\n",
      "epoch: 112 (JOINT) - Libras\n",
      "    test acc:                 83.89%\n",
      "    train overall loss:       0.47557493050893146\n",
      "    train cross_ent loss:     0.23024935772021612\n",
      "    test overall loss:        0.8034352958202362\n",
      "    test cross_ent loss:      0.5581214129924774\n",
      "    cluster loss:             194.21151733398438\n",
      "    separation loss:          0.7583801448345184\n",
      "    avg separation loss:      3.7626789808273315\n",
      "    l1_addon loss:            73.64759826660156\n",
      "    l1 loss:                  237.94912719726562\n",
      "    train time:               0.029748916625976562\n",
      "    test time:                0.004488229751586914\n",
      "    epoch time:               0.03503227233886719\n",
      "    joint lr:                 0.0033068839867389757\n",
      "epoch: 113 (JOINT) - Libras\n",
      "    test acc:                 83.33%\n",
      "    train overall loss:       0.4981343348821004\n",
      "    train cross_ent loss:     0.2528185633321603\n",
      "    test overall loss:        0.7508257329463959\n",
      "    test cross_ent loss:      0.5055065453052521\n",
      "    cluster loss:             194.20133590698242\n",
      "    separation loss:          0.759148508310318\n",
      "    avg separation loss:      3.660585880279541\n",
      "    l1_addon loss:            73.70034790039062\n",
      "    l1 loss:                  237.94912719726562\n",
      "    train time:               0.0265347957611084\n",
      "    test time:                0.0045490264892578125\n",
      "    epoch time:               0.03169846534729004\n",
      "    joint lr:                 0.0048622227203073696\n",
      "epoch: 114 (JOINT) - Libras\n",
      "    test acc:                 83.89%\n",
      "    train overall loss:       0.4845624665419261\n",
      "    train cross_ent loss:     0.23924429963032404\n",
      "    test overall loss:        0.7666887044906616\n",
      "    test cross_ent loss:      0.5213989019393921\n",
      "    cluster loss:             194.22824096679688\n",
      "    separation loss:          0.8063788712024689\n",
      "    avg separation loss:      3.610296607017517\n",
      "    l1_addon loss:            73.40643310546875\n",
      "    l1 loss:                  237.94912719726562\n",
      "    train time:               0.02888178825378418\n",
      "    test time:                0.00446772575378418\n",
      "    epoch time:               0.03391885757446289\n",
      "    joint lr:                 0.00638613399080572\n",
      "epoch: 115 (JOINT) - Libras\n",
      "    test acc:                 86.11%\n",
      "    train overall loss:       0.540022999048233\n",
      "    train cross_ent loss:     0.29475925614436466\n",
      "    test overall loss:        0.8478265106678009\n",
      "    test cross_ent loss:      0.6025069653987885\n",
      "    cluster loss:             194.24278259277344\n",
      "    separation loss:          0.8684468865394592\n",
      "    avg separation loss:      3.6427292823791504\n",
      "    l1_addon loss:            73.70419311523438\n",
      "    l1 loss:                  237.94912719726562\n",
      "    train time:               0.02889704704284668\n",
      "    test time:                0.004480123519897461\n",
      "    epoch time:               0.033941030502319336\n",
      "    joint lr:                 0.007879090813622073\n",
      "epoch: 116 (JOINT) - Libras\n",
      "    test acc:                 86.67%\n",
      "    train overall loss:       0.5325450698534647\n",
      "    train cross_ent loss:     0.2872445061802864\n",
      "    test overall loss:        0.9575789868831635\n",
      "    test cross_ent loss:      0.7123820185661316\n",
      "    cluster loss:             194.23854064941406\n",
      "    separation loss:          0.8732292950153351\n",
      "    avg separation loss:      3.5936055183410645\n",
      "    l1_addon loss:            72.4786376953125\n",
      "    l1 loss:                  237.94912719726562\n",
      "    train time:               0.028833866119384766\n",
      "    test time:                0.0044727325439453125\n",
      "    epoch time:               0.034446001052856445\n",
      "    joint lr:                 0.009341559886583039\n",
      "epoch: 117 (JOINT) - Libras\n",
      "    test acc:                 77.78%\n",
      "    train overall loss:       0.5367476145426432\n",
      "    train cross_ent loss:     0.29159412036339444\n",
      "    test overall loss:        1.0249765515327454\n",
      "    test cross_ent loss:      0.7797427773475647\n",
      "    cluster loss:             194.28314590454102\n",
      "    separation loss:          0.8502258658409119\n",
      "    avg separation loss:      3.4823672771453857\n",
      "    l1_addon loss:            72.84623718261719\n",
      "    l1 loss:                  237.94912719726562\n",
      "    train time:               0.028853178024291992\n",
      "    test time:                0.004479646682739258\n",
      "    epoch time:               0.033892154693603516\n",
      "    joint lr:                 0.010774001669003403\n",
      "epoch: 118 (JOINT) - Libras\n",
      "    test acc:                 74.44%\n",
      "    train overall loss:       0.6110515892505646\n",
      "    train cross_ent loss:     0.36586783329645794\n",
      "    test overall loss:        0.9876991510391235\n",
      "    test cross_ent loss:      0.7425498962402344\n",
      "    cluster loss:             194.2675323486328\n",
      "    separation loss:          0.8028886914253235\n",
      "    avg separation loss:      3.288365602493286\n",
      "    l1_addon loss:            72.00135803222656\n",
      "    l1 loss:                  237.94912719726562\n",
      "    train time:               0.029633760452270508\n",
      "    test time:                0.004436969757080078\n",
      "    epoch time:               0.03464055061340332\n",
      "    joint lr:                 0.012176870459786701\n",
      "epoch: 119 (JOINT) - Libras\n",
      "    test acc:                 79.44%\n",
      "    train overall loss:       0.6074439883232117\n",
      "    train cross_ent loss:     0.3622267047564189\n",
      "    test overall loss:        1.085624873638153\n",
      "    test cross_ent loss:      0.8404949009418488\n",
      "    cluster loss:             194.2706069946289\n",
      "    separation loss:          0.8744828999042511\n",
      "    avg separation loss:      3.640746235847473\n",
      "    l1_addon loss:            71.80852508544922\n",
      "    l1 loss:                  237.94912719726562\n",
      "    train time:               0.02934741973876953\n",
      "    test time:                0.00456547737121582\n",
      "    epoch time:               0.0344700813293457\n",
      "    joint lr:                 0.013550614474587434\n",
      "epoch: 120 (JOINT) - Libras\n",
      "    test acc:                 85.00%\n",
      "    train overall loss:       0.6160735984643301\n",
      "    train cross_ent loss:     0.37095676362514496\n",
      "    test overall loss:        0.928394228219986\n",
      "    test cross_ent loss:      0.6833818852901459\n",
      "    cluster loss:             194.28213500976562\n",
      "    separation loss:          0.8776184320449829\n",
      "    avg separation loss:      3.400743842124939\n",
      "    l1_addon loss:            70.63203430175781\n",
      "    l1 loss:                  237.94912719726562\n",
      "    train time:               0.028966426849365234\n",
      "    test time:                0.004483461380004883\n",
      "    epoch time:               0.03457283973693848\n",
      "    joint lr:                 0.014895675922046181\n",
      "epoch: 121 (JOINT) - Libras\n",
      "    test acc:                 76.67%\n",
      "    train overall loss:       0.7861678103605906\n",
      "    train cross_ent loss:     0.5410773505767187\n",
      "    test overall loss:        1.1918704509735107\n",
      "    test cross_ent loss:      0.9469088017940521\n",
      "    cluster loss:             194.32644653320312\n",
      "    separation loss:          0.9494425654411316\n",
      "    avg separation loss:      3.6005293130874634\n",
      "    l1_addon loss:            70.12447357177734\n",
      "    l1 loss:                  237.94912719726562\n",
      "    train time:               0.029536962509155273\n",
      "    test time:                0.0044612884521484375\n",
      "    epoch time:               0.034559011459350586\n",
      "    joint lr:                 0.014015333204684437\n",
      "epoch: 122 (JOINT) - Libras\n",
      "    test acc:                 75.00%\n",
      "    train overall loss:       0.7376992404460907\n",
      "    train cross_ent loss:     0.4926057755947113\n",
      "    test overall loss:        1.1524001359939575\n",
      "    test cross_ent loss:      0.9073279798030853\n",
      "    cluster loss:             194.3754653930664\n",
      "    separation loss:          1.0215336084365845\n",
      "    avg separation loss:      3.5735132694244385\n",
      "    l1_addon loss:            71.2303466796875\n",
      "    l1 loss:                  237.94912719726562\n",
      "    train time:               0.028936386108398438\n",
      "    test time:                0.004469394683837891\n",
      "    epoch time:               0.033982038497924805\n",
      "    joint lr:                 0.01315111777407772\n",
      "epoch: 123 (JOINT) - Libras\n",
      "    test acc:                 70.00%\n",
      "    train overall loss:       0.7087488075097402\n",
      "    train cross_ent loss:     0.46361685792605084\n",
      "    test overall loss:        1.287553310394287\n",
      "    test cross_ent loss:      1.042489767074585\n",
      "    cluster loss:             194.34333038330078\n",
      "    separation loss:          0.9403245747089386\n",
      "    avg separation loss:      4.053346037864685\n",
      "    l1_addon loss:            71.14424133300781\n",
      "    l1 loss:                  237.94912719726562\n",
      "    train time:               0.028864622116088867\n",
      "    test time:                0.004488706588745117\n",
      "    epoch time:               0.0339205265045166\n",
      "    joint lr:                 0.012302795118762673\n",
      "epoch: 124 (JOINT) - Libras\n",
      "    test acc:                 60.00%\n",
      "    train overall loss:       0.7498223682244619\n",
      "    train cross_ent loss:     0.5047173202037811\n",
      "    test overall loss:        1.7398235201835632\n",
      "    test cross_ent loss:      1.4947699904441833\n",
      "    cluster loss:             194.35166931152344\n",
      "    separation loss:          1.0021213591098785\n",
      "    avg separation loss:      3.9429508447647095\n",
      "    l1_addon loss:            71.04440307617188\n",
      "    l1 loss:                  237.94912719726562\n",
      "    train time:               0.030300378799438477\n",
      "    test time:                0.004472017288208008\n",
      "    epoch time:               0.03558707237243652\n",
      "    joint lr:                 0.011470133804776505\n",
      "epoch: 125 (JOINT) - Libras\n",
      "    test acc:                 73.89%\n",
      "    train overall loss:       0.7626144886016846\n",
      "    train cross_ent loss:     0.5176023989915848\n",
      "    test overall loss:        1.286490797996521\n",
      "    test cross_ent loss:      1.0413499176502228\n",
      "    cluster loss:             194.3685188293457\n",
      "    separation loss:          1.0333296060562134\n",
      "    avg separation loss:      3.783982992172241\n",
      "    l1_addon loss:            71.91769409179688\n",
      "    l1 loss:                  237.94912719726562\n",
      "    train time:               0.0296022891998291\n",
      "    test time:                0.004454851150512695\n",
      "    epoch time:               0.0346219539642334\n",
      "    joint lr:                 0.010652905437558197\n",
      "epoch: 126 (JOINT) - Libras\n",
      "    test acc:                 77.78%\n",
      "    train overall loss:       0.6927859981854757\n",
      "    train cross_ent loss:     0.4477194895346959\n",
      "    test overall loss:        1.114657998085022\n",
      "    test cross_ent loss:      0.8696392774581909\n",
      "    cluster loss:             194.30678176879883\n",
      "    separation loss:          0.9745120704174042\n",
      "    avg separation loss:      3.75032377243042\n",
      "    l1_addon loss:            70.69554138183594\n",
      "    l1 loss:                  237.94912719726562\n",
      "    train time:               0.028658390045166016\n",
      "    test time:                0.004475831985473633\n",
      "    epoch time:               0.03369951248168945\n",
      "    joint lr:                 0.009850884624303774\n",
      "epoch: 127 (JOINT) - Libras\n",
      "    test acc:                 66.67%\n",
      "    train overall loss:       0.6830917398134867\n",
      "    train cross_ent loss:     0.43800432483355206\n",
      "    test overall loss:        1.5772854089736938\n",
      "    test cross_ent loss:      1.3322168588638306\n",
      "    cluster loss:             194.43101119995117\n",
      "    separation loss:          1.0598846971988678\n",
      "    avg separation loss:      4.1938230991363525\n",
      "    l1_addon loss:            71.19384765625\n",
      "    l1 loss:                  237.94912719726562\n",
      "    train time:               0.029245615005493164\n",
      "    test time:                0.004461050033569336\n",
      "    epoch time:               0.0342717170715332\n",
      "    joint lr:                 0.00906384893677068\n",
      "epoch: 128 (JOINT) - Libras\n",
      "    test acc:                 79.44%\n",
      "    train overall loss:       0.6268472373485565\n",
      "    train cross_ent loss:     0.3818156272172928\n",
      "    test overall loss:        1.0204336047172546\n",
      "    test cross_ent loss:      0.7753190100193024\n",
      "    cluster loss:             194.2618865966797\n",
      "    separation loss:          0.9173054993152618\n",
      "    avg separation loss:      3.7413344383239746\n",
      "    l1_addon loss:            71.65463256835938\n",
      "    l1 loss:                  237.94912719726562\n",
      "    train time:               0.029973506927490234\n",
      "    test time:                0.004467964172363281\n",
      "    epoch time:               0.035080909729003906\n",
      "    joint lr:                 0.00829157887452582\n",
      "epoch: 129 (JOINT) - Libras\n",
      "    test acc:                 55.56%\n",
      "    train overall loss:       0.5615096737941107\n",
      "    train cross_ent loss:     0.3164248565832774\n",
      "    test overall loss:        1.6786465644836426\n",
      "    test cross_ent loss:      1.4336771667003632\n",
      "    cluster loss:             194.5922393798828\n",
      "    separation loss:          1.1437164545059204\n",
      "    avg separation loss:      4.36723518371582\n",
      "    l1_addon loss:            70.20195007324219\n",
      "    l1 loss:                  237.94912719726562\n",
      "    train time:               0.028861045837402344\n",
      "    test time:                0.004437446594238281\n",
      "    epoch time:               0.03385663032531738\n",
      "    joint lr:                 0.007533857828632187\n",
      "epoch: 130 (JOINT) - Libras\n",
      "    test acc:                 78.33%\n",
      "    train overall loss:       0.5183989008267721\n",
      "    train cross_ent loss:     0.27342022210359573\n",
      "    test overall loss:        0.9879136979579926\n",
      "    test cross_ent loss:      0.742875874042511\n",
      "    cluster loss:             194.26782989501953\n",
      "    separation loss:          0.8811523616313934\n",
      "    avg separation loss:      3.8086620569229126\n",
      "    l1_addon loss:            70.88714599609375\n",
      "    l1 loss:                  237.94912719726562\n",
      "    train time:               0.028963565826416016\n",
      "    test time:                0.0045397281646728516\n",
      "    epoch time:               0.03406953811645508\n",
      "    joint lr:                 0.00679047204576897\n",
      "epoch: 131 (JOINT) - Libras\n",
      "    test acc:                 80.56%\n",
      "    train overall loss:       0.49279401699701947\n",
      "    train cross_ent loss:     0.24778339018424353\n",
      "    test overall loss:        0.726121187210083\n",
      "    test cross_ent loss:      0.4811345934867859\n",
      "    cluster loss:             194.23316192626953\n",
      "    separation loss:          0.8336958289146423\n",
      "    avg separation loss:      3.5681354999542236\n",
      "    l1_addon loss:            70.37458038330078\n",
      "    l1 loss:                  237.94912719726562\n",
      "    train time:               0.028710365295410156\n",
      "    test time:                0.004459857940673828\n",
      "    epoch time:               0.03373289108276367\n",
      "    joint lr:                 0.006061210592780146\n",
      "epoch: 132 (JOINT) - Libras\n",
      "    test acc:                 70.56%\n",
      "    train overall loss:       0.49651038149992627\n",
      "    train cross_ent loss:     0.2515399443606536\n",
      "    test overall loss:        1.0981143712997437\n",
      "    test cross_ent loss:      0.8531278371810913\n",
      "    cluster loss:             194.26199340820312\n",
      "    separation loss:          0.7690124809741974\n",
      "    avg separation loss:      3.5290470123291016\n",
      "    l1_addon loss:            70.37408447265625\n",
      "    l1 loss:                  237.94912719726562\n",
      "    train time:               0.030388832092285156\n",
      "    test time:                0.0044705867767333984\n",
      "    epoch time:               0.0354461669921875\n",
      "    joint lr:                 0.005345865321646531\n",
      "epoch: 133 (JOINT) - Libras\n",
      "    test acc:                 81.67%\n",
      "    train overall loss:       0.4302367369333903\n",
      "    train cross_ent loss:     0.18525290240844092\n",
      "    test overall loss:        0.7723868787288666\n",
      "    test cross_ent loss:      0.5274178087711334\n",
      "    cluster loss:             194.21247482299805\n",
      "    separation loss:          0.7286455035209656\n",
      "    avg separation loss:      3.5072226524353027\n",
      "    l1_addon loss:            70.19920349121094\n",
      "    l1 loss:                  237.94912719726562\n",
      "    train time:               0.02940988540649414\n",
      "    test time:                0.004441976547241211\n",
      "    epoch time:               0.034438371658325195\n",
      "    joint lr:                 0.00464423083487631\n",
      "epoch: 134 (JOINT) - Libras\n",
      "    test acc:                 86.11%\n",
      "    train overall loss:       0.41298557817935944\n",
      "    train cross_ent loss:     0.1680138489852349\n",
      "    test overall loss:        0.6446660161018372\n",
      "    test cross_ent loss:      0.3996831327676773\n",
      "    cluster loss:             194.2110939025879\n",
      "    separation loss:          0.7139763832092285\n",
      "    avg separation loss:      3.33840811252594\n",
      "    l1_addon loss:            70.337646484375\n",
      "    l1 loss:                  237.94912719726562\n",
      "    train time:               0.02929234504699707\n",
      "    test time:                0.004456996917724609\n",
      "    epoch time:               0.03432106971740723\n",
      "    joint lr:                 0.003956104451309328\n",
      "epoch: 135 (JOINT) - Libras\n",
      "    test acc:                 84.44%\n",
      "    train overall loss:       0.46396883328755695\n",
      "    train cross_ent loss:     0.2189974014957746\n",
      "    test overall loss:        0.6248953640460968\n",
      "    test cross_ent loss:      0.37993694841861725\n",
      "    cluster loss:             194.21388244628906\n",
      "    separation loss:          0.6947974562644958\n",
      "    avg separation loss:      3.2498339414596558\n",
      "    l1_addon loss:            70.09284210205078\n",
      "    l1 loss:                  237.94912719726562\n",
      "    train time:               0.029263734817504883\n",
      "    test time:                0.004480600357055664\n",
      "    epoch time:               0.03431272506713867\n",
      "    joint lr:                 0.0032812861723301896\n",
      "epoch: 136 (JOINT) - Libras\n",
      "    test acc:                 85.00%\n",
      "    train overall loss:       0.41878361999988556\n",
      "    train cross_ent loss:     0.17382208878795305\n",
      "    test overall loss:        0.6560038030147552\n",
      "    test cross_ent loss:      0.4110442250967026\n",
      "    cluster loss:             194.22365188598633\n",
      "    separation loss:          0.6947554051876068\n",
      "    avg separation loss:      3.2440123558044434\n",
      "    l1_addon loss:            70.10435485839844\n",
      "    l1 loss:                  237.94912719726562\n",
      "    train time:               0.02932882308959961\n",
      "    test time:                0.004587411880493164\n",
      "    epoch time:               0.03477358818054199\n",
      "    joint lr:                 0.0026195786484855114\n",
      "epoch: 137 (JOINT) - Libras\n",
      "    test acc:                 83.89%\n",
      "    train overall loss:       0.4244493693113327\n",
      "    train cross_ent loss:     0.17949723452329636\n",
      "    test overall loss:        0.6509177088737488\n",
      "    test cross_ent loss:      0.4059842824935913\n",
      "    cluster loss:             194.21085357666016\n",
      "    separation loss:          0.690382570028305\n",
      "    avg separation loss:      3.2698322534561157\n",
      "    l1_addon loss:            69.84275817871094\n",
      "    l1 loss:                  237.94912719726562\n",
      "    train time:               0.028881311416625977\n",
      "    test time:                0.004503011703491211\n",
      "    epoch time:               0.03394007682800293\n",
      "    joint lr:                 0.0019707871465004943\n",
      "epoch: 138 (JOINT) - Libras\n",
      "    test acc:                 85.00%\n",
      "    train overall loss:       0.4098105976978938\n",
      "    train cross_ent loss:     0.1648761828740438\n",
      "    test overall loss:        0.6608198881149292\n",
      "    test cross_ent loss:      0.41587650775909424\n",
      "    cluster loss:             194.2124252319336\n",
      "    separation loss:          0.6999959647655487\n",
      "    avg separation loss:      3.2438143491744995\n",
      "    l1_addon loss:            69.9425048828125\n",
      "    l1 loss:                  237.94912719726562\n",
      "    train time:               0.028894424438476562\n",
      "    test time:                0.007443666458129883\n",
      "    epoch time:               0.03690338134765625\n",
      "    joint lr:                 0.0013347195166903292\n",
      "epoch: 139 (JOINT) - Libras\n",
      "    test acc:                 83.33%\n",
      "    train overall loss:       0.42486873765786487\n",
      "    train cross_ent loss:     0.17991531019409499\n",
      "    test overall loss:        0.6928140223026276\n",
      "    test cross_ent loss:      0.44786015152931213\n",
      "    cluster loss:             194.2116813659668\n",
      "    separation loss:          0.6928127706050873\n",
      "    avg separation loss:      3.2080078125\n",
      "    l1_addon loss:            70.04763793945312\n",
      "    l1 loss:                  237.94912719726562\n",
      "    train time:               0.02892017364501953\n",
      "    test time:                0.004464387893676758\n",
      "    epoch time:               0.03394961357116699\n",
      "    joint lr:                 0.0007111861607617089\n",
      "epoch: 140 (JOINT) - Libras\n",
      "    test acc:                 84.44%\n",
      "    train overall loss:       0.39927002290884656\n",
      "    train cross_ent loss:     0.15432304392258325\n",
      "    test overall loss:        0.6125153005123138\n",
      "    test cross_ent loss:      0.3675767630338669\n",
      "    cluster loss:             194.2058982849121\n",
      "    separation loss:          0.6794376075267792\n",
      "    avg separation loss:      3.1764869689941406\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  237.94912719726562\n",
      "    train time:               0.030545949935913086\n",
      "    test time:                0.0044651031494140625\n",
      "    epoch time:               0.03557705879211426\n",
      "    joint lr:                 0.0001\n",
      "epoch: 140 (PUSH) - Libras\n",
      "    test acc:                 82.78%\n",
      "    train overall loss:       0.39927002290884656\n",
      "    train cross_ent loss:     0.15432304392258325\n",
      "    test overall loss:        0.7423454523086548\n",
      "    test cross_ent loss:      0.49740689992904663\n",
      "    cluster loss:             194.1997833251953\n",
      "    separation loss:          0.6615169942378998\n",
      "    avg separation loss:      3.2053449153900146\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  237.94912719726562\n",
      "    train time:               0.030545949935913086\n",
      "    test time:                0.004511356353759766\n",
      "    epoch time:               0.06558680534362793\n",
      "epoch: 140 (1/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 83.33%\n",
      "    train overall loss:       0.43518999218940735\n",
      "    train cross_ent loss:     0.19027501344680786\n",
      "    test overall loss:        0.7323847115039825\n",
      "    test cross_ent loss:      0.4875030219554901\n",
      "    cluster loss:             194.1987533569336\n",
      "    separation loss:          0.6567091345787048\n",
      "    avg separation loss:      3.187296986579895\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  237.89224243164062\n",
      "    train time:               0.012413263320922852\n",
      "    test time:                0.004472494125366211\n",
      "    epoch time:               0.017357826232910156\n",
      "    last layer lr:            0.0007599999999999978\n",
      "epoch: 140 (2/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 83.89%\n",
      "    train overall loss:       0.4535509745279948\n",
      "    train cross_ent loss:     0.20887101193269095\n",
      "    test overall loss:        0.7239809036254883\n",
      "    test cross_ent loss:      0.47957925498485565\n",
      "    cluster loss:             194.19871139526367\n",
      "    separation loss:          0.6556739211082458\n",
      "    avg separation loss:      3.183745265007019\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  237.41221618652344\n",
      "    train time:               0.012392520904541016\n",
      "    test time:                0.0044782161712646484\n",
      "    epoch time:               0.01734304428100586\n",
      "    last layer lr:            0.0014199999999999955\n",
      "epoch: 140 (3/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 84.44%\n",
      "    train overall loss:       0.42958297332127887\n",
      "    train cross_ent loss:     0.1855880580842495\n",
      "    test overall loss:        0.7210592925548553\n",
      "    test cross_ent loss:      0.4775960147380829\n",
      "    cluster loss:             194.1988067626953\n",
      "    separation loss:          0.655504047870636\n",
      "    avg separation loss:      3.1793185472488403\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  236.47384643554688\n",
      "    train time:               0.012355566024780273\n",
      "    test time:                0.004462480545043945\n",
      "    epoch time:               0.017290353775024414\n",
      "    last layer lr:            0.0020800000000000046\n",
      "epoch: 140 (4/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 84.44%\n",
      "    train overall loss:       0.41827290256818134\n",
      "    train cross_ent loss:     0.17533636341492334\n",
      "    test overall loss:        0.7181123793125153\n",
      "    test cross_ent loss:      0.47592893242836\n",
      "    cluster loss:             194.19904327392578\n",
      "    separation loss:          0.6548435091972351\n",
      "    avg separation loss:      3.171509027481079\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  235.19403076171875\n",
      "    train time:               0.012420654296875\n",
      "    test time:                0.004477262496948242\n",
      "    epoch time:               0.017377138137817383\n",
      "    last layer lr:            0.0027400000000000024\n",
      "epoch: 140 (5/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 84.44%\n",
      "    train overall loss:       0.4516754150390625\n",
      "    train cross_ent loss:     0.21027440577745438\n",
      "    test overall loss:        0.7159386277198792\n",
      "    test cross_ent loss:      0.4756331592798233\n",
      "    cluster loss:             194.1991958618164\n",
      "    separation loss:          0.6551822423934937\n",
      "    avg separation loss:      3.1733874082565308\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  233.3160400390625\n",
      "    train time:               0.012375354766845703\n",
      "    test time:                0.0044710636138916016\n",
      "    epoch time:               0.017322301864624023\n",
      "    last layer lr:            0.0034\n",
      "epoch: 140 (6/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 84.44%\n",
      "    train overall loss:       0.4268746127684911\n",
      "    train cross_ent loss:     0.18753017112612724\n",
      "    test overall loss:        0.7117880880832672\n",
      "    test cross_ent loss:      0.4737939387559891\n",
      "    cluster loss:             194.19887924194336\n",
      "    separation loss:          0.6548017859458923\n",
      "    avg separation loss:      3.166606068611145\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  231.00469970703125\n",
      "    train time:               0.012455224990844727\n",
      "    test time:                0.004464387893676758\n",
      "    epoch time:               0.01740121841430664\n",
      "    last layer lr:            0.004059999999999998\n",
      "epoch: 140 (7/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 85.56%\n",
      "    train overall loss:       0.44616002837816876\n",
      "    train cross_ent loss:     0.20928972462813059\n",
      "    test overall loss:        0.7089247107505798\n",
      "    test cross_ent loss:      0.4736398905515671\n",
      "    cluster loss:             194.19990921020508\n",
      "    separation loss:          0.6598843038082123\n",
      "    avg separation loss:      3.1786409616470337\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  228.29541015625\n",
      "    train time:               0.012376546859741211\n",
      "    test time:                0.005789518356323242\n",
      "    epoch time:               0.018642902374267578\n",
      "    last layer lr:            0.004719999999999996\n",
      "epoch: 140 (8/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 86.11%\n",
      "    train overall loss:       0.4060383935769399\n",
      "    train cross_ent loss:     0.1719202051560084\n",
      "    test overall loss:        0.7120747268199921\n",
      "    test cross_ent loss:      0.47966326773166656\n",
      "    cluster loss:             194.20013046264648\n",
      "    separation loss:          0.6602071225643158\n",
      "    avg separation loss:      3.181317090988159\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  225.42202758789062\n",
      "    train time:               0.012369871139526367\n",
      "    test time:                0.004431486129760742\n",
      "    epoch time:               0.017275571823120117\n",
      "    last layer lr:            0.0053800000000000054\n",
      "epoch: 140 (9/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 86.11%\n",
      "    train overall loss:       0.4096374561389287\n",
      "    train cross_ent loss:     0.17876326044400534\n",
      "    test overall loss:        0.7139054536819458\n",
      "    test cross_ent loss:      0.4851886034011841\n",
      "    cluster loss:             194.19923782348633\n",
      "    separation loss:          0.6561303436756134\n",
      "    avg separation loss:      3.1733622550964355\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  221.7274169921875\n",
      "    train time:               0.012902259826660156\n",
      "    test time:                0.004494905471801758\n",
      "    epoch time:               0.017912626266479492\n",
      "    last layer lr:            0.006040000000000003\n",
      "epoch: 140 (10/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 86.11%\n",
      "    train overall loss:       0.4212365796168645\n",
      "    train cross_ent loss:     0.19417897736032805\n",
      "    test overall loss:        0.7075846195220947\n",
      "    test cross_ent loss:      0.4827951490879059\n",
      "    cluster loss:             194.20074462890625\n",
      "    separation loss:          0.659855842590332\n",
      "    avg separation loss:      3.1874128580093384\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  217.80003356933594\n",
      "    train time:               0.012347221374511719\n",
      "    test time:                0.005239963531494141\n",
      "    epoch time:               0.018065452575683594\n",
      "    last layer lr:            0.0067\n",
      "epoch: 140 (11/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 85.56%\n",
      "    train overall loss:       0.39840783178806305\n",
      "    train cross_ent loss:     0.17537352442741394\n",
      "    test overall loss:        0.7026451826095581\n",
      "    test cross_ent loss:      0.48206429183483124\n",
      "    cluster loss:             194.19994735717773\n",
      "    separation loss:          0.6572947204113007\n",
      "    avg separation loss:      3.18946373462677\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  213.59144592285156\n",
      "    train time:               0.012332439422607422\n",
      "    test time:                0.004439353942871094\n",
      "    epoch time:               0.0172421932220459\n",
      "    last layer lr:            0.0073599999999999985\n",
      "epoch: 140 (12/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 83.89%\n",
      "    train overall loss:       0.39694306751092273\n",
      "    train cross_ent loss:     0.1781991943717003\n",
      "    test overall loss:        0.6938350796699524\n",
      "    test cross_ent loss:      0.4777538776397705\n",
      "    cluster loss:             194.1993179321289\n",
      "    separation loss:          0.6560282409191132\n",
      "    avg separation loss:      3.18535840511322\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  209.09173583984375\n",
      "    train time:               0.012317657470703125\n",
      "    test time:                0.00515294075012207\n",
      "    epoch time:               0.017944812774658203\n",
      "    last layer lr:            0.008019999999999994\n",
      "epoch: 140 (13/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 83.89%\n",
      "    train overall loss:       0.38691147168477374\n",
      "    train cross_ent loss:     0.17305022105574608\n",
      "    test overall loss:        0.6881393492221832\n",
      "    test cross_ent loss:      0.47733065485954285\n",
      "    cluster loss:             194.19955444335938\n",
      "    separation loss:          0.6572109758853912\n",
      "    avg separation loss:      3.18076491355896\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  203.8192596435547\n",
      "    train time:               0.012422561645507812\n",
      "    test time:                0.0045239925384521484\n",
      "    epoch time:               0.01741814613342285\n",
      "    last layer lr:            0.008680000000000005\n",
      "epoch: 140 (14/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 83.89%\n",
      "    train overall loss:       0.4010698199272156\n",
      "    train cross_ent loss:     0.19264365111788115\n",
      "    test overall loss:        0.6874848008155823\n",
      "    test cross_ent loss:      0.4822787046432495\n",
      "    cluster loss:             194.19913482666016\n",
      "    separation loss:          0.6552225947380066\n",
      "    avg separation loss:      3.179153561592102\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  198.2166748046875\n",
      "    train time:               0.01237177848815918\n",
      "    test time:                0.004437923431396484\n",
      "    epoch time:               0.017292022705078125\n",
      "    last layer lr:            0.009340000000000003\n",
      "epoch: 140 (15/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 86.11%\n",
      "    train overall loss:       0.3715014159679413\n",
      "    train cross_ent loss:     0.16888512298464775\n",
      "    test overall loss:        0.678331583738327\n",
      "    test cross_ent loss:      0.47903965413570404\n",
      "    cluster loss:             194.19896697998047\n",
      "    separation loss:          0.6538550555706024\n",
      "    avg separation loss:      3.1744823455810547\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  192.30252075195312\n",
      "    train time:               0.012374639511108398\n",
      "    test time:                0.00445866584777832\n",
      "    epoch time:               0.01730513572692871\n",
      "    last layer lr:            0.01\n",
      "epoch: 140 (16/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 87.22%\n",
      "    train overall loss:       0.3614007482926051\n",
      "    train cross_ent loss:     0.1641867458820343\n",
      "    test overall loss:        0.6833879947662354\n",
      "    test cross_ent loss:      0.48932456970214844\n",
      "    cluster loss:             194.19932174682617\n",
      "    separation loss:          0.6566359102725983\n",
      "    avg separation loss:      3.175584554672241\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  187.07400512695312\n",
      "    train time:               0.012336254119873047\n",
      "    test time:                0.004450559616088867\n",
      "    epoch time:               0.0172574520111084\n",
      "    last layer lr:            0.009604000000000001\n",
      "epoch: 140 (17/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 87.22%\n",
      "    train overall loss:       0.35356132686138153\n",
      "    train cross_ent loss:     0.16200550893942514\n",
      "    test overall loss:        0.677025705575943\n",
      "    test cross_ent loss:      0.4889487773180008\n",
      "    cluster loss:             194.19956588745117\n",
      "    separation loss:          0.6561205089092255\n",
      "    avg separation loss:      3.1800519227981567\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  181.08749389648438\n",
      "    train time:               0.012399911880493164\n",
      "    test time:                0.004412651062011719\n",
      "    epoch time:               0.017286062240600586\n",
      "    last layer lr:            0.009208000000000003\n",
      "epoch: 140 (18/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 86.11%\n",
      "    train overall loss:       0.3646499266227086\n",
      "    train cross_ent loss:     0.17904306575655937\n",
      "    test overall loss:        0.6698593497276306\n",
      "    test cross_ent loss:      0.4873865395784378\n",
      "    cluster loss:             194.19903564453125\n",
      "    separation loss:          0.6539662778377533\n",
      "    avg separation loss:      3.1695674657821655\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  175.4833984375\n",
      "    train time:               0.012336254119873047\n",
      "    test time:                0.004465818405151367\n",
      "    epoch time:               0.017275571823120117\n",
      "    last layer lr:            0.008811999999999997\n",
      "epoch: 140 (19/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 84.44%\n",
      "    train overall loss:       0.34860385954380035\n",
      "    train cross_ent loss:     0.16812589888771376\n",
      "    test overall loss:        0.6653465628623962\n",
      "    test cross_ent loss:      0.4875412732362747\n",
      "    cluster loss:             194.19890594482422\n",
      "    separation loss:          0.6538493037223816\n",
      "    avg separation loss:      3.1629754304885864\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  170.8158416748047\n",
      "    train time:               0.012364625930786133\n",
      "    test time:                0.00450587272644043\n",
      "    epoch time:               0.01735067367553711\n",
      "    last layer lr:            0.008415999999999998\n",
      "epoch: 140 (20/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 85.56%\n",
      "    train overall loss:       0.3486613631248474\n",
      "    train cross_ent loss:     0.1724565364420414\n",
      "    test overall loss:        0.6615093648433685\n",
      "    test cross_ent loss:      0.48755840957164764\n",
      "    cluster loss:             194.19931030273438\n",
      "    separation loss:          0.6554206311702728\n",
      "    avg separation loss:      3.1695990562438965\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  166.96153259277344\n",
      "    train time:               0.012347221374511719\n",
      "    test time:                0.004465579986572266\n",
      "    epoch time:               0.017286062240600586\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 140 (21/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 87.22%\n",
      "    train overall loss:       0.34622108439604443\n",
      "    train cross_ent loss:     0.17392914990584055\n",
      "    test overall loss:        0.6577426195144653\n",
      "    test cross_ent loss:      0.48791664838790894\n",
      "    cluster loss:             194.19956970214844\n",
      "    separation loss:          0.6569339632987976\n",
      "    avg separation loss:      3.172592520713806\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  162.83657836914062\n",
      "    train time:               0.012371301651000977\n",
      "    test time:                0.004472970962524414\n",
      "    epoch time:               0.017322063446044922\n",
      "    last layer lr:            0.007624000000000002\n",
      "epoch: 140 (22/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 86.67%\n",
      "    train overall loss:       0.32928722848494846\n",
      "    train cross_ent loss:     0.1612781658768654\n",
      "    test overall loss:        0.6543403267860413\n",
      "    test cross_ent loss:      0.4887271374464035\n",
      "    cluster loss:             194.1994400024414\n",
      "    separation loss:          0.655508428812027\n",
      "    avg separation loss:      3.1709513664245605\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  158.62374877929688\n",
      "    train time:               0.012356996536254883\n",
      "    test time:                0.004436492919921875\n",
      "    epoch time:               0.017264127731323242\n",
      "    last layer lr:            0.0072280000000000035\n",
      "epoch: 140 (23/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 86.67%\n",
      "    train overall loss:       0.3241331875324249\n",
      "    train cross_ent loss:     0.15988254050413767\n",
      "    test overall loss:        0.6575339734554291\n",
      "    test cross_ent loss:      0.4952722042798996\n",
      "    cluster loss:             194.1993064880371\n",
      "    separation loss:          0.6550944149494171\n",
      "    avg separation loss:      3.174248218536377\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  155.27235412597656\n",
      "    train time:               0.012329339981079102\n",
      "    test time:                0.0050640106201171875\n",
      "    epoch time:               0.01787424087524414\n",
      "    last layer lr:            0.006831999999999998\n",
      "epoch: 140 (24/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 86.67%\n",
      "    train overall loss:       0.3108355949322383\n",
      "    train cross_ent loss:     0.14999205122391382\n",
      "    test overall loss:        0.6602828502655029\n",
      "    test cross_ent loss:      0.5013338774442673\n",
      "    cluster loss:             194.19952774047852\n",
      "    separation loss:          0.6554911434650421\n",
      "    avg separation loss:      3.176683783531189\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  151.95953369140625\n",
      "    train time:               0.012543201446533203\n",
      "    test time:                0.004563570022583008\n",
      "    epoch time:               0.017584562301635742\n",
      "    last layer lr:            0.006436\n",
      "epoch: 140 (25/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 87.22%\n",
      "    train overall loss:       0.32386306921641034\n",
      "    train cross_ent loss:     0.16621601457397142\n",
      "    test overall loss:        0.6555800437927246\n",
      "    test cross_ent loss:      0.49984973669052124\n",
      "    cluster loss:             194.19919967651367\n",
      "    separation loss:          0.6547441184520721\n",
      "    avg separation loss:      3.174099922180176\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  148.7408447265625\n",
      "    train time:               0.01237034797668457\n",
      "    test time:                0.006356000900268555\n",
      "    epoch time:               0.019201278686523438\n",
      "    last layer lr:            0.00604\n",
      "epoch: 140 (26/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 86.67%\n",
      "    train overall loss:       0.3162477066119512\n",
      "    train cross_ent loss:     0.16172278424104056\n",
      "    test overall loss:        0.6455965936183929\n",
      "    test cross_ent loss:      0.4928506910800934\n",
      "    cluster loss:             194.19923400878906\n",
      "    separation loss:          0.6549954116344452\n",
      "    avg separation loss:      3.169893980026245\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  145.7564697265625\n",
      "    train time:               0.012322425842285156\n",
      "    test time:                0.004450559616088867\n",
      "    epoch time:               0.017265796661376953\n",
      "    last layer lr:            0.005644000000000002\n",
      "epoch: 140 (27/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 86.11%\n",
      "    train overall loss:       0.31304866820573807\n",
      "    train cross_ent loss:     0.16137653961777687\n",
      "    test overall loss:        0.6388415992259979\n",
      "    test cross_ent loss:      0.488678440451622\n",
      "    cluster loss:             194.19995880126953\n",
      "    separation loss:          0.65631103515625\n",
      "    avg separation loss:      3.1784900426864624\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  143.17372131347656\n",
      "    train time:               0.01233053207397461\n",
      "    test time:                0.005087614059448242\n",
      "    epoch time:               0.017888784408569336\n",
      "    last layer lr:            0.005248000000000003\n",
      "epoch: 140 (28/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 85.56%\n",
      "    train overall loss:       0.3217104847232501\n",
      "    train cross_ent loss:     0.1727600395679474\n",
      "    test overall loss:        0.6329331994056702\n",
      "    test cross_ent loss:      0.48540301620960236\n",
      "    cluster loss:             194.20010375976562\n",
      "    separation loss:          0.6556508541107178\n",
      "    avg separation loss:      3.179436683654785\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  140.54075622558594\n",
      "    train time:               0.01279592514038086\n",
      "    test time:                0.004489421844482422\n",
      "    epoch time:               0.01776432991027832\n",
      "    last layer lr:            0.004851999999999998\n",
      "epoch: 140 (29/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 84.44%\n",
      "    train overall loss:       0.31449077030022937\n",
      "    train cross_ent loss:     0.1675157199303309\n",
      "    test overall loss:        0.6326136291027069\n",
      "    test cross_ent loss:      0.48657289147377014\n",
      "    cluster loss:             194.19966506958008\n",
      "    separation loss:          0.6560486257076263\n",
      "    avg separation loss:      3.1795809268951416\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  139.05130004882812\n",
      "    train time:               0.012525558471679688\n",
      "    test time:                0.004431009292602539\n",
      "    epoch time:               0.017431974411010742\n",
      "    last layer lr:            0.004455999999999999\n",
      "epoch: 140 (30/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 86.11%\n",
      "    train overall loss:       0.30132344861825305\n",
      "    train cross_ent loss:     0.15594998560845852\n",
      "    test overall loss:        0.6316502094268799\n",
      "    test cross_ent loss:      0.48718583583831787\n",
      "    cluster loss:             194.1991844177246\n",
      "    separation loss:          0.6540534198284149\n",
      "    avg separation loss:      3.1725815534591675\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  137.47496032714844\n",
      "    train time:               0.012333869934082031\n",
      "    test time:                0.004442691802978516\n",
      "    epoch time:               0.01725006103515625\n",
      "    last layer lr:            0.004060000000000001\n",
      "epoch: 140 (31/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 85.56%\n",
      "    train overall loss:       0.2906443327665329\n",
      "    train cross_ent loss:     0.1467226209739844\n",
      "    test overall loss:        0.6357829570770264\n",
      "    test cross_ent loss:      0.49263930320739746\n",
      "    cluster loss:             194.19929122924805\n",
      "    separation loss:          0.6551171541213989\n",
      "    avg separation loss:      3.17191481590271\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  136.15420532226562\n",
      "    train time:               0.012358903884887695\n",
      "    test time:                0.004431724548339844\n",
      "    epoch time:               0.017264604568481445\n",
      "    last layer lr:            0.0036640000000000015\n",
      "epoch: 140 (32/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 86.11%\n",
      "    train overall loss:       0.30165912210941315\n",
      "    train cross_ent loss:     0.15906806662678719\n",
      "    test overall loss:        0.6373336613178253\n",
      "    test cross_ent loss:      0.49548259377479553\n",
      "    cluster loss:             194.19939804077148\n",
      "    separation loss:          0.6568745970726013\n",
      "    avg separation loss:      3.1784207820892334\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  134.86163330078125\n",
      "    train time:               0.01234745979309082\n",
      "    test time:                0.004425048828125\n",
      "    epoch time:               0.01724529266357422\n",
      "    last layer lr:            0.003268000000000003\n",
      "epoch: 140 (33/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 86.11%\n",
      "    train overall loss:       0.30337420602639514\n",
      "    train cross_ent loss:     0.1619082366426786\n",
      "    test overall loss:        0.6378910541534424\n",
      "    test cross_ent loss:      0.4970974326133728\n",
      "    cluster loss:             194.19994735717773\n",
      "    separation loss:          0.6565412878990173\n",
      "    avg separation loss:      3.1786638498306274\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  133.80416870117188\n",
      "    train time:               0.01280975341796875\n",
      "    test time:                0.0044291019439697266\n",
      "    epoch time:               0.017714500427246094\n",
      "    last layer lr:            0.002871999999999997\n",
      "epoch: 140 (34/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 86.11%\n",
      "    train overall loss:       0.2897425591945648\n",
      "    train cross_ent loss:     0.14947626615564027\n",
      "    test overall loss:        0.6388773918151855\n",
      "    test cross_ent loss:      0.49938851594924927\n",
      "    cluster loss:             194.19908142089844\n",
      "    separation loss:          0.6544165909290314\n",
      "    avg separation loss:      3.1837610006332397\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  132.49945068359375\n",
      "    train time:               0.012351751327514648\n",
      "    test time:                0.004428386688232422\n",
      "    epoch time:               0.017292261123657227\n",
      "    last layer lr:            0.0024759999999999986\n",
      "epoch: 140 (35/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 86.11%\n",
      "    train overall loss:       0.2994710902372996\n",
      "    train cross_ent loss:     0.16046402975916862\n",
      "    test overall loss:        0.6333437263965607\n",
      "    test cross_ent loss:      0.4950147420167923\n",
      "    cluster loss:             194.19942474365234\n",
      "    separation loss:          0.6549567580223083\n",
      "    avg separation loss:      3.175544261932373\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  131.3395538330078\n",
      "    train time:               0.012357473373413086\n",
      "    test time:                0.00453948974609375\n",
      "    epoch time:               0.017385005950927734\n",
      "    last layer lr:            0.0020800000000000003\n",
      "epoch: 140 (36/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 86.11%\n",
      "    train overall loss:       0.2843262453873952\n",
      "    train cross_ent loss:     0.14638295521338782\n",
      "    test overall loss:        0.6385113000869751\n",
      "    test cross_ent loss:      0.5010920763015747\n",
      "    cluster loss:             194.2001495361328\n",
      "    separation loss:          0.6568732559680939\n",
      "    avg separation loss:      3.1698447465896606\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  130.4298095703125\n",
      "    train time:               0.012357711791992188\n",
      "    test time:                0.004465818405151367\n",
      "    epoch time:               0.017296791076660156\n",
      "    last layer lr:            0.0016840000000000017\n",
      "epoch: 140 (37/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 85.56%\n",
      "    train overall loss:       0.2998611902197202\n",
      "    train cross_ent loss:     0.16275190065304437\n",
      "    test overall loss:        0.6330378651618958\n",
      "    test cross_ent loss:      0.4963601380586624\n",
      "    cluster loss:             194.20008850097656\n",
      "    separation loss:          0.657018393278122\n",
      "    avg separation loss:      3.17697274684906\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  129.6883087158203\n",
      "    train time:               0.012346267700195312\n",
      "    test time:                0.004433870315551758\n",
      "    epoch time:               0.017251968383789062\n",
      "    last layer lr:            0.001288000000000003\n",
      "epoch: 140 (38/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 86.11%\n",
      "    train overall loss:       0.2860319937268893\n",
      "    train cross_ent loss:     0.14958367000023523\n",
      "    test overall loss:        0.6299708485603333\n",
      "    test cross_ent loss:      0.4938257783651352\n",
      "    cluster loss:             194.19975662231445\n",
      "    separation loss:          0.6580875217914581\n",
      "    avg separation loss:      3.184654951095581\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  129.1556396484375\n",
      "    train time:               0.012704849243164062\n",
      "    test time:                0.004441738128662109\n",
      "    epoch time:               0.017653465270996094\n",
      "    last layer lr:            0.0008919999999999973\n",
      "epoch: 140 (39/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 86.11%\n",
      "    train overall loss:       0.2862844218810399\n",
      "    train cross_ent loss:     0.1502859409277638\n",
      "    test overall loss:        0.6299559473991394\n",
      "    test cross_ent loss:      0.49416595697402954\n",
      "    cluster loss:             194.1998519897461\n",
      "    separation loss:          0.6565792858600616\n",
      "    avg separation loss:      3.186720609664917\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  128.80056762695312\n",
      "    train time:               0.01237344741821289\n",
      "    test time:                0.004474163055419922\n",
      "    epoch time:               0.01732158660888672\n",
      "    last layer lr:            0.0004959999999999986\n",
      "epoch: 140 (40/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 86.11%\n",
      "    train overall loss:       0.3071180731058121\n",
      "    train cross_ent loss:     0.17141593620181084\n",
      "    test overall loss:        0.6341473162174225\n",
      "    test cross_ent loss:      0.4985746890306473\n",
      "    cluster loss:             194.19941329956055\n",
      "    separation loss:          0.6552951633930206\n",
      "    avg separation loss:      3.177950859069824\n",
      "    l1_addon loss:            69.89413452148438\n",
      "    l1 loss:                  128.58322143554688\n",
      "    train time:               0.012359142303466797\n",
      "    test time:                0.004435062408447266\n",
      "    epoch time:               0.01726698875427246\n",
      "    last layer lr:            0.0001\n",
      "epoch: 141 (JOINT) - Libras\n",
      "    test acc:                 85.56%\n",
      "    train overall loss:       0.29644669344027835\n",
      "    train cross_ent loss:     0.16087496280670166\n",
      "    test overall loss:        0.6288433372974396\n",
      "    test cross_ent loss:      0.4932723492383957\n",
      "    cluster loss:             194.2010612487793\n",
      "    separation loss:          0.658820629119873\n",
      "    avg separation loss:      3.1859138011932373\n",
      "    l1_addon loss:            69.87725067138672\n",
      "    l1 loss:                  128.58322143554688\n",
      "    train time:               0.029071331024169922\n",
      "    test time:                0.0044841766357421875\n",
      "    epoch time:               0.034123897552490234\n",
      "    joint lr:                 0.001298047112325102\n",
      "epoch: 142 (JOINT) - Libras\n",
      "    test acc:                 85.00%\n",
      "    train overall loss:       0.30321647723515827\n",
      "    train cross_ent loss:     0.16764311119914055\n",
      "    test overall loss:        0.5764645338058472\n",
      "    test cross_ent loss:      0.44089139997959137\n",
      "    cluster loss:             194.1993751525879\n",
      "    separation loss:          0.6298095881938934\n",
      "    avg separation loss:      3.1651288270950317\n",
      "    l1_addon loss:            69.89884185791016\n",
      "    l1 loss:                  128.58322143554688\n",
      "    train time:               0.028896093368530273\n",
      "    test time:                0.004454374313354492\n",
      "    epoch time:               0.0339045524597168\n",
      "    joint lr:                 0.002472133282403701\n",
      "epoch: 143 (JOINT) - Libras\n",
      "    test acc:                 84.44%\n",
      "    train overall loss:       0.3117978249986966\n",
      "    train cross_ent loss:     0.17623457809289297\n",
      "    test overall loss:        0.5595145523548126\n",
      "    test cross_ent loss:      0.42396584153175354\n",
      "    cluster loss:             194.19607162475586\n",
      "    separation loss:          0.6337500959634781\n",
      "    avg separation loss:      3.136018991470337\n",
      "    l1_addon loss:            69.65487670898438\n",
      "    l1 loss:                  128.58322143554688\n",
      "    train time:               0.02915334701538086\n",
      "    test time:                0.004494428634643555\n",
      "    epoch time:               0.034209489822387695\n",
      "    joint lr:                 0.0036226179243694966\n",
      "epoch: 144 (JOINT) - Libras\n",
      "    test acc:                 88.89%\n",
      "    train overall loss:       0.2754698072870572\n",
      "    train cross_ent loss:     0.1399182981501023\n",
      "    test overall loss:        0.5778630971908569\n",
      "    test cross_ent loss:      0.44230908155441284\n",
      "    cluster loss:             194.1941261291504\n",
      "    separation loss:          0.639702707529068\n",
      "    avg separation loss:      3.05755615234375\n",
      "    l1_addon loss:            69.7084732055664\n",
      "    l1 loss:                  128.58322143554688\n",
      "    train time:               0.02991342544555664\n",
      "    test time:                0.0044689178466796875\n",
      "    epoch time:               0.03495287895202637\n",
      "    joint lr:                 0.004749855660167736\n",
      "epoch: 145 (JOINT) - Libras\n",
      "    test acc:                 87.22%\n",
      "    train overall loss:       0.3083846792578697\n",
      "    train cross_ent loss:     0.1728483239809672\n",
      "    test overall loss:        0.5365376472473145\n",
      "    test cross_ent loss:      0.40102407336235046\n",
      "    cluster loss:             194.19652557373047\n",
      "    separation loss:          0.6398085057735443\n",
      "    avg separation loss:      3.029984474182129\n",
      "    l1_addon loss:            69.30380249023438\n",
      "    l1 loss:                  128.58322143554688\n",
      "    train time:               0.029163122177124023\n",
      "    test time:                0.0044651031494140625\n",
      "    epoch time:               0.03419232368469238\n",
      "    joint lr:                 0.005854196379457574\n",
      "epoch: 146 (JOINT) - Libras\n",
      "    test acc:                 87.22%\n",
      "    train overall loss:       0.315160592397054\n",
      "    train cross_ent loss:     0.17965571830670038\n",
      "    test overall loss:        0.5141659826040268\n",
      "    test cross_ent loss:      0.3786560297012329\n",
      "    cluster loss:             194.21286392211914\n",
      "    separation loss:          0.6597591936588287\n",
      "    avg separation loss:      2.9159905910491943\n",
      "    l1_addon loss:            69.26734924316406\n",
      "    l1 loss:                  128.58322143554688\n",
      "    train time:               0.02911520004272461\n",
      "    test time:                0.004518270492553711\n",
      "    epoch time:               0.0342106819152832\n",
      "    joint lr:                 0.006935985298795627\n",
      "epoch: 147 (JOINT) - Libras\n",
      "    test acc:                 85.00%\n",
      "    train overall loss:       0.3423496261239052\n",
      "    train cross_ent loss:     0.2068559800585111\n",
      "    test overall loss:        0.624410092830658\n",
      "    test cross_ent loss:      0.48893606662750244\n",
      "    cluster loss:             194.23173141479492\n",
      "    separation loss:          0.6741550266742706\n",
      "    avg separation loss:      2.8074753284454346\n",
      "    l1_addon loss:            68.90826416015625\n",
      "    l1 loss:                  128.58322143554688\n",
      "    train time:               0.02901005744934082\n",
      "    test time:                0.0044596195220947266\n",
      "    epoch time:               0.034030914306640625\n",
      "    joint lr:                 0.007995563020108943\n",
      "epoch: 148 (JOINT) - Libras\n",
      "    test acc:                 85.00%\n",
      "    train overall loss:       0.3660004089275996\n",
      "    train cross_ent loss:     0.23055144275228182\n",
      "    test overall loss:        0.6551326513290405\n",
      "    test cross_ent loss:      0.5197007656097412\n",
      "    cluster loss:             194.22711944580078\n",
      "    separation loss:          0.702639102935791\n",
      "    avg separation loss:      2.865972876548767\n",
      "    l1_addon loss:            68.48695373535156\n",
      "    l1 loss:                  128.58322143554688\n",
      "    train time:               0.029126405715942383\n",
      "    test time:                0.00738215446472168\n",
      "    epoch time:               0.037068843841552734\n",
      "    joint lr:                 0.009033265588466115\n",
      "epoch: 149 (JOINT) - Libras\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       0.45222224791844684\n",
      "    train cross_ent loss:     0.3167784884572029\n",
      "    test overall loss:        0.60890132188797\n",
      "    test cross_ent loss:      0.4734567701816559\n",
      "    cluster loss:             194.25403213500977\n",
      "    separation loss:          0.7150533199310303\n",
      "    avg separation loss:      2.8821781873703003\n",
      "    l1_addon loss:            68.61314392089844\n",
      "    l1 loss:                  128.58322143554688\n",
      "    train time:               0.02944159507751465\n",
      "    test time:                0.004484891891479492\n",
      "    epoch time:               0.03450179100036621\n",
      "    joint lr:                 0.010049424549154131\n",
      "epoch: 150 (JOINT) - Libras\n",
      "    test acc:                 77.22%\n",
      "    train overall loss:       0.4667045573393504\n",
      "    train cross_ent loss:     0.3312577431400617\n",
      "    test overall loss:        0.9374227225780487\n",
      "    test cross_ent loss:      0.8019325137138367\n",
      "    cluster loss:             194.2854766845703\n",
      "    separation loss:          0.7137919366359711\n",
      "    avg separation loss:      3.033519983291626\n",
      "    l1_addon loss:            69.07022857666016\n",
      "    l1 loss:                  128.58322143554688\n",
      "    train time:               0.028696298599243164\n",
      "    test time:                0.009255647659301758\n",
      "    epoch time:               0.03851151466369629\n",
      "    joint lr:                 0.011044367004069541\n",
      "epoch: 151 (JOINT) - Libras\n",
      "    test acc:                 78.89%\n",
      "    train overall loss:       0.49016158282756805\n",
      "    train cross_ent loss:     0.3547160252928734\n",
      "    test overall loss:        0.893346905708313\n",
      "    test cross_ent loss:      0.7579355537891388\n",
      "    cluster loss:             194.29468154907227\n",
      "    separation loss:          0.8195105791091919\n",
      "    avg separation loss:      3.096227526664734\n",
      "    l1_addon loss:            68.28108978271484\n",
      "    l1 loss:                  128.58322143554688\n",
      "    train time:               0.028753995895385742\n",
      "    test time:                0.004439592361450195\n",
      "    epoch time:               0.03379368782043457\n",
      "    joint lr:                 0.010393177167327405\n",
      "epoch: 152 (JOINT) - Libras\n",
      "    test acc:                 74.44%\n",
      "    train overall loss:       0.4882495105266571\n",
      "    train cross_ent loss:     0.35282351324955624\n",
      "    test overall loss:        0.9471695721149445\n",
      "    test cross_ent loss:      0.8116700351238251\n",
      "    cluster loss:             194.31564712524414\n",
      "    separation loss:          0.8128930330276489\n",
      "    avg separation loss:      3.032084822654724\n",
      "    l1_addon loss:            69.16319274902344\n",
      "    l1 loss:                  128.58322143554688\n",
      "    train time:               0.029370784759521484\n",
      "    test time:                0.004569292068481445\n",
      "    epoch time:               0.03480362892150879\n",
      "    joint lr:                 0.009753916690619703\n",
      "epoch: 153 (JOINT) - Libras\n",
      "    test acc:                 63.89%\n",
      "    train overall loss:       0.5822731405496597\n",
      "    train cross_ent loss:     0.4468907341361046\n",
      "    test overall loss:        1.1910611987113953\n",
      "    test cross_ent loss:      1.0556674599647522\n",
      "    cluster loss:             194.34840774536133\n",
      "    separation loss:          0.9067122042179108\n",
      "    avg separation loss:      3.3442095518112183\n",
      "    l1_addon loss:            68.1055908203125\n",
      "    l1 loss:                  128.58322143554688\n",
      "    train time:               0.029194355010986328\n",
      "    test time:                0.005630016326904297\n",
      "    epoch time:               0.03540325164794922\n",
      "    joint lr:                 0.009126412105729424\n",
      "epoch: 154 (JOINT) - Libras\n",
      "    test acc:                 78.33%\n",
      "    train overall loss:       0.4748566647370656\n",
      "    train cross_ent loss:     0.3394334961970647\n",
      "    test overall loss:        0.979532778263092\n",
      "    test cross_ent loss:      0.8442251980304718\n",
      "    cluster loss:             194.32245635986328\n",
      "    separation loss:          0.9632015824317932\n",
      "    avg separation loss:      3.452544927597046\n",
      "    l1_addon loss:            67.24382019042969\n",
      "    l1 loss:                  128.58322143554688\n",
      "    train time:               0.029352664947509766\n",
      "    test time:                0.004606485366821289\n",
      "    epoch time:               0.03480958938598633\n",
      "    joint lr:                 0.008510492220867888\n",
      "epoch: 155 (JOINT) - Libras\n",
      "    test acc:                 72.78%\n",
      "    train overall loss:       0.4257713556289673\n",
      "    train cross_ent loss:     0.2903847446044286\n",
      "    test overall loss:        1.0807531476020813\n",
      "    test cross_ent loss:      0.9452529549598694\n",
      "    cluster loss:             194.29401779174805\n",
      "    separation loss:          0.8083987832069397\n",
      "    avg separation loss:      3.2804001569747925\n",
      "    l1_addon loss:            69.16991424560547\n",
      "    l1 loss:                  128.58322143554688\n",
      "    train time:               0.02895641326904297\n",
      "    test time:                0.004445791244506836\n",
      "    epoch time:               0.03397536277770996\n",
      "    joint lr:                 0.00790598809249301\n",
      "epoch: 156 (JOINT) - Libras\n",
      "    test acc:                 78.89%\n",
      "    train overall loss:       0.42200620472431183\n",
      "    train cross_ent loss:     0.28658343603213626\n",
      "    test overall loss:        0.9393071532249451\n",
      "    test cross_ent loss:      0.8040173053741455\n",
      "    cluster loss:             194.29875946044922\n",
      "    separation loss:          0.8555305004119873\n",
      "    avg separation loss:      3.2993624210357666\n",
      "    l1_addon loss:            67.06651306152344\n",
      "    l1 loss:                  128.58322143554688\n",
      "    train time:               0.028944969177246094\n",
      "    test time:                0.0044422149658203125\n",
      "    epoch time:               0.03395676612854004\n",
      "    joint lr:                 0.007312732997463544\n",
      "epoch: 157 (JOINT) - Libras\n",
      "    test acc:                 82.22%\n",
      "    train overall loss:       0.463839719692866\n",
      "    train cross_ent loss:     0.3284408350785573\n",
      "    test overall loss:        0.7747328281402588\n",
      "    test cross_ent loss:      0.6392263919115067\n",
      "    cluster loss:             194.2741584777832\n",
      "    separation loss:          0.7827033400535583\n",
      "    avg separation loss:      3.308205246925354\n",
      "    l1_addon loss:            69.23210906982422\n",
      "    l1 loss:                  128.58322143554688\n",
      "    train time:               0.02889275550842285\n",
      "    test time:                0.00510716438293457\n",
      "    epoch time:               0.03456473350524902\n",
      "    joint lr:                 0.006730562405525418\n",
      "epoch: 158 (JOINT) - Libras\n",
      "    test acc:                 84.44%\n",
      "    train overall loss:       0.35681430002053577\n",
      "    train cross_ent loss:     0.22135969499746957\n",
      "    test overall loss:        0.8248503804206848\n",
      "    test cross_ent loss:      0.689514696598053\n",
      "    cluster loss:             194.28377151489258\n",
      "    separation loss:          0.853431910276413\n",
      "    avg separation loss:      3.4545133113861084\n",
      "    l1_addon loss:            67.52455139160156\n",
      "    l1 loss:                  128.58322143554688\n",
      "    train time:               0.029856204986572266\n",
      "    test time:                0.0045166015625\n",
      "    epoch time:               0.03493475914001465\n",
      "    joint lr:                 0.006159313952126306\n",
      "epoch: 159 (JOINT) - Libras\n",
      "    test acc:                 81.67%\n",
      "    train overall loss:       0.3758442799250285\n",
      "    train cross_ent loss:     0.2404398409028848\n",
      "    test overall loss:        0.8803987503051758\n",
      "    test cross_ent loss:      0.7448992431163788\n",
      "    cluster loss:             194.23737335205078\n",
      "    separation loss:          0.7453006505966187\n",
      "    avg separation loss:      3.2317445278167725\n",
      "    l1_addon loss:            69.16313171386719\n",
      "    l1 loss:                  128.58322143554688\n",
      "    train time:               0.029242515563964844\n",
      "    test time:                0.004443645477294922\n",
      "    epoch time:               0.03425264358520508\n",
      "    joint lr:                 0.005598827411554625\n",
      "epoch: 160 (JOINT) - Libras\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       0.3050636326273282\n",
      "    train cross_ent loss:     0.16961779072880745\n",
      "    test overall loss:        0.5078131407499313\n",
      "    test cross_ent loss:      0.3724335581064224\n",
      "    cluster loss:             194.21271896362305\n",
      "    separation loss:          0.6892340779304504\n",
      "    avg separation loss:      3.212732672691345\n",
      "    l1_addon loss:            67.96357727050781\n",
      "    l1 loss:                  128.58322143554688\n",
      "    train time:               0.02931380271911621\n",
      "    test time:                0.0044727325439453125\n",
      "    epoch time:               0.03435564041137695\n",
      "    joint lr:                 0.005048944670399165\n",
      "epoch: 161 (JOINT) - Libras\n",
      "    test acc:                 91.11%\n",
      "    train overall loss:       0.2834349200129509\n",
      "    train cross_ent loss:     0.1480423534909884\n",
      "    test overall loss:        0.5080495774745941\n",
      "    test cross_ent loss:      0.3726179152727127\n",
      "    cluster loss:             194.21004104614258\n",
      "    separation loss:          0.6806491613388062\n",
      "    avg separation loss:      3.1676641702651978\n",
      "    l1_addon loss:            68.48431396484375\n",
      "    l1 loss:                  128.58322143554688\n",
      "    train time:               0.028939485549926758\n",
      "    test time:                0.004490375518798828\n",
      "    epoch time:               0.03399991989135742\n",
      "    joint lr:                 0.004509509701325646\n",
      "epoch: 162 (JOINT) - Libras\n",
      "    test acc:                 87.78%\n",
      "    train overall loss:       0.2746574307481448\n",
      "    train cross_ent loss:     0.13921582885086536\n",
      "    test overall loss:        0.5213797241449356\n",
      "    test cross_ent loss:      0.3859557807445526\n",
      "    cluster loss:             194.20405960083008\n",
      "    separation loss:          0.6829661130905151\n",
      "    avg separation loss:      3.1018131971359253\n",
      "    l1_addon loss:            68.40705871582031\n",
      "    l1 loss:                  128.58322143554688\n",
      "    train time:               0.029071569442749023\n",
      "    test time:                0.004492282867431641\n",
      "    epoch time:               0.034128665924072266\n",
      "    joint lr:                 0.00398036853716657\n",
      "epoch: 163 (JOINT) - Libras\n",
      "    test acc:                 86.67%\n",
      "    train overall loss:       0.24913110584020615\n",
      "    train cross_ent loss:     0.113723523914814\n",
      "    test overall loss:        0.4999856501817703\n",
      "    test cross_ent loss:      0.36458049714565277\n",
      "    cluster loss:             194.21061325073242\n",
      "    separation loss:          0.668776124715805\n",
      "    avg separation loss:      3.0379852056503296\n",
      "    l1_addon loss:            68.21946716308594\n",
      "    l1 loss:                  128.58322143554688\n",
      "    train time:               0.029044628143310547\n",
      "    test time:                0.004445791244506836\n",
      "    epoch time:               0.034053802490234375\n",
      "    joint lr:                 0.0034613692453205423\n",
      "epoch: 164 (JOINT) - Libras\n",
      "    test acc:                 88.89%\n",
      "    train overall loss:       0.26570577671130496\n",
      "    train cross_ent loss:     0.13030338287353516\n",
      "    test overall loss:        0.4811869412660599\n",
      "    test cross_ent loss:      0.3458022028207779\n",
      "    cluster loss:             194.2039794921875\n",
      "    separation loss:          0.6319386959075928\n",
      "    avg separation loss:      2.9726765155792236\n",
      "    l1_addon loss:            68.01530456542969\n",
      "    l1 loss:                  128.58322143554688\n",
      "    train time:               0.029470205307006836\n",
      "    test time:                0.004491329193115234\n",
      "    epoch time:               0.0345301628112793\n",
      "    joint lr:                 0.002952361902457719\n",
      "epoch: 165 (JOINT) - Libras\n",
      "    test acc:                 87.22%\n",
      "    train overall loss:       0.269046609600385\n",
      "    train cross_ent loss:     0.13366341777145863\n",
      "    test overall loss:        0.47114571928977966\n",
      "    test cross_ent loss:      0.33576594293117523\n",
      "    cluster loss:             194.20272827148438\n",
      "    separation loss:          0.620879128575325\n",
      "    avg separation loss:      2.92979097366333\n",
      "    l1_addon loss:            67.96543884277344\n",
      "    l1 loss:                  128.58322143554688\n",
      "    train time:               0.02882099151611328\n",
      "    test time:                0.0044460296630859375\n",
      "    epoch time:               0.03383517265319824\n",
      "    joint lr:                 0.0024531985695276076\n",
      "epoch: 166 (JOINT) - Libras\n",
      "    test acc:                 86.11%\n",
      "    train overall loss:       0.22991918275753656\n",
      "    train cross_ent loss:     0.09454852901399136\n",
      "    test overall loss:        0.5447882413864136\n",
      "    test cross_ent loss:      0.4094271808862686\n",
      "    cluster loss:             194.2118377685547\n",
      "    separation loss:          0.6618398427963257\n",
      "    avg separation loss:      2.900954008102417\n",
      "    l1_addon loss:            67.7783203125\n",
      "    l1 loss:                  128.58322143554688\n",
      "    train time:               0.02945995330810547\n",
      "    test time:                0.00450444221496582\n",
      "    epoch time:               0.034529924392700195\n",
      "    joint lr:                 0.001963733267065865\n",
      "epoch: 167 (JOINT) - Libras\n",
      "    test acc:                 86.67%\n",
      "    train overall loss:       0.24538190166155496\n",
      "    train cross_ent loss:     0.11001535629232724\n",
      "    test overall loss:        0.5100929141044617\n",
      "    test cross_ent loss:      0.3747183829545975\n",
      "    cluster loss:             194.20584106445312\n",
      "    separation loss:          0.6356465816497803\n",
      "    avg separation loss:      2.864005446434021\n",
      "    l1_addon loss:            67.91302490234375\n",
      "    l1 loss:                  128.58322143554688\n",
      "    train time:               0.02724480628967285\n",
      "    test time:                0.0055141448974609375\n",
      "    epoch time:               0.03338813781738281\n",
      "    joint lr:                 0.001483821950796405\n",
      "epoch: 168 (JOINT) - Libras\n",
      "    test acc:                 87.78%\n",
      "    train overall loss:       0.23405111332734427\n",
      "    train cross_ent loss:     0.09867667562017839\n",
      "    test overall loss:        0.4837117940187454\n",
      "    test cross_ent loss:      0.3483469933271408\n",
      "    cluster loss:             194.20264434814453\n",
      "    separation loss:          0.6252356767654419\n",
      "    avg separation loss:      2.8411821126937866\n",
      "    l1_addon loss:            67.8160400390625\n",
      "    l1 loss:                  128.58322143554688\n",
      "    train time:               0.028049707412719727\n",
      "    test time:                0.004586935043334961\n",
      "    epoch time:               0.03322935104370117\n",
      "    joint lr:                 0.0010133224875256274\n",
      "epoch: 169 (JOINT) - Libras\n",
      "    test acc:                 89.44%\n",
      "    train overall loss:       0.23999964197476706\n",
      "    train cross_ent loss:     0.10463784479846557\n",
      "    test overall loss:        0.4679252654314041\n",
      "    test cross_ent loss:      0.33256062865257263\n",
      "    cluster loss:             194.19980239868164\n",
      "    separation loss:          0.6143873631954193\n",
      "    avg separation loss:      2.8393547534942627\n",
      "    l1_addon loss:            67.81394958496094\n",
      "    l1 loss:                  128.58322143554688\n",
      "    train time:               0.02967047691345215\n",
      "    test time:                0.0044403076171875\n",
      "    epoch time:               0.03467202186584473\n",
      "    joint lr:                 0.0005520946313251855\n",
      "epoch: 170 (JOINT) - Libras\n",
      "    test acc:                 88.89%\n",
      "    train overall loss:       0.24985738346974054\n",
      "    train cross_ent loss:     0.11448961993058522\n",
      "    test overall loss:        0.46960198879241943\n",
      "    test cross_ent loss:      0.3342294916510582\n",
      "    cluster loss:             194.19889450073242\n",
      "    separation loss:          0.6090752631425858\n",
      "    avg separation loss:      2.8373780250549316\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  128.58322143554688\n",
      "    train time:               0.02951836585998535\n",
      "    test time:                0.004450798034667969\n",
      "    epoch time:               0.03454113006591797\n",
      "    joint lr:                 0.0001\n",
      "epoch: 170 (PUSH) - Libras\n",
      "    test acc:                 89.44%\n",
      "    train overall loss:       0.24985738346974054\n",
      "    train cross_ent loss:     0.11448961993058522\n",
      "    test overall loss:        0.550521731376648\n",
      "    test cross_ent loss:      0.4151492118835449\n",
      "    cluster loss:             194.18812942504883\n",
      "    separation loss:          0.5883494317531586\n",
      "    avg separation loss:      2.8222097158432007\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  128.58322143554688\n",
      "    train time:               0.02951836585998535\n",
      "    test time:                0.004667997360229492\n",
      "    epoch time:               0.0661165714263916\n",
      "epoch: 170 (1/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 90.00%\n",
      "    train overall loss:       0.26699170221885044\n",
      "    train cross_ent loss:     0.13163710882266363\n",
      "    test overall loss:        0.5514276027679443\n",
      "    test cross_ent loss:      0.4160988926887512\n",
      "    cluster loss:             194.18816375732422\n",
      "    separation loss:          0.5868733823299408\n",
      "    avg separation loss:      2.8175289630889893\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  128.53945922851562\n",
      "    train time:               0.012510538101196289\n",
      "    test time:                0.0044362545013427734\n",
      "    epoch time:               0.017416954040527344\n",
      "    last layer lr:            0.0007599999999999978\n",
      "epoch: 170 (2/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 89.44%\n",
      "    train overall loss:       0.2553434098760287\n",
      "    train cross_ent loss:     0.12013653976221879\n",
      "    test overall loss:        0.5508825778961182\n",
      "    test cross_ent loss:      0.4158638268709183\n",
      "    cluster loss:             194.188232421875\n",
      "    separation loss:          0.5876336246728897\n",
      "    avg separation loss:      2.820632219314575\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  128.22947692871094\n",
      "    train time:               0.012593984603881836\n",
      "    test time:                0.004472255706787109\n",
      "    epoch time:               0.017542362213134766\n",
      "    last layer lr:            0.0014199999999999955\n",
      "epoch: 170 (3/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 88.89%\n",
      "    train overall loss:       0.2653767913579941\n",
      "    train cross_ent loss:     0.13064827397465706\n",
      "    test overall loss:        0.5458901226520538\n",
      "    test cross_ent loss:      0.41156429052352905\n",
      "    cluster loss:             194.1882781982422\n",
      "    separation loss:          0.588191419839859\n",
      "    avg separation loss:      2.8255274295806885\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  127.53654479980469\n",
      "    train time:               0.012367010116577148\n",
      "    test time:                0.004481077194213867\n",
      "    epoch time:               0.017322301864624023\n",
      "    last layer lr:            0.0020800000000000046\n",
      "epoch: 170 (4/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 88.89%\n",
      "    train overall loss:       0.2599250425895055\n",
      "    train cross_ent loss:     0.12602400158842406\n",
      "    test overall loss:        0.5438761711120605\n",
      "    test cross_ent loss:      0.41050226986408234\n",
      "    cluster loss:             194.18813705444336\n",
      "    separation loss:          0.5862186253070831\n",
      "    avg separation loss:      2.8171809911727905\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  126.5846176147461\n",
      "    train time:               0.012446880340576172\n",
      "    test time:                0.004591226577758789\n",
      "    epoch time:               0.017510414123535156\n",
      "    last layer lr:            0.0027400000000000024\n",
      "epoch: 170 (5/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 87.22%\n",
      "    train overall loss:       0.2543364316225052\n",
      "    train cross_ent loss:     0.1213248074054718\n",
      "    test overall loss:        0.5448661148548126\n",
      "    test cross_ent loss:      0.41239771246910095\n",
      "    cluster loss:             194.1882667541504\n",
      "    separation loss:          0.5866574048995972\n",
      "    avg separation loss:      2.8242733478546143\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  125.67912292480469\n",
      "    train time:               0.012417078018188477\n",
      "    test time:                0.004471778869628906\n",
      "    epoch time:               0.01736927032470703\n",
      "    last layer lr:            0.0034\n",
      "epoch: 170 (6/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 86.67%\n",
      "    train overall loss:       0.25183431307474774\n",
      "    train cross_ent loss:     0.1198879045744737\n",
      "    test overall loss:        0.5409767925739288\n",
      "    test cross_ent loss:      0.40981192886829376\n",
      "    cluster loss:             194.1888198852539\n",
      "    separation loss:          0.5886084735393524\n",
      "    avg separation loss:      2.8228466510772705\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  124.37557220458984\n",
      "    train time:               0.01253819465637207\n",
      "    test time:                0.0044324398040771484\n",
      "    epoch time:               0.017457008361816406\n",
      "    last layer lr:            0.004059999999999998\n",
      "epoch: 170 (7/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 87.22%\n",
      "    train overall loss:       0.25955942769845325\n",
      "    train cross_ent loss:     0.12897731612126032\n",
      "    test overall loss:        0.5402901470661163\n",
      "    test cross_ent loss:      0.41073252260684967\n",
      "    cluster loss:             194.18840789794922\n",
      "    separation loss:          0.5890380889177322\n",
      "    avg separation loss:      2.8250017166137695\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  122.7683334350586\n",
      "    train time:               0.012450933456420898\n",
      "    test time:                0.004465341567993164\n",
      "    epoch time:               0.01738882064819336\n",
      "    last layer lr:            0.004719999999999996\n",
      "epoch: 170 (8/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 87.22%\n",
      "    train overall loss:       0.25223581741253537\n",
      "    train cross_ent loss:     0.12354434778292973\n",
      "    test overall loss:        0.5350569188594818\n",
      "    test cross_ent loss:      0.407502144575119\n",
      "    cluster loss:             194.18843841552734\n",
      "    separation loss:          0.5888587236404419\n",
      "    avg separation loss:      2.827191948890686\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  120.76549530029297\n",
      "    train time:               0.01240992546081543\n",
      "    test time:                0.004466056823730469\n",
      "    epoch time:               0.017349958419799805\n",
      "    last layer lr:            0.0053800000000000054\n",
      "epoch: 170 (9/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       0.25805369516213733\n",
      "    train cross_ent loss:     0.13142300645510355\n",
      "    test overall loss:        0.5294401943683624\n",
      "    test cross_ent loss:      0.40406665205955505\n",
      "    cluster loss:             194.1883659362793\n",
      "    separation loss:          0.589308351278305\n",
      "    avg separation loss:      2.8230385780334473\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  118.58425903320312\n",
      "    train time:               0.012353658676147461\n",
      "    test time:                0.004485368728637695\n",
      "    epoch time:               0.01732182502746582\n",
      "    last layer lr:            0.006040000000000003\n",
      "epoch: 170 (10/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 87.22%\n",
      "    train overall loss:       0.2505326047539711\n",
      "    train cross_ent loss:     0.12584932893514633\n",
      "    test overall loss:        0.5335967540740967\n",
      "    test cross_ent loss:      0.4099569767713547\n",
      "    cluster loss:             194.18854141235352\n",
      "    separation loss:          0.5899878889322281\n",
      "    avg separation loss:      2.8297377824783325\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  116.85047912597656\n",
      "    train time:               0.012530326843261719\n",
      "    test time:                0.004419803619384766\n",
      "    epoch time:               0.017421960830688477\n",
      "    last layer lr:            0.0067\n",
      "epoch: 170 (11/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 86.67%\n",
      "    train overall loss:       0.26190850387016934\n",
      "    train cross_ent loss:     0.13922972232103348\n",
      "    test overall loss:        0.5368179380893707\n",
      "    test cross_ent loss:      0.41530950367450714\n",
      "    cluster loss:             194.18872833251953\n",
      "    separation loss:          0.5889726728200912\n",
      "    avg separation loss:      2.8320188522338867\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  114.7191390991211\n",
      "    train time:               0.012370109558105469\n",
      "    test time:                0.004414796829223633\n",
      "    epoch time:               0.017257213592529297\n",
      "    last layer lr:            0.0073599999999999985\n",
      "epoch: 170 (12/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 87.22%\n",
      "    train overall loss:       0.23834874977668127\n",
      "    train cross_ent loss:     0.1175725484887759\n",
      "    test overall loss:        0.5385729074478149\n",
      "    test cross_ent loss:      0.41913066804409027\n",
      "    cluster loss:             194.18865203857422\n",
      "    separation loss:          0.5895579308271408\n",
      "    avg separation loss:      2.833751916885376\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  112.6529541015625\n",
      "    train time:               0.012380838394165039\n",
      "    test time:                0.004443168640136719\n",
      "    epoch time:               0.017293691635131836\n",
      "    last layer lr:            0.008019999999999994\n",
      "epoch: 170 (13/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 86.11%\n",
      "    train overall loss:       0.2495089794198672\n",
      "    train cross_ent loss:     0.13129580828050771\n",
      "    test overall loss:        0.5329227149486542\n",
      "    test cross_ent loss:      0.41655974090099335\n",
      "    cluster loss:             194.18911743164062\n",
      "    separation loss:          0.5905436277389526\n",
      "    avg separation loss:      2.8387540578842163\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  109.57368469238281\n",
      "    train time:               0.012368917465209961\n",
      "    test time:                0.004450798034667969\n",
      "    epoch time:               0.017292261123657227\n",
      "    last layer lr:            0.008680000000000005\n",
      "epoch: 170 (14/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 87.78%\n",
      "    train overall loss:       0.2316786845525106\n",
      "    train cross_ent loss:     0.11648465817173322\n",
      "    test overall loss:        0.5264500379562378\n",
      "    test cross_ent loss:      0.41287843883037567\n",
      "    cluster loss:             194.18854141235352\n",
      "    separation loss:          0.5895094275474548\n",
      "    avg separation loss:      2.828972578048706\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  106.7823257446289\n",
      "    train time:               0.012371063232421875\n",
      "    test time:                0.004440784454345703\n",
      "    epoch time:               0.017285823822021484\n",
      "    last layer lr:            0.009340000000000003\n",
      "epoch: 170 (15/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 86.67%\n",
      "    train overall loss:       0.23799181977907816\n",
      "    train cross_ent loss:     0.12554097920656204\n",
      "    test overall loss:        0.5183053314685822\n",
      "    test cross_ent loss:      0.407489538192749\n",
      "    cluster loss:             194.18816375732422\n",
      "    separation loss:          0.5887180119752884\n",
      "    avg separation loss:      2.824126958847046\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  104.02651977539062\n",
      "    train time:               0.012382268905639648\n",
      "    test time:                0.004423856735229492\n",
      "    epoch time:               0.017278432846069336\n",
      "    last layer lr:            0.01\n",
      "epoch: 170 (16/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 87.78%\n",
      "    train overall loss:       0.23202757040659586\n",
      "    train cross_ent loss:     0.12223113452394803\n",
      "    test overall loss:        0.5224466025829315\n",
      "    test cross_ent loss:      0.4143870025873184\n",
      "    cluster loss:             194.18862915039062\n",
      "    separation loss:          0.5881212055683136\n",
      "    avg separation loss:      2.823965549468994\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  101.27032470703125\n",
      "    train time:               0.012397289276123047\n",
      "    test time:                0.00445103645324707\n",
      "    epoch time:               0.01732945442199707\n",
      "    last layer lr:            0.009604000000000001\n",
      "epoch: 170 (17/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 86.67%\n",
      "    train overall loss:       0.22266603509585062\n",
      "    train cross_ent loss:     0.11566610261797905\n",
      "    test overall loss:        0.5191193521022797\n",
      "    test cross_ent loss:      0.41372454166412354\n",
      "    cluster loss:             194.18875885009766\n",
      "    separation loss:          0.5899916142225266\n",
      "    avg separation loss:      2.831327795982361\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  98.60554504394531\n",
      "    train time:               0.012362957000732422\n",
      "    test time:                0.004550933837890625\n",
      "    epoch time:               0.01738595962524414\n",
      "    last layer lr:            0.009208000000000003\n",
      "epoch: 170 (18/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 88.89%\n",
      "    train overall loss:       0.22844430059194565\n",
      "    train cross_ent loss:     0.12440626323223114\n",
      "    test overall loss:        0.5088361501693726\n",
      "    test cross_ent loss:      0.4066063463687897\n",
      "    cluster loss:             194.18880081176758\n",
      "    separation loss:          0.5902788043022156\n",
      "    avg separation loss:      2.832479953765869\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  95.44054412841797\n",
      "    train time:               0.01267862319946289\n",
      "    test time:                0.004439830780029297\n",
      "    epoch time:               0.0175933837890625\n",
      "    last layer lr:            0.008811999999999997\n",
      "epoch: 170 (19/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 88.89%\n",
      "    train overall loss:       0.21691053360700607\n",
      "    train cross_ent loss:     0.11575353145599365\n",
      "    test overall loss:        0.5073411464691162\n",
      "    test cross_ent loss:      0.4075396806001663\n",
      "    cluster loss:             194.1887435913086\n",
      "    separation loss:          0.5902503281831741\n",
      "    avg separation loss:      2.8337626457214355\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  93.01219177246094\n",
      "    train time:               0.012380599975585938\n",
      "    test time:                0.005299806594848633\n",
      "    epoch time:               0.018159866333007812\n",
      "    last layer lr:            0.008415999999999998\n",
      "epoch: 170 (20/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 87.22%\n",
      "    train overall loss:       0.2244019384185473\n",
      "    train cross_ent loss:     0.12566709456344446\n",
      "    test overall loss:        0.4982409179210663\n",
      "    test cross_ent loss:      0.40084658563137054\n",
      "    cluster loss:             194.1884880065918\n",
      "    separation loss:          0.5907606482505798\n",
      "    avg separation loss:      2.8386088609695435\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  90.60504913330078\n",
      "    train time:               0.012411355972290039\n",
      "    test time:                0.004547119140625\n",
      "    epoch time:               0.017432689666748047\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 170 (21/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 87.78%\n",
      "    train overall loss:       0.20562229305505753\n",
      "    train cross_ent loss:     0.10905419290065765\n",
      "    test overall loss:        0.496650755405426\n",
      "    test cross_ent loss:      0.4013272374868393\n",
      "    cluster loss:             194.1885871887207\n",
      "    separation loss:          0.5910634547472\n",
      "    avg separation loss:      2.841756224632263\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  88.53425598144531\n",
      "    train time:               0.012398004531860352\n",
      "    test time:                0.0044803619384765625\n",
      "    epoch time:               0.017353534698486328\n",
      "    last layer lr:            0.007624000000000002\n",
      "epoch: 170 (22/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 87.22%\n",
      "    train overall loss:       0.2143895278374354\n",
      "    train cross_ent loss:     0.11980739856759708\n",
      "    test overall loss:        0.49773094058036804\n",
      "    test cross_ent loss:      0.4042033851146698\n",
      "    cluster loss:             194.18851470947266\n",
      "    separation loss:          0.5897596627473831\n",
      "    avg separation loss:      2.8334879875183105\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  86.73828887939453\n",
      "    train time:               0.012547016143798828\n",
      "    test time:                0.004450321197509766\n",
      "    epoch time:               0.017471790313720703\n",
      "    last layer lr:            0.0072280000000000035\n",
      "epoch: 170 (23/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 87.78%\n",
      "    train overall loss:       0.217039592564106\n",
      "    train cross_ent loss:     0.12421831736962001\n",
      "    test overall loss:        0.49384936690330505\n",
      "    test cross_ent loss:      0.40207721292972565\n",
      "    cluster loss:             194.18830490112305\n",
      "    separation loss:          0.5898362994194031\n",
      "    avg separation loss:      2.833499789237976\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  84.98287200927734\n",
      "    train time:               0.012505292892456055\n",
      "    test time:                0.004481077194213867\n",
      "    epoch time:               0.01746225357055664\n",
      "    last layer lr:            0.006831999999999998\n",
      "epoch: 170 (24/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 86.67%\n",
      "    train overall loss:       0.19693327446778616\n",
      "    train cross_ent loss:     0.10565840949614842\n",
      "    test overall loss:        0.48645833134651184\n",
      "    test cross_ent loss:      0.3959936797618866\n",
      "    cluster loss:             194.18820571899414\n",
      "    separation loss:          0.5899872034788132\n",
      "    avg separation loss:      2.8342432975769043\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  83.67538452148438\n",
      "    train time:               0.012446403503417969\n",
      "    test time:                0.004469394683837891\n",
      "    epoch time:               0.017389535903930664\n",
      "    last layer lr:            0.006436\n",
      "epoch: 170 (25/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 86.67%\n",
      "    train overall loss:       0.19518420845270157\n",
      "    train cross_ent loss:     0.10527341688672702\n",
      "    test overall loss:        0.4930266737937927\n",
      "    test cross_ent loss:      0.40395183861255646\n",
      "    cluster loss:             194.18822479248047\n",
      "    separation loss:          0.5891496688127518\n",
      "    avg separation loss:      2.8302544355392456\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  82.28557586669922\n",
      "    train time:               0.01260519027709961\n",
      "    test time:                0.004479646682739258\n",
      "    epoch time:               0.017597198486328125\n",
      "    last layer lr:            0.00604\n",
      "epoch: 170 (26/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 86.67%\n",
      "    train overall loss:       0.19816339512666067\n",
      "    train cross_ent loss:     0.10973560065031052\n",
      "    test overall loss:        0.4888683259487152\n",
      "    test cross_ent loss:      0.40129703283309937\n",
      "    cluster loss:             194.18857192993164\n",
      "    separation loss:          0.5903079807758331\n",
      "    avg separation loss:      2.834446668624878\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  80.78201293945312\n",
      "    train time:               0.01243281364440918\n",
      "    test time:                0.004460334777832031\n",
      "    epoch time:               0.017368316650390625\n",
      "    last layer lr:            0.005644000000000002\n",
      "epoch: 170 (27/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 86.67%\n",
      "    train overall loss:       0.20704047878583273\n",
      "    train cross_ent loss:     0.12013407237827778\n",
      "    test overall loss:        0.4833386540412903\n",
      "    test cross_ent loss:      0.3973296582698822\n",
      "    cluster loss:             194.18842697143555\n",
      "    separation loss:          0.5889933556318283\n",
      "    avg separation loss:      2.829585552215576\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  79.21973419189453\n",
      "    train time:               0.012410640716552734\n",
      "    test time:                0.004907131195068359\n",
      "    epoch time:               0.017792224884033203\n",
      "    last layer lr:            0.005248000000000003\n",
      "epoch: 170 (28/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 87.22%\n",
      "    train overall loss:       0.20966838796933493\n",
      "    train cross_ent loss:     0.12416812404990196\n",
      "    test overall loss:        0.4792269170284271\n",
      "    test cross_ent loss:      0.39434103667736053\n",
      "    cluster loss:             194.18855667114258\n",
      "    separation loss:          0.5879879593849182\n",
      "    avg separation loss:      2.8243690729141235\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  78.09660339355469\n",
      "    train time:               0.01239633560180664\n",
      "    test time:                0.004443645477294922\n",
      "    epoch time:               0.017313241958618164\n",
      "    last layer lr:            0.004851999999999998\n",
      "epoch: 170 (29/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 87.78%\n",
      "    train overall loss:       0.19342065354188284\n",
      "    train cross_ent loss:     0.10885132973392804\n",
      "    test overall loss:        0.48680421710014343\n",
      "    test cross_ent loss:      0.4026743769645691\n",
      "    cluster loss:             194.18873977661133\n",
      "    separation loss:          0.5871551632881165\n",
      "    avg separation loss:      2.824406862258911\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  77.34056091308594\n",
      "    train time:               0.012383460998535156\n",
      "    test time:                0.004485368728637695\n",
      "    epoch time:               0.01735854148864746\n",
      "    last layer lr:            0.004455999999999999\n",
      "epoch: 170 (30/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 87.78%\n",
      "    train overall loss:       0.19318334758281708\n",
      "    train cross_ent loss:     0.10937299579381943\n",
      "    test overall loss:        0.4881460666656494\n",
      "    test cross_ent loss:      0.4048314392566681\n",
      "    cluster loss:             194.1885528564453\n",
      "    separation loss:          0.5893191993236542\n",
      "    avg separation loss:      2.824914813041687\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  76.52535247802734\n",
      "    train time:               0.012425899505615234\n",
      "    test time:                0.0044858455657958984\n",
      "    epoch time:               0.017388343811035156\n",
      "    last layer lr:            0.004060000000000001\n",
      "epoch: 170 (31/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 87.78%\n",
      "    train overall loss:       0.2085887094338735\n",
      "    train cross_ent loss:     0.1255564937988917\n",
      "    test overall loss:        0.4860420525074005\n",
      "    test cross_ent loss:      0.4035197049379349\n",
      "    cluster loss:             194.18865966796875\n",
      "    separation loss:          0.5894121080636978\n",
      "    avg separation loss:      2.830386996269226\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  75.73306274414062\n",
      "    train time:               0.012448787689208984\n",
      "    test time:                0.004510641098022461\n",
      "    epoch time:               0.017439842224121094\n",
      "    last layer lr:            0.0036640000000000015\n",
      "epoch: 170 (32/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 87.22%\n",
      "    train overall loss:       0.18708097065488496\n",
      "    train cross_ent loss:     0.10473824044068654\n",
      "    test overall loss:        0.4870086908340454\n",
      "    test cross_ent loss:      0.40498507022857666\n",
      "    cluster loss:             194.18869400024414\n",
      "    separation loss:          0.5874566286802292\n",
      "    avg separation loss:      2.828717350959778\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  75.2343521118164\n",
      "    train time:               0.012758970260620117\n",
      "    test time:                0.0074770450592041016\n",
      "    epoch time:               0.020714282989501953\n",
      "    last layer lr:            0.003268000000000003\n",
      "epoch: 170 (33/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 86.67%\n",
      "    train overall loss:       0.18922310943404833\n",
      "    train cross_ent loss:     0.10744491840402286\n",
      "    test overall loss:        0.48047158122062683\n",
      "    test cross_ent loss:      0.39908650517463684\n",
      "    cluster loss:             194.1884002685547\n",
      "    separation loss:          0.588354155421257\n",
      "    avg separation loss:      2.832718849182129\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  74.59577941894531\n",
      "    train time:               0.012351274490356445\n",
      "    test time:                0.004492521286010742\n",
      "    epoch time:               0.01732611656188965\n",
      "    last layer lr:            0.002871999999999997\n",
      "epoch: 170 (34/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 86.67%\n",
      "    train overall loss:       0.20795400192340216\n",
      "    train cross_ent loss:     0.12689690043528876\n",
      "    test overall loss:        0.47788843512535095\n",
      "    test cross_ent loss:      0.3972195088863373\n",
      "    cluster loss:             194.18854522705078\n",
      "    separation loss:          0.5897939205169678\n",
      "    avg separation loss:      2.839949607849121\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  73.87965393066406\n",
      "    train time:               0.012439489364624023\n",
      "    test time:                0.00446629524230957\n",
      "    epoch time:               0.017391443252563477\n",
      "    last layer lr:            0.0024759999999999986\n",
      "epoch: 170 (35/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 86.67%\n",
      "    train overall loss:       0.19785129775603613\n",
      "    train cross_ent loss:     0.11732791488369305\n",
      "    test overall loss:        0.4780275821685791\n",
      "    test cross_ent loss:      0.3976779282093048\n",
      "    cluster loss:             194.1885108947754\n",
      "    separation loss:          0.5886440873146057\n",
      "    avg separation loss:      2.839659333229065\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  73.56038665771484\n",
      "    train time:               0.012455940246582031\n",
      "    test time:                0.004429340362548828\n",
      "    epoch time:               0.017358064651489258\n",
      "    last layer lr:            0.0020800000000000003\n",
      "epoch: 170 (36/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 86.67%\n",
      "    train overall loss:       0.20668814331293106\n",
      "    train cross_ent loss:     0.12640910844008127\n",
      "    test overall loss:        0.4845452904701233\n",
      "    test cross_ent loss:      0.40443405508995056\n",
      "    cluster loss:             194.18825149536133\n",
      "    separation loss:          0.5893497169017792\n",
      "    avg separation loss:      2.8362960815429688\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  73.32194519042969\n",
      "    train time:               0.012408018112182617\n",
      "    test time:                0.004428386688232422\n",
      "    epoch time:               0.017305612564086914\n",
      "    last layer lr:            0.0016840000000000017\n",
      "epoch: 170 (37/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 86.67%\n",
      "    train overall loss:       0.20316109309593836\n",
      "    train cross_ent loss:     0.12312853708863258\n",
      "    test overall loss:        0.4832445979118347\n",
      "    test cross_ent loss:      0.40338824689388275\n",
      "    cluster loss:             194.1886978149414\n",
      "    separation loss:          0.5908216685056686\n",
      "    avg separation loss:      2.8376704454421997\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  73.06706237792969\n",
      "    train time:               0.012438058853149414\n",
      "    test time:                0.009138107299804688\n",
      "    epoch time:               0.02205181121826172\n",
      "    last layer lr:            0.001288000000000003\n",
      "epoch: 170 (38/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 86.67%\n",
      "    train overall loss:       0.1847088485956192\n",
      "    train cross_ent loss:     0.10500003397464752\n",
      "    test overall loss:        0.47531914710998535\n",
      "    test cross_ent loss:      0.39581434428691864\n",
      "    cluster loss:             194.18864059448242\n",
      "    separation loss:          0.5900499373674393\n",
      "    avg separation loss:      2.8342427015304565\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  72.71554565429688\n",
      "    train time:               0.012553215026855469\n",
      "    test time:                0.004444122314453125\n",
      "    epoch time:               0.017482519149780273\n",
      "    last layer lr:            0.0008919999999999973\n",
      "epoch: 170 (39/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 86.67%\n",
      "    train overall loss:       0.18788063898682594\n",
      "    train cross_ent loss:     0.10846168423692386\n",
      "    test overall loss:        0.46908727288246155\n",
      "    test cross_ent loss:      0.3898094594478607\n",
      "    cluster loss:             194.1886329650879\n",
      "    separation loss:          0.5900855511426926\n",
      "    avg separation loss:      2.834217071533203\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  72.488525390625\n",
      "    train time:               0.012384176254272461\n",
      "    test time:                0.004439592361450195\n",
      "    epoch time:               0.01729607582092285\n",
      "    last layer lr:            0.0004959999999999986\n",
      "epoch: 170 (40/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 85.56%\n",
      "    train overall loss:       0.19469811022281647\n",
      "    train cross_ent loss:     0.11548049996296565\n",
      "    test overall loss:        0.4717367887496948\n",
      "    test cross_ent loss:      0.39262621104717255\n",
      "    cluster loss:             194.1886978149414\n",
      "    separation loss:          0.5914954543113708\n",
      "    avg separation loss:      2.8394782543182373\n",
      "    l1_addon loss:            67.892822265625\n",
      "    l1 loss:                  72.32130432128906\n",
      "    train time:               0.012656927108764648\n",
      "    test time:                0.004426002502441406\n",
      "    epoch time:               0.017554283142089844\n",
      "    last layer lr:            0.0001\n",
      "epoch: 171 (JOINT) - Libras\n",
      "    test acc:                 86.11%\n",
      "    train overall loss:       0.19027606149514517\n",
      "    train cross_ent loss:     0.11116494114200275\n",
      "    test overall loss:        0.47725482285022736\n",
      "    test cross_ent loss:      0.39814332127571106\n",
      "    cluster loss:             194.1884651184082\n",
      "    separation loss:          0.5893521010875702\n",
      "    avg separation loss:      2.8265280723571777\n",
      "    l1_addon loss:            67.90178680419922\n",
      "    l1 loss:                  72.32130432128906\n",
      "    train time:               0.0300295352935791\n",
      "    test time:                0.004582405090332031\n",
      "    epoch time:               0.03549790382385254\n",
      "    joint lr:                 0.0009861958963236286\n",
      "epoch: 172 (JOINT) - Libras\n",
      "    test acc:                 86.67%\n",
      "    train overall loss:       0.18011438101530075\n",
      "    train cross_ent loss:     0.10100672207772732\n",
      "    test overall loss:        0.47676680982112885\n",
      "    test cross_ent loss:      0.3976620137691498\n",
      "    cluster loss:             194.18640518188477\n",
      "    separation loss:          0.5846371203660965\n",
      "    avg separation loss:      2.796710729598999\n",
      "    l1_addon loss:            67.83511352539062\n",
      "    l1 loss:                  72.32130432128906\n",
      "    train time:               0.02956986427307129\n",
      "    test time:                0.004546642303466797\n",
      "    epoch time:               0.03470301628112793\n",
      "    joint lr:                 0.001854667874720785\n",
      "epoch: 173 (JOINT) - Libras\n",
      "    test acc:                 87.22%\n",
      "    train overall loss:       0.18275477488835654\n",
      "    train cross_ent loss:     0.10364910773932934\n",
      "    test overall loss:        0.4961838275194168\n",
      "    test cross_ent loss:      0.41707780957221985\n",
      "    cluster loss:             194.1892547607422\n",
      "    separation loss:          0.5999535620212555\n",
      "    avg separation loss:      2.763380527496338\n",
      "    l1_addon loss:            67.84703063964844\n",
      "    l1 loss:                  72.32130432128906\n",
      "    train time:               0.02926158905029297\n",
      "    test time:                0.004693269729614258\n",
      "    epoch time:               0.03452467918395996\n",
      "    joint lr:                 0.0027056817939603655\n",
      "epoch: 174 (JOINT) - Libras\n",
      "    test acc:                 87.78%\n",
      "    train overall loss:       0.16227306177218756\n",
      "    train cross_ent loss:     0.08316689232985179\n",
      "    test overall loss:        0.43062156438827515\n",
      "    test cross_ent loss:      0.35151318460702896\n",
      "    cluster loss:             194.18893432617188\n",
      "    separation loss:          0.5942511856555939\n",
      "    avg separation loss:      2.733271360397339\n",
      "    l1_addon loss:            67.87089538574219\n",
      "    l1 loss:                  72.32130432128906\n",
      "    train time:               0.028922080993652344\n",
      "    test time:                0.004502773284912109\n",
      "    epoch time:               0.03400707244873047\n",
      "    joint lr:                 0.003539499968027705\n",
      "epoch: 175 (JOINT) - Libras\n",
      "    test acc:                 87.78%\n",
      "    train overall loss:       0.16424031431476274\n",
      "    train cross_ent loss:     0.08513528481125832\n",
      "    test overall loss:        0.41849786043167114\n",
      "    test cross_ent loss:      0.3393894284963608\n",
      "    cluster loss:             194.18909454345703\n",
      "    separation loss:          0.5927900671958923\n",
      "    avg separation loss:      2.6908347606658936\n",
      "    l1_addon loss:            67.87124633789062\n",
      "    l1 loss:                  72.32130432128906\n",
      "    train time:               0.02962327003479004\n",
      "    test time:                0.0044558048248291016\n",
      "    epoch time:               0.034647226333618164\n",
      "    joint lr:                 0.00435638121043428\n",
      "epoch: 176 (JOINT) - Libras\n",
      "    test acc:                 90.00%\n",
      "    train overall loss:       0.16160543262958527\n",
      "    train cross_ent loss:     0.08249669211606185\n",
      "    test overall loss:        0.4337621331214905\n",
      "    test cross_ent loss:      0.3546663969755173\n",
      "    cluster loss:             194.18911743164062\n",
      "    separation loss:          0.5760223567485809\n",
      "    avg separation loss:      2.64204740524292\n",
      "    l1_addon loss:            67.74418640136719\n",
      "    l1 loss:                  72.32130432128906\n",
      "    train time:               0.028902530670166016\n",
      "    test time:                0.004459381103515625\n",
      "    epoch time:               0.03394889831542969\n",
      "    joint lr:                 0.00515658087799592\n",
      "epoch: 177 (JOINT) - Libras\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       0.16134242216746011\n",
      "    train cross_ent loss:     0.0822666147723794\n",
      "    test overall loss:        0.5305086374282837\n",
      "    test cross_ent loss:      0.4514292925596237\n",
      "    cluster loss:             194.19408416748047\n",
      "    separation loss:          0.5729621052742004\n",
      "    avg separation loss:      2.627426862716675\n",
      "    l1_addon loss:            67.58015441894531\n",
      "    l1 loss:                  72.32130432128906\n",
      "    train time:               0.02891373634338379\n",
      "    test time:                0.005227088928222656\n",
      "    epoch time:               0.03471016883850098\n",
      "    joint lr:                 0.005940350914085284\n",
      "epoch: 178 (JOINT) - Libras\n",
      "    test acc:                 90.56%\n",
      "    train overall loss:       0.16214817886551222\n",
      "    train cross_ent loss:     0.08305070176720619\n",
      "    test overall loss:        0.4724806398153305\n",
      "    test cross_ent loss:      0.3933148831129074\n",
      "    cluster loss:             194.20095443725586\n",
      "    separation loss:          0.5637030899524689\n",
      "    avg separation loss:      2.589578151702881\n",
      "    l1_addon loss:            68.44437408447266\n",
      "    l1 loss:                  72.32130432128906\n",
      "    train time:               0.02946925163269043\n",
      "    test time:                0.005236148834228516\n",
      "    epoch time:               0.0352787971496582\n",
      "    joint lr:                 0.00670793989136506\n",
      "epoch: 179 (JOINT) - Libras\n",
      "    test acc:                 87.22%\n",
      "    train overall loss:       0.24848309407631555\n",
      "    train cross_ent loss:     0.169389591862758\n",
      "    test overall loss:        0.5214515626430511\n",
      "    test cross_ent loss:      0.44244715571403503\n",
      "    cluster loss:             194.20745468139648\n",
      "    separation loss:          0.5738057792186737\n",
      "    avg separation loss:      2.524004578590393\n",
      "    l1_addon loss:            66.83116149902344\n",
      "    l1 loss:                  72.32130432128906\n",
      "    train time:               0.028769493103027344\n",
      "    test time:                0.004446268081665039\n",
      "    epoch time:               0.03377270698547363\n",
      "    joint lr:                 0.007459593054007833\n",
      "epoch: 180 (JOINT) - Libras\n",
      "    test acc:                 73.33%\n",
      "    train overall loss:       0.2300405129790306\n",
      "    train cross_ent loss:     0.15097171689073244\n",
      "    test overall loss:        1.0051734149456024\n",
      "    test cross_ent loss:      0.9260838627815247\n",
      "    cluster loss:             194.27789688110352\n",
      "    separation loss:          0.7063937783241272\n",
      "    avg separation loss:      2.570393919944763\n",
      "    l1_addon loss:            67.68262481689453\n",
      "    l1 loss:                  72.32130432128906\n",
      "    train time:               0.02935314178466797\n",
      "    test time:                0.004503011703491211\n",
      "    epoch time:               0.0344243049621582\n",
      "    joint lr:                 0.008195552359408614\n",
      "epoch: 181 (JOINT) - Libras\n",
      "    test acc:                 75.56%\n",
      "    train overall loss:       0.31929779549439746\n",
      "    train cross_ent loss:     0.24022613962491354\n",
      "    test overall loss:        0.9149851500988007\n",
      "    test cross_ent loss:      0.8358035683631897\n",
      "    cluster loss:             194.2513313293457\n",
      "    separation loss:          0.6801005005836487\n",
      "    avg separation loss:      2.761883497238159\n",
      "    l1_addon loss:            68.60260009765625\n",
      "    l1 loss:                  72.32130432128906\n",
      "    train time:               0.029548168182373047\n",
      "    test time:                0.004486083984375\n",
      "    epoch time:               0.03461408615112305\n",
      "    joint lr:                 0.007713866994023813\n",
      "epoch: 182 (JOINT) - Libras\n",
      "    test acc:                 72.78%\n",
      "    train overall loss:       0.3564444159468015\n",
      "    train cross_ent loss:     0.2773535003264745\n",
      "    test overall loss:        0.9500715136528015\n",
      "    test cross_ent loss:      0.8710301518440247\n",
      "    cluster loss:             194.31591033935547\n",
      "    separation loss:          0.7970615327358246\n",
      "    avg separation loss:      2.741662621498108\n",
      "    l1_addon loss:            67.20050811767578\n",
      "    l1 loss:                  72.32130432128906\n",
      "    train time:               0.02901744842529297\n",
      "    test time:                0.004450559616088867\n",
      "    epoch time:               0.03403735160827637\n",
      "    joint lr:                 0.007241005780710745\n",
      "epoch: 183 (JOINT) - Libras\n",
      "    test acc:                 81.67%\n",
      "    train overall loss:       0.25734590739011765\n",
      "    train cross_ent loss:     0.1782524697482586\n",
      "    test overall loss:        0.8634417355060577\n",
      "    test cross_ent loss:      0.7843376398086548\n",
      "    cluster loss:             194.30970001220703\n",
      "    separation loss:          0.7062506973743439\n",
      "    avg separation loss:      2.8894819021224976\n",
      "    l1_addon loss:            67.82823944091797\n",
      "    l1 loss:                  72.32130432128906\n",
      "    train time:               0.028989553451538086\n",
      "    test time:                0.004545688629150391\n",
      "    epoch time:               0.03410768508911133\n",
      "    joint lr:                 0.006776840404964548\n",
      "epoch: 184 (JOINT) - Libras\n",
      "    test acc:                 79.44%\n",
      "    train overall loss:       0.2413051277399063\n",
      "    train cross_ent loss:     0.1622223531206449\n",
      "    test overall loss:        0.674106165766716\n",
      "    test cross_ent loss:      0.5949861854314804\n",
      "    cluster loss:             194.25244522094727\n",
      "    separation loss:          0.7193081378936768\n",
      "    avg separation loss:      2.7930245399475098\n",
      "    l1_addon loss:            67.98667907714844\n",
      "    l1 loss:                  72.32130432128906\n",
      "    train time:               0.029166460037231445\n",
      "    test time:                0.004467487335205078\n",
      "    epoch time:               0.03420519828796387\n",
      "    joint lr:                 0.006321244236155204\n",
      "epoch: 185 (JOINT) - Libras\n",
      "    test acc:                 76.11%\n",
      "    train overall loss:       0.23846057057380676\n",
      "    train cross_ent loss:     0.15932678679625192\n",
      "    test overall loss:        0.9003263115882874\n",
      "    test cross_ent loss:      0.8211947083473206\n",
      "    cluster loss:             194.29319763183594\n",
      "    separation loss:          0.7084354162216187\n",
      "    avg separation loss:      2.763842821121216\n",
      "    l1_addon loss:            68.1030502319336\n",
      "    l1 loss:                  72.32130432128906\n",
      "    train time:               0.029721498489379883\n",
      "    test time:                0.004446506500244141\n",
      "    epoch time:               0.03473544120788574\n",
      "    joint lr:                 0.00587409230668155\n",
      "epoch: 186 (JOINT) - Libras\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       0.21860867738723755\n",
      "    train cross_ent loss:     0.13947242933015028\n",
      "    test overall loss:        0.48288387060165405\n",
      "    test cross_ent loss:      0.40374283492565155\n",
      "    cluster loss:             194.2300682067871\n",
      "    separation loss:          0.6547794044017792\n",
      "    avg separation loss:      2.7474541664123535\n",
      "    l1_addon loss:            68.19717407226562\n",
      "    l1 loss:                  72.32130432128906\n",
      "    train time:               0.029700279235839844\n",
      "    test time:                0.0044362545013427734\n",
      "    epoch time:               0.0347285270690918\n",
      "    joint lr:                 0.0054352612913737535\n",
      "epoch: 187 (JOINT) - Libras\n",
      "    test acc:                 78.89%\n",
      "    train overall loss:       0.2280397762854894\n",
      "    train cross_ent loss:     0.14895827074845633\n",
      "    test overall loss:        0.7610882073640823\n",
      "    test cross_ent loss:      0.6820443272590637\n",
      "    cluster loss:             194.23480606079102\n",
      "    separation loss:          0.6299672424793243\n",
      "    avg separation loss:      2.6316241025924683\n",
      "    l1_addon loss:            67.2253189086914\n",
      "    l1 loss:                  72.32130432128906\n",
      "    train time:               0.030550241470336914\n",
      "    test time:                0.004452705383300781\n",
      "    epoch time:               0.03555798530578613\n",
      "    joint lr:                 0.005004629487141445\n",
      "epoch: 188 (JOINT) - Libras\n",
      "    test acc:                 82.22%\n",
      "    train overall loss:       0.21690312772989273\n",
      "    train cross_ent loss:     0.1378305951754252\n",
      "    test overall loss:        0.7750919759273529\n",
      "    test cross_ent loss:      0.6959978640079498\n",
      "    cluster loss:             194.22261810302734\n",
      "    separation loss:          0.6398715674877167\n",
      "    avg separation loss:      2.7547186613082886\n",
      "    l1_addon loss:            67.72808074951172\n",
      "    l1 loss:                  72.32130432128906\n",
      "    train time:               0.029248714447021484\n",
      "    test time:                0.004439353942871094\n",
      "    epoch time:               0.03425788879394531\n",
      "    joint lr:                 0.004582076792864645\n",
      "epoch: 189 (JOINT) - Libras\n",
      "    test acc:                 85.56%\n",
      "    train overall loss:       0.18392758443951607\n",
      "    train cross_ent loss:     0.1048453679929177\n",
      "    test overall loss:        0.6588001847267151\n",
      "    test cross_ent loss:      0.5797113627195358\n",
      "    cluster loss:             194.2312889099121\n",
      "    separation loss:          0.668572336435318\n",
      "    avg separation loss:      2.757433295249939\n",
      "    l1_addon loss:            67.67521667480469\n",
      "    l1 loss:                  72.32130432128906\n",
      "    train time:               0.02925276756286621\n",
      "    test time:                0.004469871520996094\n",
      "    epoch time:               0.03432154655456543\n",
      "    joint lr:                 0.004167484689524657\n",
      "epoch: 190 (JOINT) - Libras\n",
      "    test acc:                 87.78%\n",
      "    train overall loss:       0.18771288295586905\n",
      "    train cross_ent loss:     0.10860877484083176\n",
      "    test overall loss:        0.4661221206188202\n",
      "    test cross_ent loss:      0.38702794909477234\n",
      "    cluster loss:             194.21894073486328\n",
      "    separation loss:          0.6549763977527618\n",
      "    avg separation loss:      2.7236467599868774\n",
      "    l1_addon loss:            67.72869110107422\n",
      "    l1 loss:                  72.32130432128906\n",
      "    train time:               0.029298067092895508\n",
      "    test time:                0.004479169845581055\n",
      "    epoch time:               0.03433585166931152\n",
      "    joint lr:                 0.003760736220572192\n",
      "epoch: 191 (JOINT) - Libras\n",
      "    test acc:                 84.44%\n",
      "    train overall loss:       0.18580448006590208\n",
      "    train cross_ent loss:     0.10673067873964708\n",
      "    test overall loss:        0.6202099621295929\n",
      "    test cross_ent loss:      0.5411346107721329\n",
      "    cluster loss:             194.21611404418945\n",
      "    separation loss:          0.6054396033287048\n",
      "    avg separation loss:      2.6385202407836914\n",
      "    l1_addon loss:            67.54060363769531\n",
      "    l1 loss:                  72.32130432128906\n",
      "    train time:               0.029179811477661133\n",
      "    test time:                0.004465818405151367\n",
      "    epoch time:               0.034221649169921875\n",
      "    joint lr:                 0.0033617159725298235\n",
      "epoch: 192 (JOINT) - Libras\n",
      "    test acc:                 86.67%\n",
      "    train overall loss:       0.18367632354299226\n",
      "    train cross_ent loss:     0.10459519581248362\n",
      "    test overall loss:        0.4626307040452957\n",
      "    test cross_ent loss:      0.38354845345020294\n",
      "    cluster loss:             194.2037811279297\n",
      "    separation loss:          0.5891008377075195\n",
      "    avg separation loss:      2.5825228691101074\n",
      "    l1_addon loss:            67.60928344726562\n",
      "    l1 loss:                  72.32130432128906\n",
      "    train time:               0.029688596725463867\n",
      "    test time:                0.0044558048248291016\n",
      "    epoch time:               0.03472328186035156\n",
      "    joint lr:                 0.002970310055826246\n",
      "epoch: 193 (JOINT) - Libras\n",
      "    test acc:                 85.56%\n",
      "    train overall loss:       0.15569978828231493\n",
      "    train cross_ent loss:     0.07662128936499357\n",
      "    test overall loss:        0.4615600109100342\n",
      "    test cross_ent loss:      0.38249120116233826\n",
      "    cluster loss:             194.20218658447266\n",
      "    separation loss:          0.5594831854104996\n",
      "    avg separation loss:      2.5674465894699097\n",
      "    l1_addon loss:            67.47492980957031\n",
      "    l1 loss:                  72.32130432128906\n",
      "    train time:               0.028810501098632812\n",
      "    test time:                0.004471302032470703\n",
      "    epoch time:               0.03383994102478027\n",
      "    joint lr:                 0.0025864060858594865\n",
      "epoch: 194 (JOINT) - Libras\n",
      "    test acc:                 86.67%\n",
      "    train overall loss:       0.16221950699885687\n",
      "    train cross_ent loss:     0.08315994900961717\n",
      "    test overall loss:        0.42226357758045197\n",
      "    test cross_ent loss:      0.3432041108608246\n",
      "    cluster loss:             194.19901275634766\n",
      "    separation loss:          0.5518788695335388\n",
      "    avg separation loss:      2.5424472093582153\n",
      "    l1_addon loss:            67.38151550292969\n",
      "    l1 loss:                  72.32130432128906\n",
      "    train time:               0.029392719268798828\n",
      "    test time:                0.004542112350463867\n",
      "    epoch time:               0.03450584411621094\n",
      "    joint lr:                 0.00220989316428648\n",
      "epoch: 195 (JOINT) - Libras\n",
      "    test acc:                 87.78%\n",
      "    train overall loss:       0.14889348049958548\n",
      "    train cross_ent loss:     0.06983374307552974\n",
      "    test overall loss:        0.41396351158618927\n",
      "    test cross_ent loss:      0.33490534126758575\n",
      "    cluster loss:             194.19539642333984\n",
      "    separation loss:          0.567669689655304\n",
      "    avg separation loss:      2.536866784095764\n",
      "    l1_addon loss:            67.36848449707031\n",
      "    l1 loss:                  72.32130432128906\n",
      "    train time:               0.029379606246948242\n",
      "    test time:                0.004477739334106445\n",
      "    epoch time:               0.03442716598510742\n",
      "    joint lr:                 0.0018406618605363474\n",
      "epoch: 196 (JOINT) - Libras\n",
      "    test acc:                 87.78%\n",
      "    train overall loss:       0.13949513932069144\n",
      "    train cross_ent loss:     0.06043647509068251\n",
      "    test overall loss:        0.4011988341808319\n",
      "    test cross_ent loss:      0.3221444860100746\n",
      "    cluster loss:             194.19468307495117\n",
      "    separation loss:          0.5663279294967651\n",
      "    avg separation loss:      2.5233144760131836\n",
      "    l1_addon loss:            67.3302001953125\n",
      "    l1 loss:                  72.32130432128906\n",
      "    train time:               0.029550552368164062\n",
      "    test time:                0.004484653472900391\n",
      "    epoch time:               0.03461885452270508\n",
      "    joint lr:                 0.001478604193544789\n",
      "epoch: 197 (JOINT) - Libras\n",
      "    test acc:                 87.22%\n",
      "    train overall loss:       0.13795499751965204\n",
      "    train cross_ent loss:     0.05890113674104214\n",
      "    test overall loss:        0.4063118100166321\n",
      "    test cross_ent loss:      0.32726267725229263\n",
      "    cluster loss:             194.19375610351562\n",
      "    separation loss:          0.5577169060707092\n",
      "    avg separation loss:      2.5058058500289917\n",
      "    l1_addon loss:            67.27821350097656\n",
      "    l1 loss:                  72.32130432128906\n",
      "    train time:               0.02899003028869629\n",
      "    test time:                0.004490375518798828\n",
      "    epoch time:               0.03405880928039551\n",
      "    joint lr:                 0.0011236136137069992\n",
      "epoch: 198 (JOINT) - Libras\n",
      "    test acc:                 87.78%\n",
      "    train overall loss:       0.14244558910528818\n",
      "    train cross_ent loss:     0.06339717283844948\n",
      "    test overall loss:        0.40216824412345886\n",
      "    test cross_ent loss:      0.32312024384737015\n",
      "    cluster loss:             194.19342422485352\n",
      "    separation loss:          0.5494143962860107\n",
      "    avg separation loss:      2.4922449588775635\n",
      "    l1_addon loss:            67.26693725585938\n",
      "    l1 loss:                  72.32130432128906\n",
      "    train time:               0.028910398483276367\n",
      "    test time:                0.0045049190521240234\n",
      "    epoch time:               0.03399014472961426\n",
      "    joint lr:                 0.0007755849850466195\n",
      "epoch: 199 (JOINT) - Libras\n",
      "    test acc:                 87.78%\n",
      "    train overall loss:       0.12498460089166959\n",
      "    train cross_ent loss:     0.04593638548006614\n",
      "    test overall loss:        0.39659997820854187\n",
      "    test cross_ent loss:      0.3175526484847069\n",
      "    cluster loss:             194.19336700439453\n",
      "    separation loss:          0.5456380397081375\n",
      "    avg separation loss:      2.486765503883362\n",
      "    l1_addon loss:            67.26040649414062\n",
      "    l1 loss:                  72.32130432128906\n",
      "    train time:               0.029171228408813477\n",
      "    test time:                0.004498958587646484\n",
      "    epoch time:               0.03424191474914551\n",
      "    joint lr:                 0.0004344145675980766\n",
      "epoch: 200 (JOINT) - Libras\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       0.12748689328630766\n",
      "    train cross_ent loss:     0.04844039647529522\n",
      "    test overall loss:        0.39845117926597595\n",
      "    test cross_ent loss:      0.31940505653619766\n",
      "    cluster loss:             194.19287490844727\n",
      "    separation loss:          0.5440650284290314\n",
      "    avg separation loss:      2.490955352783203\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  72.32130432128906\n",
      "    train time:               0.028794050216674805\n",
      "    test time:                0.0045053958892822266\n",
      "    epoch time:               0.03386855125427246\n",
      "    joint lr:                 0.0001\n",
      "epoch: 200 (PUSH) - Libras\n",
      "    test acc:                 86.11%\n",
      "    train overall loss:       0.12748689328630766\n",
      "    train cross_ent loss:     0.04844039647529522\n",
      "    test overall loss:        0.46920131146907806\n",
      "    test cross_ent loss:      0.3901551812887192\n",
      "    cluster loss:             194.19398498535156\n",
      "    separation loss:          0.5484327673912048\n",
      "    avg separation loss:      2.5030893087387085\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  72.32130432128906\n",
      "    train time:               0.028794050216674805\n",
      "    test time:                0.004522562026977539\n",
      "    epoch time:               0.07436227798461914\n",
      "epoch: 200 (1/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 86.11%\n",
      "    train overall loss:       0.18134864419698715\n",
      "    train cross_ent loss:     0.10232322352627914\n",
      "    test overall loss:        0.4739091992378235\n",
      "    test cross_ent loss:      0.39491306245326996\n",
      "    cluster loss:             194.19413375854492\n",
      "    separation loss:          0.5494707077741623\n",
      "    avg separation loss:      2.5072866678237915\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  72.27130889892578\n",
      "    train time:               0.013219356536865234\n",
      "    test time:                0.0045185089111328125\n",
      "    epoch time:               0.01822638511657715\n",
      "    last layer lr:            0.0007600000000000095\n",
      "epoch: 200 (2/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 87.22%\n",
      "    train overall loss:       0.1602674312889576\n",
      "    train cross_ent loss:     0.08136775965491931\n",
      "    test overall loss:        0.47066590189933777\n",
      "    test cross_ent loss:      0.3918979614973068\n",
      "    cluster loss:             194.19393157958984\n",
      "    separation loss:          0.5482048988342285\n",
      "    avg separation loss:      2.5051547288894653\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  72.0431137084961\n",
      "    train time:               0.013020038604736328\n",
      "    test time:                0.004509687423706055\n",
      "    epoch time:               0.01804208755493164\n",
      "    last layer lr:            0.0014199999999999955\n",
      "epoch: 200 (3/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 86.67%\n",
      "    train overall loss:       0.18399604161580405\n",
      "    train cross_ent loss:     0.10542430977026622\n",
      "    test overall loss:        0.4611538499593735\n",
      "    test cross_ent loss:      0.38282959163188934\n",
      "    cluster loss:             194.19445419311523\n",
      "    separation loss:          0.5503007769584656\n",
      "    avg separation loss:      2.5076125860214233\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  71.59943389892578\n",
      "    train time:               0.012906312942504883\n",
      "    test time:                0.004459857940673828\n",
      "    epoch time:               0.01784229278564453\n",
      "    last layer lr:            0.0020800000000000046\n",
      "epoch: 200 (4/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 87.22%\n",
      "    train overall loss:       0.17606604720155397\n",
      "    train cross_ent loss:     0.09793825137118499\n",
      "    test overall loss:        0.4548758715391159\n",
      "    test cross_ent loss:      0.3770572692155838\n",
      "    cluster loss:             194.19388961791992\n",
      "    separation loss:          0.5480675846338272\n",
      "    avg separation loss:      2.5067211389541626\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  71.09378051757812\n",
      "    train time:               0.013314485549926758\n",
      "    test time:                0.004791259765625\n",
      "    epoch time:               0.01858210563659668\n",
      "    last layer lr:            0.0027399999999999907\n",
      "epoch: 200 (5/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 87.78%\n",
      "    train overall loss:       0.1724077264467875\n",
      "    train cross_ent loss:     0.09487927953402202\n",
      "    test overall loss:        0.44232654571533203\n",
      "    test cross_ent loss:      0.365212619304657\n",
      "    cluster loss:             194.1943817138672\n",
      "    separation loss:          0.5492706447839737\n",
      "    avg separation loss:      2.5019149780273438\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  70.38909912109375\n",
      "    train time:               0.012854814529418945\n",
      "    test time:                0.004544734954833984\n",
      "    epoch time:               0.017875194549560547\n",
      "    last layer lr:            0.0034\n",
      "epoch: 200 (6/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 87.22%\n",
      "    train overall loss:       0.16004739825924238\n",
      "    train cross_ent loss:     0.0832945139457782\n",
      "    test overall loss:        0.43668121099472046\n",
      "    test cross_ent loss:      0.36048219352960587\n",
      "    cluster loss:             194.19427490234375\n",
      "    separation loss:          0.5491516143083572\n",
      "    avg separation loss:      2.506278395652771\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  69.47421264648438\n",
      "    train time:               0.012780904769897461\n",
      "    test time:                0.004445314407348633\n",
      "    epoch time:               0.01771998405456543\n",
      "    last layer lr:            0.00406000000000001\n",
      "epoch: 200 (7/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 87.22%\n",
      "    train overall loss:       0.1553291566669941\n",
      "    train cross_ent loss:     0.07950617993871371\n",
      "    test overall loss:        0.4366728961467743\n",
      "    test cross_ent loss:      0.36148616671562195\n",
      "    cluster loss:             194.19437408447266\n",
      "    separation loss:          0.550790399312973\n",
      "    avg separation loss:      2.5129584074020386\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  68.46189880371094\n",
      "    train time:               0.012830495834350586\n",
      "    test time:                0.004960060119628906\n",
      "    epoch time:               0.018288612365722656\n",
      "    last layer lr:            0.004719999999999996\n",
      "epoch: 200 (8/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       0.14947105571627617\n",
      "    train cross_ent loss:     0.07495370258887608\n",
      "    test overall loss:        0.4329545348882675\n",
      "    test cross_ent loss:      0.3593238666653633\n",
      "    cluster loss:             194.19424438476562\n",
      "    separation loss:          0.5493777990341187\n",
      "    avg separation loss:      2.5099486112594604\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  66.90583801269531\n",
      "    train time:               0.013338804244995117\n",
      "    test time:                0.004427194595336914\n",
      "    epoch time:               0.018261194229125977\n",
      "    last layer lr:            0.0053800000000000054\n",
      "epoch: 200 (9/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 88.89%\n",
      "    train overall loss:       0.17419098317623138\n",
      "    train cross_ent loss:     0.10110751291116078\n",
      "    test overall loss:        0.43454691767692566\n",
      "    test cross_ent loss:      0.3621697425842285\n",
      "    cluster loss:             194.19457626342773\n",
      "    separation loss:          0.5498789697885513\n",
      "    avg separation loss:      2.510484457015991\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  65.65235900878906\n",
      "    train time:               0.013010263442993164\n",
      "    test time:                0.004469871520996094\n",
      "    epoch time:               0.01797199249267578\n",
      "    last layer lr:            0.0060399999999999916\n",
      "epoch: 200 (10/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       0.16321426878372827\n",
      "    train cross_ent loss:     0.09152710748215516\n",
      "    test overall loss:        0.4330998957157135\n",
      "    test cross_ent loss:      0.36235489696264267\n",
      "    cluster loss:             194.1948471069336\n",
      "    separation loss:          0.5505845844745636\n",
      "    avg separation loss:      2.50838041305542\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  64.02017211914062\n",
      "    train time:               0.012616157531738281\n",
      "    test time:                0.004433155059814453\n",
      "    epoch time:               0.01752638816833496\n",
      "    last layer lr:            0.0067\n",
      "epoch: 200 (11/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 89.44%\n",
      "    train overall loss:       0.14930519461631775\n",
      "    train cross_ent loss:     0.07906035333871841\n",
      "    test overall loss:        0.429944172501564\n",
      "    test cross_ent loss:      0.3603278547525406\n",
      "    cluster loss:             194.1938591003418\n",
      "    separation loss:          0.5479068458080292\n",
      "    avg separation loss:      2.4996490478515625\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  62.89149475097656\n",
      "    train time:               0.01241159439086914\n",
      "    test time:                0.005945682525634766\n",
      "    epoch time:               0.018833398818969727\n",
      "    last layer lr:            0.007360000000000011\n",
      "epoch: 200 (12/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 89.44%\n",
      "    train overall loss:       0.16027503336469331\n",
      "    train cross_ent loss:     0.09133218290905158\n",
      "    test overall loss:        0.4305616170167923\n",
      "    test cross_ent loss:      0.3627168834209442\n",
      "    cluster loss:             194.1936264038086\n",
      "    separation loss:          0.5469448566436768\n",
      "    avg separation loss:      2.502118706703186\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  61.11991882324219\n",
      "    train time:               0.01273655891418457\n",
      "    test time:                0.004480838775634766\n",
      "    epoch time:               0.01769542694091797\n",
      "    last layer lr:            0.008019999999999994\n",
      "epoch: 200 (13/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 89.44%\n",
      "    train overall loss:       0.147775466243426\n",
      "    train cross_ent loss:     0.08067493761579196\n",
      "    test overall loss:        0.4237177073955536\n",
      "    test cross_ent loss:      0.35755886882543564\n",
      "    cluster loss:             194.19417190551758\n",
      "    separation loss:          0.5480204224586487\n",
      "    avg separation loss:      2.5029165744781494\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  59.433998107910156\n",
      "    train time:               0.012386083602905273\n",
      "    test time:                0.004439830780029297\n",
      "    epoch time:               0.01730060577392578\n",
      "    last layer lr:            0.008680000000000005\n",
      "epoch: 200 (14/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 88.89%\n",
      "    train overall loss:       0.1392360789080461\n",
      "    train cross_ent loss:     0.07354464071492355\n",
      "    test overall loss:        0.4255302995443344\n",
      "    test cross_ent loss:      0.36036665737628937\n",
      "    cluster loss:             194.19433975219727\n",
      "    separation loss:          0.5484697222709656\n",
      "    avg separation loss:      2.5072606801986694\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  58.438812255859375\n",
      "    train time:               0.012395381927490234\n",
      "    test time:                0.004491567611694336\n",
      "    epoch time:               0.017362594604492188\n",
      "    last layer lr:            0.00933999999999999\n",
      "epoch: 200 (15/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       0.1457588536043962\n",
      "    train cross_ent loss:     0.08082969610889752\n",
      "    test overall loss:        0.42033933103084564\n",
      "    test cross_ent loss:      0.3563882037997246\n",
      "    cluster loss:             194.19493103027344\n",
      "    separation loss:          0.5509091168642044\n",
      "    avg separation loss:      2.5132030248641968\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  57.22630310058594\n",
      "    train time:               0.012392520904541016\n",
      "    test time:                0.005217552185058594\n",
      "    epoch time:               0.01808309555053711\n",
      "    last layer lr:            0.01\n",
      "epoch: 200 (16/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       0.1598956622183323\n",
      "    train cross_ent loss:     0.09687730669975281\n",
      "    test overall loss:        0.41412705183029175\n",
      "    test cross_ent loss:      0.3522109240293503\n",
      "    cluster loss:             194.19477462768555\n",
      "    separation loss:          0.5488508641719818\n",
      "    avg separation loss:      2.502899169921875\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  55.191307067871094\n",
      "    train time:               0.012955427169799805\n",
      "    test time:                0.0045359134674072266\n",
      "    epoch time:               0.01797008514404297\n",
      "    last layer lr:            0.009603999999999994\n",
      "epoch: 200 (17/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       0.12899338329831758\n",
      "    train cross_ent loss:     0.06774401571601629\n",
      "    test overall loss:        0.4088229387998581\n",
      "    test cross_ent loss:      0.3484780639410019\n",
      "    cluster loss:             194.19446182250977\n",
      "    separation loss:          0.5478010475635529\n",
      "    avg separation loss:      2.500973701477051\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  53.62006378173828\n",
      "    train time:               0.012372255325317383\n",
      "    test time:                0.004477739334106445\n",
      "    epoch time:               0.017339229583740234\n",
      "    last layer lr:            0.009208000000000003\n",
      "epoch: 200 (18/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       0.12750066940983137\n",
      "    train cross_ent loss:     0.06783866758147876\n",
      "    test overall loss:        0.4092906266450882\n",
      "    test cross_ent loss:      0.35064568370580673\n",
      "    cluster loss:             194.19445419311523\n",
      "    separation loss:          0.5492920130491257\n",
      "    avg separation loss:      2.5077682733535767\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  51.920127868652344\n",
      "    train time:               0.012380123138427734\n",
      "    test time:                0.0044307708740234375\n",
      "    epoch time:               0.017285823822021484\n",
      "    last layer lr:            0.008811999999999997\n",
      "epoch: 200 (19/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       0.13735163832704225\n",
      "    train cross_ent loss:     0.07927741048236688\n",
      "    test overall loss:        0.40995021164417267\n",
      "    test cross_ent loss:      0.35283101350069046\n",
      "    cluster loss:             194.19468688964844\n",
      "    separation loss:          0.5491516292095184\n",
      "    avg separation loss:      2.5067111253738403\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  50.39435577392578\n",
      "    train time:               0.012730121612548828\n",
      "    test time:                0.004425048828125\n",
      "    epoch time:               0.017634153366088867\n",
      "    last layer lr:            0.008416000000000005\n",
      "epoch: 200 (20/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 88.89%\n",
      "    train overall loss:       0.1367133061091105\n",
      "    train cross_ent loss:     0.08032485842704773\n",
      "    test overall loss:        0.4056238383054733\n",
      "    test cross_ent loss:      0.3500956818461418\n",
      "    cluster loss:             194.1941909790039\n",
      "    separation loss:          0.5467848181724548\n",
      "    avg separation loss:      2.499677062034607\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  48.803348541259766\n",
      "    train time:               0.012550830841064453\n",
      "    test time:                0.004473686218261719\n",
      "    epoch time:               0.017505884170532227\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 200 (21/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 88.89%\n",
      "    train overall loss:       0.1300495577355226\n",
      "    train cross_ent loss:     0.0749537122125427\n",
      "    test overall loss:        0.4062614440917969\n",
      "    test cross_ent loss:      0.35172079503536224\n",
      "    cluster loss:             194.19437408447266\n",
      "    separation loss:          0.5467356592416763\n",
      "    avg separation loss:      2.5002686977386475\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  47.81581497192383\n",
      "    train time:               0.012914657592773438\n",
      "    test time:                0.005176067352294922\n",
      "    epoch time:               0.018578767776489258\n",
      "    last layer lr:            0.007623999999999995\n",
      "epoch: 200 (22/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       0.12863498801986376\n",
      "    train cross_ent loss:     0.07452606658140819\n",
      "    test overall loss:        0.40472494065761566\n",
      "    test cross_ent loss:      0.3510628193616867\n",
      "    cluster loss:             194.19471740722656\n",
      "    separation loss:          0.5483846068382263\n",
      "    avg separation loss:      2.504944920539856\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  46.93730545043945\n",
      "    train time:               0.012537479400634766\n",
      "    test time:                0.005229949951171875\n",
      "    epoch time:               0.018242597579956055\n",
      "    last layer lr:            0.0072280000000000035\n",
      "epoch: 200 (23/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       0.1449661540488402\n",
      "    train cross_ent loss:     0.09084037318825722\n",
      "    test overall loss:        0.40380826592445374\n",
      "    test cross_ent loss:      0.3497585132718086\n",
      "    cluster loss:             194.1951026916504\n",
      "    separation loss:          0.5478922575712204\n",
      "    avg separation loss:      2.5021404027938843\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  47.324951171875\n",
      "    train time:               0.012694120407104492\n",
      "    test time:                0.004429817199707031\n",
      "    epoch time:               0.01762533187866211\n",
      "    last layer lr:            0.006831999999999998\n",
      "epoch: 200 (24/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       0.11959422876437505\n",
      "    train cross_ent loss:     0.06593553566684325\n",
      "    test overall loss:        0.4021277278661728\n",
      "    test cross_ent loss:      0.34907328337430954\n",
      "    cluster loss:             194.19493865966797\n",
      "    separation loss:          0.5473290383815765\n",
      "    avg separation loss:      2.5005083084106445\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  46.32962417602539\n",
      "    train time:               0.012545347213745117\n",
      "    test time:                0.0068051815032958984\n",
      "    epoch time:               0.019824981689453125\n",
      "    last layer lr:            0.006436000000000007\n",
      "epoch: 200 (25/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       0.14140995840231577\n",
      "    train cross_ent loss:     0.08907490409910679\n",
      "    test overall loss:        0.39905597269535065\n",
      "    test cross_ent loss:      0.34748849272727966\n",
      "    cluster loss:             194.19407272338867\n",
      "    separation loss:          0.5466905385255814\n",
      "    avg separation loss:      2.5026179552078247\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  44.842655181884766\n",
      "    train time:               0.012426614761352539\n",
      "    test time:                0.004446983337402344\n",
      "    epoch time:               0.01734638214111328\n",
      "    last layer lr:            0.00604\n",
      "epoch: 200 (26/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       0.11598524202903111\n",
      "    train cross_ent loss:     0.06438455606500308\n",
      "    test overall loss:        0.39595310389995575\n",
      "    test cross_ent loss:      0.34448307007551193\n",
      "    cluster loss:             194.19475555419922\n",
      "    separation loss:          0.5485504120588303\n",
      "    avg separation loss:      2.5074074268341064\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  44.74520492553711\n",
      "    train time:               0.012758016586303711\n",
      "    test time:                0.0044629573822021484\n",
      "    epoch time:               0.017699718475341797\n",
      "    last layer lr:            0.0056439999999999945\n",
      "epoch: 200 (27/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 88.89%\n",
      "    train overall loss:       0.12426650275786717\n",
      "    train cross_ent loss:     0.07322281847397487\n",
      "    test overall loss:        0.3906518816947937\n",
      "    test cross_ent loss:      0.34033580869436264\n",
      "    cluster loss:             194.1939697265625\n",
      "    separation loss:          0.5481825172901154\n",
      "    avg separation loss:      2.498218059539795\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  43.59125518798828\n",
      "    train time:               0.012355566024780273\n",
      "    test time:                0.004554033279418945\n",
      "    epoch time:               0.017381906509399414\n",
      "    last layer lr:            0.005248000000000003\n",
      "epoch: 200 (28/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       0.13273843874533972\n",
      "    train cross_ent loss:     0.08263043935100238\n",
      "    test overall loss:        0.39542338252067566\n",
      "    test cross_ent loss:      0.34569208323955536\n",
      "    cluster loss:             194.19455337524414\n",
      "    separation loss:          0.5483842641115189\n",
      "    avg separation loss:      2.5014811754226685\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  43.00648498535156\n",
      "    train time:               0.012650012969970703\n",
      "    test time:                0.004500627517700195\n",
      "    epoch time:               0.01763629913330078\n",
      "    last layer lr:            0.004851999999999998\n",
      "epoch: 200 (29/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       0.11729825908939044\n",
      "    train cross_ent loss:     0.06768404816587766\n",
      "    test overall loss:        0.3918878138065338\n",
      "    test cross_ent loss:      0.342521607875824\n",
      "    cluster loss:             194.19414520263672\n",
      "    separation loss:          0.548967182636261\n",
      "    avg separation loss:      2.503367781639099\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  42.641387939453125\n",
      "    train time:               0.012947320938110352\n",
      "    test time:                0.004441022872924805\n",
      "    epoch time:               0.017888784408569336\n",
      "    last layer lr:            0.004456000000000006\n",
      "epoch: 200 (30/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 87.78%\n",
      "    train overall loss:       0.14156797900795937\n",
      "    train cross_ent loss:     0.09233947843313217\n",
      "    test overall loss:        0.3927128463983536\n",
      "    test cross_ent loss:      0.3438844308257103\n",
      "    cluster loss:             194.19488525390625\n",
      "    separation loss:          0.5493092983961105\n",
      "    avg separation loss:      2.5091185569763184\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  42.103599548339844\n",
      "    train time:               0.01278233528137207\n",
      "    test time:                0.004431247711181641\n",
      "    epoch time:               0.017691850662231445\n",
      "    last layer lr:            0.004060000000000001\n",
      "epoch: 200 (31/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       0.11910405134161313\n",
      "    train cross_ent loss:     0.07059840795894463\n",
      "    test overall loss:        0.3925207704305649\n",
      "    test cross_ent loss:      0.34436168521642685\n",
      "    cluster loss:             194.1951141357422\n",
      "    separation loss:          0.5511729121208191\n",
      "    avg separation loss:      2.5133241415023804\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  41.43427276611328\n",
      "    train time:               0.01278996467590332\n",
      "    test time:                0.005842924118041992\n",
      "    epoch time:               0.019115447998046875\n",
      "    last layer lr:            0.0036639999999999945\n",
      "epoch: 200 (32/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       0.12626654282212257\n",
      "    train cross_ent loss:     0.07827375394602616\n",
      "    test overall loss:        0.3906928598880768\n",
      "    test cross_ent loss:      0.3430528938770294\n",
      "    cluster loss:             194.19475555419922\n",
      "    separation loss:          0.5498752295970917\n",
      "    avg separation loss:      2.5104585886001587\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  40.915138244628906\n",
      "    train time:               0.012782096862792969\n",
      "    test time:                0.004465579986572266\n",
      "    epoch time:               0.01773691177368164\n",
      "    last layer lr:            0.003268000000000003\n",
      "epoch: 200 (33/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       0.11862798035144806\n",
      "    train cross_ent loss:     0.0712279441456\n",
      "    test overall loss:        0.3917442709207535\n",
      "    test cross_ent loss:      0.3446297124028206\n",
      "    cluster loss:             194.1950340270996\n",
      "    separation loss:          0.5504658967256546\n",
      "    avg separation loss:      2.5182015895843506\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  40.38972473144531\n",
      "    train time:               0.012821197509765625\n",
      "    test time:                0.004475831985473633\n",
      "    epoch time:               0.017781496047973633\n",
      "    last layer lr:            0.002871999999999997\n",
      "epoch: 200 (34/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       0.11443265030781428\n",
      "    train cross_ent loss:     0.06751496717333794\n",
      "    test overall loss:        0.3892980366945267\n",
      "    test cross_ent loss:      0.34264201670885086\n",
      "    cluster loss:             194.194580078125\n",
      "    separation loss:          0.5496727824211121\n",
      "    avg separation loss:      2.5109193325042725\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  39.931190490722656\n",
      "    train time:               0.012807607650756836\n",
      "    test time:                0.004441976547241211\n",
      "    epoch time:               0.017746448516845703\n",
      "    last layer lr:            0.0024760000000000055\n",
      "epoch: 200 (35/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       0.11845708141724269\n",
      "    train cross_ent loss:     0.0719618909060955\n",
      "    test overall loss:        0.3911093473434448\n",
      "    test cross_ent loss:      0.3448574021458626\n",
      "    cluster loss:             194.19406509399414\n",
      "    separation loss:          0.5479003936052322\n",
      "    avg separation loss:      2.5078485012054443\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  39.52714157104492\n",
      "    train time:               0.01282191276550293\n",
      "    test time:                0.004475831985473633\n",
      "    epoch time:               0.017781734466552734\n",
      "    last layer lr:            0.0020800000000000003\n",
      "epoch: 200 (36/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       0.12169022113084793\n",
      "    train cross_ent loss:     0.07554557919502258\n",
      "    test overall loss:        0.3866422772407532\n",
      "    test cross_ent loss:      0.3406878113746643\n",
      "    cluster loss:             194.1944122314453\n",
      "    separation loss:          0.5484832972288132\n",
      "    avg separation loss:      2.5034849643707275\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  39.229652404785156\n",
      "    train time:               0.013184547424316406\n",
      "    test time:                0.005600690841674805\n",
      "    epoch time:               0.019269227981567383\n",
      "    last layer lr:            0.0016839999999999945\n",
      "epoch: 200 (37/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       0.11719183872143428\n",
      "    train cross_ent loss:     0.0713374416033427\n",
      "    test overall loss:        0.3845929652452469\n",
      "    test cross_ent loss:      0.338853657245636\n",
      "    cluster loss:             194.19471740722656\n",
      "    separation loss:          0.5500508844852448\n",
      "    avg separation loss:      2.505552053451538\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  39.01448059082031\n",
      "    train time:               0.01279449462890625\n",
      "    test time:                0.004442453384399414\n",
      "    epoch time:               0.01773238182067871\n",
      "    last layer lr:            0.001288000000000003\n",
      "epoch: 200 (38/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       0.1080164723098278\n",
      "    train cross_ent loss:     0.06236254796385765\n",
      "    test overall loss:        0.385837197303772\n",
      "    test cross_ent loss:      0.34031614661216736\n",
      "    cluster loss:             194.19435119628906\n",
      "    separation loss:          0.5494873225688934\n",
      "    avg separation loss:      2.506727457046509\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  38.796241760253906\n",
      "    train time:               0.013181447982788086\n",
      "    test time:                0.004561185836791992\n",
      "    epoch time:               0.01822805404663086\n",
      "    last layer lr:            0.0008919999999999973\n",
      "epoch: 200 (39/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       0.11823463191588719\n",
      "    train cross_ent loss:     0.07279899095495541\n",
      "    test overall loss:        0.3845887631177902\n",
      "    test cross_ent loss:      0.33924268186092377\n",
      "    cluster loss:             194.19440841674805\n",
      "    separation loss:          0.5481686294078827\n",
      "    avg separation loss:      2.500054955482483\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  38.62125015258789\n",
      "    train time:               0.012798070907592773\n",
      "    test time:                0.004446744918823242\n",
      "    epoch time:               0.017723798751831055\n",
      "    last layer lr:            0.0004960000000000057\n",
      "epoch: 200 (40/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       0.12178921575347583\n",
      "    train cross_ent loss:     0.07645204104483128\n",
      "    test overall loss:        0.3849543333053589\n",
      "    test cross_ent loss:      0.3396433964371681\n",
      "    cluster loss:             194.19447326660156\n",
      "    separation loss:          0.550148531794548\n",
      "    avg separation loss:      2.505433201789856\n",
      "    l1_addon loss:            67.24810791015625\n",
      "    l1 loss:                  38.58610534667969\n",
      "    train time:               0.012797832489013672\n",
      "    test time:                0.005771636962890625\n",
      "    epoch time:               0.01904463768005371\n",
      "    last layer lr:            0.0001\n",
      "Finished training in 18.84 seconds\n",
      "Last epoch test accu: 88.33%\n",
      "Done in 200 epochs, 24.75s\n"
     ]
    }
   ],
   "source": [
    "experiment_name = \"PrototypesTests\"\n",
    "\n",
    "selected_dses = [\"Libras\"]\n",
    "\n",
    "best_params = pd.read_csv('best_params.csv', index_col=0)\n",
    "\n",
    "default_params = {\n",
    "    \"coeffs\": ProtoTSCoeffs(crs_ent=1, clst=0, sep=0, l1=1e-3, l1_addon=1e-4),\n",
    "    \"reception\": 0.25,\n",
    "    \"proto_len\": 5,\n",
    "    \"protos_per_class\": 3,\n",
    "    \"proto_features\": 32,\n",
    "    \"features_lr\": 1e-4,\n",
    "    \"push_start_epoch\": 110,\n",
    "    \"num_last_layer_epochs\": 40,\n",
    "}\n",
    "\n",
    "for ds_name, dataset in all_ds.items():\n",
    "    if ds_name not in selected_dses:\n",
    "        continue\n",
    "    \n",
    "    ds_info = ds_get_info(dataset.name)\n",
    "\n",
    "    proto_len = int(best_params.loc[ds_name, 'proto_len'])\n",
    "    reception = float(best_params.loc[ds_name, 'reception'])\n",
    "    epochs = int(best_params.loc[ds_name, 'epochs'])\n",
    "    curr_experiment_dir = experiment_setup(f\"{experiment_name}/{dataset.name}\")\n",
    "\n",
    "    log, logclose = create_logger(curr_experiment_dir / \"log.txt\", display=True)\n",
    "\n",
    "    try:\n",
    "        curr_link_path = Path.cwd() / 'experiments' / experiment_name / 'current'\n",
    "        if os.path.islink(curr_link_path):\n",
    "            os.unlink(curr_link_path)\n",
    "        os.symlink(curr_experiment_dir, curr_link_path)\n",
    "        \n",
    "        curr_log_link_path = Path.cwd() / 'experiments' / experiment_name / 'curr_log.txt'\n",
    "        if os.path.islink(curr_log_link_path):\n",
    "            os.unlink(curr_log_link_path)\n",
    "        os.symlink(curr_experiment_dir / 'log.txt', curr_log_link_path)\n",
    "        \n",
    "        features_lr = default_params[\"features_lr\"]\n",
    "\n",
    "        protos_per_class = default_params[\"protos_per_class\"]\n",
    "        proto_features = default_params[\"proto_features\"]\n",
    "        train_batch_size = 32\n",
    "        while train_batch_size > len(dataset.train.X) / 2:\n",
    "            train_batch_size //= 2\n",
    "        test_batch_size = 128\n",
    "        if ds_name == 'EigenWorms':\n",
    "            train_batch_size //= 2\n",
    "            test_batch_size = 64\n",
    "        coeffs = default_params[\"coeffs\"]\n",
    "        padding = 'same'\n",
    "\n",
    "        push_start_epoch = default_params[\"push_start_epoch\"]\n",
    "        num_warm_epochs = push_start_epoch - 60\n",
    "        num_last_layer_epochs = default_params[\"num_last_layer_epochs\"]\n",
    "        push_epochs = range(push_start_epoch, 1000, 30)\n",
    "\n",
    "        params = {\n",
    "            \"protos_per_class\": protos_per_class,\n",
    "            \"proto_features\": proto_features,\n",
    "            \"proto_len_latent\": proto_len,\n",
    "            \"features_lr\": features_lr,\n",
    "            \"num_classes\": ds_info.num_classes,\n",
    "            \"protos_per_class\": protos_per_class,\n",
    "            \"coeffs\": coeffs._asdict(),\n",
    "            \"num_warm_epochs\": num_warm_epochs,\n",
    "            \"push_start_epoch\": push_start_epoch,\n",
    "            \"num_last_layer_epochs\": num_last_layer_epochs,\n",
    "            \"epochs\": epochs,\n",
    "        }\n",
    "        with open(curr_experiment_dir / \"params.json\", \"w\") as f:\n",
    "            json.dump(params, f, indent=4)\n",
    "\n",
    "        log(\n",
    "            f\"Training for {dataset.name}, proto len {proto_len}, reception {reception}, features_lr {features_lr}, protos per class {protos_per_class}, l1_addon {coeffs.l1_addon}\",\n",
    "            flush=True,\n",
    "            display=True\n",
    "        )\n",
    "        log(f'Params: {json.dumps(params, indent=4)}')\n",
    "        \n",
    "        whole_training_start = time.time()\n",
    "\n",
    "        log(f'Training encoder', flush=True, display=True)\n",
    "        autoencoder = PermutingConvAutoencoder(num_features=ds_info.features, latent_features=proto_features, reception_percent=reception, padding=padding)\n",
    "        train_ds = TSCDataset(dataset.train.X, dataset.train.y)\n",
    "        train_loader = torch.utils.data.DataLoader(dataset.train, batch_size=train_batch_size, shuffle=True)\n",
    "        test_loader = torch.utils.data.DataLoader(dataset.test, batch_size=test_batch_size)\n",
    "        train_autoencoder(autoencoder, train_loader, test_loader, device=device, log=log)\n",
    "        encoder = autoencoder.encoder\n",
    "\n",
    "        log(f'Training ProtoTSNet', flush=True, display=True)\n",
    "        trainer = train_prototsnet(\n",
    "            dataset,\n",
    "            curr_experiment_dir,\n",
    "            device,\n",
    "            encoder,\n",
    "            features_lr,\n",
    "            coeffs,\n",
    "            protos_per_class,\n",
    "            proto_features,\n",
    "            proto_len,\n",
    "            train_batch_size,\n",
    "            test_batch_size,\n",
    "            num_epochs=epochs,\n",
    "            num_warm_epochs=num_warm_epochs,\n",
    "            push_start_epoch=push_start_epoch,\n",
    "            push_epochs=push_epochs,\n",
    "            ds_info=ds_info,\n",
    "            num_last_layer_epochs=num_last_layer_epochs,\n",
    "            custom_checkpointers=[\n",
    "                get_verbose_logger(dataset.name)\n",
    "            ],\n",
    "            log=log,\n",
    "        )\n",
    "\n",
    "        accu_test = trainer.latest_stat(\"accu_test\")\n",
    "        log(f'Last epoch test accu: {accu_test*100:.2f}%', display=True)\n",
    "        with open(curr_experiment_dir / \"test_accu.json\", \"w\") as f:\n",
    "            json.dump({\"value\": accu_test}, f, indent=4)\n",
    "\n",
    "        whole_training_end = time.time()\n",
    "        log(f\"Done in {trainer.curr_epoch - 1} epochs, {whole_training_end - whole_training_start:.2f}s\", display=True)\n",
    "    except Exception as e:\n",
    "        log(f\"Exception ocurred for {ds_name}: {e}\", display=True)\n",
    "        tb_str = traceback.format_tb(e.__traceback__)\n",
    "        log('\\n'.join(tb_str), display=True)\n",
    "    finally:\n",
    "        logclose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d04f0193",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "artifTrainDS = ArtificialProtos(1000, feature_noise_power=0.05, randomize_right_side=False)\n",
    "artifTestDS = ArtificialProtos(300, feature_noise_power=0.05, randomize_right_side=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79478451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for ArtificialDataset, proto len 20, reception 0.75, features_lr 0.001, protos per class 1, l1_addon 0.0003\n",
      "Params: {\n",
      "    \"protos_per_class\": 1,\n",
      "    \"proto_features\": 32,\n",
      "    \"proto_len_latent\": 20,\n",
      "    \"features_lr\": 0.001,\n",
      "    \"num_classes\": 4,\n",
      "    \"coeffs\": {\n",
      "        \"crs_ent\": 1,\n",
      "        \"clst\": 0,\n",
      "        \"sep\": 0,\n",
      "        \"l1\": 0.001,\n",
      "        \"l1_addon\": 0.0003\n",
      "    },\n",
      "    \"num_warm_epochs\": 50,\n",
      "    \"push_start_epoch\": 110,\n",
      "    \"num_last_layer_epochs\": 40,\n",
      "    \"epochs\": 200\n",
      "}\n",
      "Training encoder\n",
      "epoch:   10/300 mse loss: 0.0104\n",
      "epoch:   20/300 mse loss: 0.0164\n",
      "epoch:   30/300 mse loss: 0.0157\n",
      "epoch:   40/300 mse loss: 0.0163\n",
      "epoch:   50/300 mse loss: 0.0161\n",
      "epoch:   60/300 mse loss: 0.0136\n",
      "epoch:   70/300 mse loss: 0.0111\n",
      "epoch:   80/300 mse loss: 0.0150\n",
      "epoch:   90/300 mse loss: 0.0146\n",
      "epoch:  100/300 mse loss: 0.0102\n",
      "epoch:  110/300 mse loss: 0.0129\n",
      "epoch:  120/300 mse loss: 0.0138\n",
      "epoch:  130/300 mse loss: 0.0146\n",
      "epoch:  140/300 mse loss: 0.0133\n",
      "epoch:  150/300 mse loss: 0.0136\n",
      "epoch:  160/300 mse loss: 0.0137\n",
      "epoch:  170/300 mse loss: 0.0128\n",
      "epoch:  180/300 mse loss: 0.0130\n",
      "epoch:  190/300 mse loss: 0.0134\n",
      "epoch:  200/300 mse loss: 0.0123\n",
      "epoch:  210/300 mse loss: 0.0126\n",
      "epoch:  220/300 mse loss: 0.0130\n",
      "epoch:  230/300 mse loss: 0.0128\n",
      "epoch:  240/300 mse loss: 0.0131\n",
      "epoch:  250/300 mse loss: 0.0129\n",
      "epoch:  260/300 mse loss: 0.0130\n",
      "epoch:  270/300 mse loss: 0.0131\n",
      "epoch:  280/300 mse loss: 0.0130\n",
      "epoch:  290/300 mse loss: 0.0125\n",
      "epoch:  300/300 mse loss: 0.0132\n",
      "Training ProtoTSNet\n",
      "Starting training\n",
      "epoch:   1 (WARM) - ArtificialDataset\n",
      "    test acc:                 8.67%\n",
      "    train overall loss:       1.4423900321125984\n",
      "    train cross_ent loss:     1.386315457522869\n",
      "    test overall loss:        1.4304454723993938\n",
      "    test cross_ent loss:      1.3862786690394084\n",
      "    cluster loss:             149.9109344482422\n",
      "    separation loss:          149.32719930013022\n",
      "    avg separation loss:      151.87835184733072\n",
      "    l1_addon loss:            127.22249603271484\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08528709411621094\n",
      "    test time:                0.00868368148803711\n",
      "    epoch time:               0.09448695182800293\n",
      "epoch:   2 (WARM) - ArtificialDataset\n",
      "    test acc:                 28.00%\n",
      "    train overall loss:       1.4217747785151005\n",
      "    train cross_ent loss:     1.3862908221781254\n",
      "    test overall loss:        1.4136128822962444\n",
      "    test cross_ent loss:      1.3862232367197673\n",
      "    cluster loss:             156.2458292643229\n",
      "    separation loss:          155.56505330403647\n",
      "    avg separation loss:      160.5762481689453\n",
      "    l1_addon loss:            71.29851531982422\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08498287200927734\n",
      "    test time:                0.008661270141601562\n",
      "    epoch time:               0.09414029121398926\n",
      "epoch:   3 (WARM) - ArtificialDataset\n",
      "    test acc:                 44.00%\n",
      "    train overall loss:       1.4080317616462708\n",
      "    train cross_ent loss:     1.3862257115542889\n",
      "    test overall loss:        1.4030085404713948\n",
      "    test cross_ent loss:      1.3861759503682454\n",
      "    cluster loss:             160.19017537434897\n",
      "    separation loss:          162.00939432779947\n",
      "    avg separation loss:      166.33259073893228\n",
      "    l1_addon loss:            36.108360290527344\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08742117881774902\n",
      "    test time:                0.00867462158203125\n",
      "    epoch time:               0.09661984443664551\n",
      "epoch:   4 (WARM) - ArtificialDataset\n",
      "    test acc:                 43.67%\n",
      "    train overall loss:       1.39985840767622\n",
      "    train cross_ent loss:     1.386156614869833\n",
      "    test overall loss:        1.397169868151347\n",
      "    test cross_ent loss:      1.3861316839853923\n",
      "    cluster loss:             164.96093241373697\n",
      "    separation loss:          168.2105458577474\n",
      "    avg separation loss:      172.62127685546875\n",
      "    l1_addon loss:            16.79387855529785\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08576202392578125\n",
      "    test time:                0.008559942245483398\n",
      "    epoch time:               0.09480452537536621\n",
      "epoch:   5 (WARM) - ArtificialDataset\n",
      "    test acc:                 25.00%\n",
      "    train overall loss:       1.3956881053745747\n",
      "    train cross_ent loss:     1.3861481808125973\n",
      "    test overall loss:        1.3945072889328003\n",
      "    test cross_ent loss:      1.38614821434021\n",
      "    cluster loss:             175.34431966145834\n",
      "    separation loss:          178.62154134114584\n",
      "    avg separation loss:      181.8407440185547\n",
      "    l1_addon loss:            7.863582611083984\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.0840761661529541\n",
      "    test time:                0.008563995361328125\n",
      "    epoch time:               0.0931081771850586\n",
      "epoch:   6 (WARM) - ArtificialDataset\n",
      "    test acc:                 53.00%\n",
      "    train overall loss:       1.3939265087246895\n",
      "    train cross_ent loss:     1.386158388108015\n",
      "    test overall loss:        1.3933887084325154\n",
      "    test cross_ent loss:      1.3861653407414753\n",
      "    cluster loss:             178.87256368001303\n",
      "    separation loss:          181.1540273030599\n",
      "    avg separation loss:      184.1459757486979\n",
      "    l1_addon loss:            4.077746391296387\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08527231216430664\n",
      "    test time:                0.008565664291381836\n",
      "    epoch time:               0.09430360794067383\n",
      "epoch:   7 (WARM) - ArtificialDataset\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       1.3930991142988205\n",
      "    train cross_ent loss:     1.3861985318362713\n",
      "    test overall loss:        1.3928511142730713\n",
      "    test cross_ent loss:      1.3862076997756958\n",
      "    cluster loss:             183.56935119628906\n",
      "    separation loss:          184.44439697265625\n",
      "    avg separation loss:      186.68905131022134\n",
      "    l1_addon loss:            2.14467453956604\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08420515060424805\n",
      "    test time:                0.00853729248046875\n",
      "    epoch time:               0.09322452545166016\n",
      "epoch:   8 (WARM) - ArtificialDataset\n",
      "    test acc:                 29.67%\n",
      "    train overall loss:       1.3927451632916927\n",
      "    train cross_ent loss:     1.3862480111420155\n",
      "    test overall loss:        1.392602562904358\n",
      "    test cross_ent loss:      1.3862448930740356\n",
      "    cluster loss:             187.30931599934897\n",
      "    separation loss:          187.26710510253906\n",
      "    avg separation loss:      188.99994913736978\n",
      "    l1_addon loss:            1.1919554471969604\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08601951599121094\n",
      "    test time:                0.009032964706420898\n",
      "    epoch time:               0.09558415412902832\n",
      "epoch:   9 (WARM) - ArtificialDataset\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       1.3925433196127415\n",
      "    train cross_ent loss:     1.3862778916954994\n",
      "    test overall loss:        1.3924411137898762\n",
      "    test cross_ent loss:      1.3862543900807698\n",
      "    cluster loss:             190.50365702311197\n",
      "    separation loss:          190.30919901529947\n",
      "    avg separation loss:      191.37569681803384\n",
      "    l1_addon loss:            0.6221929788589478\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08807945251464844\n",
      "    test time:                0.008749723434448242\n",
      "    epoch time:               0.09735918045043945\n",
      "epoch:  10 (WARM) - ArtificialDataset\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       1.3924481719732285\n",
      "    train cross_ent loss:     1.3862965665757656\n",
      "    test overall loss:        1.392350713411967\n",
      "    test cross_ent loss:      1.3862290779749553\n",
      "    cluster loss:             192.95708211263022\n",
      "    separation loss:          192.8503621419271\n",
      "    avg separation loss:      193.1581013997396\n",
      "    l1_addon loss:            0.4053391218185425\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08777046203613281\n",
      "    test time:                0.00874781608581543\n",
      "    epoch time:               0.09704017639160156\n",
      "epoch:  11 (WARM) - ArtificialDataset\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       1.3924184255301952\n",
      "    train cross_ent loss:     1.3862972445786\n",
      "    test overall loss:        1.392355998357137\n",
      "    test cross_ent loss:      1.3862346013387044\n",
      "    cluster loss:             193.34709676106772\n",
      "    separation loss:          193.2755330403646\n",
      "    avg separation loss:      193.46541849772134\n",
      "    l1_addon loss:            0.40459713339805603\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08530688285827637\n",
      "    test time:                0.00871133804321289\n",
      "    epoch time:               0.09452486038208008\n",
      "epoch:  12 (WARM) - ArtificialDataset\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       1.3924169316887856\n",
      "    train cross_ent loss:     1.3862976357340813\n",
      "    test overall loss:        1.3923682769139607\n",
      "    test cross_ent loss:      1.3862472375233967\n",
      "    cluster loss:             193.36424255371094\n",
      "    separation loss:          193.28612772623697\n",
      "    avg separation loss:      193.48355102539062\n",
      "    l1_addon loss:            0.4034864008426666\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08690762519836426\n",
      "    test time:                0.008631467819213867\n",
      "    epoch time:               0.09601473808288574\n",
      "epoch:  13 (WARM) - ArtificialDataset\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       1.3924117758870125\n",
      "    train cross_ent loss:     1.3862930126488209\n",
      "    test overall loss:        1.3923495213190715\n",
      "    test cross_ent loss:      1.3862300316492717\n",
      "    cluster loss:             193.35418701171875\n",
      "    separation loss:          193.23619588216147\n",
      "    avg separation loss:      193.58284505208334\n",
      "    l1_addon loss:            0.398043155670166\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08729410171508789\n",
      "    test time:                0.00874018669128418\n",
      "    epoch time:               0.09657001495361328\n",
      "epoch:  14 (WARM) - ArtificialDataset\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       1.3924249485135078\n",
      "    train cross_ent loss:     1.386304847896099\n",
      "    test overall loss:        1.3923221826553345\n",
      "    test cross_ent loss:      1.3862032890319824\n",
      "    cluster loss:             193.84056091308594\n",
      "    separation loss:          193.74417114257812\n",
      "    avg separation loss:      193.9357147216797\n",
      "    l1_addon loss:            0.3961896300315857\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.0913090705871582\n",
      "    test time:                0.008752822875976562\n",
      "    epoch time:               0.10058903694152832\n",
      "epoch:  15 (WARM) - ArtificialDataset\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       1.3924106284976006\n",
      "    train cross_ent loss:     1.3862910978496075\n",
      "    test overall loss:        1.3923437198003132\n",
      "    test cross_ent loss:      1.38621719678243\n",
      "    cluster loss:             193.77784220377603\n",
      "    separation loss:          193.6806640625\n",
      "    avg separation loss:      193.8728790283203\n",
      "    l1_addon loss:            0.4217161536216736\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.0888829231262207\n",
      "    test time:                0.00876617431640625\n",
      "    epoch time:               0.09817242622375488\n",
      "epoch:  16 (WARM) - ArtificialDataset\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       1.392411444336176\n",
      "    train cross_ent loss:     1.3862903825938702\n",
      "    test overall loss:        1.3923231363296509\n",
      "    test cross_ent loss:      1.3862059116363525\n",
      "    cluster loss:             194.20808919270834\n",
      "    separation loss:          194.13255310058594\n",
      "    avg separation loss:      194.33806355794272\n",
      "    l1_addon loss:            0.39069342613220215\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08820366859436035\n",
      "    test time:                0.00873255729675293\n",
      "    epoch time:               0.09745669364929199\n",
      "epoch:  17 (WARM) - ArtificialDataset\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       1.3923982493579388\n",
      "    train cross_ent loss:     1.3862815015017986\n",
      "    test overall loss:        1.392328143119812\n",
      "    test cross_ent loss:      1.3862043619155884\n",
      "    cluster loss:             193.75112915039062\n",
      "    separation loss:          193.5405069986979\n",
      "    avg separation loss:      193.96642049153647\n",
      "    l1_addon loss:            0.4125516414642334\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08807587623596191\n",
      "    test time:                0.008729934692382812\n",
      "    epoch time:               0.09732794761657715\n",
      "epoch:  18 (WARM) - ArtificialDataset\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       1.3924086801707745\n",
      "    train cross_ent loss:     1.3862893357872963\n",
      "    test overall loss:        1.3923004070917766\n",
      "    test cross_ent loss:      1.3861865202585857\n",
      "    cluster loss:             194.63065592447916\n",
      "    separation loss:          194.57138061523438\n",
      "    avg separation loss:      194.71785990397134\n",
      "    l1_addon loss:            0.37958377599716187\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.0864109992980957\n",
      "    test time:                0.008691787719726562\n",
      "    epoch time:               0.09562063217163086\n",
      "epoch:  19 (WARM) - ArtificialDataset\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       1.3924261704087257\n",
      "    train cross_ent loss:     1.3863076977431774\n",
      "    test overall loss:        1.3923083543777466\n",
      "    test cross_ent loss:      1.3861883878707886\n",
      "    cluster loss:             194.56847127278647\n",
      "    separation loss:          194.51063028971353\n",
      "    avg separation loss:      194.7046661376953\n",
      "    l1_addon loss:            0.39966002106666565\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08511590957641602\n",
      "    test time:                0.008737564086914062\n",
      "    epoch time:               0.0943601131439209\n",
      "epoch:  20 (WARM) - ArtificialDataset\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       1.3923946879804134\n",
      "    train cross_ent loss:     1.3862747475504875\n",
      "    test overall loss:        1.3923044602076213\n",
      "    test cross_ent loss:      1.386183778444926\n",
      "    cluster loss:             194.4197998046875\n",
      "    separation loss:          194.2866668701172\n",
      "    avg separation loss:      194.58856201171875\n",
      "    l1_addon loss:            0.40219926834106445\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08553600311279297\n",
      "    test time:                0.008533954620361328\n",
      "    epoch time:               0.0945589542388916\n",
      "epoch:  21 (WARM) - ArtificialDataset\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       1.3924211040139198\n",
      "    train cross_ent loss:     1.386302012950182\n",
      "    test overall loss:        1.3922696510950725\n",
      "    test cross_ent loss:      1.3861481348673503\n",
      "    cluster loss:             195.35284932454428\n",
      "    separation loss:          195.29242960611978\n",
      "    avg separation loss:      195.43521118164062\n",
      "    l1_addon loss:            0.40500444173812866\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08391952514648438\n",
      "    test time:                0.008657693862915039\n",
      "    epoch time:               0.09308838844299316\n",
      "epoch:  22 (WARM) - ArtificialDataset\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       1.3924120403826237\n",
      "    train cross_ent loss:     1.3862934447824955\n",
      "    test overall loss:        1.3922871748606365\n",
      "    test cross_ent loss:      1.3861688772837322\n",
      "    cluster loss:             195.24905395507812\n",
      "    separation loss:          195.1365203857422\n",
      "    avg separation loss:      195.36962381998697\n",
      "    l1_addon loss:            0.3942101299762726\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08389902114868164\n",
      "    test time:                0.008561134338378906\n",
      "    epoch time:               0.0929253101348877\n",
      "epoch:  23 (WARM) - ArtificialDataset\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       1.3923865891993046\n",
      "    train cross_ent loss:     1.3862680867314339\n",
      "    test overall loss:        1.3922773996988933\n",
      "    test cross_ent loss:      1.3861525456110637\n",
      "    cluster loss:             194.7601521809896\n",
      "    separation loss:          194.60336303710938\n",
      "    avg separation loss:      195.04765828450522\n",
      "    l1_addon loss:            0.41597291827201843\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.0881509780883789\n",
      "    test time:                0.008736371994018555\n",
      "    epoch time:               0.09740877151489258\n",
      "epoch:  24 (WARM) - ArtificialDataset\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       1.3924012668430805\n",
      "    train cross_ent loss:     1.3862791284918785\n",
      "    test overall loss:        1.3922384977340698\n",
      "    test cross_ent loss:      1.3861160278320312\n",
      "    cluster loss:             194.9132283528646\n",
      "    separation loss:          194.63646443684897\n",
      "    avg separation loss:      195.0807088216146\n",
      "    l1_addon loss:            0.4079008102416992\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.0883638858795166\n",
      "    test time:                0.008733034133911133\n",
      "    epoch time:               0.09762120246887207\n",
      "epoch:  25 (WARM) - ArtificialDataset\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       1.392408810555935\n",
      "    train cross_ent loss:     1.3862842656672\n",
      "    test overall loss:        1.39223047097524\n",
      "    test cross_ent loss:      1.3861119349797566\n",
      "    cluster loss:             195.6023915608724\n",
      "    separation loss:          195.50459798177084\n",
      "    avg separation loss:      195.70462036132812\n",
      "    l1_addon loss:            0.3951486349105835\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08707308769226074\n",
      "    test time:                0.008630990982055664\n",
      "    epoch time:               0.09622883796691895\n",
      "epoch:  26 (WARM) - ArtificialDataset\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       1.3923887573182583\n",
      "    train cross_ent loss:     1.3862652704119682\n",
      "    test overall loss:        1.3922230799992878\n",
      "    test cross_ent loss:      1.3860933383305867\n",
      "    cluster loss:             195.52213541666666\n",
      "    separation loss:          195.37654622395834\n",
      "    avg separation loss:      195.6518809000651\n",
      "    l1_addon loss:            0.43248939514160156\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08759450912475586\n",
      "    test time:                0.008723258972167969\n",
      "    epoch time:               0.09684205055236816\n",
      "epoch:  27 (WARM) - ArtificialDataset\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       1.392416074872017\n",
      "    train cross_ent loss:     1.3862925693392754\n",
      "    test overall loss:        1.3921963373819988\n",
      "    test cross_ent loss:      1.3860748211542766\n",
      "    cluster loss:             195.95301818847656\n",
      "    separation loss:          195.84270222981772\n",
      "    avg separation loss:      196.06482442220053\n",
      "    l1_addon loss:            0.40472912788391113\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08710122108459473\n",
      "    test time:                0.008719444274902344\n",
      "    epoch time:               0.09632253646850586\n",
      "epoch:  28 (WARM) - ArtificialDataset\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       1.3924087174236774\n",
      "    train cross_ent loss:     1.3862872645258904\n",
      "    test overall loss:        1.3922208944956462\n",
      "    test cross_ent loss:      1.3860985438028972\n",
      "    cluster loss:             195.70437622070312\n",
      "    separation loss:          195.54166666666666\n",
      "    avg separation loss:      195.81243896484375\n",
      "    l1_addon loss:            0.4076867699623108\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08670639991760254\n",
      "    test time:                0.008615970611572266\n",
      "    epoch time:               0.09582090377807617\n",
      "epoch:  29 (WARM) - ArtificialDataset\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       1.392413329333067\n",
      "    train cross_ent loss:     1.3862933330237865\n",
      "    test overall loss:        1.392188549041748\n",
      "    test cross_ent loss:      1.3860671520233154\n",
      "    cluster loss:             195.9971720377604\n",
      "    separation loss:          195.86577860514322\n",
      "    avg separation loss:      196.09671020507812\n",
      "    l1_addon loss:            0.40470901131629944\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08474397659301758\n",
      "    test time:                0.008626461029052734\n",
      "    epoch time:               0.09383916854858398\n",
      "epoch:  30 (WARM) - ArtificialDataset\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       1.3923771381378174\n",
      "    train cross_ent loss:     1.3862514309585094\n",
      "    test overall loss:        1.3921846548716228\n",
      "    test cross_ent loss:      1.386052171389262\n",
      "    cluster loss:             195.32483418782553\n",
      "    separation loss:          195.0943400065104\n",
      "    avg separation loss:      195.49676513671875\n",
      "    l1_addon loss:            0.4416384994983673\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08437156677246094\n",
      "    test time:                0.008649110794067383\n",
      "    epoch time:               0.09354376792907715\n",
      "epoch:  31 (WARM) - ArtificialDataset\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       1.392424538731575\n",
      "    train cross_ent loss:     1.3862939774990082\n",
      "    test overall loss:        1.3921619653701782\n",
      "    test cross_ent loss:      1.3860281705856323\n",
      "    cluster loss:             194.84001668294272\n",
      "    separation loss:          194.4756113688151\n",
      "    avg separation loss:      195.26507568359375\n",
      "    l1_addon loss:            0.44565969705581665\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.0851132869720459\n",
      "    test time:                0.008598804473876953\n",
      "    epoch time:               0.09418439865112305\n",
      "epoch:  32 (WARM) - ArtificialDataset\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       1.3924179337918758\n",
      "    train cross_ent loss:     1.386292539536953\n",
      "    test overall loss:        1.3921481370925903\n",
      "    test cross_ent loss:      1.3860301971435547\n",
      "    cluster loss:             196.73089090983072\n",
      "    separation loss:          196.61272684733072\n",
      "    avg separation loss:      196.79364522298178\n",
      "    l1_addon loss:            0.3928617537021637\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08411788940429688\n",
      "    test time:                0.008604288101196289\n",
      "    epoch time:               0.09319067001342773\n",
      "epoch:  33 (WARM) - ArtificialDataset\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       1.3924039043486118\n",
      "    train cross_ent loss:     1.3862792365252972\n",
      "    test overall loss:        1.3921597798665364\n",
      "    test cross_ent loss:      1.3860315879185994\n",
      "    cluster loss:             196.50375366210938\n",
      "    separation loss:          196.35334269205728\n",
      "    avg separation loss:      196.64481099446616\n",
      "    l1_addon loss:            0.427099347114563\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08434605598449707\n",
      "    test time:                0.008621931076049805\n",
      "    epoch time:               0.09346985816955566\n",
      "epoch:  34 (WARM) - ArtificialDataset\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       1.392421618103981\n",
      "    train cross_ent loss:     1.3862978033721447\n",
      "    test overall loss:        1.3921369314193726\n",
      "    test cross_ent loss:      1.3860148191452026\n",
      "    cluster loss:             196.81868489583334\n",
      "    separation loss:          196.70490010579428\n",
      "    avg separation loss:      196.90031941731772\n",
      "    l1_addon loss:            0.4068530201911926\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08541727066040039\n",
      "    test time:                0.008583784103393555\n",
      "    epoch time:               0.09448051452636719\n",
      "epoch:  35 (WARM) - ArtificialDataset\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       1.3923842534422874\n",
      "    train cross_ent loss:     1.3862606696784496\n",
      "    test overall loss:        1.3921382427215576\n",
      "    test cross_ent loss:      1.3860161304473877\n",
      "    cluster loss:             196.0490976969401\n",
      "    separation loss:          195.78536987304688\n",
      "    avg separation loss:      196.35408528645834\n",
      "    l1_addon loss:            0.40676677227020264\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08593297004699707\n",
      "    test time:                0.008692502975463867\n",
      "    epoch time:               0.09513664245605469\n",
      "epoch:  36 (WARM) - ArtificialDataset\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       1.3924223817884922\n",
      "    train cross_ent loss:     1.386299442499876\n",
      "    test overall loss:        1.3921151558558147\n",
      "    test cross_ent loss:      1.3859994808832805\n",
      "    cluster loss:             197.1539510091146\n",
      "    separation loss:          197.03386942545572\n",
      "    avg separation loss:      197.2716267903646\n",
      "    l1_addon loss:            0.3853183686733246\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.0842292308807373\n",
      "    test time:                0.008667469024658203\n",
      "    epoch time:               0.09339761734008789\n",
      "epoch:  37 (WARM) - ArtificialDataset\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       1.3923408053815365\n",
      "    train cross_ent loss:     1.3862139694392681\n",
      "    test overall loss:        1.3921230634053547\n",
      "    test cross_ent loss:      1.3859852155049641\n",
      "    cluster loss:             195.7791544596354\n",
      "    separation loss:          195.3399403889974\n",
      "    avg separation loss:      196.01350911458334\n",
      "    l1_addon loss:            0.45918798446655273\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08624053001403809\n",
      "    test time:                0.008677005767822266\n",
      "    epoch time:               0.09542655944824219\n",
      "epoch:  38 (WARM) - ArtificialDataset\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       1.3923813849687576\n",
      "    train cross_ent loss:     1.386242263019085\n",
      "    test overall loss:        1.3920669158299763\n",
      "    test cross_ent loss:      1.3859212001164753\n",
      "    cluster loss:             195.3570760091146\n",
      "    separation loss:          194.87466939290366\n",
      "    avg separation loss:      195.74512736002603\n",
      "    l1_addon loss:            0.4857698678970337\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08414292335510254\n",
      "    test time:                0.008533954620361328\n",
      "    epoch time:               0.0931699275970459\n",
      "epoch:  39 (WARM) - ArtificialDataset\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       1.392381813377142\n",
      "    train cross_ent loss:     1.3862339705228806\n",
      "    test overall loss:        1.3920268217722576\n",
      "    test cross_ent loss:      1.3858749071757\n",
      "    cluster loss:             194.8051300048828\n",
      "    separation loss:          194.14251708984375\n",
      "    avg separation loss:      195.22052510579428\n",
      "    l1_addon loss:            0.506189227104187\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08431386947631836\n",
      "    test time:                0.008496761322021484\n",
      "    epoch time:               0.09328746795654297\n",
      "epoch:  40 (WARM) - ArtificialDataset\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       1.3923784382641315\n",
      "    train cross_ent loss:     1.386227149516344\n",
      "    test overall loss:        1.3920090595881145\n",
      "    test cross_ent loss:      1.3858400980631511\n",
      "    cluster loss:             193.2545420328776\n",
      "    separation loss:          192.55471801757812\n",
      "    avg separation loss:      193.91617838541666\n",
      "    l1_addon loss:            0.5630332827568054\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08561205863952637\n",
      "    test time:                0.008556604385375977\n",
      "    epoch time:               0.09464716911315918\n",
      "epoch:  41 (WARM) - ArtificialDataset\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       1.3923417963087559\n",
      "    train cross_ent loss:     1.3861794359982014\n",
      "    test overall loss:        1.3919515212376912\n",
      "    test cross_ent loss:      1.3857355912526448\n",
      "    cluster loss:             189.41908264160156\n",
      "    separation loss:          187.93169657389322\n",
      "    avg separation loss:      190.4655965169271\n",
      "    l1_addon loss:            0.7195385694503784\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08395123481750488\n",
      "    test time:                0.008745431900024414\n",
      "    epoch time:               0.09320807456970215\n",
      "epoch:  42 (WARM) - ArtificialDataset\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       1.3924158737063408\n",
      "    train cross_ent loss:     1.3861257396638393\n",
      "    test overall loss:        1.3915006717046101\n",
      "    test cross_ent loss:      1.3850311835606892\n",
      "    cluster loss:             174.16910807291666\n",
      "    separation loss:          169.95579528808594\n",
      "    avg separation loss:      177.73128763834634\n",
      "    l1_addon loss:            1.564773678779602\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08634734153747559\n",
      "    test time:                0.008695363998413086\n",
      "    epoch time:               0.09553194046020508\n",
      "epoch:  43 (WARM) - ArtificialDataset\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       1.3805945813655853\n",
      "    train cross_ent loss:     1.3725546225905418\n",
      "    test overall loss:        1.3594833612442017\n",
      "    test cross_ent loss:      1.34706711769104\n",
      "    cluster loss:             124.12101491292317\n",
      "    separation loss:          114.55803934733073\n",
      "    avg separation loss:      131.8483683268229\n",
      "    l1_addon loss:            21.387235641479492\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.0867459774017334\n",
      "    test time:                0.008523941040039062\n",
      "    epoch time:               0.09574604034423828\n",
      "epoch:  44 (WARM) - ArtificialDataset\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       1.3246515691280365\n",
      "    train cross_ent loss:     1.3122166097164154\n",
      "    test overall loss:        1.3294766743977864\n",
      "    test cross_ent loss:      1.3173890908559163\n",
      "    cluster loss:             95.95247904459636\n",
      "    separation loss:          100.20943705240886\n",
      "    avg separation loss:      113.4329350789388\n",
      "    l1_addon loss:            20.291667938232422\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08748221397399902\n",
      "    test time:                0.008739948272705078\n",
      "    epoch time:               0.0967416763305664\n",
      "epoch:  45 (WARM) - ArtificialDataset\n",
      "    test acc:                 26.67%\n",
      "    train overall loss:       1.3064028955996037\n",
      "    train cross_ent loss:     1.2947255820035934\n",
      "    test overall loss:        1.317855993906657\n",
      "    test cross_ent loss:      1.3065112034479778\n",
      "    cluster loss:             68.08830261230469\n",
      "    separation loss:          79.11898040771484\n",
      "    avg separation loss:      88.15779622395833\n",
      "    l1_addon loss:            17.815969467163086\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08786749839782715\n",
      "    test time:                0.008737325668334961\n",
      "    epoch time:               0.09712457656860352\n",
      "epoch:  46 (WARM) - ArtificialDataset\n",
      "    test acc:                 75.00%\n",
      "    train overall loss:       1.2105800546705723\n",
      "    train cross_ent loss:     1.1992760002613068\n",
      "    test overall loss:        0.9788565834363302\n",
      "    test cross_ent loss:      0.967842161655426\n",
      "    cluster loss:             37.418924967447914\n",
      "    separation loss:          49.96197509765625\n",
      "    avg separation loss:      54.376824696858726\n",
      "    l1_addon loss:            16.714759826660156\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08865833282470703\n",
      "    test time:                0.00875401496887207\n",
      "    epoch time:               0.09793376922607422\n",
      "epoch:  47 (WARM) - ArtificialDataset\n",
      "    test acc:                 75.00%\n",
      "    train overall loss:       0.9047891851514578\n",
      "    train cross_ent loss:     0.8938871324062347\n",
      "    test overall loss:        0.7496697306632996\n",
      "    test cross_ent loss:      0.7390018105506897\n",
      "    cluster loss:             19.778055826822918\n",
      "    separation loss:          33.52733866373698\n",
      "    avg separation loss:      37.31267293294271\n",
      "    l1_addon loss:            15.559864044189453\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08847641944885254\n",
      "    test time:                0.008936405181884766\n",
      "    epoch time:               0.0979471206665039\n",
      "epoch:  48 (WARM) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.7329001016914845\n",
      "    train cross_ent loss:     0.7224477427080274\n",
      "    test overall loss:        0.7260592778523763\n",
      "    test cross_ent loss:      0.7158069213231405\n",
      "    cluster loss:             0.9268544514973959\n",
      "    separation loss:          12.904815673828125\n",
      "    avg separation loss:      16.622289657592773\n",
      "    l1_addon loss:            14.17452335357666\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.0863187313079834\n",
      "    test time:                0.008503437042236328\n",
      "    epoch time:               0.09529829025268555\n",
      "epoch:  49 (WARM) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.44508949806913733\n",
      "    train cross_ent loss:     0.43500587716698647\n",
      "    test overall loss:        0.3605336546897888\n",
      "    test cross_ent loss:      0.35053393244743347\n",
      "    cluster loss:             0.18662007649739584\n",
      "    separation loss:          9.588246663411459\n",
      "    avg separation loss:      12.606648445129395\n",
      "    l1_addon loss:            13.332368850708008\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08455228805541992\n",
      "    test time:                0.008502006530761719\n",
      "    epoch time:               0.09355044364929199\n",
      "epoch:  50 (WARM) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.5431896355003119\n",
      "    train cross_ent loss:     0.5332973133772612\n",
      "    test overall loss:        0.6193989316622416\n",
      "    test cross_ent loss:      0.6093858877817789\n",
      "    cluster loss:             0.3998921712239583\n",
      "    separation loss:          8.985076904296875\n",
      "    avg separation loss:      11.950299898783365\n",
      "    l1_addon loss:            13.376775741577148\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.08549690246582031\n",
      "    test time:                0.008639812469482422\n",
      "    epoch time:               0.09464502334594727\n",
      "epoch:  51 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.3113077702000737\n",
      "    train cross_ent loss:     0.30140094412490726\n",
      "    test overall loss:        0.1770752469698588\n",
      "    test cross_ent loss:      0.16722249488035837\n",
      "    cluster loss:             0.09284464518229167\n",
      "    separation loss:          9.255025227864584\n",
      "    avg separation loss:      12.185131390889486\n",
      "    l1_addon loss:            12.842519760131836\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.1419975757598877\n",
      "    test time:                0.008698701858520508\n",
      "    epoch time:               0.151228666305542\n",
      "    joint lr:                 0.0030601000000000087\n",
      "epoch:  52 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.5983444354496896\n",
      "    train cross_ent loss:     0.5884115439839661\n",
      "    test overall loss:        0.9286547303199768\n",
      "    test cross_ent loss:      0.91863614320755\n",
      "    cluster loss:             1.2498982747395833\n",
      "    separation loss:          9.647003173828125\n",
      "    avg separation loss:      12.571130434672037\n",
      "    l1_addon loss:            13.3953857421875\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.12914085388183594\n",
      "    test time:                0.00851750373840332\n",
      "    epoch time:               0.138139009475708\n",
      "    joint lr:                 0.005960997999999999\n",
      "epoch:  53 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.23340363474562764\n",
      "    train cross_ent loss:     0.22345293033868074\n",
      "    test overall loss:        0.80262158314387\n",
      "    test cross_ent loss:      0.7927232185999552\n",
      "    cluster loss:             0.8895416259765625\n",
      "    separation loss:          7.9715321858723955\n",
      "    avg separation loss:      10.653741200764975\n",
      "    l1_addon loss:            12.994522094726562\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.1293952465057373\n",
      "    test time:                0.008623123168945312\n",
      "    epoch time:               0.13854360580444336\n",
      "    joint lr:                 0.008803582030000007\n",
      "epoch:  54 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.11414452153258026\n",
      "    train cross_ent loss:     0.10448802961036563\n",
      "    test overall loss:        0.14983929693698883\n",
      "    test cross_ent loss:      0.14041925966739655\n",
      "    cluster loss:             0.09491984049479167\n",
      "    separation loss:          7.3105621337890625\n",
      "    avg separation loss:      9.703712145487467\n",
      "    l1_addon loss:            11.400115966796875\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.12997198104858398\n",
      "    test time:                0.008667230606079102\n",
      "    epoch time:               0.13915634155273438\n",
      "    joint lr:                 0.011588728279599995\n",
      "epoch:  55 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.1509218713035807\n",
      "    train cross_ent loss:     0.14156179159181193\n",
      "    test overall loss:        0.12531587481498718\n",
      "    test cross_ent loss:      0.1160943607489268\n",
      "    cluster loss:             0.07640584309895833\n",
      "    separation loss:          6.129252115885417\n",
      "    avg separation loss:      8.547794977823893\n",
      "    l1_addon loss:            10.738386154174805\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.13114285469055176\n",
      "    test time:                0.008650064468383789\n",
      "    epoch time:               0.14027118682861328\n",
      "    joint lr:                 0.014317301246005004\n",
      "epoch:  56 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0900007535237819\n",
      "    train cross_ent loss:     0.08081141737056896\n",
      "    test overall loss:        0.05697981764872869\n",
      "    test cross_ent loss:      0.047877506663401924\n",
      "    cluster loss:             0.036997477213541664\n",
      "    separation loss:          5.3235524495442705\n",
      "    avg separation loss:      7.334012667338054\n",
      "    l1_addon loss:            10.341028213500977\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.12875628471374512\n",
      "    test time:                0.008534669876098633\n",
      "    epoch time:               0.137803316116333\n",
      "    joint lr:                 0.016990153880253933\n",
      "epoch:  57 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.028857305296696723\n",
      "    train cross_ent loss:     0.019796951673924923\n",
      "    test overall loss:        0.05423199385404587\n",
      "    test cross_ent loss:      0.045186154544353485\n",
      "    cluster loss:             0.03192138671875\n",
      "    separation loss:          4.7024993896484375\n",
      "    avg separation loss:      6.814607620239258\n",
      "    l1_addon loss:            10.152790069580078\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.12980151176452637\n",
      "    test time:                0.008632659912109375\n",
      "    epoch time:               0.1389143466949463\n",
      "    joint lr:                 0.019608127731693303\n",
      "epoch:  58 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.028066991362720728\n",
      "    train cross_ent loss:     0.01910595883964561\n",
      "    test overall loss:        0.03078959820171197\n",
      "    test cross_ent loss:      0.02189161318043868\n",
      "    cluster loss:             0.020375569661458332\n",
      "    separation loss:          4.4378814697265625\n",
      "    avg separation loss:      6.3388716379801435\n",
      "    l1_addon loss:            9.65994644165039\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.12760400772094727\n",
      "    test time:                0.008660316467285156\n",
      "    epoch time:               0.13680720329284668\n",
      "    joint lr:                 0.02217205309071584\n",
      "epoch:  59 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.03259036084637046\n",
      "    train cross_ent loss:     0.023686288361204788\n",
      "    test overall loss:        0.0861227015654246\n",
      "    test cross_ent loss:      0.07727951804796855\n",
      "    cluster loss:             0.059290568033854164\n",
      "    separation loss:          4.168894449869792\n",
      "    avg separation loss:      5.9412735303243\n",
      "    l1_addon loss:            9.477289199829102\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.12956976890563965\n",
      "    test time:                0.0086517333984375\n",
      "    epoch time:               0.13878393173217773\n",
      "    joint lr:                 0.024682749129784777\n",
      "epoch:  60 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.08638065913692117\n",
      "    train cross_ent loss:     0.07740468086558394\n",
      "    test overall loss:        0.21780596673488617\n",
      "    test cross_ent loss:      0.20857028663158417\n",
      "    cluster loss:             0.14771016438802084\n",
      "    separation loss:          3.8171183268229165\n",
      "    avg separation loss:      5.410532156626384\n",
      "    l1_addon loss:            10.785595893859863\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.12816524505615234\n",
      "    test time:                0.008824825286865234\n",
      "    epoch time:               0.13754940032958984\n",
      "    joint lr:                 0.027141024042763244\n",
      "epoch:  61 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.03968468407401815\n",
      "    train cross_ent loss:     0.030528677816619165\n",
      "    test overall loss:        0.022163198019067448\n",
      "    test cross_ent loss:      0.01308978721499443\n",
      "    cluster loss:             0.015619913736979166\n",
      "    separation loss:          3.652928670247396\n",
      "    avg separation loss:      5.023589928944905\n",
      "    l1_addon loss:            10.244701385498047\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.13099217414855957\n",
      "    test time:                0.00873708724975586\n",
      "    epoch time:               0.1403036117553711\n",
      "    joint lr:                 0.025532083112218835\n",
      "epoch:  62 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.03562383144162595\n",
      "    train cross_ent loss:     0.02663859789754497\n",
      "    test overall loss:        0.01663895013431708\n",
      "    test cross_ent loss:      0.007715157854060332\n",
      "    cluster loss:             0.011617024739583334\n",
      "    separation loss:          3.4249064127604165\n",
      "    avg separation loss:      4.724477132161458\n",
      "    l1_addon loss:            9.745975494384766\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.13036155700683594\n",
      "    test time:                0.00867915153503418\n",
      "    epoch time:               0.13961148262023926\n",
      "    joint lr:                 0.023952616897881036\n",
      "epoch:  63 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.013992440392030403\n",
      "    train cross_ent loss:     0.005106804754177574\n",
      "    test overall loss:        0.01056630133340756\n",
      "    test cross_ent loss:      0.001738249712313215\n",
      "    cluster loss:             0.0028330485026041665\n",
      "    separation loss:          3.3243306477864585\n",
      "    avg separation loss:      4.513608296712239\n",
      "    l1_addon loss:            9.426837921142578\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.12910771369934082\n",
      "    test time:                0.008569002151489258\n",
      "    epoch time:               0.13819336891174316\n",
      "    joint lr:                 0.022402196799518763\n",
      "epoch:  64 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.011049623775761575\n",
      "    train cross_ent loss:     0.002278043390106177\n",
      "    test overall loss:        0.010134867392480373\n",
      "    test cross_ent loss:      0.0014163953795408208\n",
      "    cluster loss:             0.0022379557291666665\n",
      "    separation loss:          3.268040974934896\n",
      "    avg separation loss:      4.374874909718831\n",
      "    l1_addon loss:            9.061573028564453\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.12801313400268555\n",
      "    test time:                0.00863790512084961\n",
      "    epoch time:               0.13715028762817383\n",
      "    joint lr:                 0.02088039984143395\n",
      "epoch:  65 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.010881123889703304\n",
      "    train cross_ent loss:     0.0022012441004335415\n",
      "    test overall loss:        0.00997858370343844\n",
      "    test cross_ent loss:      0.0013327743702878554\n",
      "    cluster loss:             0.0024159749348958335\n",
      "    separation loss:          3.1787872314453125\n",
      "    avg separation loss:      4.276711622873942\n",
      "    l1_addon loss:            8.819364547729492\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.1284492015838623\n",
      "    test time:                0.008733510971069336\n",
      "    epoch time:               0.13772821426391602\n",
      "    joint lr:                 0.01938680860283089\n",
      "epoch:  66 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.011935453163459897\n",
      "    train cross_ent loss:     0.0033248358995479066\n",
      "    test overall loss:        0.009866325495143732\n",
      "    test cross_ent loss:      0.0012932024352873366\n",
      "    cluster loss:             0.0023600260416666665\n",
      "    separation loss:          3.113683064778646\n",
      "    avg separation loss:      4.211713473002116\n",
      "    l1_addon loss:            8.577075958251953\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.12789392471313477\n",
      "    test time:                0.008653640747070312\n",
      "    epoch time:               0.13704228401184082\n",
      "    joint lr:                 0.017921011149015745\n",
      "epoch:  67 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.010353335994295776\n",
      "    train cross_ent loss:     0.001804045052267611\n",
      "    test overall loss:        0.009742850127319494\n",
      "    test cross_ent loss:      0.001222925609908998\n",
      "    cluster loss:             0.0023600260416666665\n",
      "    separation loss:          3.0569356282552085\n",
      "    avg separation loss:      4.164550145467122\n",
      "    l1_addon loss:            8.399747848510742\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.13273191452026367\n",
      "    test time:                0.008742332458496094\n",
      "    epoch time:               0.14200925827026367\n",
      "    joint lr:                 0.016482600963416614\n",
      "epoch:  68 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.010704828600864857\n",
      "    train cross_ent loss:     0.0022028247840353288\n",
      "    test overall loss:        0.00952643621712923\n",
      "    test cross_ent loss:      0.001044673069069783\n",
      "    cluster loss:             0.001922607421875\n",
      "    separation loss:          2.995452880859375\n",
      "    avg separation loss:      4.098308086395264\n",
      "    l1_addon loss:            8.272542953491211\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.13309836387634277\n",
      "    test time:                0.008819103240966797\n",
      "    epoch time:               0.14249157905578613\n",
      "    joint lr:                 0.015071176880414561\n",
      "epoch:  69 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.009520155377686024\n",
      "    train cross_ent loss:     0.0010670039437172818\n",
      "    test overall loss:        0.009203794101874033\n",
      "    test cross_ent loss:      0.0007735033480760952\n",
      "    cluster loss:             0.0013631184895833333\n",
      "    separation loss:          2.969395955403646\n",
      "    avg separation loss:      4.033441225687663\n",
      "    l1_addon loss:            8.100970268249512\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.13192105293273926\n",
      "    test time:                0.008552312850952148\n",
      "    epoch time:               0.14096784591674805\n",
      "    joint lr:                 0.01368634301897622\n",
      "epoch:  70 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.009368907049065456\n",
      "    train cross_ent loss:     0.0009616138977435185\n",
      "    test overall loss:        0.008972219501932463\n",
      "    test cross_ent loss:      0.0005871819060606261\n",
      "    cluster loss:             0.0011952718098958333\n",
      "    separation loss:          2.9268290201822915\n",
      "    avg separation loss:      3.9789905548095703\n",
      "    l1_addon loss:            7.950125694274902\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.1296086311340332\n",
      "    test time:                0.008694887161254883\n",
      "    epoch time:               0.13880443572998047\n",
      "    joint lr:                 0.012327708717078603\n",
      "epoch:  71 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.009127388708293438\n",
      "    train cross_ent loss:     0.0007606660983583424\n",
      "    test overall loss:        0.0090932073071599\n",
      "    test cross_ent loss:      0.0007479233318008482\n",
      "    cluster loss:             0.0012868245442708333\n",
      "    separation loss:          2.9170023600260415\n",
      "    avg separation loss:      3.9365268548329673\n",
      "    l1_addon loss:            7.817612648010254\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.13050389289855957\n",
      "    test time:                0.008629322052001953\n",
      "    epoch time:               0.13962078094482422\n",
      "    joint lr:                 0.01099488846691703\n",
      "epoch:  72 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.009107687947107479\n",
      "    train cross_ent loss:     0.00077755692655046\n",
      "    test overall loss:        0.008796090260148048\n",
      "    test cross_ent loss:      0.000484549052392443\n",
      "    cluster loss:             0.0009307861328125\n",
      "    separation loss:          2.8870391845703125\n",
      "    avg separation loss:      3.9076949755350747\n",
      "    l1_addon loss:            7.705136775970459\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.128173828125\n",
      "    test time:                0.008675336837768555\n",
      "    epoch time:               0.13736367225646973\n",
      "    joint lr:                 0.009687501850886984\n",
      "epoch:  73 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.00891340256202966\n",
      "    train cross_ent loss:     0.0006179063166200649\n",
      "    test overall loss:        0.008802913750211397\n",
      "    test cross_ent loss:      0.0005245345334211985\n",
      "    cluster loss:             0.0011545817057291667\n",
      "    separation loss:          2.859130859375\n",
      "    avg separation loss:      3.8782012462615967\n",
      "    l1_addon loss:            7.5945963859558105\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.12909984588623047\n",
      "    test time:                0.008785724639892578\n",
      "    epoch time:               0.13840699195861816\n",
      "    joint lr:                 0.008405173478330853\n",
      "epoch:  74 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.00893230689689517\n",
      "    train cross_ent loss:     0.000668708487864933\n",
      "    test overall loss:        0.008805775083601475\n",
      "    test cross_ent loss:      0.000558122080595543\n",
      "    cluster loss:             0.0009256998697916666\n",
      "    separation loss:          2.8430023193359375\n",
      "    avg separation loss:      3.84934671719869\n",
      "    l1_addon loss:            7.4921770095825195\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.12912869453430176\n",
      "    test time:                0.008656024932861328\n",
      "    epoch time:               0.13826346397399902\n",
      "    joint lr:                 0.007147532923040749\n",
      "epoch:  75 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.008877345127984881\n",
      "    train cross_ent loss:     0.000641317918052664\n",
      "    test overall loss:        0.00867573699603478\n",
      "    test cross_ent loss:      0.0004537003308845063\n",
      "    cluster loss:             0.000885009765625\n",
      "    separation loss:          2.823949178059896\n",
      "    avg separation loss:      3.8216070334116616\n",
      "    l1_addon loss:            7.406788349151611\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.1357877254486084\n",
      "    test time:                0.008586645126342773\n",
      "    epoch time:               0.14490532875061035\n",
      "    joint lr:                 0.005914214661508615\n",
      "epoch:  76 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.00879208545666188\n",
      "    train cross_ent loss:     0.0005812899116790504\n",
      "    test overall loss:        0.008651215583086014\n",
      "    test cross_ent loss:      0.00045197516252907616\n",
      "    cluster loss:             0.0009816487630208333\n",
      "    separation loss:          2.811431884765625\n",
      "    avg separation loss:      3.805198828379313\n",
      "    l1_addon loss:            7.330801486968994\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.13044166564941406\n",
      "    test time:                0.008619546890258789\n",
      "    epoch time:               0.13958430290222168\n",
      "    joint lr:                 0.004704858011914826\n",
      "epoch:  77 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.008784633653704077\n",
      "    train cross_ent loss:     0.0005950210579612758\n",
      "    test overall loss:        0.00861928736170133\n",
      "    test cross_ent loss:      0.00043884550298874575\n",
      "    cluster loss:             0.0008951822916666666\n",
      "    separation loss:          2.7949066162109375\n",
      "    avg separation loss:      3.7892274856567383\n",
      "    l1_addon loss:            7.268138885498047\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.12929821014404297\n",
      "    test time:                0.008722782135009766\n",
      "    epoch time:               0.13855576515197754\n",
      "    joint lr:                 0.0035191070738467612\n",
      "epoch:  78 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.008771616965532303\n",
      "    train cross_ent loss:     0.0005980332498438656\n",
      "    test overall loss:        0.008586053115626177\n",
      "    test cross_ent loss:      0.00041938665284154314\n",
      "    cluster loss:             0.0008341471354166666\n",
      "    separation loss:          2.7915242513020835\n",
      "    avg separation loss:      3.77634596824646\n",
      "    l1_addon loss:            7.222220420837402\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.13272595405578613\n",
      "    test time:                0.008631706237792969\n",
      "    epoch time:               0.14185833930969238\n",
      "    joint lr:                 0.00235661066873886\n",
      "epoch:  79 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.008652868098579347\n",
      "    train cross_ent loss:     0.0004921340550936293\n",
      "    test overall loss:        0.008569282169143358\n",
      "    test cross_ent loss:      0.00041361124992060166\n",
      "    cluster loss:             0.0008290608723958334\n",
      "    separation loss:          2.7831217447916665\n",
      "    avg separation loss:      3.764484167098999\n",
      "    l1_addon loss:            7.1855692863464355\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.13031625747680664\n",
      "    test time:                0.008619070053100586\n",
      "    epoch time:               0.13946533203125\n",
      "    joint lr:                 0.001217022281025732\n",
      "epoch:  80 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.008702360501047224\n",
      "    train cross_ent loss:     0.0005498069322129595\n",
      "    test overall loss:        0.008556925691664219\n",
      "    test cross_ent loss:      0.00040660391096025705\n",
      "    cluster loss:             0.0007985432942708334\n",
      "    separation loss:          2.780914306640625\n",
      "    avg separation loss:      3.7598865826924643\n",
      "    l1_addon loss:            7.1677398681640625\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.12801098823547363\n",
      "    test time:                0.008685588836669922\n",
      "    epoch time:               0.13722014427185059\n",
      "    joint lr:                 0.0001\n",
      "epoch:  81 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.008656634308863431\n",
      "    train cross_ent loss:     0.0005073815455034492\n",
      "    test overall loss:        0.008551199610034624\n",
      "    test cross_ent loss:      0.00040265828526268405\n",
      "    cluster loss:             0.00079345703125\n",
      "    separation loss:          2.7826690673828125\n",
      "    avg separation loss:      3.7617551485697427\n",
      "    l1_addon loss:            7.161803722381592\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.13386273384094238\n",
      "    test time:                0.008740663528442383\n",
      "    epoch time:               0.14312076568603516\n",
      "    joint lr:                 0.00228958707526664\n",
      "epoch:  82 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.008673426258610561\n",
      "    train cross_ent loss:     0.0005275895236991346\n",
      "    test overall loss:        0.008544613917668661\n",
      "    test cross_ent loss:      0.00040300590141365927\n",
      "    cluster loss:             0.0008138020833333334\n",
      "    separation loss:          2.7762349446614585\n",
      "    avg separation loss:      3.7557448546091714\n",
      "    l1_addon loss:            7.138693809509277\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.1361403465270996\n",
      "    test time:                0.008757591247558594\n",
      "    epoch time:               0.14544034004211426\n",
      "    joint lr:                 0.004435382409027948\n",
      "epoch:  83 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.00872590029030107\n",
      "    train cross_ent loss:     0.0005918770812058938\n",
      "    test overall loss:        0.008593976808091005\n",
      "    test cross_ent loss:      0.00046929116554868716\n",
      "    cluster loss:             0.0008494059244791666\n",
      "    separation loss:          2.7726898193359375\n",
      "    avg separation loss:      3.739046494166056\n",
      "    l1_addon loss:            7.0822858810424805\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.13353991508483887\n",
      "    test time:                0.008542060852050781\n",
      "    epoch time:               0.14258098602294922\n",
      "    joint lr:                 0.006538042877406532\n",
      "epoch:  84 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.008752202469622716\n",
      "    train cross_ent loss:     0.0006380840932251886\n",
      "    test overall loss:        0.00854171005388101\n",
      "    test cross_ent loss:      0.0004424135646938036\n",
      "    cluster loss:             0.0008646647135416666\n",
      "    separation loss:          2.7480265299479165\n",
      "    avg separation loss:      3.711392402648926\n",
      "    l1_addon loss:            6.997653961181641\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.1298515796661377\n",
      "    test time:                0.00883173942565918\n",
      "    epoch time:               0.13928508758544922\n",
      "    joint lr:                 0.008598216598176611\n",
      "epoch:  85 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.008613654848886654\n",
      "    train cross_ent loss:     0.0005291420629873755\n",
      "    test overall loss:        0.008497481544812521\n",
      "    test cross_ent loss:      0.00043170692515559494\n",
      "    cluster loss:             0.0008697509765625\n",
      "    separation loss:          2.7269744873046875\n",
      "    avg separation loss:      3.681861480077108\n",
      "    l1_addon loss:            6.885912895202637\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.12907958030700684\n",
      "    test time:                0.008693933486938477\n",
      "    epoch time:               0.13826918601989746\n",
      "    joint lr:                 0.010616543040243577\n",
      "epoch:  86 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.008792738080956042\n",
      "    train cross_ent loss:     0.0007430103523802245\n",
      "    test overall loss:        0.008648451107243696\n",
      "    test cross_ent loss:      0.0006165191880427301\n",
      "    cluster loss:             0.0012054443359375\n",
      "    separation loss:          2.696375528971354\n",
      "    avg separation loss:      3.636524041493734\n",
      "    l1_addon loss:            6.773105621337891\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.12851619720458984\n",
      "    test time:                0.009485721588134766\n",
      "    epoch time:               0.13864874839782715\n",
      "    joint lr:                 0.012593653131809358\n",
      "epoch:  87 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.009144868148723617\n",
      "    train cross_ent loss:     0.0011279444324827637\n",
      "    test overall loss:        0.008677418033281961\n",
      "    test cross_ent loss:      0.0006858271275026103\n",
      "    cluster loss:             0.0013326009114583333\n",
      "    separation loss:          2.6687520345052085\n",
      "    avg separation loss:      3.5872413317362466\n",
      "    l1_addon loss:            6.638636112213135\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.14176106452941895\n",
      "    test time:                0.008852720260620117\n",
      "    epoch time:               0.15120673179626465\n",
      "    joint lr:                 0.014530169367239798\n",
      "epoch:  88 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0085398439259734\n",
      "    train cross_ent loss:     0.0005715607330785133\n",
      "    test overall loss:        0.00854837397734324\n",
      "    test cross_ent loss:      0.0006062309063660601\n",
      "    cluster loss:             0.001251220703125\n",
      "    separation loss:          2.633082071940104\n",
      "    avg separation loss:      3.5488088925679526\n",
      "    l1_addon loss:            6.473810195922852\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.13240694999694824\n",
      "    test time:                0.008591651916503906\n",
      "    epoch time:               0.14155983924865723\n",
      "    joint lr:                 0.01642670591264845\n",
      "epoch:  89 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.008713045041076839\n",
      "    train cross_ent loss:     0.0007929009007057175\n",
      "    test overall loss:        0.008491166246434053\n",
      "    test cross_ent loss:      0.0005969059808800617\n",
      "    cluster loss:             0.0012766520182291667\n",
      "    separation loss:          2.5903828938802085\n",
      "    avg separation loss:      3.4691453774770102\n",
      "    l1_addon loss:            6.314199447631836\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.1290760040283203\n",
      "    test time:                0.008738994598388672\n",
      "    epoch time:               0.13836050033569336\n",
      "    joint lr:                 0.018283868710212207\n",
      "epoch:  90 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.008849137666402385\n",
      "    train cross_ent loss:     0.0009722768281790195\n",
      "    test overall loss:        0.008462975732982159\n",
      "    test cross_ent loss:      0.0006112713987628619\n",
      "    cluster loss:             0.0013834635416666667\n",
      "    separation loss:          2.5432535807291665\n",
      "    avg separation loss:      3.432767152786255\n",
      "    l1_addon loss:            6.172346115112305\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.1279609203338623\n",
      "    test time:                0.008670568466186523\n",
      "    epoch time:               0.13716673851013184\n",
      "    joint lr:                 0.020102255581233422\n",
      "epoch:  91 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.008489250292768702\n",
      "    train cross_ent loss:     0.0006646102738159243\n",
      "    test overall loss:        0.008392474614083767\n",
      "    test cross_ent loss:      0.0005988292202043036\n",
      "    cluster loss:             0.0013783772786458333\n",
      "    separation loss:          2.491480509440104\n",
      "    avg separation loss:      3.356346686681112\n",
      "    l1_addon loss:            5.978816986083984\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.1290574073791504\n",
      "    test time:                0.00871729850769043\n",
      "    epoch time:               0.1383066177368164\n",
      "    joint lr:                 0.018912121374150048\n",
      "epoch:  92 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.008813481836114079\n",
      "    train cross_ent loss:     0.0010399826023785863\n",
      "    test overall loss:        0.008768240300317606\n",
      "    test cross_ent loss:      0.0010055757593363523\n",
      "    cluster loss:             0.0021718343098958335\n",
      "    separation loss:          2.4738616943359375\n",
      "    avg separation loss:      3.314915736516317\n",
      "    l1_addon loss:            5.875547409057617\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.12816500663757324\n",
      "    test time:                0.008671045303344727\n",
      "    epoch time:               0.13738441467285156\n",
      "    joint lr:                 0.017743789625650205\n",
      "epoch:  93 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.008697701821802184\n",
      "    train cross_ent loss:     0.0009642483146308223\n",
      "    test overall loss:        0.008238890518744787\n",
      "    test cross_ent loss:      0.0005290608387440443\n",
      "    cluster loss:             0.0012919108072916667\n",
      "    separation loss:          2.4359334309895835\n",
      "    avg separation loss:      3.252987861633301\n",
      "    l1_addon loss:            5.699430465698242\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.1296389102935791\n",
      "    test time:                0.008533954620361328\n",
      "    epoch time:               0.13867688179016113\n",
      "    joint lr:                 0.01659694329998293\n",
      "epoch:  94 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.008310761244501919\n",
      "    train cross_ent loss:     0.0006223795571713708\n",
      "    test overall loss:        0.008105046736697355\n",
      "    test cross_ent loss:      0.00043708496377803385\n",
      "    cluster loss:             0.0009256998697916666\n",
      "    separation loss:          2.4049275716145835\n",
      "    avg separation loss:      3.206385612487793\n",
      "    l1_addon loss:            5.559871673583984\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.13537001609802246\n",
      "    test time:                0.008644580841064453\n",
      "    epoch time:               0.14455628395080566\n",
      "    joint lr:                 0.01547126952186645\n",
      "epoch:  95 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.00834023009520024\n",
      "    train cross_ent loss:     0.0006886615346957115\n",
      "    test overall loss:        0.008278665443261465\n",
      "    test cross_ent loss:      0.0006451234415483972\n",
      "    cluster loss:             0.0013326009114583333\n",
      "    separation loss:          2.381622314453125\n",
      "    avg separation loss:      3.1712276935577393\n",
      "    l1_addon loss:            5.445138931274414\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.13128209114074707\n",
      "    test time:                0.008771657943725586\n",
      "    epoch time:               0.1406230926513672\n",
      "    joint lr:                 0.014366459524982304\n",
      "epoch:  96 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.008217728434829041\n",
      "    train cross_ent loss:     0.0005962450750303105\n",
      "    test overall loss:        0.007958241427938143\n",
      "    test cross_ent loss:      0.0003539684403222054\n",
      "    cluster loss:             0.0007425944010416666\n",
      "    separation loss:          2.3472137451171875\n",
      "    avg separation loss:      3.1393610636393228\n",
      "    l1_addon loss:            5.347576141357422\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.12783145904541016\n",
      "    test time:                0.008737802505493164\n",
      "    epoch time:               0.13709616661071777\n",
      "    joint lr:                 0.013282208601083652\n",
      "epoch:  97 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.008022156893275678\n",
      "    train cross_ent loss:     0.00043000375171686755\n",
      "    test overall loss:        0.008045271970331669\n",
      "    test cross_ent loss:      0.0004684086889028549\n",
      "    cluster loss:             0.0009256998697916666\n",
      "    separation loss:          2.3251190185546875\n",
      "    avg separation loss:      3.10953156153361\n",
      "    l1_addon loss:            5.256211280822754\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.1308763027191162\n",
      "    test time:                0.008690357208251953\n",
      "    epoch time:               0.14008378982543945\n",
      "    joint lr:                 0.012218216049710476\n",
      "epoch:  98 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.008109643298666924\n",
      "    train cross_ent loss:     0.0005416211415649741\n",
      "    test overall loss:        0.008281448235114416\n",
      "    test cross_ent loss:      0.0007170899965179464\n",
      "    cluster loss:             0.0013020833333333333\n",
      "    separation loss:          2.2993672688802085\n",
      "    avg separation loss:      3.0863917668660483\n",
      "    l1_addon loss:            5.214527606964111\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.13477730751037598\n",
      "    test time:                0.008717060089111328\n",
      "    epoch time:               0.14400815963745117\n",
      "    joint lr:                 0.011174185128504639\n",
      "epoch:  99 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.008124872401822358\n",
      "    train cross_ent loss:     0.0005747198465542169\n",
      "    test overall loss:        0.007865572658677896\n",
      "    test cross_ent loss:      0.0003252847915670524\n",
      "    cluster loss:             0.0007985432942708334\n",
      "    separation loss:          2.2817840576171875\n",
      "    avg separation loss:      3.0553746223449707\n",
      "    l1_addon loss:            5.134293556213379\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.14285731315612793\n",
      "    test time:                0.008483648300170898\n",
      "    epoch time:               0.15185141563415527\n",
      "    joint lr:                 0.010149823004117963\n",
      "epoch: 100 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.008035599123104475\n",
      "    train cross_ent loss:     0.0005074698556200019\n",
      "    test overall loss:        0.00828109122812748\n",
      "    test cross_ent loss:      0.000763306743465364\n",
      "    cluster loss:             0.0013427734375\n",
      "    separation loss:          2.276031494140625\n",
      "    avg separation loss:      3.0290319124857583\n",
      "    l1_addon loss:            5.059281826019287\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.1365666389465332\n",
      "    test time:                0.008721590042114258\n",
      "    epoch time:               0.14583039283752441\n",
      "    joint lr:                 0.009144840703706159\n",
      "epoch: 101 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.007993391700438224\n",
      "    train cross_ent loss:     0.0004825256419280777\n",
      "    test overall loss:        0.008201216037074724\n",
      "    test cross_ent loss:      0.0006933859161411723\n",
      "    cluster loss:             0.001495361328125\n",
      "    separation loss:          2.260223388671875\n",
      "    avg separation loss:      3.0190877119700112\n",
      "    l1_addon loss:            5.02609920501709\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.15654802322387695\n",
      "    test time:                0.008775711059570312\n",
      "    epoch time:               0.16587233543395996\n",
      "    joint lr:                 0.008158953067002189\n",
      "epoch: 102 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.007989186546183191\n",
      "    train cross_ent loss:     0.0004935136039421195\n",
      "    test overall loss:        0.007836568169295788\n",
      "    test cross_ent loss:      0.0003529158323847999\n",
      "    cluster loss:             0.0007781982421875\n",
      "    separation loss:          2.2474263509114585\n",
      "    avg separation loss:      2.997227589289347\n",
      "    l1_addon loss:            4.945506572723389\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.1559593677520752\n",
      "    test time:                0.00861978530883789\n",
      "    epoch time:               0.1651015281677246\n",
      "    joint lr:                 0.0071918786989619305\n",
      "epoch: 103 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.007848344830563292\n",
      "    train cross_ent loss:     0.0003708227268361952\n",
      "    test overall loss:        0.007724657189100981\n",
      "    test cross_ent loss:      0.0002554542782794063\n",
      "    cluster loss:             0.0005594889322916666\n",
      "    separation loss:          2.230865478515625\n",
      "    avg separation loss:      2.9794651667277017\n",
      "    l1_addon loss:            4.897342681884766\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.13960599899291992\n",
      "    test time:                0.008783340454101562\n",
      "    epoch time:               0.14892864227294922\n",
      "    joint lr:                 0.006243339922975775\n",
      "epoch: 104 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.007745708469883539\n",
      "    train cross_ent loss:     0.00028306387866905425\n",
      "    test overall loss:        0.0077065521230300265\n",
      "    test cross_ent loss:      0.00025142427572670084\n",
      "    cluster loss:             0.0004831949869791667\n",
      "    separation loss:          2.2144266764322915\n",
      "    avg separation loss:      2.959512948989868\n",
      "    l1_addon loss:            4.850425720214844\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.13331246376037598\n",
      "    test time:                0.008760452270507812\n",
      "    epoch time:               0.1426551342010498\n",
      "    joint lr:                 0.005313062734639446\n",
      "epoch: 105 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.007763459187117405\n",
      "    train cross_ent loss:     0.0003126656383756199\n",
      "    test overall loss:        0.007689310858647029\n",
      "    test cross_ent loss:      0.00024371604862002036\n",
      "    cluster loss:             0.0005442301432291666\n",
      "    separation loss:          2.2072855631510415\n",
      "    avg separation loss:      2.9475621382395425\n",
      "    l1_addon loss:            4.818649768829346\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.13013029098510742\n",
      "    test time:                0.00863790512084961\n",
      "    epoch time:               0.13925576210021973\n",
      "    joint lr:                 0.004400776756077547\n",
      "epoch: 106 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.007706445641815662\n",
      "    train cross_ent loss:     0.0002668278593773721\n",
      "    test overall loss:        0.007661831099539995\n",
      "    test cross_ent loss:      0.00022774332319386303\n",
      "    cluster loss:             0.000518798828125\n",
      "    separation loss:          2.1994222005208335\n",
      "    avg separation loss:      2.9375157356262207\n",
      "    l1_addon loss:            4.780292510986328\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.13656091690063477\n",
      "    test time:                0.00885629653930664\n",
      "    epoch time:               0.14597296714782715\n",
      "    joint lr:                 0.0035062151908134102\n",
      "epoch: 107 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.007708626275416464\n",
      "    train cross_ent loss:     0.0002779159863166569\n",
      "    test overall loss:        0.0076887890075643854\n",
      "    test cross_ent loss:      0.0002590300524995352\n",
      "    cluster loss:             0.0005900065104166666\n",
      "    separation loss:          2.1932474772135415\n",
      "    avg separation loss:      2.9292050202687583\n",
      "    l1_addon loss:            4.765863418579102\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.13082361221313477\n",
      "    test time:                0.008716821670532227\n",
      "    epoch time:               0.14006471633911133\n",
      "    joint lr:                 0.0026291147791789593\n",
      "epoch: 108 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.007680056311073713\n",
      "    train cross_ent loss:     0.00025591165331206867\n",
      "    test overall loss:        0.007657851247737805\n",
      "    test cross_ent loss:      0.00023651092002789179\n",
      "    cluster loss:             0.0005645751953125\n",
      "    separation loss:          2.187744140625\n",
      "    avg separation loss:      2.9231799443562827\n",
      "    l1_addon loss:            4.737800598144531\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.1347193717956543\n",
      "    test time:                0.00867915153503418\n",
      "    epoch time:               0.1439516544342041\n",
      "    joint lr:                 0.001769215754258106\n",
      "epoch: 109 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.007702126516960561\n",
      "    train cross_ent loss:     0.00028376337604640867\n",
      "    test overall loss:        0.0076442671318848925\n",
      "    test cross_ent loss:      0.00022707772829259434\n",
      "    cluster loss:             0.00048828125\n",
      "    separation loss:          2.1851959228515625\n",
      "    avg separation loss:      2.917588392893473\n",
      "    l1_addon loss:            4.723964214324951\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.14351511001586914\n",
      "    test time:                0.008713960647583008\n",
      "    epoch time:               0.15280842781066895\n",
      "    joint lr:                 0.0009262617983577627\n",
      "epoch: 110 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.007753453537588939\n",
      "    train cross_ent loss:     0.00033866329977172427\n",
      "    test overall loss:        0.007639357820153236\n",
      "    test cross_ent loss:      0.00022484596411231905\n",
      "    cluster loss:             0.0005340576171875\n",
      "    separation loss:          2.180943806966146\n",
      "    avg separation loss:      2.917149623235067\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.14551663398742676\n",
      "    test time:                0.008697748184204102\n",
      "    epoch time:               0.1547534465789795\n",
      "    joint lr:                 0.0001\n",
      "epoch: 110 (PUSH) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.007753453537588939\n",
      "    train cross_ent loss:     0.00033866329977172427\n",
      "    test overall loss:        0.007737442851066589\n",
      "    test cross_ent loss:      0.0003229308349546045\n",
      "    cluster loss:             0.0007171630859375\n",
      "    separation loss:          2.178197224934896\n",
      "    avg separation loss:      2.916062116622925\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  6.0\n",
      "    train time:               0.14551663398742676\n",
      "    test time:                0.008747577667236328\n",
      "    epoch time:               0.06249523162841797\n",
      "epoch: 110 (1/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.007753147205221467\n",
      "    train cross_ent loss:     0.00035712975022761384\n",
      "    test overall loss:        0.007693521988888581\n",
      "    test cross_ent loss:      0.0003171360876876861\n",
      "    cluster loss:             0.0007069905598958334\n",
      "    separation loss:          2.1806742350260415\n",
      "    avg separation loss:      2.917458693186442\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  5.961873531341553\n",
      "    train time:               0.060778141021728516\n",
      "    test time:                0.00860905647277832\n",
      "    epoch time:               0.06979656219482422\n",
      "    last layer lr:            0.0007599999999999978\n",
      "epoch: 110 (2/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0075760079198516905\n",
      "    train cross_ent loss:     0.0003404173703529523\n",
      "    test overall loss:        0.0074067927586535616\n",
      "    test cross_ent loss:      0.00032125347449133795\n",
      "    cluster loss:             0.0006968180338541666\n",
      "    separation loss:          2.1821136474609375\n",
      "    avg separation loss:      2.918372948964437\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  5.671027183532715\n",
      "    train time:               0.06321477890014648\n",
      "    test time:                0.00849008560180664\n",
      "    epoch time:               0.07211017608642578\n",
      "    last layer lr:            0.0014200000000000013\n",
      "epoch: 110 (3/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.007217535792733543\n",
      "    train cross_ent loss:     0.00039332301003014436\n",
      "    test overall loss:        0.00687994606172045\n",
      "    test cross_ent loss:      0.00033176625341487426\n",
      "    cluster loss:             0.0007120768229166666\n",
      "    separation loss:          2.1808013916015625\n",
      "    avg separation loss:      2.91573174794515\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  5.133667945861816\n",
      "    train time:               0.06386375427246094\n",
      "    test time:                0.008581876754760742\n",
      "    epoch time:               0.0728604793548584\n",
      "    last layer lr:            0.0020799999999999985\n",
      "epoch: 110 (4/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.006584270202438347\n",
      "    train cross_ent loss:     0.000410853997891536\n",
      "    test overall loss:        0.006090712578346332\n",
      "    test cross_ent loss:      0.0003182850293039034\n",
      "    cluster loss:             0.0006815592447916666\n",
      "    separation loss:          2.1805013020833335\n",
      "    avg separation loss:      2.918707529703776\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  4.35791540145874\n",
      "    train time:               0.06363725662231445\n",
      "    test time:                0.00866556167602539\n",
      "    epoch time:               0.07274889945983887\n",
      "    last layer lr:            0.0027400000000000024\n",
      "epoch: 110 (5/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.00564519535691943\n",
      "    train cross_ent loss:     0.00037634881846315693\n",
      "    test overall loss:        0.005068585742264986\n",
      "    test cross_ent loss:      0.00033975411012458306\n",
      "    cluster loss:             0.0007069905598958334\n",
      "    separation loss:          2.1811116536458335\n",
      "    avg separation loss:      2.9172077973683677\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  3.314319610595703\n",
      "    train time:               0.06393814086914062\n",
      "    test time:                0.00876760482788086\n",
      "    epoch time:               0.07316350936889648\n",
      "    last layer lr:            0.0034\n",
      "epoch: 110 (6/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.004527125624008477\n",
      "    train cross_ent loss:     0.0004199564091322827\n",
      "    test overall loss:        0.0038022611600657306\n",
      "    test cross_ent loss:      0.0003511118605577697\n",
      "    cluster loss:             0.0007171630859375\n",
      "    separation loss:          2.179835001627604\n",
      "    avg separation loss:      2.9149890740712485\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  2.036637306213379\n",
      "    train time:               0.06504297256469727\n",
      "    test time:                0.008794307708740234\n",
      "    epoch time:               0.07430028915405273\n",
      "    last layer lr:            0.004059999999999998\n",
      "epoch: 110 (7/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0030982186217443086\n",
      "    train cross_ent loss:     0.00038124787351989653\n",
      "    test overall loss:        0.0022773304178069034\n",
      "    test cross_ent loss:      0.0003572503919713199\n",
      "    cluster loss:             0.0006917317708333334\n",
      "    separation loss:          2.1800130208333335\n",
      "    avg separation loss:      2.9176628589630127\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  0.5055680274963379\n",
      "    train time:               0.0648794174194336\n",
      "    test time:                0.008733749389648438\n",
      "    epoch time:               0.07408285140991211\n",
      "    last layer lr:            0.004720000000000002\n",
      "epoch: 110 (8/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0018715345104283188\n",
      "    train cross_ent loss:     0.00032944335907814093\n",
      "    test overall loss:        0.0016589307536681492\n",
      "    test cross_ent loss:      0.00021485413890331984\n",
      "    cluster loss:             0.0006917317708333334\n",
      "    separation loss:          2.181401570638021\n",
      "    avg separation loss:      2.9177310466766357\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  0.029564689844846725\n",
      "    train time:               0.06482958793640137\n",
      "    test time:                0.008736371994018555\n",
      "    epoch time:               0.07402706146240234\n",
      "    last layer lr:            0.005379999999999999\n",
      "epoch: 110 (9/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0016235824914474506\n",
      "    train cross_ent loss:     0.00019180991421308136\n",
      "    test overall loss:        0.0015448612393811345\n",
      "    test cross_ent loss:      0.0001212464485433884\n",
      "    cluster loss:             0.0006917317708333334\n",
      "    separation loss:          2.1793111165364585\n",
      "    avg separation loss:      2.917083263397217\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  0.009102856740355492\n",
      "    train time:               0.06569552421569824\n",
      "    test time:                0.008631467819213867\n",
      "    epoch time:               0.07476377487182617\n",
      "    last layer lr:            0.006040000000000003\n",
      "epoch: 110 (10/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0015368020758614875\n",
      "    train cross_ent loss:     0.00011163958606630331\n",
      "    test overall loss:        0.0015140972100198269\n",
      "    test cross_ent loss:      8.369934221263975e-05\n",
      "    cluster loss:             0.0006968180338541666\n",
      "    separation loss:          2.18096923828125\n",
      "    avg separation loss:      2.9184502760569253\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  0.01588590070605278\n",
      "    train time:               0.06380558013916016\n",
      "    test time:                0.00848841667175293\n",
      "    epoch time:               0.07271003723144531\n",
      "    last layer lr:            0.0067\n",
      "epoch: 110 (11/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.001507903310994152\n",
      "    train cross_ent loss:     8.054104910115711e-05\n",
      "    test overall loss:        0.0014917462831363082\n",
      "    test cross_ent loss:      6.137989354707922e-05\n",
      "    cluster loss:             0.0007171630859375\n",
      "    separation loss:          2.1789398193359375\n",
      "    avg separation loss:      2.916983445485433\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  0.015854468569159508\n",
      "    train time:               0.06233787536621094\n",
      "    test time:                0.008669614791870117\n",
      "    epoch time:               0.07145285606384277\n",
      "    last layer lr:            0.0073599999999999985\n",
      "epoch: 110 (12/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0014924147726560477\n",
      "    train cross_ent loss:     6.621406782869599e-05\n",
      "    test overall loss:        0.0014754825582106907\n",
      "    test cross_ent loss:      4.7104148203895115e-05\n",
      "    cluster loss:             0.0007171630859375\n",
      "    separation loss:          2.18023681640625\n",
      "    avg separation loss:      2.9160338242848716\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  0.013866456225514412\n",
      "    train time:               0.06375336647033691\n",
      "    test time:                0.008569002151489258\n",
      "    epoch time:               0.07272863388061523\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 110 (13/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0014769559893466067\n",
      "    train cross_ent loss:     4.7052219770193915e-05\n",
      "    test overall loss:        0.0014629400490472715\n",
      "    test cross_ent loss:      3.6989295040257275e-05\n",
      "    cluster loss:             0.0007069905598958334\n",
      "    separation loss:          2.1823883056640625\n",
      "    avg separation loss:      2.917625665664673\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  0.011438826099038124\n",
      "    train time:               0.06218600273132324\n",
      "    test time:                0.008471012115478516\n",
      "    epoch time:               0.07106900215148926\n",
      "    last layer lr:            0.008679999999999998\n",
      "epoch: 110 (14/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0014720478757226374\n",
      "    train cross_ent loss:     4.2713811922112654e-05\n",
      "    test overall loss:        0.0014566136912132304\n",
      "    test cross_ent loss:      3.0411642001126893e-05\n",
      "    cluster loss:             0.0007222493489583334\n",
      "    separation loss:          2.1828155517578125\n",
      "    avg separation loss:      2.9176851908365884\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  0.011690115556120872\n",
      "    train time:               0.06260871887207031\n",
      "    test time:                0.008628368377685547\n",
      "    epoch time:               0.07168292999267578\n",
      "    last layer lr:            0.009340000000000003\n",
      "epoch: 110 (15/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0014627928685513325\n",
      "    train cross_ent loss:     3.291876026878526e-05\n",
      "    test overall loss:        0.0014553810469806194\n",
      "    test cross_ent loss:      2.4003492095895734e-05\n",
      "    cluster loss:             0.0006968180338541666\n",
      "    separation loss:          2.179204305013021\n",
      "    avg separation loss:      2.917126178741455\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  0.01686558499932289\n",
      "    train time:               0.06512832641601562\n",
      "    test time:                0.00855398178100586\n",
      "    epoch time:               0.07409310340881348\n",
      "    last layer lr:            0.01\n",
      "epoch: 110 (16/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.001459116243495373\n",
      "    train cross_ent loss:     2.9782689807689167e-05\n",
      "    test overall loss:        0.0014462978191052873\n",
      "    test cross_ent loss:      2.051200438775898e-05\n",
      "    cluster loss:             0.0007171630859375\n",
      "    separation loss:          2.181757609049479\n",
      "    avg separation loss:      2.9154610633850098\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  0.011273864656686783\n",
      "    train time:               0.06305813789367676\n",
      "    test time:                0.008679389953613281\n",
      "    epoch time:               0.07216620445251465\n",
      "    last layer lr:            0.009604000000000001\n",
      "epoch: 110 (17/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0014494577553705312\n",
      "    train cross_ent loss:     1.9233616825431454e-05\n",
      "    test overall loss:        0.0014452571825434764\n",
      "    test cross_ent loss:      1.683282122636835e-05\n",
      "    cluster loss:             0.0006917317708333334\n",
      "    separation loss:          2.1805267333984375\n",
      "    avg separation loss:      2.9192825158437095\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  0.013912418857216835\n",
      "    train time:               0.06278443336486816\n",
      "    test time:                0.008716821670532227\n",
      "    epoch time:               0.07195067405700684\n",
      "    last layer lr:            0.009208\n",
      "epoch: 110 (18/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0014501578552881256\n",
      "    train cross_ent loss:     1.9119282853807817e-05\n",
      "    test overall loss:        0.0014420578954741359\n",
      "    test cross_ent loss:      1.5030224858492147e-05\n",
      "    cluster loss:             0.0007069905598958334\n",
      "    separation loss:          2.179906209309896\n",
      "    avg separation loss:      2.917367776234945\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  0.012515739537775517\n",
      "    train time:               0.0655677318572998\n",
      "    test time:                0.008591651916503906\n",
      "    epoch time:               0.07460689544677734\n",
      "    last layer lr:            0.008812\n",
      "epoch: 110 (19/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.00144523539711372\n",
      "    train cross_ent loss:     1.7436357268252323e-05\n",
      "    test overall loss:        0.0014439151079083483\n",
      "    test cross_ent loss:      1.3236707066729044e-05\n",
      "    cluster loss:             0.0006917317708333334\n",
      "    separation loss:          2.1807149251302085\n",
      "    avg separation loss:      2.9186397393544516\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  0.016166482120752335\n",
      "    train time:               0.06436538696289062\n",
      "    test time:                0.008630990982055664\n",
      "    epoch time:               0.07344865798950195\n",
      "    last layer lr:            0.008415999999999998\n",
      "epoch: 110 (20/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0014413012977456674\n",
      "    train cross_ent loss:     1.4922976674824895e-05\n",
      "    test overall loss:        0.0014401216758415103\n",
      "    test cross_ent loss:      1.1979704140685499e-05\n",
      "    cluster loss:             0.0006968180338541666\n",
      "    separation loss:          2.181243896484375\n",
      "    avg separation loss:      2.919508457183838\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  0.013630046509206295\n",
      "    train time:               0.06354522705078125\n",
      "    test time:                0.008485794067382812\n",
      "    epoch time:               0.07243585586547852\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 110 (21/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0014414931974897627\n",
      "    train cross_ent loss:     1.3938943197899789e-05\n",
      "    test overall loss:        0.0014348385157063603\n",
      "    test cross_ent loss:      1.108175668681118e-05\n",
      "    cluster loss:             0.000701904296875\n",
      "    separation loss:          2.1803436279296875\n",
      "    avg separation loss:      2.9168991247812905\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  0.009244844317436218\n",
      "    train time:               0.06453728675842285\n",
      "    test time:                0.008560419082641602\n",
      "    epoch time:               0.07350420951843262\n",
      "    last layer lr:            0.007624000000000002\n",
      "epoch: 110 (22/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0014361162066052202\n",
      "    train cross_ent loss:     1.2327555538149682e-05\n",
      "    test overall loss:        0.0014379295753315091\n",
      "    test cross_ent loss:      1.0278916003395958e-05\n",
      "    cluster loss:             0.0006968180338541666\n",
      "    separation loss:          2.1823883056640625\n",
      "    avg separation loss:      2.919210354487101\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  0.013138698413968086\n",
      "    train time:               0.06211137771606445\n",
      "    test time:                0.00849008560180664\n",
      "    epoch time:               0.07104825973510742\n",
      "    last layer lr:            0.007228000000000001\n",
      "epoch: 110 (23/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.001440700150851626\n",
      "    train cross_ent loss:     1.3597863798509024e-05\n",
      "    test overall loss:        0.0014394513176133235\n",
      "    test cross_ent loss:      1.007318223855691e-05\n",
      "    cluster loss:             0.0007120768229166666\n",
      "    separation loss:          2.1828816731770835\n",
      "    avg separation loss:      2.916277011235555\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  0.014866185374557972\n",
      "    train time:               0.062389373779296875\n",
      "    test time:                0.008538246154785156\n",
      "    epoch time:               0.07138442993164062\n",
      "    last layer lr:            0.006832000000000001\n",
      "epoch: 110 (24/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0014365186289069243\n",
      "    train cross_ent loss:     1.084899183467769e-05\n",
      "    test overall loss:        0.001432778003315131\n",
      "    test cross_ent loss:      9.102135967016997e-06\n",
      "    cluster loss:             0.000732421875\n",
      "    separation loss:          2.1792500813802085\n",
      "    avg separation loss:      2.92087984085083\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  0.009163904935121536\n",
      "    train time:               0.06374740600585938\n",
      "    test time:                0.008727073669433594\n",
      "    epoch time:               0.07293319702148438\n",
      "    last layer lr:            0.006436\n",
      "epoch: 110 (25/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0014333059334603604\n",
      "    train cross_ent loss:     1.037564827299775e-05\n",
      "    test overall loss:        0.0014312840066850185\n",
      "    test cross_ent loss:      8.533220958876578e-06\n",
      "    cluster loss:             0.0007120768229166666\n",
      "    separation loss:          2.1796417236328125\n",
      "    avg separation loss:      2.9162892500559487\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  0.008238843642175198\n",
      "    train time:               0.06387710571289062\n",
      "    test time:                0.008695602416992188\n",
      "    epoch time:               0.07303595542907715\n",
      "    last layer lr:            0.00604\n",
      "epoch: 110 (26/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0014347372380143497\n",
      "    train cross_ent loss:     1.0403237553191502e-05\n",
      "    test overall loss:        0.0014316208738212783\n",
      "    test cross_ent loss:      7.880428711359855e-06\n",
      "    cluster loss:             0.0007069905598958334\n",
      "    separation loss:          2.180486043294271\n",
      "    avg separation loss:      2.920281092325846\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  0.00922849215567112\n",
      "    train time:               0.06401920318603516\n",
      "    test time:                0.008635997772216797\n",
      "    epoch time:               0.07310795783996582\n",
      "    last layer lr:            0.005644000000000002\n",
      "epoch: 110 (27/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0014315752378024627\n",
      "    train cross_ent loss:     8.923981312136675e-06\n",
      "    test overall loss:        0.0014292425864065688\n",
      "    test cross_ent loss:      7.529945378337288e-06\n",
      "    cluster loss:             0.0006917317708333334\n",
      "    separation loss:          2.179987589518229\n",
      "    avg separation loss:      2.9180641969045005\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  0.007200728170573711\n",
      "    train time:               0.06517767906188965\n",
      "    test time:                0.008534908294677734\n",
      "    epoch time:               0.07415151596069336\n",
      "    last layer lr:            0.005248\n",
      "epoch: 110 (28/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0014289329192251898\n",
      "    train cross_ent loss:     8.142958833445846e-06\n",
      "    test overall loss:        0.001427305202620725\n",
      "    test cross_ent loss:      7.341821553078868e-06\n",
      "    cluster loss:             0.0007120768229166666\n",
      "    separation loss:          2.1792805989583335\n",
      "    avg separation loss:      2.916328271230062\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  0.005451442673802376\n",
      "    train time:               0.06233978271484375\n",
      "    test time:                0.00854802131652832\n",
      "    epoch time:               0.0713047981262207\n",
      "    last layer lr:            0.004852000000000001\n",
      "epoch: 110 (29/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0014292390806076583\n",
      "    train cross_ent loss:     8.281711473046016e-06\n",
      "    test overall loss:        0.0014270324415216844\n",
      "    test cross_ent loss:      7.018883176594197e-06\n",
      "    cluster loss:             0.0006968180338541666\n",
      "    separation loss:          2.181915283203125\n",
      "    avg separation loss:      2.917992909749349\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  0.005501626990735531\n",
      "    train time:               0.06290006637573242\n",
      "    test time:                0.008569478988647461\n",
      "    epoch time:               0.0719003677368164\n",
      "    last layer lr:            0.004455999999999999\n",
      "epoch: 110 (30/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0014283425880421419\n",
      "    train cross_ent loss:     7.369042720029029e-06\n",
      "    test overall loss:        0.0014284371475999553\n",
      "    test cross_ent loss:      6.796949492127169e-06\n",
      "    cluster loss:             0.0007069905598958334\n",
      "    separation loss:          2.181493123372396\n",
      "    avg separation loss:      2.9174588521321616\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  0.007128242868930101\n",
      "    train time:               0.0631401538848877\n",
      "    test time:                0.008530139923095703\n",
      "    epoch time:               0.07209587097167969\n",
      "    last layer lr:            0.004060000000000001\n",
      "epoch: 110 (31/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0014275572248152457\n",
      "    train cross_ent loss:     7.200941979590425e-06\n",
      "    test overall loss:        0.0014284276015435655\n",
      "    test cross_ent loss:      6.574873168574413e-06\n",
      "    cluster loss:             0.000701904296875\n",
      "    separation loss:          2.180384318033854\n",
      "    avg separation loss:      2.916783571243286\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  0.007340784650295973\n",
      "    train time:               0.06287550926208496\n",
      "    test time:                0.008615493774414062\n",
      "    epoch time:               0.07189226150512695\n",
      "    last layer lr:            0.0036640000000000015\n",
      "epoch: 110 (32/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0014278098424256314\n",
      "    train cross_ent loss:     7.927011594688338e-06\n",
      "    test overall loss:        0.0014261480343217652\n",
      "    test cross_ent loss:      6.289665482957692e-06\n",
      "    cluster loss:             0.0006866455078125\n",
      "    separation loss:          2.180384318033854\n",
      "    avg separation loss:      2.9186501502990723\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  0.005346450489014387\n",
      "    train time:               0.06346654891967773\n",
      "    test time:                0.00850820541381836\n",
      "    epoch time:               0.0723869800567627\n",
      "    last layer lr:            0.0032679999999999996\n",
      "epoch: 110 (33/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0014280772520578466\n",
      "    train cross_ent loss:     8.010941940028715e-06\n",
      "    test overall loss:        0.0014252658390129607\n",
      "    test cross_ent loss:      6.132047625821239e-06\n",
      "    cluster loss:             0.0006968180338541666\n",
      "    separation loss:          2.1802520751953125\n",
      "    avg separation loss:      2.9179514249165854\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  0.004621883854269981\n",
      "    train time:               0.06400895118713379\n",
      "    test time:                0.008523225784301758\n",
      "    epoch time:               0.07297086715698242\n",
      "    last layer lr:            0.002872000000000001\n",
      "epoch: 110 (34/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.001426686085324036\n",
      "    train cross_ent loss:     7.28254244108939e-06\n",
      "    test overall loss:        0.0014257862543066342\n",
      "    test cross_ent loss:      5.942566986050224e-06\n",
      "    cluster loss:             0.000701904296875\n",
      "    separation loss:          2.180842081705729\n",
      "    avg separation loss:      2.9191694259643555\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  0.0053317430429160595\n",
      "    train time:               0.06211996078491211\n",
      "    test time:                0.00861668586730957\n",
      "    epoch time:               0.07117509841918945\n",
      "    last layer lr:            0.0024759999999999986\n",
      "epoch: 110 (35/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0014247042199713178\n",
      "    train cross_ent loss:     7.287545358281022e-06\n",
      "    test overall loss:        0.0014231397847955425\n",
      "    test cross_ent loss:      5.974965915811481e-06\n",
      "    cluster loss:             0.0007120768229166666\n",
      "    separation loss:          2.1800384521484375\n",
      "    avg separation loss:      2.917017380396525\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  0.0026528919115662575\n",
      "    train time:               0.061868906021118164\n",
      "    test time:                0.008609771728515625\n",
      "    epoch time:               0.0709085464477539\n",
      "    last layer lr:            0.0020800000000000003\n",
      "epoch: 110 (36/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.001425581271178089\n",
      "    train cross_ent loss:     8.449580363389941e-06\n",
      "    test overall loss:        0.0014244373887777328\n",
      "    test cross_ent loss:      5.817686693868988e-06\n",
      "    cluster loss:             0.0006917317708333334\n",
      "    separation loss:          2.180486043294271\n",
      "    avg separation loss:      2.917604923248291\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  0.004107778426259756\n",
      "    train time:               0.06438899040222168\n",
      "    test time:                0.008589744567871094\n",
      "    epoch time:               0.0734105110168457\n",
      "    last layer lr:            0.0016840000000000017\n",
      "epoch: 110 (37/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.001424709025741322\n",
      "    train cross_ent loss:     6.881144869907985e-06\n",
      "    test overall loss:        0.001423194616412123\n",
      "    test cross_ent loss:      5.675252244448832e-06\n",
      "    cluster loss:             0.0007120768229166666\n",
      "    separation loss:          2.1803436279296875\n",
      "    avg separation loss:      2.9205912748972573\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  0.0030074454843997955\n",
      "    train time:               0.06418228149414062\n",
      "    test time:                0.00871419906616211\n",
      "    epoch time:               0.07334256172180176\n",
      "    last layer lr:            0.0012879999999999994\n",
      "epoch: 110 (38/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0014234890295483638\n",
      "    train cross_ent loss:     6.362409671112346e-06\n",
      "    test overall loss:        0.0014221031839648883\n",
      "    test cross_ent loss:      5.592958586930763e-06\n",
      "    cluster loss:             0.000701904296875\n",
      "    separation loss:          2.180842081705729\n",
      "    avg separation loss:      2.918697992960612\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  0.0019983050879091024\n",
      "    train time:               0.0634009838104248\n",
      "    test time:                0.008580446243286133\n",
      "    epoch time:               0.07246184349060059\n",
      "    last layer lr:            0.0008920000000000009\n",
      "epoch: 110 (39/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0014219205622794107\n",
      "    train cross_ent loss:     5.693263091188783e-06\n",
      "    test overall loss:        0.0014212611907472212\n",
      "    test cross_ent loss:      5.6830987584059285e-06\n",
      "    cluster loss:             0.000701904296875\n",
      "    separation loss:          2.180536905924479\n",
      "    avg separation loss:      2.9178593158721924\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  0.0010661963606253266\n",
      "    train time:               0.06473040580749512\n",
      "    test time:                0.008786678314208984\n",
      "    epoch time:               0.07397079467773438\n",
      "    last layer lr:            0.0004959999999999986\n",
      "epoch: 110 (40/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0014231830355129205\n",
      "    train cross_ent loss:     7.928985908733921e-06\n",
      "    test overall loss:        0.0014209732956563432\n",
      "    test cross_ent loss:      5.555959281385488e-06\n",
      "    cluster loss:             0.0006917317708333334\n",
      "    separation loss:          2.181096394856771\n",
      "    avg separation loss:      2.919417222340902\n",
      "    l1_addon loss:            4.7150397300720215\n",
      "    l1 loss:                  0.0009053669637069106\n",
      "    train time:               0.06490778923034668\n",
      "    test time:                0.008506059646606445\n",
      "    epoch time:               0.07383513450622559\n",
      "    last layer lr:            0.0001\n",
      "epoch: 111 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0014220796765584964\n",
      "    train cross_ent loss:     6.651232908438942e-06\n",
      "    test overall loss:        0.0014205963040391605\n",
      "    test cross_ent loss:      5.796437108074315e-06\n",
      "    cluster loss:             0.0007171630859375\n",
      "    separation loss:          2.180272420247396\n",
      "    avg separation loss:      2.9176084995269775\n",
      "    l1_addon loss:            4.712981224060059\n",
      "    l1 loss:                  0.0009053669637069106\n",
      "    train time:               0.1523725986480713\n",
      "    test time:                0.008729696273803711\n",
      "    epoch time:               0.1616811752319336\n",
      "    joint lr:                 0.0017196383771408863\n",
      "epoch: 112 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0014188451823429205\n",
      "    train cross_ent loss:     6.681731392177426e-06\n",
      "    test overall loss:        0.0014130840233216684\n",
      "    test cross_ent loss:      5.555140736153892e-06\n",
      "    cluster loss:             0.0007222493489583334\n",
      "    separation loss:          2.1756998697916665\n",
      "    avg separation loss:      2.9136242071787515\n",
      "    l1_addon loss:            4.688745021820068\n",
      "    l1 loss:                  0.0009053669637069106\n",
      "    train time:               0.13962221145629883\n",
      "    test time:                0.008515357971191406\n",
      "    epoch time:               0.148634672164917\n",
      "    joint lr:                 0.0033068839867389757\n",
      "epoch: 113 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0014101461492828093\n",
      "    train cross_ent loss:     6.9445919308464e-06\n",
      "    test overall loss:        0.0014041320343191426\n",
      "    test cross_ent loss:      7.028249001450604e-06\n",
      "    cluster loss:             0.0008290608723958334\n",
      "    separation loss:          2.172515869140625\n",
      "    avg separation loss:      2.9032441775004068\n",
      "    l1_addon loss:            4.653994560241699\n",
      "    l1 loss:                  0.0009053669637069106\n",
      "    train time:               0.14223337173461914\n",
      "    test time:                0.008646011352539062\n",
      "    epoch time:               0.1513688564300537\n",
      "    joint lr:                 0.0048622227203073696\n",
      "epoch: 114 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0014002558345964644\n",
      "    train cross_ent loss:     7.767389533341884e-06\n",
      "    test overall loss:        0.0013936929171904922\n",
      "    test cross_ent loss:      7.735907577928932e-06\n",
      "    cluster loss:             0.0009562174479166666\n",
      "    separation loss:          2.162994384765625\n",
      "    avg separation loss:      2.900148789087931\n",
      "    l1_addon loss:            4.616838455200195\n",
      "    l1 loss:                  0.0009053669637069106\n",
      "    train time:               0.13889002799987793\n",
      "    test time:                0.008817434310913086\n",
      "    epoch time:               0.14828085899353027\n",
      "    joint lr:                 0.00638613399080572\n",
      "epoch: 115 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0013889372021367308\n",
      "    train cross_ent loss:     8.116647208566974e-06\n",
      "    test overall loss:        0.0013805289830391605\n",
      "    test cross_ent loss:      7.631569890994191e-06\n",
      "    cluster loss:             0.0009256998697916666\n",
      "    separation loss:          2.1530049641927085\n",
      "    avg separation loss:      2.8863472938537598\n",
      "    l1_addon loss:            4.573306560516357\n",
      "    l1 loss:                  0.0009053669637069106\n",
      "    train time:               0.138810396194458\n",
      "    test time:                0.008539199829101562\n",
      "    epoch time:               0.1478424072265625\n",
      "    joint lr:                 0.007879090813622073\n",
      "epoch: 116 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.001374506959109567\n",
      "    train cross_ent loss:     7.850868357195395e-06\n",
      "    test overall loss:        0.0013656920831029613\n",
      "    test cross_ent loss:      8.490123794520818e-06\n",
      "    cluster loss:             0.0009816487630208333\n",
      "    separation loss:          2.1398468017578125\n",
      "    avg separation loss:      2.8735528786977134\n",
      "    l1_addon loss:            4.520988464355469\n",
      "    l1 loss:                  0.0009053669637069106\n",
      "    train time:               0.15360713005065918\n",
      "    test time:                0.008672714233398438\n",
      "    epoch time:               0.16280889511108398\n",
      "    joint lr:                 0.009341559886583039\n",
      "epoch: 117 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0013599637313745916\n",
      "    train cross_ent loss:     9.37855774907348e-06\n",
      "    test overall loss:        0.001348233820560078\n",
      "    test cross_ent loss:      8.524461766986255e-06\n",
      "    cluster loss:             0.0009206136067708334\n",
      "    separation loss:          2.1232452392578125\n",
      "    avg separation loss:      2.857476075490316\n",
      "    l1_addon loss:            4.462679862976074\n",
      "    l1 loss:                  0.0009053669637069106\n",
      "    train time:               0.14912676811218262\n",
      "    test time:                0.008684635162353516\n",
      "    epoch time:               0.15836548805236816\n",
      "    joint lr:                 0.010774001669003403\n",
      "epoch: 118 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0013397903785516974\n",
      "    train cross_ent loss:     8.059375872448982e-06\n",
      "    test overall loss:        0.0013279768948753674\n",
      "    test cross_ent loss:      8.688067434074279e-06\n",
      "    cluster loss:             0.0009714762369791666\n",
      "    separation loss:          2.106012980143229\n",
      "    avg separation loss:      2.8419085343678794\n",
      "    l1_addon loss:            4.394611358642578\n",
      "    l1 loss:                  0.0009053669637069106\n",
      "    train time:               0.13858962059020996\n",
      "    test time:                0.008658885955810547\n",
      "    epoch time:               0.14775538444519043\n",
      "    joint lr:                 0.012176870459786701\n",
      "epoch: 119 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0013189434976084158\n",
      "    train cross_ent loss:     8.434105239985001e-06\n",
      "    test overall loss:        0.0013057958567515016\n",
      "    test cross_ent loss:      8.233561402448686e-06\n",
      "    cluster loss:             0.0009358723958333334\n",
      "    separation loss:          2.0856170654296875\n",
      "    avg separation loss:      2.825214465459188\n",
      "    l1_addon loss:            4.3221893310546875\n",
      "    l1 loss:                  0.0009053669637069106\n",
      "    train time:               0.13653016090393066\n",
      "    test time:                0.008512020111083984\n",
      "    epoch time:               0.14554214477539062\n",
      "    joint lr:                 0.013550614474587434\n",
      "epoch: 120 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0012970908064744435\n",
      "    train cross_ent loss:     8.656216976987707e-06\n",
      "    test overall loss:        0.0012826464759806793\n",
      "    test cross_ent loss:      8.461134105649156e-06\n",
      "    cluster loss:             0.0009256998697916666\n",
      "    separation loss:          2.0674031575520835\n",
      "    avg separation loss:      2.8059539794921875\n",
      "    l1_addon loss:            4.244266510009766\n",
      "    l1 loss:                  0.0009053669637069106\n",
      "    train time:               0.14760088920593262\n",
      "    test time:                0.008685111999511719\n",
      "    epoch time:               0.1568470001220703\n",
      "    joint lr:                 0.014895675922046181\n",
      "epoch: 121 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0012737239230773412\n",
      "    train cross_ent loss:     8.253085255205406e-06\n",
      "    test overall loss:        0.0012611824398239453\n",
      "    test cross_ent loss:      8.381778570765164e-06\n",
      "    cluster loss:             0.0009206136067708334\n",
      "    separation loss:          2.0479278564453125\n",
      "    avg separation loss:      2.790468374888102\n",
      "    l1_addon loss:            4.1729841232299805\n",
      "    l1 loss:                  0.0009053669637069106\n",
      "    train time:               0.15320897102355957\n",
      "    test time:                0.008661985397338867\n",
      "    epoch time:               0.16266703605651855\n",
      "    joint lr:                 0.014015333204684437\n",
      "epoch: 122 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0012502332901931368\n",
      "    train cross_ent loss:     9.794010836117195e-06\n",
      "    test overall loss:        0.0012364624223361413\n",
      "    test cross_ent loss:      8.937369178359708e-06\n",
      "    cluster loss:             0.0009307861328125\n",
      "    separation loss:          2.0296529134114585\n",
      "    avg separation loss:      2.772253672281901\n",
      "    l1_addon loss:            4.0887322425842285\n",
      "    l1 loss:                  0.0009053669637069106\n",
      "    train time:               0.1558678150177002\n",
      "    test time:                0.008732080459594727\n",
      "    epoch time:               0.16513633728027344\n",
      "    joint lr:                 0.01315111777407772\n",
      "epoch: 123 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0012260998155397829\n",
      "    train cross_ent loss:     8.668193842709115e-06\n",
      "    test overall loss:        0.0012131395827357967\n",
      "    test cross_ent loss:      9.154871198309896e-06\n",
      "    cluster loss:             0.0009002685546875\n",
      "    separation loss:          2.0119832356770835\n",
      "    avg separation loss:      2.7573138078053794\n",
      "    l1_addon loss:            4.0102643966674805\n",
      "    l1 loss:                  0.0009053669637069106\n",
      "    train time:               0.15796661376953125\n",
      "    test time:                0.008697032928466797\n",
      "    epoch time:               0.16721487045288086\n",
      "    joint lr:                 0.012302795118762673\n",
      "epoch: 124 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0012060565641149879\n",
      "    train cross_ent loss:     1.0306435356710608e-05\n",
      "    test overall loss:        0.001194704867278536\n",
      "    test cross_ent loss:      8.696888320021875e-06\n",
      "    cluster loss:             0.0008494059244791666\n",
      "    separation loss:          1.9980570475260417\n",
      "    avg separation loss:      2.7417434056599936\n",
      "    l1_addon loss:            3.9503417015075684\n",
      "    l1 loss:                  0.0009053669637069106\n",
      "    train time:               0.15016961097717285\n",
      "    test time:                0.008511781692504883\n",
      "    epoch time:               0.15918445587158203\n",
      "    joint lr:                 0.011470133804776505\n",
      "epoch: 125 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0011847340501844883\n",
      "    train cross_ent loss:     8.637358419605334e-06\n",
      "    test overall loss:        0.001173848829542597\n",
      "    test cross_ent loss:      8.513757014346387e-06\n",
      "    cluster loss:             0.0008544921875\n",
      "    separation loss:          1.983795166015625\n",
      "    avg separation loss:      2.7281559308369956\n",
      "    l1_addon loss:            3.881432294845581\n",
      "    l1 loss:                  0.0009053669637069106\n",
      "    train time:               0.14505410194396973\n",
      "    test time:                0.008681297302246094\n",
      "    epoch time:               0.15424537658691406\n",
      "    joint lr:                 0.010652905437558197\n",
      "epoch: 126 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0011653092442429624\n",
      "    train cross_ent loss:     8.651329892472859e-06\n",
      "    test overall loss:        0.0011548434849828482\n",
      "    test cross_ent loss:      8.77517307647698e-06\n",
      "    cluster loss:             0.0008697509765625\n",
      "    separation loss:          1.9712371826171875\n",
      "    avg separation loss:      2.7164812882741294\n",
      "    l1_addon loss:            3.8172097206115723\n",
      "    l1 loss:                  0.0009053669637069106\n",
      "    train time:               0.1547849178314209\n",
      "    test time:                0.008667707443237305\n",
      "    epoch time:               0.16418766975402832\n",
      "    joint lr:                 0.009850884624303774\n",
      "epoch: 127 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0011469495002529584\n",
      "    train cross_ent loss:     8.793005136453758e-06\n",
      "    test overall loss:        0.0011396934666360419\n",
      "    test cross_ent loss:      9.209632329050995e-06\n",
      "    cluster loss:             0.0008595784505208334\n",
      "    separation loss:          1.9615580240885417\n",
      "    avg separation loss:      2.704322655995687\n",
      "    l1_addon loss:            3.765261173248291\n",
      "    l1 loss:                  0.0009053669637069106\n",
      "    train time:               0.1450347900390625\n",
      "    test time:                0.008680582046508789\n",
      "    epoch time:               0.15425324440002441\n",
      "    joint lr:                 0.00906384893677068\n",
      "epoch: 128 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0011299661855446175\n",
      "    train cross_ent loss:     8.290444100111927e-06\n",
      "    test overall loss:        0.0011226960535471637\n",
      "    test cross_ent loss:      9.043444303339735e-06\n",
      "    cluster loss:             0.0008748372395833334\n",
      "    separation loss:          1.951080322265625\n",
      "    avg separation loss:      2.694276730219523\n",
      "    l1_addon loss:            3.7091572284698486\n",
      "    l1 loss:                  0.0009053669637069106\n",
      "    train time:               0.14555954933166504\n",
      "    test time:                0.008697986602783203\n",
      "    epoch time:               0.1548140048980713\n",
      "    joint lr:                 0.00829157887452582\n",
      "epoch: 129 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0011153034065500833\n",
      "    train cross_ent loss:     8.98611907018676e-06\n",
      "    test overall loss:        0.0011074724995220702\n",
      "    test cross_ent loss:      8.769131757920453e-06\n",
      "    cluster loss:             0.0008951822916666666\n",
      "    separation loss:          1.9451395670572917\n",
      "    avg separation loss:      2.691723903020223\n",
      "    l1_addon loss:            3.6593263149261475\n",
      "    l1 loss:                  0.0009053669637069106\n",
      "    train time:               0.14446592330932617\n",
      "    test time:                0.008754491806030273\n",
      "    epoch time:               0.15373969078063965\n",
      "    joint lr:                 0.007533857828632187\n",
      "epoch: 130 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.001102875390643021\n",
      "    train cross_ent loss:     9.233944467723632e-06\n",
      "    test overall loss:        0.0010957401633883517\n",
      "    test cross_ent loss:      8.464021448162384e-06\n",
      "    cluster loss:             0.0008341471354166666\n",
      "    separation loss:          1.935638427734375\n",
      "    avg separation loss:      2.679980436960856\n",
      "    l1_addon loss:            3.6212356090545654\n",
      "    l1 loss:                  0.0009053669637069106\n",
      "    train time:               0.14724326133728027\n",
      "    test time:                0.008638143539428711\n",
      "    epoch time:               0.15642118453979492\n",
      "    joint lr:                 0.00679047204576897\n",
      "epoch: 131 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010904586015385576\n",
      "    train cross_ent loss:     9.089961750419207e-06\n",
      "    test overall loss:        0.0010838313416267435\n",
      "    test cross_ent loss:      7.800680123182246e-06\n",
      "    cluster loss:             0.0008290608723958334\n",
      "    separation loss:          1.9283447265625\n",
      "    avg separation loss:      2.672110080718994\n",
      "    l1_addon loss:            3.5837507247924805\n",
      "    l1 loss:                  0.0009053669637069106\n",
      "    train time:               0.14472222328186035\n",
      "    test time:                0.008702993392944336\n",
      "    epoch time:               0.15396595001220703\n",
      "    joint lr:                 0.006061210592780146\n",
      "epoch: 132 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010801147618622053\n",
      "    train cross_ent loss:     9.236765592390839e-06\n",
      "    test overall loss:        0.0010747706595187385\n",
      "    test cross_ent loss:      8.187226436954612e-06\n",
      "    cluster loss:             0.000762939453125\n",
      "    separation loss:          1.9226328531901042\n",
      "    avg separation loss:      2.6623762448628745\n",
      "    l1_addon loss:            3.552259922027588\n",
      "    l1 loss:                  0.0009053669637069106\n",
      "    train time:               0.14833950996398926\n",
      "    test time:                0.008635759353637695\n",
      "    epoch time:               0.15749287605285645\n",
      "    joint lr:                 0.005345865321646531\n",
      "epoch: 133 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010703801453928463\n",
      "    train cross_ent loss:     8.313473500720647e-06\n",
      "    test overall loss:        0.0010660556533063452\n",
      "    test cross_ent loss:      8.434323262918042e-06\n",
      "    cluster loss:             0.0007832845052083334\n",
      "    separation loss:          1.9179738362630208\n",
      "    avg separation loss:      2.656604448954264\n",
      "    l1_addon loss:            3.5223865509033203\n",
      "    l1 loss:                  0.0009053669637069106\n",
      "    train time:               0.14340686798095703\n",
      "    test time:                0.008580684661865234\n",
      "    epoch time:               0.1524951457977295\n",
      "    joint lr:                 0.00464423083487631\n",
      "epoch: 134 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010623690723150503\n",
      "    train cross_ent loss:     8.653760716015313e-06\n",
      "    test overall loss:        0.00105834542773664\n",
      "    test cross_ent loss:      8.040252547895458e-06\n",
      "    cluster loss:             0.00079345703125\n",
      "    separation loss:          1.9148661295572917\n",
      "    avg separation loss:      2.653543551762899\n",
      "    l1_addon loss:            3.497999429702759\n",
      "    l1 loss:                  0.0009053669637069106\n",
      "    train time:               0.13340520858764648\n",
      "    test time:                0.008621931076049805\n",
      "    epoch time:               0.1425471305847168\n",
      "    joint lr:                 0.003956104451309328\n",
      "epoch: 135 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010539541253820062\n",
      "    train cross_ent loss:     7.4235146456658185e-06\n",
      "    test overall loss:        0.0010512717223415773\n",
      "    test cross_ent loss:      7.896617413886512e-06\n",
      "    cluster loss:             0.000823974609375\n",
      "    separation loss:          1.9098103841145833\n",
      "    avg separation loss:      2.6493690808614097\n",
      "    l1_addon loss:            3.4748990535736084\n",
      "    l1 loss:                  0.0009053669637069106\n",
      "    train time:               0.1439359188079834\n",
      "    test time:                0.00872492790222168\n",
      "    epoch time:               0.15318799018859863\n",
      "    joint lr:                 0.0032812861723301896\n",
      "epoch: 136 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010487953550182283\n",
      "    train cross_ent loss:     8.473431591937697e-06\n",
      "    test overall loss:        0.0010459901144107182\n",
      "    test cross_ent loss:      8.063006437926864e-06\n",
      "    cluster loss:             0.0007985432942708334\n",
      "    separation loss:          1.90667724609375\n",
      "    avg separation loss:      2.644396702448527\n",
      "    l1_addon loss:            3.4567389488220215\n",
      "    l1 loss:                  0.0009053669637069106\n",
      "    train time:               0.13931035995483398\n",
      "    test time:                0.008668899536132812\n",
      "    epoch time:               0.14850521087646484\n",
      "    joint lr:                 0.0026195786484855114\n",
      "epoch: 137 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010434394898766186\n",
      "    train cross_ent loss:     8.323967094270301e-06\n",
      "    test overall loss:        0.001041552556368212\n",
      "    test cross_ent loss:      8.356928901775973e-06\n",
      "    cluster loss:             0.0008646647135416666\n",
      "    separation loss:          1.9044596354166667\n",
      "    avg separation loss:      2.6459227403004966\n",
      "    l1_addon loss:            3.440967321395874\n",
      "    l1 loss:                  0.0009053669637069106\n",
      "    train time:               0.15390396118164062\n",
      "    test time:                0.008582115173339844\n",
      "    epoch time:               0.1631007194519043\n",
      "    joint lr:                 0.0019707871465004943\n",
      "epoch: 138 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010393690026830882\n",
      "    train cross_ent loss:     8.194985937848287e-06\n",
      "    test overall loss:        0.0010370359135170777\n",
      "    test cross_ent loss:      7.678239853703417e-06\n",
      "    cluster loss:             0.0007731119791666666\n",
      "    separation loss:          1.9022725423177083\n",
      "    avg separation loss:      2.639359394709269\n",
      "    l1_addon loss:            3.4281740188598633\n",
      "    l1 loss:                  0.0009053669637069106\n",
      "    train time:               0.15020370483398438\n",
      "    test time:                0.008679389953613281\n",
      "    epoch time:               0.15946245193481445\n",
      "    joint lr:                 0.0013347195166903292\n",
      "epoch: 139 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.001035824796417728\n",
      "    train cross_ent loss:     8.400565405963789e-06\n",
      "    test overall loss:        0.0010337050383289654\n",
      "    test cross_ent loss:      7.523870256894345e-06\n",
      "    cluster loss:             0.00079345703125\n",
      "    separation loss:          1.90179443359375\n",
      "    avg separation loss:      2.63911501566569\n",
      "    l1_addon loss:            3.417585849761963\n",
      "    l1 loss:                  0.0009053669637069106\n",
      "    train time:               0.15631747245788574\n",
      "    test time:                0.008699178695678711\n",
      "    epoch time:               0.16556596755981445\n",
      "    joint lr:                 0.0007111861607617089\n",
      "epoch: 140 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010329555407224689\n",
      "    train cross_ent loss:     8.3637800400993e-06\n",
      "    test overall loss:        0.0010317985822136204\n",
      "    test cross_ent loss:      8.001370588317513e-06\n",
      "    cluster loss:             0.0007680257161458334\n",
      "    separation loss:          1.9005533854166667\n",
      "    avg separation loss:      2.635190010070801\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.0009053669637069106\n",
      "    train time:               0.1525890827178955\n",
      "    test time:                0.008637666702270508\n",
      "    epoch time:               0.16176962852478027\n",
      "    joint lr:                 0.0001\n",
      "epoch: 140 (PUSH) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010329555407224689\n",
      "    train cross_ent loss:     8.3637800400993e-06\n",
      "    test overall loss:        0.001033556298352778\n",
      "    test cross_ent loss:      9.759106433193665e-06\n",
      "    cluster loss:             0.0008341471354166666\n",
      "    separation loss:          1.9013570149739583\n",
      "    avg separation loss:      2.635451157887777\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.0009053669637069106\n",
      "    train time:               0.1525890827178955\n",
      "    test time:                0.008785009384155273\n",
      "    epoch time:               0.06316089630126953\n",
      "epoch: 140 (1/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010337020648876205\n",
      "    train cross_ent loss:     1.0489021690318623e-05\n",
      "    test overall loss:        0.00103240836566935\n",
      "    test cross_ent loss:      9.32199554881663e-06\n",
      "    cluster loss:             0.000885009765625\n",
      "    separation loss:          1.9032948811848958\n",
      "    avg separation loss:      2.640997330347697\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.00019454558787401766\n",
      "    train time:               0.061757802963256836\n",
      "    test time:                0.008690357208251953\n",
      "    epoch time:               0.0708770751953125\n",
      "    last layer lr:            0.0007599999999999978\n",
      "epoch: 140 (2/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010356876082369126\n",
      "    train cross_ent loss:     1.1771795655590722e-05\n",
      "    test overall loss:        0.0010343037623291214\n",
      "    test cross_ent loss:      9.894566574075725e-06\n",
      "    cluster loss:             0.0008341471354166666\n",
      "    separation loss:          1.8998870849609375\n",
      "    avg separation loss:      2.63269837697347\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.0015173840802162886\n",
      "    train time:               0.06238579750061035\n",
      "    test time:                0.008469820022583008\n",
      "    epoch time:               0.0712888240814209\n",
      "    last layer lr:            0.0014199999999999955\n",
      "epoch: 140 (3/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010339685577491764\n",
      "    train cross_ent loss:     9.355165701663282e-06\n",
      "    test overall loss:        0.0010341018981610735\n",
      "    test cross_ent loss:      9.06930138929359e-06\n",
      "    cluster loss:             0.0008494059244791666\n",
      "    separation loss:          1.9020029703776042\n",
      "    avg separation loss:      2.6387411753336587\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.002140772994607687\n",
      "    train time:               0.06415438652038574\n",
      "    test time:                0.00863504409790039\n",
      "    epoch time:               0.0732419490814209\n",
      "    last layer lr:            0.0020800000000000046\n",
      "epoch: 140 (4/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010362539687776007\n",
      "    train cross_ent loss:     1.0823742158549976e-05\n",
      "    test overall loss:        0.0010343151710306604\n",
      "    test cross_ent loss:      9.239586385471435e-06\n",
      "    cluster loss:             0.0008341471354166666\n",
      "    separation loss:          1.9026387532552083\n",
      "    avg separation loss:      2.6371278762817383\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.002183774020522833\n",
      "    train time:               0.06323575973510742\n",
      "    test time:                0.008652687072753906\n",
      "    epoch time:               0.07233738899230957\n",
      "    last layer lr:            0.0027400000000000024\n",
      "epoch: 140 (5/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.001036857305734884\n",
      "    train cross_ent loss:     1.0565663501438394e-05\n",
      "    test overall loss:        0.0010362214331204693\n",
      "    test cross_ent loss:      9.18090305882894e-06\n",
      "    cluster loss:             0.0008341471354166666\n",
      "    separation loss:          1.9003550211588542\n",
      "    avg separation loss:      2.6331273714701333\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.004148697014898062\n",
      "    train time:               0.06460285186767578\n",
      "    test time:                0.00863027572631836\n",
      "    epoch time:               0.07370567321777344\n",
      "    last layer lr:            0.0034\n",
      "epoch: 140 (6/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010373840377724264\n",
      "    train cross_ent loss:     9.560274904174548e-06\n",
      "    test overall loss:        0.0010373676583791773\n",
      "    test cross_ent loss:      8.21132577281484e-06\n",
      "    cluster loss:             0.0008951822916666666\n",
      "    separation loss:          1.9046274820963542\n",
      "    avg separation loss:      2.6430563926696777\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.006264464929699898\n",
      "    train time:               0.06536316871643066\n",
      "    test time:                0.008558034896850586\n",
      "    epoch time:               0.07438898086547852\n",
      "    last layer lr:            0.004059999999999998\n",
      "epoch: 140 (7/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010372207434556913\n",
      "    train cross_ent loss:     8.217215679451328e-06\n",
      "    test overall loss:        0.0010361076177408297\n",
      "    test cross_ent loss:      7.622711412598922e-06\n",
      "    cluster loss:             0.0008494059244791666\n",
      "    separation loss:          1.9014994303385417\n",
      "    avg separation loss:      2.638822078704834\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.005593065172433853\n",
      "    train time:               0.06349372863769531\n",
      "    test time:                0.008577346801757812\n",
      "    epoch time:               0.07250785827636719\n",
      "    last layer lr:            0.004719999999999996\n",
      "epoch: 140 (8/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010384500783402473\n",
      "    train cross_ent loss:     8.23608104383311e-06\n",
      "    test overall loss:        0.0010380925377830863\n",
      "    test cross_ent loss:      7.506732345063938e-06\n",
      "    cluster loss:             0.0008341471354166666\n",
      "    separation loss:          1.9009246826171875\n",
      "    avg separation loss:      2.6356067657470703\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.007693995721638203\n",
      "    train time:               0.06270909309387207\n",
      "    test time:                0.00844430923461914\n",
      "    epoch time:               0.07159614562988281\n",
      "    last layer lr:            0.0053800000000000054\n",
      "epoch: 140 (9/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.001038558992149774\n",
      "    train cross_ent loss:     7.742018226508662e-06\n",
      "    test overall loss:        0.0010357007461910446\n",
      "    test cross_ent loss:      7.381863876313825e-06\n",
      "    cluster loss:             0.0008392333984375\n",
      "    separation loss:          1.9020894368489583\n",
      "    avg separation loss:      2.63564666112264\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.005427025258541107\n",
      "    train time:               0.06352591514587402\n",
      "    test time:                0.008631229400634766\n",
      "    epoch time:               0.07257270812988281\n",
      "    last layer lr:            0.006040000000000003\n",
      "epoch: 140 (10/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010364939116698224\n",
      "    train cross_ent loss:     7.028871365832856e-06\n",
      "    test overall loss:        0.001036638083557288\n",
      "    test cross_ent loss:      6.944621115205034e-06\n",
      "    cluster loss:             0.0008494059244791666\n",
      "    separation loss:          1.9003092447916667\n",
      "    avg separation loss:      2.6341856320699057\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.006801622919738293\n",
      "    train time:               0.0632472038269043\n",
      "    test time:                0.008631706237792969\n",
      "    epoch time:               0.07228517532348633\n",
      "    last layer lr:            0.0067\n",
      "epoch: 140 (11/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.001037804853694979\n",
      "    train cross_ent loss:     7.23538781244315e-06\n",
      "    test overall loss:        0.0010346394265070558\n",
      "    test cross_ent loss:      5.991830372901556e-06\n",
      "    cluster loss:             0.0008646647135416666\n",
      "    separation loss:          1.9008026123046875\n",
      "    avg separation loss:      2.6388702392578125\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.005755772814154625\n",
      "    train time:               0.06277060508728027\n",
      "    test time:                0.008504867553710938\n",
      "    epoch time:               0.07172131538391113\n",
      "    last layer lr:            0.0073599999999999985\n",
      "epoch: 140 (12/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010411982475488912\n",
      "    train cross_ent loss:     8.072045979190534e-06\n",
      "    test overall loss:        0.0010362939210608602\n",
      "    test cross_ent loss:      6.229771315702237e-06\n",
      "    cluster loss:             0.0008443196614583334\n",
      "    separation loss:          1.9019114176432292\n",
      "    avg separation loss:      2.6339794794718423\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.007172328885644674\n",
      "    train time:               0.0641329288482666\n",
      "    test time:                0.008572816848754883\n",
      "    epoch time:               0.07312750816345215\n",
      "    last layer lr:            0.008019999999999994\n",
      "epoch: 140 (13/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010394106975581963\n",
      "    train cross_ent loss:     5.348791574988354e-06\n",
      "    test overall loss:        0.001041905100767811\n",
      "    test cross_ent loss:      5.339201834431151e-06\n",
      "    cluster loss:             0.0008443196614583334\n",
      "    separation loss:          1.9001719156901042\n",
      "    avg separation loss:      2.6360105673472085\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.013674049638211727\n",
      "    train time:               0.06308722496032715\n",
      "    test time:                0.008618593215942383\n",
      "    epoch time:               0.07216906547546387\n",
      "    last layer lr:            0.008680000000000005\n",
      "epoch: 140 (14/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010397337064205203\n",
      "    train cross_ent loss:     5.814441898621681e-06\n",
      "    test overall loss:        0.0010379361920058727\n",
      "    test cross_ent loss:      5.157640468193374e-06\n",
      "    cluster loss:             0.0008341471354166666\n",
      "    separation loss:          1.9014638264973958\n",
      "    avg separation loss:      2.6349677244822183\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.00988670252263546\n",
      "    train time:               0.06275129318237305\n",
      "    test time:                0.008751392364501953\n",
      "    epoch time:               0.07194352149963379\n",
      "    last layer lr:            0.009340000000000003\n",
      "epoch: 140 (15/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010410566501377616\n",
      "    train cross_ent loss:     5.975321528239874e-06\n",
      "    test overall loss:        0.001037020158643524\n",
      "    test cross_ent loss:      4.771261349863683e-06\n",
      "    cluster loss:             0.0008443196614583334\n",
      "    separation loss:          1.9021250406901042\n",
      "    avg separation loss:      2.635929743448893\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.009357062168419361\n",
      "    train time:               0.06431031227111816\n",
      "    test time:                0.008643865585327148\n",
      "    epoch time:               0.07338476181030273\n",
      "    last layer lr:            0.01\n",
      "epoch: 140 (16/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010411603543616366\n",
      "    train cross_ent loss:     5.519672889420235e-06\n",
      "    test overall loss:        0.0010396698489785194\n",
      "    test cross_ent loss:      4.184686834681391e-06\n",
      "    cluster loss:             0.0008595784505208334\n",
      "    separation loss:          1.9008585611979167\n",
      "    avg separation loss:      2.6368869145711265\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.012593312188982964\n",
      "    train time:               0.06290912628173828\n",
      "    test time:                0.008569478988647461\n",
      "    epoch time:               0.07192111015319824\n",
      "    last layer lr:            0.009604000000000001\n",
      "epoch: 140 (17/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010397860496595968\n",
      "    train cross_ent loss:     4.667644660116821e-06\n",
      "    test overall loss:        0.0010377745299289625\n",
      "    test cross_ent loss:      3.8300530225872835e-06\n",
      "    cluster loss:             0.0008392333984375\n",
      "    separation loss:          1.9013926188151042\n",
      "    avg separation loss:      2.63657553990682\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.011052637360990047\n",
      "    train time:               0.06255006790161133\n",
      "    test time:                0.008730411529541016\n",
      "    epoch time:               0.07173728942871094\n",
      "    last layer lr:            0.009208000000000003\n",
      "epoch: 140 (18/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010364982263126876\n",
      "    train cross_ent loss:     3.71945454702427e-06\n",
      "    test overall loss:        0.001045522823308905\n",
      "    test cross_ent loss:      3.4774839908398767e-06\n",
      "    cluster loss:             0.0008341471354166666\n",
      "    separation loss:          1.8986358642578125\n",
      "    avg separation loss:      2.634380578994751\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.019153516739606857\n",
      "    train time:               0.06608772277832031\n",
      "    test time:                0.008547782897949219\n",
      "    epoch time:               0.07509350776672363\n",
      "    last layer lr:            0.008811999999999997\n",
      "epoch: 140 (19/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010400495411886368\n",
      "    train cross_ent loss:     4.2430799851445045e-06\n",
      "    test overall loss:        0.0010390308452770114\n",
      "    test cross_ent loss:      3.34703994061177e-06\n",
      "    cluster loss:             0.0008188883463541666\n",
      "    separation loss:          1.8992411295572917\n",
      "    avg separation loss:      2.633552074432373\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.0127919502556324\n",
      "    train time:               0.06469464302062988\n",
      "    test time:                0.008713483810424805\n",
      "    epoch time:               0.07387137413024902\n",
      "    last layer lr:            0.008415999999999998\n",
      "epoch: 140 (20/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.001036415280395886\n",
      "    train cross_ent loss:     3.680571509789843e-06\n",
      "    test overall loss:        0.001035594924663504\n",
      "    test cross_ent loss:      3.302310915387352e-06\n",
      "    cluster loss:             0.0008799235026041666\n",
      "    separation loss:          1.9028828938802083\n",
      "    avg separation loss:      2.639780600865682\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.009400763548910618\n",
      "    train time:               0.0657188892364502\n",
      "    test time:                0.008738517761230469\n",
      "    epoch time:               0.0749208927154541\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 140 (21/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010359765183238778\n",
      "    train cross_ent loss:     3.2103732827692966e-06\n",
      "    test overall loss:        0.0010372448014095426\n",
      "    test cross_ent loss:      3.049813055137444e-06\n",
      "    cluster loss:             0.0008900960286458334\n",
      "    separation loss:          1.9025115966796875\n",
      "    avg separation loss:      2.639735698699951\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.011303138919174671\n",
      "    train time:               0.06518030166625977\n",
      "    test time:                0.008570671081542969\n",
      "    epoch time:               0.07422471046447754\n",
      "    last layer lr:            0.007624000000000002\n",
      "epoch: 140 (22/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010365960151830222\n",
      "    train cross_ent loss:     3.7563510453253457e-06\n",
      "    test overall loss:        0.0010369123580555122\n",
      "    test cross_ent loss:      2.9236614409455797e-06\n",
      "    cluster loss:             0.0008544921875\n",
      "    separation loss:          1.9014638264973958\n",
      "    avg separation loss:      2.6375091870625815\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.011096893809735775\n",
      "    train time:               0.06346249580383301\n",
      "    test time:                0.00868368148803711\n",
      "    epoch time:               0.07261419296264648\n",
      "    last layer lr:            0.0072280000000000035\n",
      "epoch: 140 (23/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010357617684348952\n",
      "    train cross_ent loss:     3.1117703720440204e-06\n",
      "    test overall loss:        0.0010331431791807215\n",
      "    test cross_ent loss:      2.8680095359353195e-06\n",
      "    cluster loss:             0.0008697509765625\n",
      "    separation loss:          1.9007975260416667\n",
      "    avg separation loss:      2.637202024459839\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.0073833344504237175\n",
      "    train time:               0.06505846977233887\n",
      "    test time:                0.008682012557983398\n",
      "    epoch time:               0.07418084144592285\n",
      "    last layer lr:            0.006831999999999998\n",
      "epoch: 140 (24/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010345183400204405\n",
      "    train cross_ent loss:     2.904435849160336e-06\n",
      "    test overall loss:        0.0010325295540193717\n",
      "    test cross_ent loss:      2.5686039559028964e-06\n",
      "    cluster loss:             0.0008392333984375\n",
      "    separation loss:          1.9000447591145833\n",
      "    avg separation loss:      2.6358892917633057\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.007069074083119631\n",
      "    train time:               0.06247544288635254\n",
      "    test time:                0.008685588836669922\n",
      "    epoch time:               0.07161235809326172\n",
      "    last layer lr:            0.006436\n",
      "epoch: 140 (25/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010341502784285694\n",
      "    train cross_ent loss:     3.056008178958791e-06\n",
      "    test overall loss:        0.0010336970444768667\n",
      "    test cross_ent loss:      2.7152929457467203e-06\n",
      "    cluster loss:             0.0008341471354166666\n",
      "    separation loss:          1.9013926188151042\n",
      "    avg separation loss:      2.634645144144694\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.008089913055300713\n",
      "    train time:               0.06336283683776855\n",
      "    test time:                0.008715152740478516\n",
      "    epoch time:               0.07253694534301758\n",
      "    last layer lr:            0.00604\n",
      "epoch: 140 (26/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010330436962249223\n",
      "    train cross_ent loss:     3.143081833911765e-06\n",
      "    test overall loss:        0.0010330934698383014\n",
      "    test cross_ent loss:      2.963189520717909e-06\n",
      "    cluster loss:             0.0008443196614583334\n",
      "    separation loss:          1.9017791748046875\n",
      "    avg separation loss:      2.6332794030507407\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.007238450460135937\n",
      "    train time:               0.06331729888916016\n",
      "    test time:                0.008605241775512695\n",
      "    epoch time:               0.07235312461853027\n",
      "    last layer lr:            0.005644000000000002\n",
      "epoch: 140 (27/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010316859261365607\n",
      "    train cross_ent loss:     2.32760231000384e-06\n",
      "    test overall loss:        0.0010308855368445318\n",
      "    test cross_ent loss:      2.4035070585644767e-06\n",
      "    cluster loss:             0.0008646647135416666\n",
      "    separation loss:          1.9023488362630208\n",
      "    avg separation loss:      2.6385861237843833\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.005590210668742657\n",
      "    train time:               0.06438827514648438\n",
      "    test time:                0.00859975814819336\n",
      "    epoch time:               0.07344555854797363\n",
      "    last layer lr:            0.005248000000000003\n",
      "epoch: 140 (28/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010311515216017142\n",
      "    train cross_ent loss:     2.6846450360551444e-06\n",
      "    test overall loss:        0.0010298557269076507\n",
      "    test cross_ent loss:      2.5506779669134025e-06\n",
      "    cluster loss:             0.0008443196614583334\n",
      "    separation loss:          1.9021759033203125\n",
      "    avg separation loss:      2.6351511478424072\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.004413203336298466\n",
      "    train time:               0.062222957611083984\n",
      "    test time:                0.008620977401733398\n",
      "    epoch time:               0.07129263877868652\n",
      "    last layer lr:            0.004851999999999998\n",
      "epoch: 140 (29/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010323641108698212\n",
      "    train cross_ent loss:     3.1139633556165336e-06\n",
      "    test overall loss:        0.0010323725873604417\n",
      "    test cross_ent loss:      2.260537902050904e-06\n",
      "    cluster loss:             0.0008494059244791666\n",
      "    separation loss:          1.9001413981119792\n",
      "    avg separation loss:      2.6368780930836997\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.007220165804028511\n",
      "    train time:               0.06284546852111816\n",
      "    test time:                0.008710622787475586\n",
      "    epoch time:               0.07201123237609863\n",
      "    last layer lr:            0.004455999999999999\n",
      "epoch: 140 (30/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010314932878827676\n",
      "    train cross_ent loss:     2.6062975848617498e-06\n",
      "    test overall loss:        0.0010317417715365689\n",
      "    test cross_ent loss:      2.2640632172018136e-06\n",
      "    cluster loss:             0.0008188883463541666\n",
      "    separation loss:          1.9019622802734375\n",
      "    avg separation loss:      2.637371857961019\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.0065858690068125725\n",
      "    train time:               0.06428790092468262\n",
      "    test time:                0.008732318878173828\n",
      "    epoch time:               0.07347798347473145\n",
      "    last layer lr:            0.004060000000000001\n",
      "epoch: 140 (31/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.001031467782013351\n",
      "    train cross_ent loss:     2.7061806839867586e-06\n",
      "    test overall loss:        0.0010328523737067978\n",
      "    test cross_ent loss:      2.15685035224548e-06\n",
      "    cluster loss:             0.0008544921875\n",
      "    separation loss:          1.90185546875\n",
      "    avg separation loss:      2.6381072998046875\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.007803661748766899\n",
      "    train time:               0.06305789947509766\n",
      "    test time:                0.008549213409423828\n",
      "    epoch time:               0.07201409339904785\n",
      "    last layer lr:            0.0036640000000000015\n",
      "epoch: 140 (32/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010314967403246555\n",
      "    train cross_ent loss:     2.361129361361236e-06\n",
      "    test overall loss:        0.0010303543725361426\n",
      "    test cross_ent loss:      2.152106996315221e-06\n",
      "    cluster loss:             0.0008443196614583334\n",
      "    separation loss:          1.9026234944661458\n",
      "    avg separation loss:      2.6380252043406167\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.005310432519763708\n",
      "    train time:               0.06327557563781738\n",
      "    test time:                0.008634090423583984\n",
      "    epoch time:               0.07235121726989746\n",
      "    last layer lr:            0.003268000000000003\n",
      "epoch: 140 (33/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.00102997375142877\n",
      "    train cross_ent loss:     2.546228543565121e-06\n",
      "    test overall loss:        0.0010303964760775368\n",
      "    test cross_ent loss:      2.1873866747531188e-06\n",
      "    cluster loss:             0.0008799235026041666\n",
      "    separation loss:          1.9030253092447917\n",
      "    avg separation loss:      2.640240510304769\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.005317230708897114\n",
      "    train time:               0.06380152702331543\n",
      "    test time:                0.008571386337280273\n",
      "    epoch time:               0.07283163070678711\n",
      "    last layer lr:            0.002871999999999997\n",
      "epoch: 140 (34/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010286633441864979\n",
      "    train cross_ent loss:     2.032258070272519e-06\n",
      "    test overall loss:        0.0010283914161846042\n",
      "    test cross_ent loss:      2.0481954834394855e-06\n",
      "    cluster loss:             0.0008443196614583334\n",
      "    separation loss:          1.9020792643229167\n",
      "    avg separation loss:      2.637747605641683\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.0034513678401708603\n",
      "    train time:               0.0639798641204834\n",
      "    test time:                0.00873422622680664\n",
      "    epoch time:               0.07317566871643066\n",
      "    last layer lr:            0.0024759999999999986\n",
      "epoch: 140 (35/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010277660730935168\n",
      "    train cross_ent loss:     2.205365930763037e-06\n",
      "    test overall loss:        0.0010275090656553705\n",
      "    test cross_ent loss:      2.009843152942873e-06\n",
      "    cluster loss:             0.0008595784505208334\n",
      "    separation loss:          1.90277099609375\n",
      "    avg separation loss:      2.639479875564575\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.0026073865592479706\n",
      "    train time:               0.06306147575378418\n",
      "    test time:                0.008623600006103516\n",
      "    epoch time:               0.07212209701538086\n",
      "    last layer lr:            0.0020800000000000003\n",
      "epoch: 140 (36/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010272737927152775\n",
      "    train cross_ent loss:     2.312233473134029e-06\n",
      "    test overall loss:        0.001027532775575916\n",
      "    test cross_ent loss:      2.250794257937135e-06\n",
      "    cluster loss:             0.0008544921875\n",
      "    separation loss:          1.9021148681640625\n",
      "    avg separation loss:      2.634979248046875\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.0023901588283479214\n",
      "    train time:               0.0644078254699707\n",
      "    test time:                0.00854802131652832\n",
      "    epoch time:               0.07341980934143066\n",
      "    last layer lr:            0.0016840000000000017\n",
      "epoch: 140 (37/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010271566789015196\n",
      "    train cross_ent loss:     2.3331879859256333e-06\n",
      "    test overall loss:        0.0010271780968954165\n",
      "    test cross_ent loss:      2.428302953679425e-06\n",
      "    cluster loss:             0.0008494059244791666\n",
      "    separation loss:          1.9022267659505208\n",
      "    avg separation loss:      2.6334193547566733\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.001857964787632227\n",
      "    train time:               0.06259632110595703\n",
      "    test time:                0.008555173873901367\n",
      "    epoch time:               0.07156705856323242\n",
      "    last layer lr:            0.001288000000000003\n",
      "epoch: 140 (38/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010267087891406845\n",
      "    train cross_ent loss:     2.2229446585697588e-06\n",
      "    test overall loss:        0.0010269332366685073\n",
      "    test cross_ent loss:      1.9891282742416174e-06\n",
      "    cluster loss:             0.0008392333984375\n",
      "    separation loss:          1.9018656412760417\n",
      "    avg separation loss:      2.6376962661743164\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.0020522596314549446\n",
      "    train time:               0.06453585624694824\n",
      "    test time:                0.008649587631225586\n",
      "    epoch time:               0.07361054420471191\n",
      "    last layer lr:            0.0008919999999999973\n",
      "epoch: 140 (39/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010262466821586713\n",
      "    train cross_ent loss:     2.01013828871055e-06\n",
      "    test overall loss:        0.001026047975756228\n",
      "    test cross_ent loss:      1.9565617321859463e-06\n",
      "    cluster loss:             0.000885009765625\n",
      "    separation loss:          1.90155029296875\n",
      "    avg separation loss:      2.6394896507263184\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.0011995695531368256\n",
      "    train time:               0.06248044967651367\n",
      "    test time:                0.008477449417114258\n",
      "    epoch time:               0.07138872146606445\n",
      "    last layer lr:            0.0004959999999999986\n",
      "epoch: 140 (40/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010260401650157291\n",
      "    train cross_ent loss:     2.3505311723681643e-06\n",
      "    test overall loss:        0.001025515841320157\n",
      "    test cross_ent loss:      1.9770778105036393e-06\n",
      "    cluster loss:             0.0008392333984375\n",
      "    separation loss:          1.9013264973958333\n",
      "    avg separation loss:      2.6371916929880777\n",
      "    l1_addon loss:            3.409639358520508\n",
      "    l1 loss:                  0.0006469276268035173\n",
      "    train time:               0.06419897079467773\n",
      "    test time:                0.008713722229003906\n",
      "    epoch time:               0.07335901260375977\n",
      "    last layer lr:            0.0001\n",
      "epoch: 141 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010244882141705602\n",
      "    train cross_ent loss:     2.2364486866877087e-06\n",
      "    test overall loss:        0.0010237212215239804\n",
      "    test cross_ent loss:      2.0002774287301386e-06\n",
      "    cluster loss:             0.0009053548177083334\n",
      "    separation loss:          1.9029642740885417\n",
      "    avg separation loss:      2.641422986984253\n",
      "    l1_addon loss:            3.4035799503326416\n",
      "    l1 loss:                  0.0006469276268035173\n",
      "    train time:               0.15491032600402832\n",
      "    test time:                0.008634090423583984\n",
      "    epoch time:               0.16424012184143066\n",
      "    joint lr:                 0.001298047112325102\n",
      "epoch: 142 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010249029655824415\n",
      "    train cross_ent loss:     2.879985732562318e-06\n",
      "    test overall loss:        0.0010226703016087413\n",
      "    test cross_ent loss:      2.685699731349208e-06\n",
      "    cluster loss:             0.0010019938151041667\n",
      "    separation loss:          1.8977254231770833\n",
      "    avg separation loss:      2.633971691131592\n",
      "    l1_addon loss:            3.397792100906372\n",
      "    l1 loss:                  0.0006469276268035173\n",
      "    train time:               0.1480121612548828\n",
      "    test time:                0.008624076843261719\n",
      "    epoch time:               0.15711712837219238\n",
      "    joint lr:                 0.002472133282403701\n",
      "epoch: 143 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010226012927887496\n",
      "    train cross_ent loss:     3.6960500331417734e-06\n",
      "    test overall loss:        0.0010199540993198752\n",
      "    test cross_ent loss:      4.337711895156342e-06\n",
      "    cluster loss:             0.0013427734375\n",
      "    separation loss:          1.8927663167317708\n",
      "    avg separation loss:      2.624322017033895\n",
      "    l1_addon loss:            3.3832314014434814\n",
      "    l1 loss:                  0.0006469276268035173\n",
      "    train time:               0.1438133716583252\n",
      "    test time:                0.008618354797363281\n",
      "    epoch time:               0.152923583984375\n",
      "    joint lr:                 0.0036226179243694966\n",
      "epoch: 144 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010205132675764617\n",
      "    train cross_ent loss:     5.06624503771036e-06\n",
      "    test overall loss:        0.0010163640060151617\n",
      "    test cross_ent loss:      4.712159200911022e-06\n",
      "    cluster loss:             0.0015462239583333333\n",
      "    separation loss:          1.8900807698567708\n",
      "    avg separation loss:      2.6246323585510254\n",
      "    l1_addon loss:            3.370016098022461\n",
      "    l1 loss:                  0.0006469276268035173\n",
      "    train time:               0.14196157455444336\n",
      "    test time:                0.008537530899047852\n",
      "    epoch time:               0.15097689628601074\n",
      "    joint lr:                 0.004749855660167736\n",
      "epoch: 145 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.001016081867419416\n",
      "    train cross_ent loss:     4.485228089379234e-06\n",
      "    test overall loss:        0.0010110692431529362\n",
      "    test cross_ent loss:      4.567968593012968e-06\n",
      "    cluster loss:             0.0014750162760416667\n",
      "    separation loss:          1.8856608072916667\n",
      "    avg separation loss:      2.615493059158325\n",
      "    l1_addon loss:            3.3528478145599365\n",
      "    l1 loss:                  0.0006469276268035173\n",
      "    train time:               0.15840721130371094\n",
      "    test time:                0.008810758590698242\n",
      "    epoch time:               0.16775774955749512\n",
      "    joint lr:                 0.005854196379457574\n",
      "epoch: 146 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010114104006788693\n",
      "    train cross_ent loss:     4.903616066087579e-06\n",
      "    test overall loss:        0.0010065465078999598\n",
      "    test cross_ent loss:      4.613829181228842e-06\n",
      "    cluster loss:             0.0015055338541666667\n",
      "    separation loss:          1.8785196940104167\n",
      "    avg separation loss:      2.6074472268422446\n",
      "    l1_addon loss:            3.337618827819824\n",
      "    l1 loss:                  0.0006469276268035173\n",
      "    train time:               0.1532425880432129\n",
      "    test time:                0.008521318435668945\n",
      "    epoch time:               0.16226577758789062\n",
      "    joint lr:                 0.006935985298795627\n",
      "epoch: 147 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0010053371188405436\n",
      "    train cross_ent loss:     4.619219147627973e-06\n",
      "    test overall loss:        0.0009988446642334263\n",
      "    test cross_ent loss:      5.2507837911737925e-06\n",
      "    cluster loss:             0.0015309651692708333\n",
      "    separation loss:          1.871612548828125\n",
      "    avg separation loss:      2.5965396563212075\n",
      "    l1_addon loss:            3.3098230361938477\n",
      "    l1 loss:                  0.0006469276268035173\n",
      "    train time:               0.14711213111877441\n",
      "    test time:                0.008674860000610352\n",
      "    epoch time:               0.1562950611114502\n",
      "    joint lr:                 0.007995563020108943\n",
      "epoch: 148 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.000998039249680005\n",
      "    train cross_ent loss:     5.0352820437638e-06\n",
      "    test overall loss:        0.000992351599658529\n",
      "    test cross_ent loss:      5.530997744547979e-06\n",
      "    cluster loss:             0.001556396484375\n",
      "    separation loss:          1.8658345540364583\n",
      "    avg separation loss:      2.5893192291259766\n",
      "    l1_addon loss:            3.287245273590088\n",
      "    l1 loss:                  0.0006469276268035173\n",
      "    train time:               0.15218234062194824\n",
      "    test time:                0.00873875617980957\n",
      "    epoch time:               0.16151094436645508\n",
      "    joint lr:                 0.009033265588466115\n",
      "epoch: 149 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0009921922246576287\n",
      "    train cross_ent loss:     6.873390589134942e-06\n",
      "    test overall loss:        0.000983959878794849\n",
      "    test cross_ent loss:      4.7927721880114404e-06\n",
      "    cluster loss:             0.001373291015625\n",
      "    separation loss:          1.8588663736979167\n",
      "    avg separation loss:      2.5761629740397134\n",
      "    l1_addon loss:            3.2617335319519043\n",
      "    l1 loss:                  0.0006469276268035173\n",
      "    train time:               0.14243721961975098\n",
      "    test time:                0.008670568466186523\n",
      "    epoch time:               0.15161347389221191\n",
      "    joint lr:                 0.010049424549154131\n",
      "epoch: 150 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0009820004870562116\n",
      "    train cross_ent loss:     5.445629490452575e-06\n",
      "    test overall loss:        0.000973073202961435\n",
      "    test cross_ent loss:      5.530026858953836e-06\n",
      "    cluster loss:             0.00140380859375\n",
      "    separation loss:          1.8505655924479167\n",
      "    avg separation loss:      2.5661046504974365\n",
      "    l1_addon loss:            3.222987413406372\n",
      "    l1 loss:                  0.0006469276268035173\n",
      "    train time:               0.14072608947753906\n",
      "    test time:                0.00862884521484375\n",
      "    epoch time:               0.14986371994018555\n",
      "    joint lr:                 0.011044367004069541\n",
      "epoch: 151 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0009702395254862495\n",
      "    train cross_ent loss:     4.267067879482056e-06\n",
      "    test overall loss:        0.0009600150709350904\n",
      "    test cross_ent loss:      5.691327108555318e-06\n",
      "    cluster loss:             0.0015869140625\n",
      "    separation loss:          1.8398844401041667\n",
      "    avg separation loss:      2.5587026278177896\n",
      "    l1_addon loss:            3.178922653198242\n",
      "    l1 loss:                  0.0006469276268035173\n",
      "    train time:               0.14342164993286133\n",
      "    test time:                0.008556842803955078\n",
      "    epoch time:               0.15251469612121582\n",
      "    joint lr:                 0.010393177167327405\n",
      "epoch: 152 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0009554962925903965\n",
      "    train cross_ent loss:     4.8407464063870975e-06\n",
      "    test overall loss:        0.0009471647790633142\n",
      "    test cross_ent loss:      5.097000666864915e-06\n",
      "    cluster loss:             0.001434326171875\n",
      "    separation loss:          1.8288421630859375\n",
      "    avg separation loss:      2.544683297475179\n",
      "    l1_addon loss:            3.1380693912506104\n",
      "    l1 loss:                  0.0006469276268035173\n",
      "    train time:               0.13831543922424316\n",
      "    test time:                0.008681297302246094\n",
      "    epoch time:               0.14756321907043457\n",
      "    joint lr:                 0.009753916690619703\n",
      "epoch: 153 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0009420868518645875\n",
      "    train cross_ent loss:     4.8933716243482195e-06\n",
      "    test overall loss:        0.0009334253457685312\n",
      "    test cross_ent loss:      5.399806923378492e-06\n",
      "    cluster loss:             0.0014241536458333333\n",
      "    separation loss:          1.8189900716145833\n",
      "    avg separation loss:      2.5357216199239097\n",
      "    l1_addon loss:            3.091261863708496\n",
      "    l1 loss:                  0.0006469276268035173\n",
      "    train time:               0.14528489112854004\n",
      "    test time:                0.008646011352539062\n",
      "    epoch time:               0.15448403358459473\n",
      "    joint lr:                 0.009126412105729424\n",
      "epoch: 154 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0009302411654061871\n",
      "    train cross_ent loss:     5.819289427222429e-06\n",
      "    test overall loss:        0.0009215395936431984\n",
      "    test cross_ent loss:      6.089944539174515e-06\n",
      "    cluster loss:             0.0014394124348958333\n",
      "    separation loss:          1.8076680501302083\n",
      "    avg separation loss:      2.5247042973836265\n",
      "    l1_addon loss:            3.049342155456543\n",
      "    l1 loss:                  0.0006469276268035173\n",
      "    train time:               0.1500873565673828\n",
      "    test time:                0.008675575256347656\n",
      "    epoch time:               0.15928411483764648\n",
      "    joint lr:                 0.008510492220867888\n",
      "epoch: 155 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0009180216929962626\n",
      "    train cross_ent loss:     4.668464882229273e-06\n",
      "    test overall loss:        0.0009122724877670407\n",
      "    test cross_ent loss:      5.45056127521093e-06\n",
      "    cluster loss:             0.0014902750651041667\n",
      "    separation loss:          1.8005879720052083\n",
      "    avg separation loss:      2.521120468775431\n",
      "    l1_addon loss:            3.020583152770996\n",
      "    l1 loss:                  0.0006469276268035173\n",
      "    train time:               0.1408393383026123\n",
      "    test time:                0.008748769760131836\n",
      "    epoch time:               0.15012359619140625\n",
      "    joint lr:                 0.00790598809249301\n",
      "epoch: 156 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0009071405766007956\n",
      "    train cross_ent loss:     5.151645531498161e-06\n",
      "    test overall loss:        0.0009003590287951132\n",
      "    test cross_ent loss:      5.2432895548311835e-06\n",
      "    cluster loss:             0.0013682047526041667\n",
      "    separation loss:          1.78985595703125\n",
      "    avg separation loss:      2.510817209879557\n",
      "    l1_addon loss:            2.981562614440918\n",
      "    l1 loss:                  0.0006469276268035173\n",
      "    train time:               0.14807462692260742\n",
      "    test time:                0.008917093276977539\n",
      "    epoch time:               0.15757966041564941\n",
      "    joint lr:                 0.007312732997463544\n",
      "epoch: 157 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008969862701633247\n",
      "    train cross_ent loss:     4.929457752211874e-06\n",
      "    test overall loss:        0.0008904217975214124\n",
      "    test cross_ent loss:      4.9134741857415065e-06\n",
      "    cluster loss:             0.0014801025390625\n",
      "    separation loss:          1.7837727864583333\n",
      "    avg separation loss:      2.5082268714904785\n",
      "    l1_addon loss:            2.949537754058838\n",
      "    l1 loss:                  0.0006469276268035173\n",
      "    train time:               0.15891242027282715\n",
      "    test time:                0.008640050888061523\n",
      "    epoch time:               0.1680583953857422\n",
      "    joint lr:                 0.006730562405525418\n",
      "epoch: 158 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008862870345183183\n",
      "    train cross_ent loss:     4.778242747249806e-06\n",
      "    test overall loss:        0.0008832299499772489\n",
      "    test cross_ent loss:      5.416851005672167e-06\n",
      "    cluster loss:             0.0013682047526041667\n",
      "    separation loss:          1.7767995198567708\n",
      "    avg separation loss:      2.50213352839152\n",
      "    l1_addon loss:            2.923887014389038\n",
      "    l1 loss:                  0.0006469276268035173\n",
      "    train time:               0.1558992862701416\n",
      "    test time:                0.008672475814819336\n",
      "    epoch time:               0.16508746147155762\n",
      "    joint lr:                 0.006159313952126306\n",
      "epoch: 159 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008778389128565323\n",
      "    train cross_ent loss:     4.766250953025519e-06\n",
      "    test overall loss:        0.0008730435899148384\n",
      "    test cross_ent loss:      5.342150567836749e-06\n",
      "    cluster loss:             0.0013783772786458333\n",
      "    separation loss:          1.7717081705729167\n",
      "    avg separation loss:      2.498025973637899\n",
      "    l1_addon loss:            2.890181541442871\n",
      "    l1 loss:                  0.0006469276268035173\n",
      "    train time:               0.1507549285888672\n",
      "    test time:                0.008649587631225586\n",
      "    epoch time:               0.15995311737060547\n",
      "    joint lr:                 0.005598827411554625\n",
      "epoch: 160 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008711168738955166\n",
      "    train cross_ent loss:     5.663889695028956e-06\n",
      "    test overall loss:        0.0008662375621497631\n",
      "    test cross_ent loss:      4.6188310989236925e-06\n",
      "    cluster loss:             0.001312255859375\n",
      "    separation loss:          1.7649078369140625\n",
      "    avg separation loss:      2.4931636651357016\n",
      "    l1_addon loss:            2.869905948638916\n",
      "    l1 loss:                  0.0006469276268035173\n",
      "    train time:               0.15227198600769043\n",
      "    test time:                0.008724451065063477\n",
      "    epoch time:               0.16152215003967285\n",
      "    joint lr:                 0.005048944670399165\n",
      "epoch: 161 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008633809829916572\n",
      "    train cross_ent loss:     5.081834558495757e-06\n",
      "    test overall loss:        0.0008598864078521729\n",
      "    test cross_ent loss:      5.069238265302071e-06\n",
      "    cluster loss:             0.0013275146484375\n",
      "    separation loss:          1.7592875162760417\n",
      "    avg separation loss:      2.4874510765075684\n",
      "    l1_addon loss:            2.847234010696411\n",
      "    l1 loss:                  0.0006469276268035173\n",
      "    train time:               0.1511843204498291\n",
      "    test time:                0.008781194686889648\n",
      "    epoch time:               0.16050362586975098\n",
      "    joint lr:                 0.004509509701325646\n",
      "epoch: 162 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008558706704206998\n",
      "    train cross_ent loss:     4.923635039233432e-06\n",
      "    test overall loss:        0.0008523638631838063\n",
      "    test cross_ent loss:      4.726094781896488e-06\n",
      "    cluster loss:             0.001312255859375\n",
      "    separation loss:          1.7573140462239583\n",
      "    avg separation loss:      2.48758331934611\n",
      "    l1_addon loss:            2.823302745819092\n",
      "    l1 loss:                  0.0006469276268035173\n",
      "    train time:               0.13791322708129883\n",
      "    test time:                0.008642196655273438\n",
      "    epoch time:               0.14705300331115723\n",
      "    joint lr:                 0.00398036853716657\n",
      "epoch: 163 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008504886700393399\n",
      "    train cross_ent loss:     5.520130820002578e-06\n",
      "    test overall loss:        0.0008467882289551198\n",
      "    test cross_ent loss:      4.5764051416578395e-06\n",
      "    cluster loss:             0.0012969970703125\n",
      "    separation loss:          1.753936767578125\n",
      "    avg separation loss:      2.4861273765563965\n",
      "    l1_addon loss:            2.8052163124084473\n",
      "    l1 loss:                  0.0006469276268035173\n",
      "    train time:               0.15479516983032227\n",
      "    test time:                0.008736371994018555\n",
      "    epoch time:               0.16408395767211914\n",
      "    joint lr:                 0.0034613692453205423\n",
      "epoch: 164 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008434634419245413\n",
      "    train cross_ent loss:     4.603267484526441e-06\n",
      "    test overall loss:        0.000841331920431306\n",
      "    test cross_ent loss:      4.872927699276867e-06\n",
      "    cluster loss:             0.001312255859375\n",
      "    separation loss:          1.7472991943359375\n",
      "    avg separation loss:      2.4795265992482505\n",
      "    l1_addon loss:            2.7860400676727295\n",
      "    l1 loss:                  0.0006469276268035173\n",
      "    train time:               0.1455228328704834\n",
      "    test time:                0.008514881134033203\n",
      "    epoch time:               0.15453028678894043\n",
      "    joint lr:                 0.002952361902457719\n",
      "epoch: 165 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008380332928936696\n",
      "    train cross_ent loss:     4.766483726825754e-06\n",
      "    test overall loss:        0.0008360126909489433\n",
      "    test cross_ent loss:      5.065266426148203e-06\n",
      "    cluster loss:             0.0013427734375\n",
      "    separation loss:          1.7445526123046875\n",
      "    avg separation loss:      2.4764504432678223\n",
      "    l1_addon loss:            2.7676682472229004\n",
      "    l1 loss:                  0.0006469276268035173\n",
      "    train time:               0.1436595916748047\n",
      "    test time:                0.008535146713256836\n",
      "    epoch time:               0.1526944637298584\n",
      "    joint lr:                 0.0024531985695276076\n",
      "epoch: 166 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008336372102348832\n",
      "    train cross_ent loss:     4.890338281882123e-06\n",
      "    test overall loss:        0.0008320060248176256\n",
      "    test cross_ent loss:      5.158631059506054e-06\n",
      "    cluster loss:             0.0013224283854166667\n",
      "    separation loss:          1.7435811360677083\n",
      "    avg separation loss:      2.4770150979359946\n",
      "    l1_addon loss:            2.7540013790130615\n",
      "    l1 loss:                  0.0006469276268035173\n",
      "    train time:               0.13695740699768066\n",
      "    test time:                0.008516311645507812\n",
      "    epoch time:               0.14595723152160645\n",
      "    joint lr:                 0.001963733267065865\n",
      "epoch: 167 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008300508688989794\n",
      "    train cross_ent loss:     5.426292986498993e-06\n",
      "    test overall loss:        0.0008274211819904546\n",
      "    test cross_ent loss:      4.74280682283279e-06\n",
      "    cluster loss:             0.0013529459635416667\n",
      "    separation loss:          1.7438710530598958\n",
      "    avg separation loss:      2.4789918263753257\n",
      "    l1_addon loss:            2.7401046752929688\n",
      "    l1 loss:                  0.0006469276268035173\n",
      "    train time:               0.13654017448425293\n",
      "    test time:                0.008619546890258789\n",
      "    epoch time:               0.14569807052612305\n",
      "    joint lr:                 0.001483821950796405\n",
      "epoch: 168 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008259956448455341\n",
      "    train cross_ent loss:     5.130034359979163e-06\n",
      "    test overall loss:        0.000825902447104454\n",
      "    test cross_ent loss:      6.101840578291255e-06\n",
      "    cluster loss:             0.0013682047526041667\n",
      "    separation loss:          1.7388966878255208\n",
      "    avg separation loss:      2.472036043802897\n",
      "    l1_addon loss:            2.7305121421813965\n",
      "    l1 loss:                  0.0006469276268035173\n",
      "    train time:               0.1459958553314209\n",
      "    test time:                0.008648872375488281\n",
      "    epoch time:               0.15523838996887207\n",
      "    joint lr:                 0.0010133224875256274\n",
      "epoch: 169 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008236411958932877\n",
      "    train cross_ent loss:     5.486491431838658e-06\n",
      "    test overall loss:        0.0008217662495250503\n",
      "    test cross_ent loss:      4.506017830863129e-06\n",
      "    cluster loss:             0.0012613932291666667\n",
      "    separation loss:          1.7389170328776042\n",
      "    avg separation loss:      2.4750684897104898\n",
      "    l1_addon loss:            2.7220442295074463\n",
      "    l1 loss:                  0.0006469276268035173\n",
      "    train time:               0.14789462089538574\n",
      "    test time:                0.008685111999511719\n",
      "    epoch time:               0.15711498260498047\n",
      "    joint lr:                 0.0005520946313251855\n",
      "epoch: 170 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.000820321087303455\n",
      "    train cross_ent loss:     4.799191174242878e-06\n",
      "    test overall loss:        0.000818917683015267\n",
      "    test cross_ent loss:      4.337852866835116e-06\n",
      "    cluster loss:             0.0012715657552083333\n",
      "    separation loss:          1.7389882405598958\n",
      "    avg separation loss:      2.4752511183420816\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.0006469276268035173\n",
      "    train time:               0.1419522762298584\n",
      "    test time:                0.008493661880493164\n",
      "    epoch time:               0.15093541145324707\n",
      "    joint lr:                 0.0001\n",
      "epoch: 170 (PUSH) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.000820321087303455\n",
      "    train cross_ent loss:     4.799191174242878e-06\n",
      "    test overall loss:        0.0008191831099490324\n",
      "    test cross_ent loss:      4.603265324476524e-06\n",
      "    cluster loss:             0.0009969075520833333\n",
      "    separation loss:          1.74017333984375\n",
      "    avg separation loss:      2.4772204558054605\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.0006469276268035173\n",
      "    train time:               0.1419522762298584\n",
      "    test time:                0.008744001388549805\n",
      "    epoch time:               0.06563663482666016\n",
      "epoch: 170 (1/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008186822833522456\n",
      "    train cross_ent loss:     4.501276727353343e-06\n",
      "    test overall loss:        0.000819007633253932\n",
      "    test cross_ent loss:      4.899049069232812e-06\n",
      "    cluster loss:             0.001007080078125\n",
      "    separation loss:          1.7382253011067708\n",
      "    avg separation loss:      2.473954677581787\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.00017567232134751976\n",
      "    train time:               0.06271600723266602\n",
      "    test time:                0.008548736572265625\n",
      "    epoch time:               0.07167482376098633\n",
      "    last layer lr:            0.0007599999999999978\n",
      "epoch: 170 (2/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008195055706892163\n",
      "    train cross_ent loss:     4.687429964178591e-06\n",
      "    test overall loss:        0.0008193579657624165\n",
      "    test cross_ent loss:      4.8395281737612095e-06\n",
      "    cluster loss:             0.0010528564453125\n",
      "    separation loss:          1.7418975830078125\n",
      "    avg separation loss:      2.477913777033488\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.0005855172057636082\n",
      "    train time:               0.06279277801513672\n",
      "    test time:                0.008746147155761719\n",
      "    epoch time:               0.07198810577392578\n",
      "    last layer lr:            0.0014199999999999955\n",
      "epoch: 170 (3/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008212783741328167\n",
      "    train cross_ent loss:     5.793905849316161e-06\n",
      "    test overall loss:        0.0008199056804490586\n",
      "    test cross_ent loss:      4.699923617105621e-06\n",
      "    cluster loss:             0.001007080078125\n",
      "    separation loss:          1.7389272054036458\n",
      "    avg separation loss:      2.474907477696737\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.0012728477595373988\n",
      "    train time:               0.06287789344787598\n",
      "    test time:                0.00873255729675293\n",
      "    epoch time:               0.07206988334655762\n",
      "    last layer lr:            0.0020800000000000046\n",
      "epoch: 170 (4/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.000821090065073804\n",
      "    train cross_ent loss:     4.645160842642326e-06\n",
      "    test overall loss:        0.0008203582644152144\n",
      "    test cross_ent loss:      4.644002956410986e-06\n",
      "    cluster loss:             0.0010172526041666667\n",
      "    separation loss:          1.7387746175130208\n",
      "    avg separation loss:      2.4740896224975586\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.0017813470913097262\n",
      "    train time:               0.06181669235229492\n",
      "    test time:                0.008561849594116211\n",
      "    epoch time:               0.07080674171447754\n",
      "    last layer lr:            0.0027400000000000024\n",
      "epoch: 170 (5/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008228575352404732\n",
      "    train cross_ent loss:     5.294625516683027e-06\n",
      "    test overall loss:        0.0008217435291347405\n",
      "    test cross_ent loss:      4.32431200655022e-06\n",
      "    cluster loss:             0.0010019938151041667\n",
      "    separation loss:          1.7399953206380208\n",
      "    avg separation loss:      2.476196050643921\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.0034863012842833996\n",
      "    train time:               0.06232118606567383\n",
      "    test time:                0.008741617202758789\n",
      "    epoch time:               0.0715339183807373\n",
      "    last layer lr:            0.0034\n",
      "epoch: 170 (6/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008217693448386854\n",
      "    train cross_ent loss:     3.844711002898293e-06\n",
      "    test overall loss:        0.0008210605980517963\n",
      "    test cross_ent loss:      4.314979908789003e-06\n",
      "    cluster loss:             0.001007080078125\n",
      "    separation loss:          1.7405751546223958\n",
      "    avg separation loss:      2.4776803652445474\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.0028126821853220463\n",
      "    train time:               0.06449675559997559\n",
      "    test time:                0.008684635162353516\n",
      "    epoch time:               0.07362914085388184\n",
      "    last layer lr:            0.004059999999999998\n",
      "epoch: 170 (7/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008226481604651781\n",
      "    train cross_ent loss:     4.13747605421122e-06\n",
      "    test overall loss:        0.0008239294790352384\n",
      "    test cross_ent loss:      3.7797989686320457e-06\n",
      "    cluster loss:             0.0010223388671875\n",
      "    separation loss:          1.7413279215494792\n",
      "    avg separation loss:      2.4776129722595215\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.006216763518750668\n",
      "    train time:               0.06417369842529297\n",
      "    test time:                0.008695125579833984\n",
      "    epoch time:               0.07332539558410645\n",
      "    last layer lr:            0.004719999999999996\n",
      "epoch: 170 (8/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008225727251556236\n",
      "    train cross_ent loss:     3.6736974777795695e-06\n",
      "    test overall loss:        0.0008255850795346001\n",
      "    test cross_ent loss:      3.982807811553357e-06\n",
      "    cluster loss:             0.0010172526041666667\n",
      "    separation loss:          1.7392069498697917\n",
      "    avg separation loss:      2.474818468093872\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.00766936456784606\n",
      "    train time:               0.06217217445373535\n",
      "    test time:                0.008566617965698242\n",
      "    epoch time:               0.0711510181427002\n",
      "    last layer lr:            0.0053800000000000054\n",
      "epoch: 170 (9/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008244856053352123\n",
      "    train cross_ent loss:     4.24831277712201e-06\n",
      "    test overall loss:        0.0008245216643748184\n",
      "    test cross_ent loss:      4.587828698277008e-06\n",
      "    cluster loss:             0.0010630289713541667\n",
      "    separation loss:          1.7395833333333333\n",
      "    avg separation loss:      2.475231091181437\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.00600090529769659\n",
      "    train time:               0.06356430053710938\n",
      "    test time:                0.008675336837768555\n",
      "    epoch time:               0.07266521453857422\n",
      "    last layer lr:            0.006040000000000003\n",
      "epoch: 170 (10/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008268969286291394\n",
      "    train cross_ent loss:     4.396151133789772e-06\n",
      "    test overall loss:        0.0008261503535322845\n",
      "    test cross_ent loss:      3.544334049365716e-06\n",
      "    cluster loss:             0.0010325113932291667\n",
      "    separation loss:          1.7406870524088542\n",
      "    avg separation loss:      2.477019468943278\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.008673107251524925\n",
      "    train time:               0.06170368194580078\n",
      "    test time:                0.008623361587524414\n",
      "    epoch time:               0.07075905799865723\n",
      "    last layer lr:            0.0067\n",
      "epoch: 170 (11/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008262033352366416\n",
      "    train cross_ent loss:     3.3131617485082643e-06\n",
      "    test overall loss:        0.0008246755266251663\n",
      "    test cross_ent loss:      2.9672474208079316e-06\n",
      "    cluster loss:             0.0010019938151041667\n",
      "    separation loss:          1.7384541829427083\n",
      "    avg separation loss:      2.474714914957682\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.007775368634611368\n",
      "    train time:               0.06367063522338867\n",
      "    test time:                0.008537054061889648\n",
      "    epoch time:               0.07266545295715332\n",
      "    last layer lr:            0.0073599999999999985\n",
      "epoch: 170 (12/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008273114690382499\n",
      "    train cross_ent loss:     3.832127969616295e-06\n",
      "    test overall loss:        0.0008271591311010221\n",
      "    test cross_ent loss:      3.2341472812428642e-06\n",
      "    cluster loss:             0.0010426839192708333\n",
      "    separation loss:          1.7413279215494792\n",
      "    avg separation loss:      2.477900505065918\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.009992055594921112\n",
      "    train time:               0.06257104873657227\n",
      "    test time:                0.008530855178833008\n",
      "    epoch time:               0.07156562805175781\n",
      "    last layer lr:            0.008019999999999994\n",
      "epoch: 170 (13/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008266476506832987\n",
      "    train cross_ent loss:     2.904549024407288e-06\n",
      "    test overall loss:        0.0008271588982703785\n",
      "    test cross_ent loss:      2.6263017313491823e-06\n",
      "    cluster loss:             0.0009918212890625\n",
      "    separation loss:          1.74041748046875\n",
      "    avg separation loss:      2.477059284845988\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.010599678382277489\n",
      "    train time:               0.06303763389587402\n",
      "    test time:                0.008553743362426758\n",
      "    epoch time:               0.0720062255859375\n",
      "    last layer lr:            0.008680000000000005\n",
      "epoch: 170 (14/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.000829118140245555\n",
      "    train cross_ent loss:     3.3663531198158125e-06\n",
      "    test overall loss:        0.0008246246725320816\n",
      "    test cross_ent loss:      3.196157687549809e-06\n",
      "    cluster loss:             0.0010528564453125\n",
      "    separation loss:          1.7386067708333333\n",
      "    avg separation loss:      2.473660945892334\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.007495615631341934\n",
      "    train time:               0.06205415725708008\n",
      "    test time:                0.008592367172241211\n",
      "    epoch time:               0.0710597038269043\n",
      "    last layer lr:            0.009340000000000003\n",
      "epoch: 170 (15/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008281907666969346\n",
      "    train cross_ent loss:     3.5865787744171485e-06\n",
      "    test overall loss:        0.0008294977790986499\n",
      "    test cross_ent loss:      2.7723032189896912e-06\n",
      "    cluster loss:             0.0010274251302083333\n",
      "    separation loss:          1.7406056722005208\n",
      "    avg separation loss:      2.4772138595581055\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.012792568653821945\n",
      "    train time:               0.06362533569335938\n",
      "    test time:                0.008635282516479492\n",
      "    epoch time:               0.07269644737243652\n",
      "    last layer lr:            0.01\n",
      "epoch: 170 (16/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008288913704745937\n",
      "    train cross_ent loss:     2.464265133284016e-06\n",
      "    test overall loss:        0.0008239023542652527\n",
      "    test cross_ent loss:      2.035769398389675e-06\n",
      "    cluster loss:             0.001007080078125\n",
      "    separation loss:          1.7427724202473958\n",
      "    avg separation loss:      2.480782906214396\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.007933666929602623\n",
      "    train time:               0.06259584426879883\n",
      "    test time:                0.008668661117553711\n",
      "    epoch time:               0.07171916961669922\n",
      "    last layer lr:            0.009604000000000001\n",
      "epoch: 170 (17/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008279775065602735\n",
      "    train cross_ent loss:     2.571242839977117e-06\n",
      "    test overall loss:        0.0008232961990870535\n",
      "    test cross_ent loss:      1.9781422224696144e-06\n",
      "    cluster loss:             0.0010223388671875\n",
      "    separation loss:          1.7415618896484375\n",
      "    avg separation loss:      2.4782255490620932\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.007385142147541046\n",
      "    train time:               0.06472158432006836\n",
      "    test time:                0.008628368377685547\n",
      "    epoch time:               0.07378292083740234\n",
      "    last layer lr:            0.009208000000000003\n",
      "epoch: 170 (18/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008256092387455283\n",
      "    train cross_ent loss:     1.810601430562997e-06\n",
      "    test overall loss:        0.0008227937893631557\n",
      "    test cross_ent loss:      1.8754384048709956e-06\n",
      "    cluster loss:             0.0010019938151041667\n",
      "    separation loss:          1.7412872314453125\n",
      "    avg separation loss:      2.478950023651123\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.00698542594909668\n",
      "    train time:               0.06267476081848145\n",
      "    test time:                0.00859832763671875\n",
      "    epoch time:               0.07167863845825195\n",
      "    last layer lr:            0.008811999999999997\n",
      "epoch: 170 (19/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008252880888903746\n",
      "    train cross_ent loss:     2.1014047106859834e-06\n",
      "    test overall loss:        0.0008265359986883899\n",
      "    test cross_ent loss:      1.9336613377163303e-06\n",
      "    cluster loss:             0.0010223388671875\n",
      "    separation loss:          1.7400258382161458\n",
      "    avg separation loss:      2.4763484795888266\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.010669425129890442\n",
      "    train time:               0.06363892555236816\n",
      "    test time:                0.008548736572265625\n",
      "    epoch time:               0.07265591621398926\n",
      "    last layer lr:            0.008415999999999998\n",
      "epoch: 170 (20/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008272422492154874\n",
      "    train cross_ent loss:     3.2542099450694195e-06\n",
      "    test overall loss:        0.0008283478673547506\n",
      "    test cross_ent loss:      2.452018217506217e-06\n",
      "    cluster loss:             0.0010884602864583333\n",
      "    separation loss:          1.7369588216145833\n",
      "    avg separation loss:      2.471501668294271\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.011962948366999626\n",
      "    train time:               0.06125235557556152\n",
      "    test time:                0.008492469787597656\n",
      "    epoch time:               0.0701756477355957\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 170 (21/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008266925597126829\n",
      "    train cross_ent loss:     2.816524697024647e-06\n",
      "    test overall loss:        0.000824750381677101\n",
      "    test cross_ent loss:      2.0086714206020892e-06\n",
      "    cluster loss:             0.0010630289713541667\n",
      "    separation loss:          1.7381591796875\n",
      "    avg separation loss:      2.4725917975107827\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.008808787912130356\n",
      "    train time:               0.0630807876586914\n",
      "    test time:                0.0087127685546875\n",
      "    epoch time:               0.07226157188415527\n",
      "    last layer lr:            0.007624000000000002\n",
      "epoch: 170 (22/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008247144432971254\n",
      "    train cross_ent loss:     1.6473862078925094e-06\n",
      "    test overall loss:        0.0008256902995829781\n",
      "    test cross_ent loss:      1.3847271513138064e-06\n",
      "    cluster loss:             0.00103759765625\n",
      "    separation loss:          1.7436421712239583\n",
      "    avg separation loss:      2.4822071393330893\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.010372651740908623\n",
      "    train time:               0.06292939186096191\n",
      "    test time:                0.00872492790222168\n",
      "    epoch time:               0.07211160659790039\n",
      "    last layer lr:            0.0072280000000000035\n",
      "epoch: 170 (23/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008244118598668138\n",
      "    train cross_ent loss:     1.7654283013257555e-06\n",
      "    test overall loss:        0.0008264802357492348\n",
      "    test cross_ent loss:      1.7477323505469637e-06\n",
      "    cluster loss:             0.0010274251302083333\n",
      "    separation loss:          1.7398732503255208\n",
      "    avg separation loss:      2.4759726524353027\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.010799587704241276\n",
      "    train time:               0.06294918060302734\n",
      "    test time:                0.008696556091308594\n",
      "    epoch time:               0.07211518287658691\n",
      "    last layer lr:            0.006831999999999998\n",
      "epoch: 170 (24/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.000822837106170482\n",
      "    train cross_ent loss:     1.361472339311831e-06\n",
      "    test overall loss:        0.0008231024839915335\n",
      "    test cross_ent loss:      1.4772369733388284e-06\n",
      "    cluster loss:             0.0010274251302083333\n",
      "    separation loss:          1.7403818766276042\n",
      "    avg separation loss:      2.476384162902832\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.007692324463278055\n",
      "    train time:               0.0625298023223877\n",
      "    test time:                0.00871896743774414\n",
      "    epoch time:               0.07170438766479492\n",
      "    last layer lr:            0.006436\n",
      "epoch: 170 (25/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008234767065005144\n",
      "    train cross_ent loss:     1.6559830875451098e-06\n",
      "    test overall loss:        0.0008232448017224669\n",
      "    test cross_ent loss:      1.7487723766862473e-06\n",
      "    cluster loss:             0.0010528564453125\n",
      "    separation loss:          1.7402445475260417\n",
      "    avg separation loss:      2.4768503506978354\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.007563130930066109\n",
      "    train time:               0.06283855438232422\n",
      "    test time:                0.0086822509765625\n",
      "    epoch time:               0.0719602108001709\n",
      "    last layer lr:            0.00604\n",
      "epoch: 170 (26/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008228275928559015\n",
      "    train cross_ent loss:     2.0587885263267935e-06\n",
      "    test overall loss:        0.0008239755212950209\n",
      "    test cross_ent loss:      2.0509052471121927e-06\n",
      "    cluster loss:             0.0011037190755208333\n",
      "    separation loss:          1.7376047770182292\n",
      "    avg separation loss:      2.471896171569824\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.00799170508980751\n",
      "    train time:               0.06179523468017578\n",
      "    test time:                0.008587360382080078\n",
      "    epoch time:               0.07078862190246582\n",
      "    last layer lr:            0.005644000000000002\n",
      "epoch: 170 (27/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008238002665166277\n",
      "    train cross_ent loss:     3.1644522291429666e-06\n",
      "    test overall loss:        0.0008226231050988039\n",
      "    test cross_ent loss:      2.0721859073091764e-06\n",
      "    cluster loss:             0.0011240641276041667\n",
      "    separation loss:          1.7395375569661458\n",
      "    avg separation loss:      2.4737394650777182\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.0066180042922496796\n",
      "    train time:               0.0633845329284668\n",
      "    test time:                0.008661746978759766\n",
      "    epoch time:               0.07248115539550781\n",
      "    last layer lr:            0.005248000000000003\n",
      "epoch: 170 (28/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008218422481149901\n",
      "    train cross_ent loss:     1.4126954788196144e-06\n",
      "    test overall loss:        0.0008213108715911707\n",
      "    test cross_ent loss:      1.5885069994207395e-06\n",
      "    cluster loss:             0.0010579427083333333\n",
      "    separation loss:          1.7381083170572917\n",
      "    avg separation loss:      2.4728052616119385\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.005789452698081732\n",
      "    train time:               0.06439542770385742\n",
      "    test time:                0.008673906326293945\n",
      "    epoch time:               0.0735177993774414\n",
      "    last layer lr:            0.004851999999999998\n",
      "epoch: 170 (29/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008211325584852602\n",
      "    train cross_ent loss:     1.5938204311893855e-06\n",
      "    test overall loss:        0.0008202809452389678\n",
      "    test cross_ent loss:      1.2401739960902585e-06\n",
      "    cluster loss:             0.0010121663411458333\n",
      "    separation loss:          1.7405751546223958\n",
      "    avg separation loss:      2.4772516886393228\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.005107867531478405\n",
      "    train time:               0.0635080337524414\n",
      "    test time:                0.00874638557434082\n",
      "    epoch time:               0.07269167900085449\n",
      "    last layer lr:            0.004455999999999999\n",
      "epoch: 170 (30/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008200894208130194\n",
      "    train cross_ent loss:     1.3634522275651761e-06\n",
      "    test overall loss:        0.0008196852868422866\n",
      "    test cross_ent loss:      1.07860663926355e-06\n",
      "    cluster loss:             0.0010121663411458333\n",
      "    separation loss:          1.7426401774088542\n",
      "    avg separation loss:      2.480975786844889\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.0046737645752727985\n",
      "    train time:               0.061682939529418945\n",
      "    test time:                0.00854349136352539\n",
      "    epoch time:               0.07063603401184082\n",
      "    last layer lr:            0.004060000000000001\n",
      "epoch: 170 (31/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008200853153539356\n",
      "    train cross_ent loss:     1.334462405466752e-06\n",
      "    test overall loss:        0.0008193604104841749\n",
      "    test cross_ent loss:      1.37668024535742e-06\n",
      "    cluster loss:             0.0010274251302083333\n",
      "    separation loss:          1.7390340169270833\n",
      "    avg separation loss:      2.474137465159098\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.004050822928547859\n",
      "    train time:               0.06271815299987793\n",
      "    test time:                0.008619070053100586\n",
      "    epoch time:               0.07179427146911621\n",
      "    last layer lr:            0.0036640000000000015\n",
      "epoch: 170 (32/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008196120943466667\n",
      "    train cross_ent loss:     1.301985529167382e-06\n",
      "    test overall loss:        0.0008189868337164322\n",
      "    test cross_ent loss:      1.461370724579562e-06\n",
      "    cluster loss:             0.0010579427083333333\n",
      "    separation loss:          1.7379099527994792\n",
      "    avg separation loss:      2.472553014755249\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.003592555643990636\n",
      "    train time:               0.06191539764404297\n",
      "    test time:                0.008437633514404297\n",
      "    epoch time:               0.0707707405090332\n",
      "    last layer lr:            0.003268000000000003\n",
      "epoch: 170 (33/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008199539934139466\n",
      "    train cross_ent loss:     2.045258637117797e-06\n",
      "    test overall loss:        0.0008187945156047741\n",
      "    test cross_ent loss:      1.095483658749193e-06\n",
      "    cluster loss:             0.0010121663411458333\n",
      "    separation loss:          1.7391916910807292\n",
      "    avg separation loss:      2.475466807683309\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.003766125999391079\n",
      "    train time:               0.06433296203613281\n",
      "    test time:                0.008632421493530273\n",
      "    epoch time:               0.07340240478515625\n",
      "    last layer lr:            0.002871999999999997\n",
      "epoch: 170 (34/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008188438696379308\n",
      "    train cross_ent loss:     1.1128114199010497e-06\n",
      "    test overall loss:        0.0008174420412008961\n",
      "    test cross_ent loss:      1.0409310107206693e-06\n",
      "    cluster loss:             0.001007080078125\n",
      "    separation loss:          1.7400767008463542\n",
      "    avg separation loss:      2.4769748051961265\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.002468185033649206\n",
      "    train time:               0.06279206275939941\n",
      "    test time:                0.008692026138305664\n",
      "    epoch time:               0.07193183898925781\n",
      "    last layer lr:            0.0024759999999999986\n",
      "epoch: 170 (35/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008180589829862583\n",
      "    train cross_ent loss:     1.339004057854254e-06\n",
      "    test overall loss:        0.000817686493974179\n",
      "    test cross_ent loss:      1.2339919900720513e-06\n",
      "    cluster loss:             0.0010172526041666667\n",
      "    separation loss:          1.7399698893229167\n",
      "    avg separation loss:      2.4760727087656655\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.002519577043130994\n",
      "    train time:               0.0626826286315918\n",
      "    test time:                0.008509635925292969\n",
      "    epoch time:               0.0716092586517334\n",
      "    last layer lr:            0.0020800000000000003\n",
      "epoch: 170 (36/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.000817953041405417\n",
      "    train cross_ent loss:     1.2475021851088286e-06\n",
      "    test overall loss:        0.0008169430657289922\n",
      "    test cross_ent loss:      1.0418063046320942e-06\n",
      "    cluster loss:             0.0010477701822916667\n",
      "    separation loss:          1.744232177734375\n",
      "    avg separation loss:      2.4826029936472573\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.001968344673514366\n",
      "    train time:               0.062499284744262695\n",
      "    test time:                0.008532524108886719\n",
      "    epoch time:               0.07144308090209961\n",
      "    last layer lr:            0.0016840000000000017\n",
      "epoch: 170 (37/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008174909180524992\n",
      "    train cross_ent loss:     1.2426112725449912e-06\n",
      "    test overall loss:        0.0008171325704703728\n",
      "    test cross_ent loss:      1.0263976453946573e-06\n",
      "    cluster loss:             0.0010426839192708333\n",
      "    separation loss:          1.7427724202473958\n",
      "    avg separation loss:      2.4803008238474527\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.0021732677705585957\n",
      "    train time:               0.06304669380187988\n",
      "    test time:                0.008699417114257812\n",
      "    epoch time:               0.07220458984375\n",
      "    last layer lr:            0.001288000000000003\n",
      "epoch: 170 (38/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.000816866720924736\n",
      "    train cross_ent loss:     1.1390049472481678e-06\n",
      "    test overall loss:        0.0008162086790738007\n",
      "    test cross_ent loss:      1.157879296442843e-06\n",
      "    cluster loss:             0.0010172526041666667\n",
      "    separation loss:          1.7391001383463542\n",
      "    avg separation loss:      2.474760055541992\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.0011178822023794055\n",
      "    train time:               0.06232595443725586\n",
      "    test time:                0.008526802062988281\n",
      "    epoch time:               0.07128143310546875\n",
      "    last layer lr:            0.0008919999999999973\n",
      "epoch: 170 (39/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008162509184330702\n",
      "    train cross_ent loss:     1.124102571026242e-06\n",
      "    test overall loss:        0.000815987994428724\n",
      "    test cross_ent loss:      1.2183856483716227e-06\n",
      "    cluster loss:             0.0010223388671875\n",
      "    separation loss:          1.7371673583984375\n",
      "    avg separation loss:      2.4723060925801597\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.0008366901893168688\n",
      "    train time:               0.06349968910217285\n",
      "    test time:                0.008665084838867188\n",
      "    epoch time:               0.07263350486755371\n",
      "    last layer lr:            0.0004959999999999986\n",
      "epoch: 170 (40/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.000816041854704963\n",
      "    train cross_ent loss:     1.46228653363778e-06\n",
      "    test overall loss:        0.0008154316456057131\n",
      "    test cross_ent loss:      1.0246189958706964e-06\n",
      "    cluster loss:             0.0010172526041666667\n",
      "    separation loss:          1.74176025390625\n",
      "    avg separation loss:      2.478893200556437\n",
      "    l1_addon loss:            2.7131094932556152\n",
      "    l1 loss:                  0.0004741191223729402\n",
      "    train time:               0.062774658203125\n",
      "    test time:                0.008662223815917969\n",
      "    epoch time:               0.07184100151062012\n",
      "    last layer lr:            0.0001\n",
      "epoch: 171 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.00081417641013104\n",
      "    train cross_ent loss:     1.219331278612401e-06\n",
      "    test overall loss:        0.0008135160702901582\n",
      "    test cross_ent loss:      1.1500329340681976e-06\n",
      "    cluster loss:             0.0010172526041666667\n",
      "    separation loss:          1.7408650716145833\n",
      "    avg separation loss:      2.4774237473805747\n",
      "    l1_addon loss:            2.706306219100952\n",
      "    l1 loss:                  0.0004741191223729402\n",
      "    train time:               0.1560516357421875\n",
      "    test time:                0.008645772933959961\n",
      "    epoch time:               0.16524386405944824\n",
      "    joint lr:                 0.0009861958963236286\n",
      "epoch: 172 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008147120224748505\n",
      "    train cross_ent loss:     1.3076902867226181e-06\n",
      "    test overall loss:        0.0008130351585956911\n",
      "    test cross_ent loss:      1.6103324090484723e-06\n",
      "    cluster loss:             0.00128173828125\n",
      "    separation loss:          1.7421773274739583\n",
      "    avg separation loss:      2.4743600686391196\n",
      "    l1_addon loss:            2.7031688690185547\n",
      "    l1 loss:                  0.0004741191223729402\n",
      "    train time:               0.15308761596679688\n",
      "    test time:                0.008497953414916992\n",
      "    epoch time:               0.16228461265563965\n",
      "    joint lr:                 0.001854667874720785\n",
      "epoch: 173 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008139214642142178\n",
      "    train cross_ent loss:     2.8457486287436495e-06\n",
      "    test overall loss:        0.0008116983226500452\n",
      "    test cross_ent loss:      3.817934536224736e-06\n",
      "    cluster loss:             0.0021107991536458335\n",
      "    separation loss:          1.7411295572916667\n",
      "    avg separation loss:      2.4697255293528237\n",
      "    l1_addon loss:            2.6913540363311768\n",
      "    l1 loss:                  0.0004741191223729402\n",
      "    train time:               0.1423635482788086\n",
      "    test time:                0.00853586196899414\n",
      "    epoch time:               0.15139532089233398\n",
      "    joint lr:                 0.0027056817939603655\n",
      "epoch: 174 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008140433947119163\n",
      "    train cross_ent loss:     4.61220107794702e-06\n",
      "    test overall loss:        0.0008104691708770891\n",
      "    test cross_ent loss:      4.263663565022095e-06\n",
      "    cluster loss:             0.0023295084635416665\n",
      "    separation loss:          1.7371317545572917\n",
      "    avg separation loss:      2.4695618947347007\n",
      "    l1_addon loss:            2.6857712268829346\n",
      "    l1 loss:                  0.0004741191223729402\n",
      "    train time:               0.1454625129699707\n",
      "    test time:                0.008625030517578125\n",
      "    epoch time:               0.15459036827087402\n",
      "    joint lr:                 0.003539499968027705\n",
      "epoch: 175 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008115915152302478\n",
      "    train cross_ent loss:     3.6061790105179625e-06\n",
      "    test overall loss:        0.0008086397428996861\n",
      "    test cross_ent loss:      4.387085103492912e-06\n",
      "    cluster loss:             0.0025990804036458335\n",
      "    separation loss:          1.7325286865234375\n",
      "    avg separation loss:      2.4659230709075928\n",
      "    l1_addon loss:            2.6792616844177246\n",
      "    l1 loss:                  0.0004741191223729402\n",
      "    train time:               0.1396775245666504\n",
      "    test time:                0.008780956268310547\n",
      "    epoch time:               0.14904999732971191\n",
      "    joint lr:                 0.00435638121043428\n",
      "epoch: 176 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.000809241635579383\n",
      "    train cross_ent loss:     4.173116167294211e-06\n",
      "    test overall loss:        0.0008052785221176842\n",
      "    test cross_ent loss:      4.0541028738516616e-06\n",
      "    cluster loss:             0.0025634765625\n",
      "    separation loss:          1.7293294270833333\n",
      "    avg separation loss:      2.4695398012797036\n",
      "    l1_addon loss:            2.6691675186157227\n",
      "    l1 loss:                  0.0004741191223729402\n",
      "    train time:               0.15853285789489746\n",
      "    test time:                0.008742570877075195\n",
      "    epoch time:               0.16782045364379883\n",
      "    joint lr:                 0.00515658087799592\n",
      "epoch: 177 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008065429392445367\n",
      "    train cross_ent loss:     5.041790501536525e-06\n",
      "    test overall loss:        0.000800594260605673\n",
      "    test cross_ent loss:      4.828423546617462e-06\n",
      "    cluster loss:             0.0026295979817708335\n",
      "    separation loss:          1.7198537190755208\n",
      "    avg separation loss:      2.4599101543426514\n",
      "    l1_addon loss:            2.650972366333008\n",
      "    l1 loss:                  0.0004741191223729402\n",
      "    train time:               0.14436793327331543\n",
      "    test time:                0.008600711822509766\n",
      "    epoch time:               0.15348076820373535\n",
      "    joint lr:                 0.005940350914085284\n",
      "epoch: 178 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0008005995114217512\n",
      "    train cross_ent loss:     3.4590347830487644e-06\n",
      "    test overall loss:        0.0007970203878358006\n",
      "    test cross_ent loss:      5.490357731711508e-06\n",
      "    cluster loss:             0.0028432210286458335\n",
      "    separation loss:          1.7128143310546875\n",
      "    avg separation loss:      2.4572791258494058\n",
      "    l1_addon loss:            2.636852979660034\n",
      "    l1 loss:                  0.0004741191223729402\n",
      "    train time:               0.14167094230651855\n",
      "    test time:                0.008571147918701172\n",
      "    epoch time:               0.15076494216918945\n",
      "    joint lr:                 0.00670793989136506\n",
      "epoch: 179 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0007959459308040095\n",
      "    train cross_ent loss:     4.361231681571098e-06\n",
      "    test overall loss:        0.0007915702881291509\n",
      "    test cross_ent loss:      3.7249177845903128e-06\n",
      "    cluster loss:             0.0024312337239583335\n",
      "    separation loss:          1.7058512369791667\n",
      "    avg separation loss:      2.4564925034840903\n",
      "    l1_addon loss:            2.624570608139038\n",
      "    l1 loss:                  0.0004741191223729402\n",
      "    train time:               0.14278268814086914\n",
      "    test time:                0.008532047271728516\n",
      "    epoch time:               0.15183329582214355\n",
      "    joint lr:                 0.007459593054007833\n",
      "epoch: 180 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0007886795392550994\n",
      "    train cross_ent loss:     4.15810490039803e-06\n",
      "    test overall loss:        0.0007836976243803898\n",
      "    test cross_ent loss:      5.1982622153445845e-06\n",
      "    cluster loss:             0.002685546875\n",
      "    separation loss:          1.6959889729817708\n",
      "    avg separation loss:      2.451575676600138\n",
      "    l1_addon loss:            2.5934174060821533\n",
      "    l1 loss:                  0.0004741191223729402\n",
      "    train time:               0.15050864219665527\n",
      "    test time:                0.008655309677124023\n",
      "    epoch time:               0.15992164611816406\n",
      "    joint lr:                 0.008195552359408614\n",
      "epoch: 181 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0007826941528037423\n",
      "    train cross_ent loss:     4.5119878357979815e-06\n",
      "    test overall loss:        0.000774862690983961\n",
      "    test cross_ent loss:      3.593337927062142e-06\n",
      "    cluster loss:             0.002349853515625\n",
      "    separation loss:          1.68768310546875\n",
      "    avg separation loss:      2.45203963915507\n",
      "    l1_addon loss:            2.56931734085083\n",
      "    l1 loss:                  0.0004741191223729402\n",
      "    train time:               0.13936495780944824\n",
      "    test time:                0.008687496185302734\n",
      "    epoch time:               0.14857220649719238\n",
      "    joint lr:                 0.007713866994023813\n",
      "epoch: 182 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0007694515679759206\n",
      "    train cross_ent loss:     3.890464054023823e-06\n",
      "    test overall loss:        0.0007633800657155613\n",
      "    test cross_ent loss:      4.796903112946893e-06\n",
      "    cluster loss:             0.0026804606119791665\n",
      "    separation loss:          1.6787668863932292\n",
      "    avg separation loss:      2.443995396296183\n",
      "    l1_addon loss:            2.5270299911499023\n",
      "    l1 loss:                  0.0004741191223729402\n",
      "    train time:               0.15338850021362305\n",
      "    test time:                0.008667469024658203\n",
      "    epoch time:               0.16273760795593262\n",
      "    joint lr:                 0.007241005780710745\n",
      "epoch: 183 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.000759816799472901\n",
      "    train cross_ent loss:     6.3107882759538825e-06\n",
      "    test overall loss:        0.0007543471098567048\n",
      "    test cross_ent loss:      4.144591533380056e-06\n",
      "    cluster loss:             0.0021820068359375\n",
      "    separation loss:          1.6646474202473958\n",
      "    avg separation loss:      2.435924768447876\n",
      "    l1_addon loss:            2.4990944862365723\n",
      "    l1 loss:                  0.0004741191223729402\n",
      "    train time:               0.14713811874389648\n",
      "    test time:                0.008550882339477539\n",
      "    epoch time:               0.15622162818908691\n",
      "    joint lr:                 0.006776840404964548\n",
      "epoch: 184 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0007494458041037433\n",
      "    train cross_ent loss:     4.367277082195642e-06\n",
      "    test overall loss:        0.0007427381545615693\n",
      "    test cross_ent loss:      6.18138225642421e-06\n",
      "    cluster loss:             0.0026702880859375\n",
      "    separation loss:          1.658660888671875\n",
      "    avg separation loss:      2.431750456492106\n",
      "    l1_addon loss:            2.453608751296997\n",
      "    l1 loss:                  0.0004741191223729402\n",
      "    train time:               0.14600706100463867\n",
      "    test time:                0.008527994155883789\n",
      "    epoch time:               0.1550133228302002\n",
      "    joint lr:                 0.006321244236155204\n",
      "epoch: 185 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0007372697182290722\n",
      "    train cross_ent loss:     3.6018721161212852e-06\n",
      "    test overall loss:        0.0007325827415722111\n",
      "    test cross_ent loss:      4.524856346203403e-06\n",
      "    cluster loss:             0.0027923583984375\n",
      "    separation loss:          1.6569264729817708\n",
      "    avg separation loss:      2.4353396892547607\n",
      "    l1_addon loss:            2.425279140472412\n",
      "    l1 loss:                  0.0004741191223729402\n",
      "    train time:               0.1474318504333496\n",
      "    test time:                0.00873708724975586\n",
      "    epoch time:               0.15669965744018555\n",
      "    joint lr:                 0.00587409230668155\n",
      "epoch: 186 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0007270344431162812\n",
      "    train cross_ent loss:     4.224101900263122e-06\n",
      "    test overall loss:        0.0007215005268032352\n",
      "    test cross_ent loss:      4.294452613369988e-06\n",
      "    cluster loss:             0.0026499430338541665\n",
      "    separation loss:          1.649871826171875\n",
      "    avg separation loss:      2.432868798573812\n",
      "    l1_addon loss:            2.389106273651123\n",
      "    l1 loss:                  0.0004741191223729402\n",
      "    train time:               0.14876174926757812\n",
      "    test time:                0.008713722229003906\n",
      "    epoch time:               0.15804576873779297\n",
      "    joint lr:                 0.0054352612913737535\n",
      "epoch: 187 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0007183504658314632\n",
      "    train cross_ent loss:     4.478354330927914e-06\n",
      "    test overall loss:        0.0007126429700292647\n",
      "    test cross_ent loss:      3.54895557090155e-06\n",
      "    cluster loss:             0.0024515787760416665\n",
      "    separation loss:          1.642333984375\n",
      "    avg separation loss:      2.4277709325154624\n",
      "    l1_addon loss:            2.3620662689208984\n",
      "    l1 loss:                  0.0004741191223729402\n",
      "    train time:               0.15530753135681152\n",
      "    test time:                0.008626222610473633\n",
      "    epoch time:               0.16443777084350586\n",
      "    joint lr:                 0.005004629487141445\n",
      "epoch: 188 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.000709854230080964\n",
      "    train cross_ent loss:     5.002906689810516e-06\n",
      "    test overall loss:        0.0007059401832520962\n",
      "    test cross_ent loss:      4.892690337025367e-06\n",
      "    cluster loss:             0.0025634765625\n",
      "    separation loss:          1.6343231201171875\n",
      "    avg separation loss:      2.4208789666493735\n",
      "    l1_addon loss:            2.3352444171905518\n",
      "    l1 loss:                  0.0004741191223729402\n",
      "    train time:               0.15535736083984375\n",
      "    test time:                0.00874948501586914\n",
      "    epoch time:               0.16473031044006348\n",
      "    joint lr:                 0.004582076792864645\n",
      "epoch: 189 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0007023097532510292\n",
      "    train cross_ent loss:     3.9775386895257725e-06\n",
      "    test overall loss:        0.0006965594366192818\n",
      "    test cross_ent loss:      4.839265708748523e-06\n",
      "    cluster loss:             0.0027516682942708335\n",
      "    separation loss:          1.6309560139973958\n",
      "    avg separation loss:      2.419060230255127\n",
      "    l1_addon loss:            2.3041534423828125\n",
      "    l1 loss:                  0.0004741191223729402\n",
      "    train time:               0.1508944034576416\n",
      "    test time:                0.008582592010498047\n",
      "    epoch time:               0.16001152992248535\n",
      "    joint lr:                 0.004167484689524657\n",
      "epoch: 190 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.000694615620886907\n",
      "    train cross_ent loss:     4.9531961856530415e-06\n",
      "    test overall loss:        0.0006897158067052563\n",
      "    test cross_ent loss:      4.223438584934532e-06\n",
      "    cluster loss:             0.0025380452473958335\n",
      "    separation loss:          1.6261698404947917\n",
      "    avg separation loss:      2.4177878697713218\n",
      "    l1_addon loss:            2.2833940982818604\n",
      "    l1 loss:                  0.0004741191223729402\n",
      "    train time:               0.154754638671875\n",
      "    test time:                0.008579254150390625\n",
      "    epoch time:               0.1638498306274414\n",
      "    joint lr:                 0.003760736220572192\n",
      "epoch: 191 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0006870854613225674\n",
      "    train cross_ent loss:     4.664613381777372e-06\n",
      "    test overall loss:        0.0006843820641127726\n",
      "    test cross_ent loss:      4.031728318902121e-06\n",
      "    cluster loss:             0.0024159749348958335\n",
      "    separation loss:          1.61981201171875\n",
      "    avg separation loss:      2.414278189341227\n",
      "    l1_addon loss:            2.26625394821167\n",
      "    l1 loss:                  0.0004741191223729402\n",
      "    train time:               0.14809751510620117\n",
      "    test time:                0.00854945182800293\n",
      "    epoch time:               0.15720677375793457\n",
      "    joint lr:                 0.0033617159725298235\n",
      "epoch: 192 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.000680696064591757\n",
      "    train cross_ent loss:     4.793097328814611e-06\n",
      "    test overall loss:        0.0006773841838973264\n",
      "    test cross_ent loss:      4.53336557863319e-06\n",
      "    cluster loss:             0.0025482177734375\n",
      "    separation loss:          1.6154836018880208\n",
      "    avg separation loss:      2.4107956091562905\n",
      "    l1_addon loss:            2.241255521774292\n",
      "    l1 loss:                  0.0004741191223729402\n",
      "    train time:               0.147064208984375\n",
      "    test time:                0.008709192276000977\n",
      "    epoch time:               0.15631461143493652\n",
      "    joint lr:                 0.002970310055826246\n",
      "epoch: 193 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0006751834753231378\n",
      "    train cross_ent loss:     4.391966385242085e-06\n",
      "    test overall loss:        0.0006717188710657259\n",
      "    test cross_ent loss:      3.4943783096726597e-06\n",
      "    cluster loss:             0.00244140625\n",
      "    separation loss:          1.6134287516276042\n",
      "    avg separation loss:      2.4106871287027993\n",
      "    l1_addon loss:            2.225834369659424\n",
      "    l1 loss:                  0.0004741191223729402\n",
      "    train time:               0.15325641632080078\n",
      "    test time:                0.008645057678222656\n",
      "    epoch time:               0.16243195533752441\n",
      "    joint lr:                 0.0025864060858594865\n",
      "epoch: 194 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0006698544129903894\n",
      "    train cross_ent loss:     5.677626315758744e-06\n",
      "    test overall loss:        0.000667907491636773\n",
      "    test cross_ent loss:      4.943292045330357e-06\n",
      "    cluster loss:             0.002593994140625\n",
      "    separation loss:          1.6087493896484375\n",
      "    avg separation loss:      2.406022310256958\n",
      "    l1_addon loss:            2.2083001136779785\n",
      "    l1 loss:                  0.0004741191223729402\n",
      "    train time:               0.14294004440307617\n",
      "    test time:                0.008729696273803711\n",
      "    epoch time:               0.15220236778259277\n",
      "    joint lr:                 0.00220989316428648\n",
      "epoch: 195 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.000665139941702364\n",
      "    train cross_ent loss:     4.289282042435616e-06\n",
      "    test overall loss:        0.0006618006736971438\n",
      "    test cross_ent loss:      3.7974922785603362e-06\n",
      "    cluster loss:             0.0024363199869791665\n",
      "    separation loss:          1.6052602132161458\n",
      "    avg separation loss:      2.4036973317464194\n",
      "    l1_addon loss:            2.191763401031494\n",
      "    l1 loss:                  0.0004741191223729402\n",
      "    train time:               0.14903736114501953\n",
      "    test time:                0.008648157119750977\n",
      "    epoch time:               0.15817975997924805\n",
      "    joint lr:                 0.0018406618605363474\n",
      "epoch: 196 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.000659367693515378\n",
      "    train cross_ent loss:     4.320259581191976e-06\n",
      "    test overall loss:        0.0006570151308551431\n",
      "    test cross_ent loss:      3.9684616695012664e-06\n",
      "    cluster loss:             0.0025431315104166665\n",
      "    separation loss:          1.604095458984375\n",
      "    avg separation loss:      2.404503345489502\n",
      "    l1_addon loss:            2.175241708755493\n",
      "    l1 loss:                  0.0004741191223729402\n",
      "    train time:               0.14022374153137207\n",
      "    test time:                0.008575916290283203\n",
      "    epoch time:               0.14931941032409668\n",
      "    joint lr:                 0.001478604193544789\n",
      "epoch: 197 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.000655209158139769\n",
      "    train cross_ent loss:     4.479627090603344e-06\n",
      "    test overall loss:        0.0006529481421845654\n",
      "    test cross_ent loss:      3.6630790418712422e-06\n",
      "    cluster loss:             0.0024973551432291665\n",
      "    separation loss:          1.6029408772786458\n",
      "    avg separation loss:      2.4047231674194336\n",
      "    l1_addon loss:            2.162703037261963\n",
      "    l1 loss:                  0.0004741191223729402\n",
      "    train time:               0.1441342830657959\n",
      "    test time:                0.00865626335144043\n",
      "    epoch time:               0.15331697463989258\n",
      "    joint lr:                 0.0011236136137069992\n",
      "epoch: 198 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0006512954405479832\n",
      "    train cross_ent loss:     4.236215694675138e-06\n",
      "    test overall loss:        0.0006485209063005944\n",
      "    test cross_ent loss:      3.072891862151058e-06\n",
      "    cluster loss:             0.0024973551432291665\n",
      "    separation loss:          1.6049906412760417\n",
      "    avg separation loss:      2.4096113046010337\n",
      "    l1_addon loss:            2.1499128341674805\n",
      "    l1 loss:                  0.0004741191223729402\n",
      "    train time:               0.14246749877929688\n",
      "    test time:                0.008547544479370117\n",
      "    epoch time:               0.1515181064605713\n",
      "    joint lr:                 0.0007755849850466195\n",
      "epoch: 199 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0006503046934085432\n",
      "    train cross_ent loss:     6.724594889817581e-06\n",
      "    test overall loss:        0.0006473037065006793\n",
      "    test cross_ent loss:      4.162346992112968e-06\n",
      "    cluster loss:             0.0025685628255208335\n",
      "    separation loss:          1.5999501546223958\n",
      "    avg separation loss:      2.4035141468048096\n",
      "    l1_addon loss:            2.142224073410034\n",
      "    l1 loss:                  0.0004741191223729402\n",
      "    train time:               0.14627647399902344\n",
      "    test time:                0.008553028106689453\n",
      "    epoch time:               0.15532612800598145\n",
      "    joint lr:                 0.0004344145675980766\n",
      "epoch: 200 (JOINT) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0006448661279137013\n",
      "    train cross_ent loss:     3.434584183281686e-06\n",
      "    test overall loss:        0.0006435452378354967\n",
      "    test cross_ent loss:      3.2934112823568285e-06\n",
      "    cluster loss:             0.00244140625\n",
      "    separation loss:          1.6005096435546875\n",
      "    avg separation loss:      2.4046672185262046\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.0004741191223729402\n",
      "    train time:               0.1526343822479248\n",
      "    test time:                0.008764982223510742\n",
      "    epoch time:               0.1619408130645752\n",
      "    joint lr:                 0.0001\n",
      "epoch: 200 (PUSH) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0006448661279137013\n",
      "    train cross_ent loss:     3.434584183281686e-06\n",
      "    test overall loss:        0.0006423951320660611\n",
      "    test cross_ent loss:      2.143323475441624e-06\n",
      "    cluster loss:             0.0014139811197916667\n",
      "    separation loss:          1.598114013671875\n",
      "    avg separation loss:      2.402937332789103\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.0004741191223729402\n",
      "    train time:               0.1526343822479248\n",
      "    test time:                0.008666276931762695\n",
      "    epoch time:               0.06359982490539551\n",
      "epoch: 200 (1/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.000642540955595905\n",
      "    train cross_ent loss:     2.537021803306061e-06\n",
      "    test overall loss:        0.0006421961394759516\n",
      "    test cross_ent loss:      2.2237522519693207e-06\n",
      "    cluster loss:             0.0014088948567708333\n",
      "    separation loss:          1.5978139241536458\n",
      "    avg separation loss:      2.402440071105957\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.00019469296967145056\n",
      "    train time:               0.06279277801513672\n",
      "    test time:                0.008643388748168945\n",
      "    epoch time:               0.07185578346252441\n",
      "    last layer lr:            0.0007600000000000095\n",
      "epoch: 200 (2/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0006438304553739727\n",
      "    train cross_ent loss:     2.989985604884282e-06\n",
      "    test overall loss:        0.0006433478556573391\n",
      "    test cross_ent loss:      2.4577924856809355e-06\n",
      "    cluster loss:             0.00152587890625\n",
      "    separation loss:          1.5984700520833333\n",
      "    avg separation loss:      2.404306252797445\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.0011123826261609793\n",
      "    train time:               0.06272697448730469\n",
      "    test time:                0.00872945785522461\n",
      "    epoch time:               0.0719153881072998\n",
      "    last layer lr:            0.0014199999999999955\n",
      "epoch: 200 (3/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.000644082418148173\n",
      "    train cross_ent loss:     2.4123468911341206e-06\n",
      "    test overall loss:        0.0006442981539294124\n",
      "    test cross_ent loss:      2.6897658547871592e-06\n",
      "    cluster loss:             0.0015106201171875\n",
      "    separation loss:          1.5981190999348958\n",
      "    avg separation loss:      2.4029924074808755\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.0018306819256395102\n",
      "    train time:               0.0609438419342041\n",
      "    test time:                0.008532285690307617\n",
      "    epoch time:               0.06990909576416016\n",
      "    last layer lr:            0.0020800000000000046\n",
      "epoch: 200 (4/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0006448538024415029\n",
      "    train cross_ent loss:     2.4350472749290475e-06\n",
      "    test overall loss:        0.000644918589387089\n",
      "    test cross_ent loss:      2.4203400244005024e-06\n",
      "    cluster loss:             0.0014597574869791667\n",
      "    separation loss:          1.5958607991536458\n",
      "    avg separation loss:      2.3988633155822754\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.002720561344176531\n",
      "    train time:               0.0631256103515625\n",
      "    test time:                0.008477449417114258\n",
      "    epoch time:               0.07201719284057617\n",
      "    last layer lr:            0.0027399999999999907\n",
      "epoch: 200 (5/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.000646562219117186\n",
      "    train cross_ent loss:     2.967288740052254e-06\n",
      "    test overall loss:        0.0006468433421105146\n",
      "    test cross_ent loss:      2.7342328697462412e-06\n",
      "    cluster loss:             0.0014851888020833333\n",
      "    separation loss:          1.5973663330078125\n",
      "    avg separation loss:      2.4006516138712564\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.004331417381763458\n",
      "    train time:               0.06173205375671387\n",
      "    test time:                0.008617162704467773\n",
      "    epoch time:               0.07080936431884766\n",
      "    last layer lr:            0.0034\n",
      "epoch: 200 (6/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0006478594932559645\n",
      "    train cross_ent loss:     3.629911432767585e-06\n",
      "    test overall loss:        0.0006471755138287941\n",
      "    test cross_ent loss:      3.145012821429797e-06\n",
      "    cluster loss:             0.0015614827473958333\n",
      "    separation loss:          1.596221923828125\n",
      "    avg separation loss:      2.3985707759857178\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.004252823069691658\n",
      "    train time:               0.06276154518127441\n",
      "    test time:                0.008443832397460938\n",
      "    epoch time:               0.07161974906921387\n",
      "    last layer lr:            0.00406000000000001\n",
      "epoch: 200 (7/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0006476258386101108\n",
      "    train cross_ent loss:     2.431883824982606e-06\n",
      "    test overall loss:        0.0006456816918216646\n",
      "    test cross_ent loss:      2.1368821307987673e-06\n",
      "    cluster loss:             0.00146484375\n",
      "    separation loss:          1.5982767740885417\n",
      "    avg separation loss:      2.4031714598337808\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.003767106682062149\n",
      "    train time:               0.06235957145690918\n",
      "    test time:                0.008542776107788086\n",
      "    epoch time:               0.07133221626281738\n",
      "    last layer lr:            0.004719999999999996\n",
      "epoch: 200 (8/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.000650394955300726\n",
      "    train cross_ent loss:     3.7432617414623337e-06\n",
      "    test overall loss:        0.0006485107781675955\n",
      "    test cross_ent loss:      2.116789460160362e-06\n",
      "    cluster loss:             0.0014139811197916667\n",
      "    separation loss:          1.5963490804036458\n",
      "    avg separation loss:      2.3988017241160073\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.006616297643631697\n",
      "    train time:               0.06242179870605469\n",
      "    test time:                0.008678197860717773\n",
      "    epoch time:               0.07153439521789551\n",
      "    last layer lr:            0.0053800000000000054\n",
      "epoch: 200 (9/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0006492693755717482\n",
      "    train cross_ent loss:     2.05006320186385e-06\n",
      "    test overall loss:        0.000648271874524653\n",
      "    test cross_ent loss:      2.1412251953734085e-06\n",
      "    cluster loss:             0.0014546712239583333\n",
      "    separation loss:          1.5971272786458333\n",
      "    avg separation loss:      2.4003345171610513\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.006352975964546204\n",
      "    train time:               0.0616917610168457\n",
      "    test time:                0.008640289306640625\n",
      "    epoch time:               0.07076525688171387\n",
      "    last layer lr:            0.0060399999999999916\n",
      "epoch: 200 (10/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.000649415458610747\n",
      "    train cross_ent loss:     2.0710187840222716e-06\n",
      "    test overall loss:        0.000650938464483867\n",
      "    test cross_ent loss:      1.7321304615810125e-06\n",
      "    cluster loss:             0.0013885498046875\n",
      "    separation loss:          1.5986073811848958\n",
      "    avg separation loss:      2.4029828707377114\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.009428642690181732\n",
      "    train time:               0.06404566764831543\n",
      "    test time:                0.008562564849853516\n",
      "    epoch time:               0.07306551933288574\n",
      "    last layer lr:            0.0067\n",
      "epoch: 200 (11/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.000650808618956944\n",
      "    train cross_ent loss:     1.942610666105793e-06\n",
      "    test overall loss:        0.0006501467432826757\n",
      "    test cross_ent loss:      1.7149462034164269e-06\n",
      "    cluster loss:             0.0014750162760416667\n",
      "    separation loss:          1.5981903076171875\n",
      "    avg separation loss:      2.40327525138855\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.008654098026454449\n",
      "    train time:               0.06312727928161621\n",
      "    test time:                0.008595466613769531\n",
      "    epoch time:               0.07216119766235352\n",
      "    last layer lr:            0.007360000000000011\n",
      "epoch: 200 (12/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0006510349921882153\n",
      "    train cross_ent loss:     1.6593766165584611e-06\n",
      "    test overall loss:        0.0006498734971197943\n",
      "    test cross_ent loss:      1.362432271889702e-06\n",
      "    cluster loss:             0.0014546712239583333\n",
      "    separation loss:          1.6005147298177083\n",
      "    avg separation loss:      2.4079508781433105\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.00873338058590889\n",
      "    train time:               0.06264233589172363\n",
      "    test time:                0.008465290069580078\n",
      "    epoch time:               0.0715188980102539\n",
      "    last layer lr:            0.008019999999999994\n",
      "epoch: 200 (13/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0006517000401800033\n",
      "    train cross_ent loss:     1.7514580736843754e-06\n",
      "    test overall loss:        0.0006526891568986078\n",
      "    test cross_ent loss:      1.2893668781543965e-06\n",
      "    cluster loss:             0.0014292399088541667\n",
      "    separation loss:          1.5985921223958333\n",
      "    avg separation loss:      2.403799215952555\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.011622076854109764\n",
      "    train time:               0.062432050704956055\n",
      "    test time:                0.008735895156860352\n",
      "    epoch time:               0.07160711288452148\n",
      "    last layer lr:            0.008680000000000005\n",
      "epoch: 200 (14/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0006523777356051141\n",
      "    train cross_ent loss:     2.2438732880658563e-06\n",
      "    test overall loss:        0.0006501026800833642\n",
      "    test cross_ent loss:      1.016718480665683e-06\n",
      "    cluster loss:             0.00140380859375\n",
      "    separation loss:          1.6019846598307292\n",
      "    avg separation loss:      2.410381317138672\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.009308256208896637\n",
      "    train time:               0.06177496910095215\n",
      "    test time:                0.008606195449829102\n",
      "    epoch time:               0.07079434394836426\n",
      "    last layer lr:            0.00933999999999999\n",
      "epoch: 200 (15/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0006528396534122294\n",
      "    train cross_ent loss:     1.4495980416029397e-06\n",
      "    test overall loss:        0.0006514864896113673\n",
      "    test cross_ent loss:      1.0186650456489588e-06\n",
      "    cluster loss:             0.00140380859375\n",
      "    separation loss:          1.5998687744140625\n",
      "    avg separation loss:      2.405886729558309\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.010690120980143547\n",
      "    train time:               0.062209367752075195\n",
      "    test time:                0.008531570434570312\n",
      "    epoch time:               0.07117819786071777\n",
      "    last layer lr:            0.01\n",
      "epoch: 200 (16/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0006544615662278375\n",
      "    train cross_ent loss:     1.2823099142522665e-06\n",
      "    test overall loss:        0.0006535749028747281\n",
      "    test cross_ent loss:      9.854766365909502e-07\n",
      "    cluster loss:             0.0014139811197916667\n",
      "    separation loss:          1.5978597005208333\n",
      "    avg separation loss:      2.4030585289001465\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.012811733409762383\n",
      "    train time:               0.0623476505279541\n",
      "    test time:                0.008504629135131836\n",
      "    epoch time:               0.07129120826721191\n",
      "    last layer lr:            0.009603999999999994\n",
      "epoch: 200 (17/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0006535867287311703\n",
      "    train cross_ent loss:     1.2975595016229136e-06\n",
      "    test overall loss:        0.000653054021919767\n",
      "    test cross_ent loss:      1.1984062098235881e-06\n",
      "    cluster loss:             0.0014597574869791667\n",
      "    separation loss:          1.5984547932942708\n",
      "    avg separation loss:      2.4031683603922525\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.012077942490577698\n",
      "    train time:               0.06263589859008789\n",
      "    test time:                0.008519411087036133\n",
      "    epoch time:               0.07159185409545898\n",
      "    last layer lr:            0.009208000000000003\n",
      "epoch: 200 (18/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0006515389050036902\n",
      "    train cross_ent loss:     1.5286409444925653e-06\n",
      "    test overall loss:        0.0006484664627350867\n",
      "    test cross_ent loss:      9.425505898737659e-07\n",
      "    cluster loss:             0.0014699300130208333\n",
      "    separation loss:          1.5999857584635417\n",
      "    avg separation loss:      2.407214641571045\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.007746214512735605\n",
      "    train time:               0.0627129077911377\n",
      "    test time:                0.008539676666259766\n",
      "    epoch time:               0.07171773910522461\n",
      "    last layer lr:            0.008811999999999997\n",
      "epoch: 200 (19/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0006506729059765348\n",
      "    train cross_ent loss:     1.6484228195778883e-06\n",
      "    test overall loss:        0.0006513951811939478\n",
      "    test cross_ent loss:      6.939465417114358e-07\n",
      "    cluster loss:             0.0013529459635416667\n",
      "    separation loss:          1.600128173828125\n",
      "    avg separation loss:      2.4074520270029702\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.010923562571406364\n",
      "    train time:               0.06308627128601074\n",
      "    test time:                0.008735179901123047\n",
      "    epoch time:               0.0722804069519043\n",
      "    last layer lr:            0.008416000000000005\n",
      "epoch: 200 (20/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0006510584771604044\n",
      "    train cross_ent loss:     1.1240817121560553e-06\n",
      "    test overall loss:        0.0006531504332087934\n",
      "    test cross_ent loss:      8.266723436160343e-07\n",
      "    cluster loss:             0.00140380859375\n",
      "    separation loss:          1.5974884033203125\n",
      "    avg separation loss:      2.402080774307251\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.012546060606837273\n",
      "    train time:               0.06319570541381836\n",
      "    test time:                0.008727550506591797\n",
      "    epoch time:               0.07238316535949707\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 200 (21/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0006505156197817996\n",
      "    train cross_ent loss:     9.210759266409241e-07\n",
      "    test overall loss:        0.0006522522695983449\n",
      "    test cross_ent loss:      8.968590160899718e-07\n",
      "    cluster loss:             0.0013936360677083333\n",
      "    separation loss:          1.5962880452473958\n",
      "    avg separation loss:      2.3988167444864907\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.011577712371945381\n",
      "    train time:               0.0630490779876709\n",
      "    test time:                0.008743524551391602\n",
      "    epoch time:               0.07224416732788086\n",
      "    last layer lr:            0.007623999999999995\n",
      "epoch: 200 (22/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0006504188513645204\n",
      "    train cross_ent loss:     1.1182799446451952e-06\n",
      "    test overall loss:        0.0006503907303946713\n",
      "    test cross_ent loss:      9.666782906000055e-07\n",
      "    cluster loss:             0.0014546712239583333\n",
      "    separation loss:          1.5974222819010417\n",
      "    avg separation loss:      2.4010519981384277\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.009646366350352764\n",
      "    train time:               0.06321096420288086\n",
      "    test time:                0.008633136749267578\n",
      "    epoch time:               0.07227730751037598\n",
      "    last layer lr:            0.0072280000000000035\n",
      "epoch: 200 (23/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0006494486624433193\n",
      "    train cross_ent loss:     9.711343027518637e-07\n",
      "    test overall loss:        0.0006508333996559182\n",
      "    test cross_ent loss:      6.876525541580728e-07\n",
      "    cluster loss:             0.00140380859375\n",
      "    separation loss:          1.59808349609375\n",
      "    avg separation loss:      2.403339227040609\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.01036805845797062\n",
      "    train time:               0.0628654956817627\n",
      "    test time:                0.008599996566772461\n",
      "    epoch time:               0.0719137191772461\n",
      "    last layer lr:            0.006831999999999998\n",
      "epoch: 200 (24/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0006494168283097679\n",
      "    train cross_ent loss:     1.037839699513654e-06\n",
      "    test overall loss:        0.0006512796777921418\n",
      "    test cross_ent loss:      9.64786674254962e-07\n",
      "    cluster loss:             0.0014495849609375\n",
      "    separation loss:          1.597686767578125\n",
      "    avg separation loss:      2.401163101196289\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.010537194088101387\n",
      "    train time:               0.06172299385070801\n",
      "    test time:                0.008676528930664062\n",
      "    epoch time:               0.07085752487182617\n",
      "    last layer lr:            0.006436000000000007\n",
      "epoch: 200 (25/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0006487235968961613\n",
      "    train cross_ent loss:     9.766042516901052e-07\n",
      "    test overall loss:        0.0006486476243784031\n",
      "    test cross_ent loss:      7.563431078475938e-07\n",
      "    cluster loss:             0.0014292399088541667\n",
      "    separation loss:          1.598388671875\n",
      "    avg separation loss:      2.4033568700154624\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.008113598451018333\n",
      "    train time:               0.06230735778808594\n",
      "    test time:                0.00853419303894043\n",
      "    epoch time:               0.07126235961914062\n",
      "    last layer lr:            0.00604\n",
      "epoch: 200 (26/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0006485237809101818\n",
      "    train cross_ent loss:     9.61236227503548e-07\n",
      "    test overall loss:        0.0006481904226044813\n",
      "    test cross_ent loss:      7.925798399810446e-07\n",
      "    cluster loss:             0.0014597574869791667\n",
      "    separation loss:          1.5982462565104167\n",
      "    avg separation loss:      2.402630647023519\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.007620158139616251\n",
      "    train time:               0.06270313262939453\n",
      "    test time:                0.008494853973388672\n",
      "    epoch time:               0.07161927223205566\n",
      "    last layer lr:            0.0056439999999999945\n",
      "epoch: 200 (27/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.00064798063976923\n",
      "    train cross_ent loss:     8.867318150862502e-07\n",
      "    test overall loss:        0.0006484307426338395\n",
      "    test cross_ent loss:      6.897123701795257e-07\n",
      "    cluster loss:             0.00146484375\n",
      "    separation loss:          1.5979512532552083\n",
      "    avg separation loss:      2.4030022621154785\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.007963337935507298\n",
      "    train time:               0.06367945671081543\n",
      "    test time:                0.008617639541625977\n",
      "    epoch time:               0.07271957397460938\n",
      "    last layer lr:            0.005248000000000003\n",
      "epoch: 200 (28/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0006477565402747132\n",
      "    train cross_ent loss:     8.811459957236423e-07\n",
      "    test overall loss:        0.0006479990552179515\n",
      "    test cross_ent loss:      5.242770744947242e-07\n",
      "    cluster loss:             0.0014088948567708333\n",
      "    separation loss:          1.6009623209635417\n",
      "    avg separation loss:      2.409003178278605\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.007697085849940777\n",
      "    train time:               0.06237626075744629\n",
      "    test time:                0.00867152214050293\n",
      "    epoch time:               0.07151079177856445\n",
      "    last layer lr:            0.004851999999999998\n",
      "epoch: 200 (29/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0006486738839157624\n",
      "    train cross_ent loss:     2.525557480481666e-06\n",
      "    test overall loss:        0.0006457208267723521\n",
      "    test cross_ent loss:      7.716673735558288e-07\n",
      "    cluster loss:             0.0014851888020833333\n",
      "    separation loss:          1.5986429850260417\n",
      "    avg separation loss:      2.4035284519195557\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.00517147034406662\n",
      "    train time:               0.06138134002685547\n",
      "    test time:                0.008552789688110352\n",
      "    epoch time:               0.07038426399230957\n",
      "    last layer lr:            0.004456000000000006\n",
      "epoch: 200 (30/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.000647408442091546\n",
      "    train cross_ent loss:     1.1078027104538535e-06\n",
      "    test overall loss:        0.0006455328160276016\n",
      "    test cross_ent loss:      8.609604644031302e-07\n",
      "    cluster loss:             0.0015207926432291667\n",
      "    separation loss:          1.5963287353515625\n",
      "    avg separation loss:      2.398860057195028\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.004894183948636055\n",
      "    train time:               0.06302785873413086\n",
      "    test time:                0.008567094802856445\n",
      "    epoch time:               0.0720067024230957\n",
      "    last layer lr:            0.004060000000000001\n",
      "epoch: 200 (31/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0006462413057306549\n",
      "    train cross_ent loss:     8.690372630404397e-07\n",
      "    test overall loss:        0.0006459898043734332\n",
      "    test cross_ent loss:      6.885548107978442e-07\n",
      "    cluster loss:             0.0014597574869791667\n",
      "    separation loss:          1.5981394449869792\n",
      "    avg separation loss:      2.402496258417765\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.005523578263819218\n",
      "    train time:               0.061699628829956055\n",
      "    test time:                0.008632421493530273\n",
      "    epoch time:               0.07076501846313477\n",
      "    last layer lr:            0.0036639999999999945\n",
      "epoch: 200 (32/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0006452977086155443\n",
      "    train cross_ent loss:     8.129262720757424e-07\n",
      "    test overall loss:        0.0006453147895323733\n",
      "    test cross_ent loss:      6.730891376112899e-07\n",
      "    cluster loss:             0.0014851888020833333\n",
      "    separation loss:          1.5993754069010417\n",
      "    avg separation loss:      2.404814879099528\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.0048640137538313866\n",
      "    train time:               0.06285643577575684\n",
      "    test time:                0.008630514144897461\n",
      "    epoch time:               0.07194638252258301\n",
      "    last layer lr:            0.003268000000000003\n",
      "epoch: 200 (33/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0006453558653447544\n",
      "    train cross_ent loss:     1.3349273739748924e-06\n",
      "    test overall loss:        0.0006435469258576632\n",
      "    test cross_ent loss:      6.607002850008333e-07\n",
      "    cluster loss:             0.00152587890625\n",
      "    separation loss:          1.5976359049479167\n",
      "    avg separation loss:      2.4022059440612793\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.003108551725745201\n",
      "    train time:               0.06398439407348633\n",
      "    test time:                0.008736133575439453\n",
      "    epoch time:               0.07314753532409668\n",
      "    last layer lr:            0.002871999999999997\n",
      "epoch: 200 (34/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0006444711398216896\n",
      "    train cross_ent loss:     7.938344102065287e-07\n",
      "    test overall loss:        0.0006434379417138795\n",
      "    test cross_ent loss:      6.71932222455022e-07\n",
      "    cluster loss:             0.0014546712239583333\n",
      "    separation loss:          1.5964813232421875\n",
      "    avg separation loss:      2.398967425028483\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.0029883082024753094\n",
      "    train time:               0.06299591064453125\n",
      "    test time:                0.008657693862915039\n",
      "    epoch time:               0.0720674991607666\n",
      "    last layer lr:            0.0024760000000000055\n",
      "epoch: 200 (35/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.000644228619421483\n",
      "    train cross_ent loss:     6.979085047653655e-07\n",
      "    test overall loss:        0.0006440624711103737\n",
      "    test cross_ent loss:      6.91038242924454e-07\n",
      "    cluster loss:             0.0015004475911458333\n",
      "    separation loss:          1.5976409912109375\n",
      "    avg separation loss:      2.401758591334025\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.0035937493667006493\n",
      "    train time:               0.06382513046264648\n",
      "    test time:                0.008855581283569336\n",
      "    epoch time:               0.07315397262573242\n",
      "    last layer lr:            0.0020800000000000003\n",
      "epoch: 200 (36/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.000643806743028108\n",
      "    train cross_ent loss:     9.117621213583504e-07\n",
      "    test overall loss:        0.0006433717207983136\n",
      "    test cross_ent loss:      8.325977963371164e-07\n",
      "    cluster loss:             0.001617431640625\n",
      "    separation loss:          1.59649658203125\n",
      "    avg separation loss:      2.3999081452687583\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.0027614538557827473\n",
      "    train time:               0.06338620185852051\n",
      "    test time:                0.008730411529541016\n",
      "    epoch time:               0.07255840301513672\n",
      "    last layer lr:            0.0016839999999999945\n",
      "epoch: 200 (37/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0006427683110814542\n",
      "    train cross_ent loss:     6.15370594481135e-07\n",
      "    test overall loss:        0.0006423724310783049\n",
      "    test cross_ent loss:      4.426313087909269e-07\n",
      "    cluster loss:             0.0013936360677083333\n",
      "    separation loss:          1.5997772216796875\n",
      "    avg separation loss:      2.4063032468159995\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.0021521272137761116\n",
      "    train time:               0.06310558319091797\n",
      "    test time:                0.008723258972167969\n",
      "    epoch time:               0.07225346565246582\n",
      "    last layer lr:            0.001288000000000003\n",
      "epoch: 200 (38/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0006423948234441923\n",
      "    train cross_ent loss:     8.492454379727121e-07\n",
      "    test overall loss:        0.0006417594462012252\n",
      "    test cross_ent loss:      5.469951531722472e-07\n",
      "    cluster loss:             0.0013936360677083333\n",
      "    separation loss:          1.5963287353515625\n",
      "    avg separation loss:      2.399381240208944\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.0014347482938319445\n",
      "    train time:               0.06412911415100098\n",
      "    test time:                0.008755207061767578\n",
      "    epoch time:               0.07332348823547363\n",
      "    last layer lr:            0.0008919999999999973\n",
      "epoch: 200 (39/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0006422017431759741\n",
      "    train cross_ent loss:     1.116880491203176e-06\n",
      "    test overall loss:        0.0006410409890425702\n",
      "    test cross_ent loss:      5.943230216113685e-07\n",
      "    cluster loss:             0.0015207926432291667\n",
      "    separation loss:          1.5992380777994792\n",
      "    avg separation loss:      2.405253251393636\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.0006689784349873662\n",
      "    train time:               0.06370925903320312\n",
      "    test time:                0.008762836456298828\n",
      "    epoch time:               0.07287740707397461\n",
      "    last layer lr:            0.0004960000000000057\n",
      "epoch: 200 (40/40) (LAST_LAYER) - ArtificialDataset\n",
      "    test acc:                 100.00%\n",
      "    train overall loss:       0.0006411139020201517\n",
      "    train cross_ent loss:     7.050093784322087e-07\n",
      "    test overall loss:        0.0006409877096302807\n",
      "    test cross_ent loss:      5.698546203802834e-07\n",
      "    cluster loss:             0.0014546712239583333\n",
      "    separation loss:          1.5981903076171875\n",
      "    avg separation loss:      2.4030147393544516\n",
      "    l1_addon loss:            2.13259220123291\n",
      "    l1 loss:                  0.000640177633613348\n",
      "    train time:               0.06736326217651367\n",
      "    test time:                0.008975744247436523\n",
      "    epoch time:               0.07678651809692383\n",
      "    last layer lr:            0.0001\n",
      "Finished training in 48.22 seconds\n",
      "Last epoch test accu: 100.00%\n",
      "Done in 200 epochs, 79.35s\n"
     ]
    }
   ],
   "source": [
    "experiment_name = 'ArtificialDataset'\n",
    "experiment_dir = experiment_setup(experiment_name)\n",
    "\n",
    "default_params = {\n",
    "    \"coeffs\": ProtoTSCoeffs(crs_ent=1, clst=0, sep=0, l1=1e-3, l1_addon=3e-4),\n",
    "    \"reception\": 0.75,\n",
    "    \"proto_len\": 20,\n",
    "    \"protos_per_class\": 1,\n",
    "    \"proto_features\": 32,\n",
    "    \"features_lr\": 1e-3,\n",
    "    \"push_start_epoch\": 110,\n",
    "    \"num_last_layer_epochs\": 40,\n",
    "}\n",
    "\n",
    "dataset = TrainTestDS('ArtificialDataset', artifTrainDS, artifTestDS)\n",
    "ds_info = DSInfo(dataset.name, features=3, ts_len=100, num_classes=4)\n",
    "\n",
    "log, logclose = create_logger(experiment_dir / \"log.txt\", display=True)\n",
    "\n",
    "try:\n",
    "    features_lr = default_params[\"features_lr\"]\n",
    "\n",
    "    proto_len = default_params[\"proto_len\"]\n",
    "    reception = default_params[\"reception\"]\n",
    "    epochs = 200\n",
    "\n",
    "    protos_per_class = default_params[\"protos_per_class\"]\n",
    "    proto_features = default_params[\"proto_features\"]\n",
    "    train_batch_size = 32\n",
    "    test_batch_size = 128\n",
    "    coeffs = default_params[\"coeffs\"]\n",
    "    padding = 'same'\n",
    "\n",
    "    push_start_epoch = default_params[\"push_start_epoch\"]\n",
    "    num_warm_epochs = push_start_epoch - 60\n",
    "    num_last_layer_epochs = default_params[\"num_last_layer_epochs\"]\n",
    "    push_epochs = range(push_start_epoch, 1000, 30)\n",
    "\n",
    "    params = {\n",
    "        \"protos_per_class\": protos_per_class,\n",
    "        \"proto_features\": proto_features,\n",
    "        \"proto_len_latent\": proto_len,\n",
    "        \"features_lr\": features_lr,\n",
    "        \"num_classes\": ds_info.num_classes,\n",
    "        \"protos_per_class\": protos_per_class,\n",
    "        \"coeffs\": coeffs._asdict(),\n",
    "        \"num_warm_epochs\": num_warm_epochs,\n",
    "        \"push_start_epoch\": push_start_epoch,\n",
    "        \"num_last_layer_epochs\": num_last_layer_epochs,\n",
    "        \"epochs\": epochs,\n",
    "    }\n",
    "    with open(experiment_dir / \"params.json\", \"w\") as f:\n",
    "        json.dump(params, f, indent=4)\n",
    "\n",
    "    log(\n",
    "        f\"Training for {dataset.name}, proto len {proto_len}, reception {reception}, features_lr {features_lr}, protos per class {protos_per_class}, l1_addon {coeffs.l1_addon}\",\n",
    "        flush=True,\n",
    "        display=True\n",
    "    )\n",
    "    log(f'Params: {json.dumps(params, indent=4)}')\n",
    "    \n",
    "    whole_training_start = time.time()\n",
    "\n",
    "    log(f'Training encoder', flush=True, display=True)\n",
    "    autoencoder = PermutingConvAutoencoder(num_features=ds_info.features, latent_features=proto_features, reception_percent=reception, padding=padding)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset.train, batch_size=train_batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset.test, batch_size=test_batch_size)\n",
    "    train_autoencoder(autoencoder, train_loader, test_loader, device=device, log=log)\n",
    "    encoder = autoencoder.encoder\n",
    "\n",
    "    log(f'Training ProtoTSNet', flush=True, display=True)\n",
    "    trainer = train_prototsnet(\n",
    "        dataset,\n",
    "        experiment_dir,\n",
    "        device,\n",
    "        encoder,\n",
    "        features_lr,\n",
    "        coeffs,\n",
    "        protos_per_class,\n",
    "        proto_features,\n",
    "        proto_len,\n",
    "        train_batch_size,\n",
    "        test_batch_size,\n",
    "        num_epochs=epochs,\n",
    "        num_warm_epochs=num_warm_epochs,\n",
    "        push_start_epoch=push_start_epoch,\n",
    "        push_epochs=push_epochs,\n",
    "        ds_info=ds_info,\n",
    "        num_last_layer_epochs=num_last_layer_epochs,\n",
    "        custom_checkpointers=[\n",
    "            get_verbose_logger(dataset.name)\n",
    "        ],\n",
    "        log=log,\n",
    "    )\n",
    "\n",
    "    accu_test = trainer.latest_stat(\"accu_test\")\n",
    "    log(f'Last epoch test accu: {accu_test*100:.2f}%', display=True)\n",
    "    with open(experiment_dir / \"test_accu.json\", \"w\") as f:\n",
    "        json.dump({\"value\": accu_test}, f, indent=4)\n",
    "\n",
    "    whole_training_end = time.time()\n",
    "    log(f\"Done in {trainer.curr_epoch - 1} epochs, {whole_training_end - whole_training_start:.2f}s\", display=True)\n",
    "except Exception as e:\n",
    "    log(f\"Exception ocurred for {ds_info.name}: {e}\", display=True)\n",
    "    tb_str = traceback.format_tb(e.__traceback__)\n",
    "    log('\\n'.join(tb_str), display=True)\n",
    "    raise\n",
    "finally:\n",
    "    logclose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch kernel",
   "language": "python",
   "name": "pytorch"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
