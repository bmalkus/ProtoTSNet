{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torcheval.metrics.functional import multiclass_confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from datasets_utils import  ds_get_info, ds_load, TrainTestDS, TSCDataset, DSInfo, ArtificialProtos\n",
    "from autoencoder import PermutingConvAutoencoder, train_autoencoder, RegularConvEncoder\n",
    "from log import create_logger\n",
    "\n",
    "from typing import Dict\n",
    "\n",
    "from train_utils import EarlyStopping\n",
    "\n",
    "from train import EpochType, ProtoTSCoeffs, train_prototsnet, best_stat_saver, get_verbose_logger, BestModelCheckpointer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "# torch.cuda.set_per_process_memory_fraction(fraction=0.5, device=0)  # or 1, watch out for CUDA_VISIBLE_DEVICES\n",
    "\n",
    "# datasets should be put in the 'datasets/' directory (downloaded from timeseriesclassification.com)\n",
    "DATASETS_PATH = Path('datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_setup(experiment_subpath):\n",
    "    experiment_dir = Path.cwd() / 'experiments' / experiment_subpath\n",
    "    os.makedirs(experiment_dir, exist_ok=True)\n",
    "\n",
    "    shutil.copy(src=Path.cwd()/'autoencoder.py', dst=experiment_dir)\n",
    "    shutil.copy(src=Path.cwd()/'datasets_utils.py', dst=experiment_dir)\n",
    "    shutil.copy(src=Path.cwd()/'experiments.ipynb', dst=experiment_dir)\n",
    "    shutil.copy(src=Path.cwd()/'model.py', dst=experiment_dir)\n",
    "    shutil.copy(src=Path.cwd()/'push.py', dst=experiment_dir)\n",
    "    shutil.copy(src=Path.cwd()/'train_utils.py', dst=experiment_dir)\n",
    "    shutil.copy(src=Path.cwd()/'train.py', dst=experiment_dir)\n",
    "    \n",
    "    return experiment_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b342dedf4bf447bbb86907fd234f8f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading datasets:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainTestDS(name='Libras', train=<datasets_utils.TSCDataset object at 0x7f017712d450>, test=<datasets_utils.TSCDataset object at 0x7f0238452050>, val=None)\n",
      "DSInfo(name='Libras', features=2, ts_len=45, num_classes=15)\n"
     ]
    }
   ],
   "source": [
    "dataset, ds_info = ds_load(DATASETS_PATH, 'Libras', get_info=True)\n",
    "print(dataset)  # contains dataset.train, dataset.test, and optionally dataset.val, each contain X and y (labels), e.g. dataset.train.X\n",
    "print(ds_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "protos_per_class = 3  # number of prototypes will equal 'protos_per_class * number of classes'\n",
    "proto_len = 5  # prototype length (number of time steps) - it is latent space length, so due to receptive field in the input space it is longer\n",
    "proto_features = 32  # number of latent features (dimensions) that input is encoded to\n",
    "reception = 0.75  # estimate for the fraction of significant features, better to underestimate than overestimate\n",
    "features_lr = 1e-3  # currently unused, cyclic LR is used, configurable in train.py: ProtoTSNetTrainer._setup_optimizers()\n",
    "num_warm_epochs = 50  # number of epochs during which encoder weights are frozen, value >0 only makes sense if encoder is pretrained\n",
    "push_start_epoch = 110  # when to start pushing prototypes onto the input data\n",
    "push_epochs = range(push_start_epoch, 1000, 30)  # which epochs to push prototypes on\n",
    "num_last_layer_epochs = 40  # how many epochs to train the last layer (prototypes <-> class mapping)\n",
    "epochs = 200  # overall number of epochs (PUSH + last layer \"epochs\" count as one epoch here), set it so that the training ends with PUSH\n",
    "\n",
    "coeffs = ProtoTSCoeffs(crs_ent=1, l1=1e-3, l1_addon=3e-5)  # how much each element contributes to the loss, l1 is last layer l1 regularization, l1_addon is regularization of feature importance layer\n",
    "\n",
    "train_batch_size = 32\n",
    "# reduce in case dataset is small\n",
    "while train_batch_size > len(dataset.train.X) / 2:\n",
    "    train_batch_size //= 2\n",
    "test_batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for Libras, proto len 5, features_lr 0.001, protos per class 3, l1_addon 3e-05\n",
      "Params: {\n",
      "    \"protos_per_class\": 3,\n",
      "    \"proto_features\": 32,\n",
      "    \"proto_len_latent\": 5,\n",
      "    \"features_lr\": 0.001,\n",
      "    \"num_classes\": 15,\n",
      "    \"coeffs\": {\n",
      "        \"crs_ent\": 1,\n",
      "        \"clst\": 0,\n",
      "        \"sep\": 0,\n",
      "        \"l1\": 0.001,\n",
      "        \"l1_addon\": 3e-05\n",
      "    },\n",
      "    \"num_warm_epochs\": 50,\n",
      "    \"push_start_epoch\": 110,\n",
      "    \"num_last_layer_epochs\": 40,\n",
      "    \"epochs\": 200\n",
      "}\n",
      "Training encoder\n",
      "epoch:   10/300 mse loss: 0.0061\n",
      "epoch:   20/300 mse loss: 0.0024\n",
      "epoch:   30/300 mse loss: 0.0018\n",
      "epoch:   40/300 mse loss: 0.0016\n",
      "epoch:   50/300 mse loss: 0.0013\n",
      "epoch:   60/300 mse loss: 0.0014\n",
      "epoch:   70/300 mse loss: 0.0014\n",
      "epoch:   80/300 mse loss: 0.0015\n",
      "epoch:   90/300 mse loss: 0.0017\n",
      "epoch:  100/300 mse loss: 0.0019\n",
      "epoch:  110/300 mse loss: 0.0016\n",
      "epoch:  120/300 mse loss: 0.0017\n",
      "epoch:  130/300 mse loss: 0.0015\n",
      "epoch:  140/300 mse loss: 0.0015\n",
      "epoch:  150/300 mse loss: 0.0015\n",
      "epoch:  160/300 mse loss: 0.0015\n",
      "epoch:  170/300 mse loss: 0.0014\n",
      "epoch:  180/300 mse loss: 0.0014\n",
      "epoch:  190/300 mse loss: 0.0013\n",
      "epoch:  200/300 mse loss: 0.0015\n",
      "epoch:  210/300 mse loss: 0.0014\n",
      "epoch:  220/300 mse loss: 0.0014\n",
      "epoch:  230/300 mse loss: 0.0014\n",
      "epoch:  240/300 mse loss: 0.0014\n",
      "epoch:  250/300 mse loss: 0.0014\n",
      "epoch:  260/300 mse loss: 0.0014\n",
      "epoch:  270/300 mse loss: 0.0014\n",
      "epoch:  280/300 mse loss: 0.0014\n",
      "epoch:  290/300 mse loss: 0.0014\n",
      "epoch:  300/300 mse loss: 0.0014\n",
      "Training ProtoTSNet\n",
      "Starting training\n",
      "epoch:   1 (WARM) - Libras\n",
      "    test acc:                 6.67%\n",
      "    train overall loss:       3.0287992556889853\n",
      "    train cross_ent loss:     2.707782506942749\n",
      "    test overall loss:        3.029184937477112\n",
      "    test cross_ent loss:      2.708255171775818\n",
      "    cluster loss:             113.43758773803711\n",
      "    separation loss:          70.39138412475586\n",
      "    avg separation loss:      75.36925888061523\n",
      "    l1_addon loss:            197.6547393798828\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.016917705535888672\n",
      "    test time:                0.0038819313049316406\n",
      "    epoch time:               0.021322965621948242\n",
      "epoch:   2 (WARM) - Libras\n",
      "    test acc:                 7.78%\n",
      "    train overall loss:       3.0271829764048257\n",
      "    train cross_ent loss:     2.706312576929728\n",
      "    test overall loss:        3.028934121131897\n",
      "    test cross_ent loss:      2.7081462144851685\n",
      "    cluster loss:             108.64989852905273\n",
      "    separation loss:          60.77347183227539\n",
      "    avg separation loss:      68.16920852661133\n",
      "    l1_addon loss:            192.925537109375\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.01714038848876953\n",
      "    test time:                0.003913164138793945\n",
      "    epoch time:               0.021590709686279297\n",
      "epoch:   3 (WARM) - Libras\n",
      "    test acc:                 8.89%\n",
      "    train overall loss:       3.026005506515503\n",
      "    train cross_ent loss:     2.7052735090255737\n",
      "    test overall loss:        3.0285500288009644\n",
      "    test cross_ent loss:      2.707894206047058\n",
      "    cluster loss:             103.46713256835938\n",
      "    separation loss:          50.65751647949219\n",
      "    avg separation loss:      60.34214210510254\n",
      "    l1_addon loss:            188.52593994140625\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.0169064998626709\n",
      "    test time:                0.003957509994506836\n",
      "    epoch time:               0.02138686180114746\n",
      "epoch:   4 (WARM) - Libras\n",
      "    test acc:                 4.44%\n",
      "    train overall loss:       3.0242099364598594\n",
      "    train cross_ent loss:     2.7036051750183105\n",
      "    test overall loss:        3.028405785560608\n",
      "    test cross_ent loss:      2.7078715562820435\n",
      "    cluster loss:             98.89910125732422\n",
      "    separation loss:          43.88856506347656\n",
      "    avg separation loss:      50.26740837097168\n",
      "    l1_addon loss:            184.47323608398438\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.016828298568725586\n",
      "    test time:                0.003929853439331055\n",
      "    epoch time:               0.021278858184814453\n",
      "epoch:   5 (WARM) - Libras\n",
      "    test acc:                 6.67%\n",
      "    train overall loss:       3.022802988688151\n",
      "    train cross_ent loss:     2.7023170391718545\n",
      "    test overall loss:        3.028294563293457\n",
      "    test cross_ent loss:      2.7078747749328613\n",
      "    cluster loss:             95.8670768737793\n",
      "    separation loss:          38.11326217651367\n",
      "    avg separation loss:      42.942203521728516\n",
      "    l1_addon loss:            180.65472412109375\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.016772031784057617\n",
      "    test time:                0.003898143768310547\n",
      "    epoch time:               0.021193265914916992\n",
      "epoch:   6 (WARM) - Libras\n",
      "    test acc:                 13.33%\n",
      "    train overall loss:       3.0213242769241333\n",
      "    train cross_ent loss:     2.7009496688842773\n",
      "    test overall loss:        3.026942253112793\n",
      "    test cross_ent loss:      2.7066287994384766\n",
      "    cluster loss:             93.60422897338867\n",
      "    separation loss:          33.404354095458984\n",
      "    avg separation loss:      39.80284309387207\n",
      "    l1_addon loss:            177.11117553710938\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.016820192337036133\n",
      "    test time:                0.003914833068847656\n",
      "    epoch time:               0.021263837814331055\n",
      "epoch:   7 (WARM) - Libras\n",
      "    test acc:                 16.11%\n",
      "    train overall loss:       3.0192397038141885\n",
      "    train cross_ent loss:     2.6989656686782837\n",
      "    test overall loss:        3.0251182317733765\n",
      "    test cross_ent loss:      2.7048975229263306\n",
      "    cluster loss:             92.77899932861328\n",
      "    separation loss:          31.596487045288086\n",
      "    avg separation loss:      38.65091896057129\n",
      "    l1_addon loss:            174.02102661132812\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.0167996883392334\n",
      "    test time:                0.0038819313049316406\n",
      "    epoch time:               0.021206140518188477\n",
      "epoch:   8 (WARM) - Libras\n",
      "    test acc:                 22.78%\n",
      "    train overall loss:       3.0170315504074097\n",
      "    train cross_ent loss:     2.6968458890914917\n",
      "    test overall loss:        3.023179769515991\n",
      "    test cross_ent loss:      2.7030420303344727\n",
      "    cluster loss:             92.24612045288086\n",
      "    separation loss:          31.826950073242188\n",
      "    avg separation loss:      38.47647666931152\n",
      "    l1_addon loss:            171.2564697265625\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.01683783531188965\n",
      "    test time:                0.0039038658142089844\n",
      "    epoch time:               0.021276235580444336\n",
      "epoch:   9 (WARM) - Libras\n",
      "    test acc:                 30.00%\n",
      "    train overall loss:       3.0143867333730063\n",
      "    train cross_ent loss:     2.6942829688390098\n",
      "    test overall loss:        3.020232677459717\n",
      "    test cross_ent loss:      2.700176477432251\n",
      "    cluster loss:             91.4019660949707\n",
      "    separation loss:          30.946735382080078\n",
      "    avg separation loss:      37.855194091796875\n",
      "    l1_addon loss:            168.53558349609375\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.016863584518432617\n",
      "    test time:                0.0038788318634033203\n",
      "    epoch time:               0.021287918090820312\n",
      "epoch:  10 (WARM) - Libras\n",
      "    test acc:                 32.22%\n",
      "    train overall loss:       3.0115774075190225\n",
      "    train cross_ent loss:     2.6915558179219565\n",
      "    test overall loss:        3.016559362411499\n",
      "    test cross_ent loss:      2.696585178375244\n",
      "    cluster loss:             90.2877082824707\n",
      "    separation loss:          29.167572021484375\n",
      "    avg separation loss:      36.89995002746582\n",
      "    l1_addon loss:            165.8038330078125\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.01683783531188965\n",
      "    test time:                0.003897428512573242\n",
      "    epoch time:               0.021254539489746094\n",
      "epoch:  11 (WARM) - Libras\n",
      "    test acc:                 32.78%\n",
      "    train overall loss:       3.008140246073405\n",
      "    train cross_ent loss:     2.6881988843282065\n",
      "    test overall loss:        3.0121917724609375\n",
      "    test cross_ent loss:      2.6922953128814697\n",
      "    cluster loss:             89.18630409240723\n",
      "    separation loss:          27.43857479095459\n",
      "    avg separation loss:      35.79088592529297\n",
      "    l1_addon loss:            163.21426391601562\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017083168029785156\n",
      "    test time:                0.0043964385986328125\n",
      "    epoch time:               0.022032499313354492\n",
      "epoch:  12 (WARM) - Libras\n",
      "    test acc:                 35.56%\n",
      "    train overall loss:       3.0044838587443032\n",
      "    train cross_ent loss:     2.6846137841542563\n",
      "    test overall loss:        3.008135437965393\n",
      "    test cross_ent loss:      2.6883023977279663\n",
      "    cluster loss:             88.15939521789551\n",
      "    separation loss:          25.91414451599121\n",
      "    avg separation loss:      34.78973197937012\n",
      "    l1_addon loss:            161.09555053710938\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.01763772964477539\n",
      "    test time:                0.004271984100341797\n",
      "    epoch time:               0.022455215454101562\n",
      "epoch:  13 (WARM) - Libras\n",
      "    test acc:                 36.67%\n",
      "    train overall loss:       2.9997100035349527\n",
      "    train cross_ent loss:     2.6799048582712808\n",
      "    test overall loss:        3.0034377574920654\n",
      "    test cross_ent loss:      2.6836698055267334\n",
      "    cluster loss:             87.22042274475098\n",
      "    separation loss:          24.373655319213867\n",
      "    avg separation loss:      33.68486213684082\n",
      "    l1_addon loss:            158.93115234375\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017207622528076172\n",
      "    test time:                0.00513768196105957\n",
      "    epoch time:               0.022880077362060547\n",
      "epoch:  14 (WARM) - Libras\n",
      "    test acc:                 37.78%\n",
      "    train overall loss:       2.994297424952189\n",
      "    train cross_ent loss:     2.6745557387669883\n",
      "    test overall loss:        2.998175859451294\n",
      "    test cross_ent loss:      2.6784720420837402\n",
      "    cluster loss:             86.35290336608887\n",
      "    separation loss:          22.82337760925293\n",
      "    avg separation loss:      32.622249603271484\n",
      "    l1_addon loss:            156.79302978515625\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.01715850830078125\n",
      "    test time:                0.004268169403076172\n",
      "    epoch time:               0.021986961364746094\n",
      "epoch:  15 (WARM) - Libras\n",
      "    test acc:                 39.44%\n",
      "    train overall loss:       2.9865705966949463\n",
      "    train cross_ent loss:     2.6668965021769204\n",
      "    test overall loss:        2.9928736686706543\n",
      "    test cross_ent loss:      2.673238515853882\n",
      "    cluster loss:             85.49144744873047\n",
      "    separation loss:          21.31515598297119\n",
      "    avg separation loss:      31.644036293029785\n",
      "    l1_addon loss:            154.49984741210938\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.01717352867126465\n",
      "    test time:                0.004297971725463867\n",
      "    epoch time:               0.022000551223754883\n",
      "epoch:  16 (WARM) - Libras\n",
      "    test acc:                 38.89%\n",
      "    train overall loss:       2.9808223247528076\n",
      "    train cross_ent loss:     2.6612101793289185\n",
      "    test overall loss:        2.9852001667022705\n",
      "    test cross_ent loss:      2.665621757507324\n",
      "    cluster loss:             84.61372566223145\n",
      "    separation loss:          19.791606903076172\n",
      "    avg separation loss:      30.59078884124756\n",
      "    l1_addon loss:            152.61483764648438\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017127513885498047\n",
      "    test time:                0.004277229309082031\n",
      "    epoch time:               0.021934986114501953\n",
      "epoch:  17 (WARM) - Libras\n",
      "    test acc:                 40.00%\n",
      "    train overall loss:       2.969057321548462\n",
      "    train cross_ent loss:     2.6495058139165244\n",
      "    test overall loss:        2.9772047996520996\n",
      "    test cross_ent loss:      2.6576945781707764\n",
      "    cluster loss:             83.91894912719727\n",
      "    separation loss:          18.66177463531494\n",
      "    avg separation loss:      29.524819374084473\n",
      "    l1_addon loss:            150.33970642089844\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017140865325927734\n",
      "    test time:                0.0042994022369384766\n",
      "    epoch time:               0.021971940994262695\n",
      "epoch:  18 (WARM) - Libras\n",
      "    test acc:                 41.11%\n",
      "    train overall loss:       2.9583427906036377\n",
      "    train cross_ent loss:     2.6388642390569053\n",
      "    test overall loss:        2.96873939037323\n",
      "    test cross_ent loss:      2.6493035554885864\n",
      "    cluster loss:             83.27256965637207\n",
      "    separation loss:          17.692174911499023\n",
      "    avg separation loss:      28.535176277160645\n",
      "    l1_addon loss:            147.86221313476562\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017086029052734375\n",
      "    test time:                0.004282474517822266\n",
      "    epoch time:               0.021898984909057617\n",
      "epoch:  19 (WARM) - Libras\n",
      "    test acc:                 41.11%\n",
      "    train overall loss:       2.9464194774627686\n",
      "    train cross_ent loss:     2.627009312311808\n",
      "    test overall loss:        2.9592225551605225\n",
      "    test cross_ent loss:      2.639845848083496\n",
      "    cluster loss:             82.49220848083496\n",
      "    separation loss:          16.497015476226807\n",
      "    avg separation loss:      27.567733764648438\n",
      "    l1_addon loss:            145.89044189453125\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017194747924804688\n",
      "    test time:                0.0042612552642822266\n",
      "    epoch time:               0.02198958396911621\n",
      "epoch:  20 (WARM) - Libras\n",
      "    test acc:                 41.11%\n",
      "    train overall loss:       2.931593418121338\n",
      "    train cross_ent loss:     2.6122422218322754\n",
      "    test overall loss:        2.9467579126358032\n",
      "    test cross_ent loss:      2.627445340156555\n",
      "    cluster loss:             81.8457145690918\n",
      "    separation loss:          15.319555759429932\n",
      "    avg separation loss:      26.383764266967773\n",
      "    l1_addon loss:            143.75181579589844\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017477035522460938\n",
      "    test time:                0.00429224967956543\n",
      "    epoch time:               0.0223236083984375\n",
      "epoch:  21 (WARM) - Libras\n",
      "    test acc:                 41.11%\n",
      "    train overall loss:       2.9114269812901816\n",
      "    train cross_ent loss:     2.592139720916748\n",
      "    test overall loss:        2.9328445196151733\n",
      "    test cross_ent loss:      2.6135913133621216\n",
      "    cluster loss:             81.22199821472168\n",
      "    separation loss:          14.231282234191895\n",
      "    avg separation loss:      25.313987731933594\n",
      "    l1_addon loss:            141.77090454101562\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.01723456382751465\n",
      "    test time:                0.004291057586669922\n",
      "    epoch time:               0.02205681800842285\n",
      "epoch:  22 (WARM) - Libras\n",
      "    test acc:                 40.56%\n",
      "    train overall loss:       2.8898797035217285\n",
      "    train cross_ent loss:     2.5706498622894287\n",
      "    test overall loss:        2.914434552192688\n",
      "    test cross_ent loss:      2.5952361822128296\n",
      "    cluster loss:             80.58547782897949\n",
      "    separation loss:          13.142463684082031\n",
      "    avg separation loss:      24.25401782989502\n",
      "    l1_addon loss:            139.94155883789062\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017310142517089844\n",
      "    test time:                0.00426793098449707\n",
      "    epoch time:               0.022105932235717773\n",
      "epoch:  23 (WARM) - Libras\n",
      "    test acc:                 42.22%\n",
      "    train overall loss:       2.8671369155248008\n",
      "    train cross_ent loss:     2.5479600032170615\n",
      "    test overall loss:        2.8916901350021362\n",
      "    test cross_ent loss:      2.5725380182266235\n",
      "    cluster loss:             79.98798179626465\n",
      "    separation loss:          12.002447128295898\n",
      "    avg separation loss:      23.090962409973145\n",
      "    l1_addon loss:            138.40159606933594\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017220020294189453\n",
      "    test time:                0.004292011260986328\n",
      "    epoch time:               0.02204418182373047\n",
      "epoch:  24 (WARM) - Libras\n",
      "    test acc:                 41.11%\n",
      "    train overall loss:       2.827610731124878\n",
      "    train cross_ent loss:     2.508479356765747\n",
      "    test overall loss:        2.8688063621520996\n",
      "    test cross_ent loss:      2.549705743789673\n",
      "    cluster loss:             79.50150489807129\n",
      "    separation loss:          11.01296854019165\n",
      "    avg separation loss:      22.039928436279297\n",
      "    l1_addon loss:            136.68167114257812\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017303466796875\n",
      "    test time:                0.0043370723724365234\n",
      "    epoch time:               0.02217268943786621\n",
      "epoch:  25 (WARM) - Libras\n",
      "    test acc:                 41.11%\n",
      "    train overall loss:       2.781458258628845\n",
      "    train cross_ent loss:     2.4623806476593018\n",
      "    test overall loss:        2.842051148414612\n",
      "    test cross_ent loss:      2.5230103731155396\n",
      "    cluster loss:             79.0258846282959\n",
      "    separation loss:          10.052958011627197\n",
      "    avg separation loss:      20.957746505737305\n",
      "    l1_addon loss:            134.6938934326172\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.0172574520111084\n",
      "    test time:                0.004273176193237305\n",
      "    epoch time:               0.02206277847290039\n",
      "epoch:  26 (WARM) - Libras\n",
      "    test acc:                 42.78%\n",
      "    train overall loss:       2.755818327267965\n",
      "    train cross_ent loss:     2.4368037382761636\n",
      "    test overall loss:        2.808334231376648\n",
      "    test cross_ent loss:      2.489354968070984\n",
      "    cluster loss:             78.59615898132324\n",
      "    separation loss:          9.212061405181885\n",
      "    avg separation loss:      19.971132278442383\n",
      "    l1_addon loss:            132.6435546875\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017214536666870117\n",
      "    test time:                0.004285573959350586\n",
      "    epoch time:               0.0220334529876709\n",
      "epoch:  27 (WARM) - Libras\n",
      "    test acc:                 43.89%\n",
      "    train overall loss:       2.7024470567703247\n",
      "    train cross_ent loss:     2.3834896087646484\n",
      "    test overall loss:        2.7761412858963013\n",
      "    test cross_ent loss:      2.45720899105072\n",
      "    cluster loss:             78.11178207397461\n",
      "    separation loss:          8.38527512550354\n",
      "    avg separation loss:      18.85002613067627\n",
      "    l1_addon loss:            131.07473754882812\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017277240753173828\n",
      "    test time:                0.004259824752807617\n",
      "    epoch time:               0.02206707000732422\n",
      "epoch:  28 (WARM) - Libras\n",
      "    test acc:                 42.78%\n",
      "    train overall loss:       2.662312865257263\n",
      "    train cross_ent loss:     2.343406875928243\n",
      "    test overall loss:        2.7444766759872437\n",
      "    test cross_ent loss:      2.4256099462509155\n",
      "    cluster loss:             77.83680725097656\n",
      "    separation loss:          7.864752769470215\n",
      "    avg separation loss:      18.174641609191895\n",
      "    l1_addon loss:            128.89039611816406\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017294645309448242\n",
      "    test time:                0.00461125373840332\n",
      "    epoch time:               0.02243781089782715\n",
      "epoch:  29 (WARM) - Libras\n",
      "    test acc:                 47.22%\n",
      "    train overall loss:       2.5904351472854614\n",
      "    train cross_ent loss:     2.271575133005778\n",
      "    test overall loss:        2.7090017795562744\n",
      "    test cross_ent loss:      2.390155553817749\n",
      "    cluster loss:             77.4234390258789\n",
      "    separation loss:          7.209011554718018\n",
      "    avg separation loss:      17.3558349609375\n",
      "    l1_addon loss:            128.20425415039062\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017322540283203125\n",
      "    test time:                0.004294395446777344\n",
      "    epoch time:               0.022147178649902344\n",
      "epoch:  30 (WARM) - Libras\n",
      "    test acc:                 44.44%\n",
      "    train overall loss:       2.527649164199829\n",
      "    train cross_ent loss:     2.2088295221328735\n",
      "    test overall loss:        2.6676584482192993\n",
      "    test cross_ent loss:      2.3488739728927612\n",
      "    cluster loss:             77.11367225646973\n",
      "    separation loss:          6.4574058055877686\n",
      "    avg separation loss:      16.57534408569336\n",
      "    l1_addon loss:            126.15013885498047\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.0172421932220459\n",
      "    test time:                0.004267692565917969\n",
      "    epoch time:               0.02204108238220215\n",
      "epoch:  31 (WARM) - Libras\n",
      "    test acc:                 45.56%\n",
      "    train overall loss:       2.50178325176239\n",
      "    train cross_ent loss:     2.183013121287028\n",
      "    test overall loss:        2.6289591789245605\n",
      "    test cross_ent loss:      2.3102052211761475\n",
      "    cluster loss:             76.77302360534668\n",
      "    separation loss:          5.853018760681152\n",
      "    avg separation loss:      15.71925401687622\n",
      "    l1_addon loss:            125.13105773925781\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.0173032283782959\n",
      "    test time:                0.0042879581451416016\n",
      "    epoch time:               0.022122859954833984\n",
      "epoch:  32 (WARM) - Libras\n",
      "    test acc:                 47.22%\n",
      "    train overall loss:       2.4299093882242837\n",
      "    train cross_ent loss:     2.111178716023763\n",
      "    test overall loss:        2.5978455543518066\n",
      "    test cross_ent loss:      2.279148817062378\n",
      "    cluster loss:             76.56747817993164\n",
      "    separation loss:          5.413105249404907\n",
      "    avg separation loss:      15.064569473266602\n",
      "    l1_addon loss:            123.2223892211914\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.01725292205810547\n",
      "    test time:                0.004282712936401367\n",
      "    epoch time:               0.022093534469604492\n",
      "epoch:  33 (WARM) - Libras\n",
      "    test acc:                 46.11%\n",
      "    train overall loss:       2.3775362968444824\n",
      "    train cross_ent loss:     2.058857540289561\n",
      "    test overall loss:        2.5617377758026123\n",
      "    test cross_ent loss:      2.24308443069458\n",
      "    cluster loss:             76.33439636230469\n",
      "    separation loss:          4.916078805923462\n",
      "    avg separation loss:      14.269880771636963\n",
      "    l1_addon loss:            121.77559661865234\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.01726841926574707\n",
      "    test time:                0.00426173210144043\n",
      "    epoch time:               0.022061824798583984\n",
      "epoch:  34 (WARM) - Libras\n",
      "    test acc:                 47.22%\n",
      "    train overall loss:       2.3165138165156045\n",
      "    train cross_ent loss:     1.9978793859481812\n",
      "    test overall loss:        2.5194270610809326\n",
      "    test cross_ent loss:      2.200820207595825\n",
      "    cluster loss:             76.12337303161621\n",
      "    separation loss:          4.513864040374756\n",
      "    avg separation loss:      13.628066062927246\n",
      "    l1_addon loss:            120.2266845703125\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017258644104003906\n",
      "    test time:                0.004353046417236328\n",
      "    epoch time:               0.02213883399963379\n",
      "epoch:  35 (WARM) - Libras\n",
      "    test acc:                 48.33%\n",
      "    train overall loss:       2.304786801338196\n",
      "    train cross_ent loss:     1.986195723215739\n",
      "    test overall loss:        2.483440399169922\n",
      "    test cross_ent loss:      2.1648669242858887\n",
      "    cluster loss:             75.98797798156738\n",
      "    separation loss:          4.194704532623291\n",
      "    avg separation loss:      13.087477684020996\n",
      "    l1_addon loss:            119.11731719970703\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.0172879695892334\n",
      "    test time:                0.004291057586669922\n",
      "    epoch time:               0.022108793258666992\n",
      "epoch:  36 (WARM) - Libras\n",
      "    test acc:                 48.89%\n",
      "    train overall loss:       2.2125097115834556\n",
      "    train cross_ent loss:     1.8939433693885803\n",
      "    test overall loss:        2.4747719764709473\n",
      "    test cross_ent loss:      2.15623140335083\n",
      "    cluster loss:             75.89127349853516\n",
      "    separation loss:          3.9447855949401855\n",
      "    avg separation loss:      12.703064918518066\n",
      "    l1_addon loss:            118.01679992675781\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017611980438232422\n",
      "    test time:                0.00431370735168457\n",
      "    epoch time:               0.022464752197265625\n",
      "epoch:  37 (WARM) - Libras\n",
      "    test acc:                 48.89%\n",
      "    train overall loss:       2.1381388107935586\n",
      "    train cross_ent loss:     1.81961594025294\n",
      "    test overall loss:        2.4296624660491943\n",
      "    test cross_ent loss:      2.111156702041626\n",
      "    cluster loss:             75.74709510803223\n",
      "    separation loss:          3.753108024597168\n",
      "    avg separation loss:      12.299893856048584\n",
      "    l1_addon loss:            116.853271484375\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017343759536743164\n",
      "    test time:                0.004277467727661133\n",
      "    epoch time:               0.02217888832092285\n",
      "epoch:  38 (WARM) - Libras\n",
      "    test acc:                 51.67%\n",
      "    train overall loss:       2.1600541273752847\n",
      "    train cross_ent loss:     1.8415680925051372\n",
      "    test overall loss:        2.3935588598251343\n",
      "    test cross_ent loss:      2.075104832649231\n",
      "    cluster loss:             75.6269302368164\n",
      "    separation loss:          3.520045280456543\n",
      "    avg separation loss:      11.796624660491943\n",
      "    l1_addon loss:            115.13341522216797\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017346858978271484\n",
      "    test time:                0.004263401031494141\n",
      "    epoch time:               0.022142410278320312\n",
      "epoch:  39 (WARM) - Libras\n",
      "    test acc:                 51.11%\n",
      "    train overall loss:       2.0613762935002646\n",
      "    train cross_ent loss:     1.7429372072219849\n",
      "    test overall loss:        2.3787081241607666\n",
      "    test cross_ent loss:      2.0602946877479553\n",
      "    cluster loss:             75.55010795593262\n",
      "    separation loss:          3.303775191307068\n",
      "    avg separation loss:      11.562729358673096\n",
      "    l1_addon loss:            113.7799301147461\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017287015914916992\n",
      "    test time:                0.0042607784271240234\n",
      "    epoch time:               0.022082090377807617\n",
      "epoch:  40 (WARM) - Libras\n",
      "    test acc:                 52.78%\n",
      "    train overall loss:       1.9923189878463745\n",
      "    train cross_ent loss:     1.673925240834554\n",
      "    test overall loss:        2.3560731410980225\n",
      "    test cross_ent loss:      2.0376952290534973\n",
      "    cluster loss:             75.4894790649414\n",
      "    separation loss:          3.128222107887268\n",
      "    avg separation loss:      11.058692932128906\n",
      "    l1_addon loss:            112.59754943847656\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017369985580444336\n",
      "    test time:                0.009629487991333008\n",
      "    epoch time:               0.027529239654541016\n",
      "epoch:  41 (WARM) - Libras\n",
      "    test acc:                 52.22%\n",
      "    train overall loss:       2.018275717894236\n",
      "    train cross_ent loss:     1.6999080379803975\n",
      "    test overall loss:        2.319044351577759\n",
      "    test cross_ent loss:      2.000692129135132\n",
      "    cluster loss:             75.41740798950195\n",
      "    separation loss:          2.9839800596237183\n",
      "    avg separation loss:      10.80004596710205\n",
      "    l1_addon loss:            111.73677825927734\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.01737809181213379\n",
      "    test time:                0.004294633865356445\n",
      "    epoch time:               0.022206544876098633\n",
      "epoch:  42 (WARM) - Libras\n",
      "    test acc:                 52.78%\n",
      "    train overall loss:       1.9938997824986775\n",
      "    train cross_ent loss:     1.6755614082018535\n",
      "    test overall loss:        2.3130578994750977\n",
      "    test cross_ent loss:      1.9947400093078613\n",
      "    cluster loss:             75.35987091064453\n",
      "    separation loss:          2.8629651069641113\n",
      "    avg separation loss:      10.60143756866455\n",
      "    l1_addon loss:            110.59110260009766\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017338037490844727\n",
      "    test time:                0.0042879581451416016\n",
      "    epoch time:               0.022154569625854492\n",
      "epoch:  43 (WARM) - Libras\n",
      "    test acc:                 52.22%\n",
      "    train overall loss:       1.9417275190353394\n",
      "    train cross_ent loss:     1.623425841331482\n",
      "    test overall loss:        2.2976598739624023\n",
      "    test cross_ent loss:      1.979377031326294\n",
      "    cluster loss:             75.32519721984863\n",
      "    separation loss:          2.736556887626648\n",
      "    avg separation loss:      10.28233289718628\n",
      "    l1_addon loss:            109.42402648925781\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.01737213134765625\n",
      "    test time:                0.004298686981201172\n",
      "    epoch time:               0.02220916748046875\n",
      "epoch:  44 (WARM) - Libras\n",
      "    test acc:                 56.11%\n",
      "    train overall loss:       1.9421101013819377\n",
      "    train cross_ent loss:     1.623838186264038\n",
      "    test overall loss:        2.2670395374298096\n",
      "    test cross_ent loss:      1.9487812519073486\n",
      "    cluster loss:             75.2989616394043\n",
      "    separation loss:          2.6588650941848755\n",
      "    avg separation loss:      10.044905662536621\n",
      "    l1_addon loss:            108.60598754882812\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017411231994628906\n",
      "    test time:                0.004353523254394531\n",
      "    epoch time:               0.02229619026184082\n",
      "epoch:  45 (WARM) - Libras\n",
      "    test acc:                 53.33%\n",
      "    train overall loss:       1.970674713452657\n",
      "    train cross_ent loss:     1.6524320443471272\n",
      "    test overall loss:        2.264685273170471\n",
      "    test cross_ent loss:      1.9464656114578247\n",
      "    cluster loss:             75.28336715698242\n",
      "    separation loss:          2.529046058654785\n",
      "    avg separation loss:      9.858327865600586\n",
      "    l1_addon loss:            107.32398986816406\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.01737689971923828\n",
      "    test time:                0.004282474517822266\n",
      "    epoch time:               0.022191524505615234\n",
      "epoch:  46 (WARM) - Libras\n",
      "    test acc:                 52.78%\n",
      "    train overall loss:       1.893498698870341\n",
      "    train cross_ent loss:     1.5752964814503987\n",
      "    test overall loss:        2.246224284172058\n",
      "    test cross_ent loss:      1.9280389547348022\n",
      "    cluster loss:             75.25360107421875\n",
      "    separation loss:          2.4670320749282837\n",
      "    avg separation loss:      9.582651615142822\n",
      "    l1_addon loss:            106.17784881591797\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017385482788085938\n",
      "    test time:                0.004265785217285156\n",
      "    epoch time:               0.022181987762451172\n",
      "epoch:  47 (WARM) - Libras\n",
      "    test acc:                 53.33%\n",
      "    train overall loss:       1.862494210402171\n",
      "    train cross_ent loss:     1.5443103909492493\n",
      "    test overall loss:        2.210057497024536\n",
      "    test cross_ent loss:      1.8918850421905518\n",
      "    cluster loss:             75.21131706237793\n",
      "    separation loss:          2.4409533739089966\n",
      "    avg separation loss:      9.444603443145752\n",
      "    l1_addon loss:            105.74801635742188\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.01739335060119629\n",
      "    test time:                0.0042572021484375\n",
      "    epoch time:               0.02218151092529297\n",
      "epoch:  48 (WARM) - Libras\n",
      "    test acc:                 53.33%\n",
      "    train overall loss:       1.8440525730450947\n",
      "    train cross_ent loss:     1.5258983373641968\n",
      "    test overall loss:        2.1987574100494385\n",
      "    test cross_ent loss:      1.8806226253509521\n",
      "    cluster loss:             75.18120384216309\n",
      "    separation loss:          2.4126665592193604\n",
      "    avg separation loss:      9.287100791931152\n",
      "    l1_addon loss:            104.48847961425781\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.01735544204711914\n",
      "    test time:                0.004296064376831055\n",
      "    epoch time:               0.022185087203979492\n",
      "epoch:  49 (WARM) - Libras\n",
      "    test acc:                 57.22%\n",
      "    train overall loss:       1.7789967060089111\n",
      "    train cross_ent loss:     1.460864742596944\n",
      "    test overall loss:        2.1676493883132935\n",
      "    test cross_ent loss:      1.8495266437530518\n",
      "    cluster loss:             75.15899467468262\n",
      "    separation loss:          2.3517456650733948\n",
      "    avg separation loss:      9.047847747802734\n",
      "    l1_addon loss:            104.09403228759766\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017371654510498047\n",
      "    test time:                0.004289150238037109\n",
      "    epoch time:               0.022190570831298828\n",
      "epoch:  50 (WARM) - Libras\n",
      "    test acc:                 56.67%\n",
      "    train overall loss:       1.7539174556732178\n",
      "    train cross_ent loss:     1.4358052015304565\n",
      "    test overall loss:        2.157177686691284\n",
      "    test cross_ent loss:      1.8390856981277466\n",
      "    cluster loss:             75.13476371765137\n",
      "    separation loss:          2.2966176867485046\n",
      "    avg separation loss:      8.997964859008789\n",
      "    l1_addon loss:            103.06486511230469\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.017426729202270508\n",
      "    test time:                0.004312992095947266\n",
      "    epoch time:               0.022268295288085938\n",
      "epoch:  51 (JOINT) - Libras\n",
      "    test acc:                 43.33%\n",
      "    train overall loss:       2.1331445574760437\n",
      "    train cross_ent loss:     1.8150530060132344\n",
      "    test overall loss:        2.679958701133728\n",
      "    test cross_ent loss:      2.3618675470352173\n",
      "    cluster loss:             76.07832145690918\n",
      "    separation loss:          3.5705511569976807\n",
      "    avg separation loss:      11.167133331298828\n",
      "    l1_addon loss:            103.03776550292969\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.027104616165161133\n",
      "    test time:                0.004351377487182617\n",
      "    epoch time:               0.03206586837768555\n",
      "    joint lr:                 0.0030601000000000087\n",
      "epoch:  52 (JOINT) - Libras\n",
      "    test acc:                 13.89%\n",
      "    train overall loss:       2.8204557498296103\n",
      "    train cross_ent loss:     2.5023642579714456\n",
      "    test overall loss:        3.013060212135315\n",
      "    test cross_ent loss:      2.694968104362488\n",
      "    cluster loss:             84.23416709899902\n",
      "    separation loss:          15.236831665039062\n",
      "    avg separation loss:      33.22650909423828\n",
      "    l1_addon loss:            103.06488037109375\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.025959491729736328\n",
      "    test time:                0.004390239715576172\n",
      "    epoch time:               0.030924081802368164\n",
      "    joint lr:                 0.005960997999999999\n",
      "epoch:  53 (JOINT) - Libras\n",
      "    test acc:                 7.78%\n",
      "    train overall loss:       2.955749193827311\n",
      "    train cross_ent loss:     2.6376561721165976\n",
      "    test overall loss:        3.026414632797241\n",
      "    test cross_ent loss:      2.7083230018615723\n",
      "    cluster loss:             105.45266723632812\n",
      "    separation loss:          34.84599781036377\n",
      "    avg separation loss:      101.00299453735352\n",
      "    l1_addon loss:            103.04852294921875\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.025080204010009766\n",
      "    test time:                0.0043985843658447266\n",
      "    epoch time:               0.03005361557006836\n",
      "    joint lr:                 0.008803582030000007\n",
      "epoch:  54 (JOINT) - Libras\n",
      "    test acc:                 11.67%\n",
      "    train overall loss:       2.8690691788991294\n",
      "    train cross_ent loss:     2.5509860515594482\n",
      "    test overall loss:        3.0249656438827515\n",
      "    test cross_ent loss:      2.7068995237350464\n",
      "    cluster loss:             96.72637176513672\n",
      "    separation loss:          31.40033721923828\n",
      "    avg separation loss:      79.16804122924805\n",
      "    l1_addon loss:            102.200439453125\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.025438785552978516\n",
      "    test time:                0.004339694976806641\n",
      "    epoch time:               0.030364274978637695\n",
      "    joint lr:                 0.011588728279599995\n",
      "epoch:  55 (JOINT) - Libras\n",
      "    test acc:                 14.44%\n",
      "    train overall loss:       2.7865437269210815\n",
      "    train cross_ent loss:     2.4685026009877524\n",
      "    test overall loss:        3.005566120147705\n",
      "    test cross_ent loss:      2.687558889389038\n",
      "    cluster loss:             83.15297317504883\n",
      "    separation loss:          13.554322242736816\n",
      "    avg separation loss:      37.493587493896484\n",
      "    l1_addon loss:            100.23727416992188\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.02505636215209961\n",
      "    test time:                0.004342555999755859\n",
      "    epoch time:               0.029960155487060547\n",
      "    joint lr:                 0.014317301246005004\n",
      "epoch:  56 (JOINT) - Libras\n",
      "    test acc:                 13.89%\n",
      "    train overall loss:       2.547448992729187\n",
      "    train cross_ent loss:     2.229465961456299\n",
      "    test overall loss:        3.0177741050720215\n",
      "    test cross_ent loss:      2.699814796447754\n",
      "    cluster loss:             84.42102432250977\n",
      "    separation loss:          15.281112670898438\n",
      "    avg separation loss:      37.574331283569336\n",
      "    l1_addon loss:            98.63999938964844\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.025162458419799805\n",
      "    test time:                0.004273176193237305\n",
      "    epoch time:               0.029990673065185547\n",
      "    joint lr:                 0.016990153880253933\n",
      "epoch:  57 (JOINT) - Libras\n",
      "    test acc:                 9.44%\n",
      "    train overall loss:       2.366689682006836\n",
      "    train cross_ent loss:     2.048743486404419\n",
      "    test overall loss:        3.0191762447357178\n",
      "    test cross_ent loss:      2.7012670040130615\n",
      "    cluster loss:             82.65972900390625\n",
      "    separation loss:          12.148989200592041\n",
      "    avg separation loss:      28.92878532409668\n",
      "    l1_addon loss:            96.9739990234375\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.02475571632385254\n",
      "    test time:                0.004297733306884766\n",
      "    epoch time:               0.02960658073425293\n",
      "    joint lr:                 0.019608127731693303\n",
      "epoch:  58 (JOINT) - Libras\n",
      "    test acc:                 33.33%\n",
      "    train overall loss:       2.2561941941579184\n",
      "    train cross_ent loss:     1.9382821718851726\n",
      "    test overall loss:        2.9887874126434326\n",
      "    test cross_ent loss:      2.6708996295928955\n",
      "    cluster loss:             81.2374210357666\n",
      "    separation loss:          10.205639362335205\n",
      "    avg separation loss:      25.036906242370605\n",
      "    l1_addon loss:            96.25923156738281\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.024874210357666016\n",
      "    test time:                0.004273176193237305\n",
      "    epoch time:               0.029698610305786133\n",
      "    joint lr:                 0.02217205309071584\n",
      "epoch:  59 (JOINT) - Libras\n",
      "    test acc:                 27.22%\n",
      "    train overall loss:       2.174399514993032\n",
      "    train cross_ent loss:     1.8565016786257427\n",
      "    test overall loss:        2.969953179359436\n",
      "    test cross_ent loss:      2.6520780324935913\n",
      "    cluster loss:             80.54415702819824\n",
      "    separation loss:          9.853501319885254\n",
      "    avg separation loss:      22.45987319946289\n",
      "    l1_addon loss:            95.83362579345703\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.02475452423095703\n",
      "    test time:                0.004301786422729492\n",
      "    epoch time:               0.029610872268676758\n",
      "    joint lr:                 0.024682749129784777\n",
      "epoch:  60 (JOINT) - Libras\n",
      "    test acc:                 17.78%\n",
      "    train overall loss:       2.002700626850128\n",
      "    train cross_ent loss:     1.6848213871320088\n",
      "    test overall loss:        3.0042502880096436\n",
      "    test cross_ent loss:      2.686367988586426\n",
      "    cluster loss:             83.9113826751709\n",
      "    separation loss:          10.916559219360352\n",
      "    avg separation loss:      43.46254920959473\n",
      "    l1_addon loss:            96.07749938964844\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.02473592758178711\n",
      "    test time:                0.004279613494873047\n",
      "    epoch time:               0.029567480087280273\n",
      "    joint lr:                 0.027141024042763244\n",
      "epoch:  61 (JOINT) - Libras\n",
      "    test acc:                 46.11%\n",
      "    train overall loss:       2.0150466561317444\n",
      "    train cross_ent loss:     1.6971292694409688\n",
      "    test overall loss:        2.664999008178711\n",
      "    test cross_ent loss:      2.3470470905303955\n",
      "    cluster loss:             76.30904388427734\n",
      "    separation loss:          3.543534278869629\n",
      "    avg separation loss:      10.975993633270264\n",
      "    l1_addon loss:            98.39523315429688\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.02471327781677246\n",
      "    test time:                0.004282951354980469\n",
      "    epoch time:               0.02955007553100586\n",
      "    joint lr:                 0.025532083112218835\n",
      "epoch:  62 (JOINT) - Libras\n",
      "    test acc:                 24.44%\n",
      "    train overall loss:       1.8764257629712422\n",
      "    train cross_ent loss:     1.55848228931427\n",
      "    test overall loss:        2.8987900018692017\n",
      "    test cross_ent loss:      2.5808082818984985\n",
      "    cluster loss:             77.37647819519043\n",
      "    separation loss:          4.611880540847778\n",
      "    avg separation loss:      13.048887729644775\n",
      "    l1_addon loss:            99.3853988647461\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.027987003326416016\n",
      "    test time:                0.004563808441162109\n",
      "    epoch time:               0.03310227394104004\n",
      "    joint lr:                 0.023952616897881036\n",
      "epoch:  63 (JOINT) - Libras\n",
      "    test acc:                 50.56%\n",
      "    train overall loss:       1.799239953358968\n",
      "    train cross_ent loss:     1.4812434315681458\n",
      "    test overall loss:        2.8908365964889526\n",
      "    test cross_ent loss:      2.572807192802429\n",
      "    cluster loss:             78.52890396118164\n",
      "    separation loss:          7.434918165206909\n",
      "    avg separation loss:      17.183591842651367\n",
      "    l1_addon loss:            100.97477722167969\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.029001474380493164\n",
      "    test time:                0.004372596740722656\n",
      "    epoch time:               0.03392314910888672\n",
      "    joint lr:                 0.022402196799518763\n",
      "epoch:  64 (JOINT) - Libras\n",
      "    test acc:                 31.11%\n",
      "    train overall loss:       1.7446553309758503\n",
      "    train cross_ent loss:     1.426634967327118\n",
      "    test overall loss:        2.8814990520477295\n",
      "    test cross_ent loss:      2.563457489013672\n",
      "    cluster loss:             78.70504379272461\n",
      "    separation loss:          6.049242973327637\n",
      "    avg separation loss:      17.276862144470215\n",
      "    l1_addon loss:            101.38024139404297\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.03007221221923828\n",
      "    test time:                0.009964942932128906\n",
      "    epoch time:               0.04067063331604004\n",
      "    joint lr:                 0.02088039984143395\n",
      "epoch:  65 (JOINT) - Libras\n",
      "    test acc:                 34.44%\n",
      "    train overall loss:       1.7166802883148193\n",
      "    train cross_ent loss:     1.398662805557251\n",
      "    test overall loss:        2.7109657526016235\n",
      "    test cross_ent loss:      2.3928858041763306\n",
      "    cluster loss:             76.03372764587402\n",
      "    separation loss:          2.485524296760559\n",
      "    avg separation loss:      9.747879981994629\n",
      "    l1_addon loss:            102.66493225097656\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.03152966499328613\n",
      "    test time:                0.016976356506347656\n",
      "    epoch time:               0.04926276206970215\n",
      "    joint lr:                 0.01938680860283089\n",
      "epoch:  66 (JOINT) - Libras\n",
      "    test acc:                 45.56%\n",
      "    train overall loss:       1.6338172554969788\n",
      "    train cross_ent loss:     1.3157092928886414\n",
      "    test overall loss:        2.566675066947937\n",
      "    test cross_ent loss:      2.248625636100769\n",
      "    cluster loss:             75.5976619720459\n",
      "    separation loss:          1.9808399677276611\n",
      "    avg separation loss:      8.077941417694092\n",
      "    l1_addon loss:            101.64839172363281\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.037993669509887695\n",
      "    test time:                0.0167388916015625\n",
      "    epoch time:               0.05554628372192383\n",
      "    joint lr:                 0.017921011149015745\n",
      "epoch:  67 (JOINT) - Libras\n",
      "    test acc:                 51.11%\n",
      "    train overall loss:       1.5850770274798076\n",
      "    train cross_ent loss:     1.2670040329297383\n",
      "    test overall loss:        2.2914562225341797\n",
      "    test cross_ent loss:      1.9733300805091858\n",
      "    cluster loss:             75.28219413757324\n",
      "    separation loss:          1.6745344996452332\n",
      "    avg separation loss:      7.018672943115234\n",
      "    l1_addon loss:            104.20868682861328\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.032964229583740234\n",
      "    test time:                0.010040998458862305\n",
      "    epoch time:               0.04366660118103027\n",
      "    joint lr:                 0.016482600963416614\n",
      "epoch:  68 (JOINT) - Libras\n",
      "    test acc:                 46.67%\n",
      "    train overall loss:       1.4686158498128254\n",
      "    train cross_ent loss:     1.1505276064078014\n",
      "    test overall loss:        2.0737669467926025\n",
      "    test cross_ent loss:      1.7556940913200378\n",
      "    cluster loss:             75.13681602478027\n",
      "    separation loss:          1.2832926511764526\n",
      "    avg separation loss:      6.63002872467041\n",
      "    l1_addon loss:            102.42672729492188\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.03224468231201172\n",
      "    test time:                0.0044062137603759766\n",
      "    epoch time:               0.03732562065124512\n",
      "    joint lr:                 0.015071176880414561\n",
      "epoch:  69 (JOINT) - Libras\n",
      "    test acc:                 58.33%\n",
      "    train overall loss:       1.3807950814565022\n",
      "    train cross_ent loss:     1.062702586253484\n",
      "    test overall loss:        2.0850125551223755\n",
      "    test cross_ent loss:      1.766926109790802\n",
      "    cluster loss:             75.18546295166016\n",
      "    separation loss:          1.4699735045433044\n",
      "    avg separation loss:      6.001545190811157\n",
      "    l1_addon loss:            102.88026428222656\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.029482364654541016\n",
      "    test time:                0.010169267654418945\n",
      "    epoch time:               0.04035210609436035\n",
      "    joint lr:                 0.01368634301897622\n",
      "epoch:  70 (JOINT) - Libras\n",
      "    test acc:                 49.44%\n",
      "    train overall loss:       1.3657675782839458\n",
      "    train cross_ent loss:     1.0476756691932678\n",
      "    test overall loss:        2.3697097301483154\n",
      "    test cross_ent loss:      2.05157333612442\n",
      "    cluster loss:             75.2984561920166\n",
      "    separation loss:          1.7087373733520508\n",
      "    avg separation loss:      7.867413520812988\n",
      "    l1_addon loss:            104.54949951171875\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.030609130859375\n",
      "    test time:                0.004591464996337891\n",
      "    epoch time:               0.03589653968811035\n",
      "    joint lr:                 0.012327708717078603\n",
      "epoch:  71 (JOINT) - Libras\n",
      "    test acc:                 72.78%\n",
      "    train overall loss:       1.4376139839490254\n",
      "    train cross_ent loss:     1.1194969912370045\n",
      "    test overall loss:        1.614783227443695\n",
      "    test cross_ent loss:      1.29669588804245\n",
      "    cluster loss:             74.9407787322998\n",
      "    separation loss:          1.2502802610397339\n",
      "    avg separation loss:      6.091376543045044\n",
      "    l1_addon loss:            102.90940856933594\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.02939152717590332\n",
      "    test time:                0.01009058952331543\n",
      "    epoch time:               0.040184736251831055\n",
      "    joint lr:                 0.01099488846691703\n",
      "epoch:  72 (JOINT) - Libras\n",
      "    test acc:                 71.67%\n",
      "    train overall loss:       1.2861600915590923\n",
      "    train cross_ent loss:     0.9680646359920502\n",
      "    test overall loss:        1.5146973729133606\n",
      "    test cross_ent loss:      1.196601688861847\n",
      "    cluster loss:             74.89746284484863\n",
      "    separation loss:          1.1476194560527802\n",
      "    avg separation loss:      5.562093257904053\n",
      "    l1_addon loss:            103.1883544921875\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.029432058334350586\n",
      "    test time:                0.005141496658325195\n",
      "    epoch time:               0.035265207290649414\n",
      "    joint lr:                 0.009687501850886984\n",
      "epoch:  73 (JOINT) - Libras\n",
      "    test acc:                 55.00%\n",
      "    train overall loss:       1.0845102469126384\n",
      "    train cross_ent loss:     0.7664189537366232\n",
      "    test overall loss:        1.9337862133979797\n",
      "    test cross_ent loss:      1.6156893968582153\n",
      "    cluster loss:             75.10596466064453\n",
      "    separation loss:          1.3812176585197449\n",
      "    avg separation loss:      5.388411045074463\n",
      "    l1_addon loss:            103.22550201416016\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.029073476791381836\n",
      "    test time:                0.004780292510986328\n",
      "    epoch time:               0.034542083740234375\n",
      "    joint lr:                 0.008405173478330853\n",
      "epoch:  74 (JOINT) - Libras\n",
      "    test acc:                 72.78%\n",
      "    train overall loss:       1.0219130615393321\n",
      "    train cross_ent loss:     0.7038128127654394\n",
      "    test overall loss:        1.6232860088348389\n",
      "    test cross_ent loss:      1.305182695388794\n",
      "    cluster loss:             74.92655372619629\n",
      "    separation loss:          1.0824944376945496\n",
      "    avg separation loss:      5.697256088256836\n",
      "    l1_addon loss:            103.4428939819336\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.029408931732177734\n",
      "    test time:                0.010108232498168945\n",
      "    epoch time:               0.04021430015563965\n",
      "    joint lr:                 0.007147532923040749\n",
      "epoch:  75 (JOINT) - Libras\n",
      "    test acc:                 66.11%\n",
      "    train overall loss:       0.9367864628632864\n",
      "    train cross_ent loss:     0.6186863780021667\n",
      "    test overall loss:        1.497039258480072\n",
      "    test cross_ent loss:      1.1789575219154358\n",
      "    cluster loss:             74.88106346130371\n",
      "    separation loss:          0.9217827916145325\n",
      "    avg separation loss:      4.729510068893433\n",
      "    l1_addon loss:            102.72225952148438\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.029624223709106445\n",
      "    test time:                0.004747152328491211\n",
      "    epoch time:               0.03506135940551758\n",
      "    joint lr:                 0.005914214661508615\n",
      "epoch:  76 (JOINT) - Libras\n",
      "    test acc:                 58.89%\n",
      "    train overall loss:       0.8945282896359762\n",
      "    train cross_ent loss:     0.5764513810475668\n",
      "    test overall loss:        1.638809323310852\n",
      "    test cross_ent loss:      1.320712924003601\n",
      "    cluster loss:             74.8995475769043\n",
      "    separation loss:          0.9685636758804321\n",
      "    avg separation loss:      5.078881740570068\n",
      "    l1_addon loss:            103.21070098876953\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.0301516056060791\n",
      "    test time:                0.010102987289428711\n",
      "    epoch time:               0.04095292091369629\n",
      "    joint lr:                 0.004704858011914826\n",
      "epoch:  77 (JOINT) - Libras\n",
      "    test acc:                 78.33%\n",
      "    train overall loss:       0.8524787823359171\n",
      "    train cross_ent loss:     0.5343822439511617\n",
      "    test overall loss:        1.1353334188461304\n",
      "    test cross_ent loss:      0.817249596118927\n",
      "    cluster loss:             74.78763961791992\n",
      "    separation loss:          0.7907306551933289\n",
      "    avg separation loss:      4.589858531951904\n",
      "    l1_addon loss:            102.79405212402344\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.03007793426513672\n",
      "    test time:                0.010131120681762695\n",
      "    epoch time:               0.04090237617492676\n",
      "    joint lr:                 0.0035191070738467612\n",
      "epoch:  78 (JOINT) - Libras\n",
      "    test acc:                 77.22%\n",
      "    train overall loss:       0.8393919169902802\n",
      "    train cross_ent loss:     0.5213092168172201\n",
      "    test overall loss:        1.1034998297691345\n",
      "    test cross_ent loss:      0.7854150533676147\n",
      "    cluster loss:             74.77670860290527\n",
      "    separation loss:          0.7679888010025024\n",
      "    avg separation loss:      4.6856279373168945\n",
      "    l1_addon loss:            102.82742309570312\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.03139162063598633\n",
      "    test time:                0.009917020797729492\n",
      "    epoch time:               0.04190874099731445\n",
      "    joint lr:                 0.00235661066873886\n",
      "epoch:  79 (JOINT) - Libras\n",
      "    test acc:                 75.56%\n",
      "    train overall loss:       0.7899537086486816\n",
      "    train cross_ent loss:     0.4718676507472992\n",
      "    test overall loss:        1.1377344131469727\n",
      "    test cross_ent loss:      0.8196525871753693\n",
      "    cluster loss:             74.79140281677246\n",
      "    separation loss:          0.7706112563610077\n",
      "    avg separation loss:      4.73319673538208\n",
      "    l1_addon loss:            102.72666931152344\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.03152751922607422\n",
      "    test time:                0.004666328430175781\n",
      "    epoch time:               0.03681492805480957\n",
      "    joint lr:                 0.001217022281025732\n",
      "epoch:  80 (JOINT) - Libras\n",
      "    test acc:                 81.67%\n",
      "    train overall loss:       0.7699562708536783\n",
      "    train cross_ent loss:     0.45187458644310635\n",
      "    test overall loss:        1.0542572438716888\n",
      "    test cross_ent loss:      0.7361745238304138\n",
      "    cluster loss:             74.76951026916504\n",
      "    separation loss:          0.7374404966831207\n",
      "    avg separation loss:      4.551227569580078\n",
      "    l1_addon loss:            102.75718688964844\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.03171181678771973\n",
      "    test time:                0.00786137580871582\n",
      "    epoch time:               0.0401763916015625\n",
      "    joint lr:                 0.0001\n",
      "epoch:  81 (JOINT) - Libras\n",
      "    test acc:                 82.22%\n",
      "    train overall loss:       0.7786542177200317\n",
      "    train cross_ent loss:     0.46057132879892987\n",
      "    test overall loss:        1.0236272513866425\n",
      "    test cross_ent loss:      0.7055442631244659\n",
      "    cluster loss:             74.75728416442871\n",
      "    separation loss:          0.727341890335083\n",
      "    avg separation loss:      4.488312244415283\n",
      "    l1_addon loss:            102.76448059082031\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.03149819374084473\n",
      "    test time:                0.010002374649047852\n",
      "    epoch time:               0.04216313362121582\n",
      "    joint lr:                 0.00228958707526664\n",
      "epoch:  82 (JOINT) - Libras\n",
      "    test acc:                 83.33%\n",
      "    train overall loss:       0.7395926813284556\n",
      "    train cross_ent loss:     0.421509824693203\n",
      "    test overall loss:        1.0557065308094025\n",
      "    test cross_ent loss:      0.7376241683959961\n",
      "    cluster loss:             74.76772499084473\n",
      "    separation loss:          0.7187071144580841\n",
      "    avg separation loss:      4.350803375244141\n",
      "    l1_addon loss:            102.7442398071289\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.031716346740722656\n",
      "    test time:                0.005356788635253906\n",
      "    epoch time:               0.03771781921386719\n",
      "    joint lr:                 0.004435382409027948\n",
      "epoch:  83 (JOINT) - Libras\n",
      "    test acc:                 81.67%\n",
      "    train overall loss:       0.7351633707682291\n",
      "    train cross_ent loss:     0.417082076271375\n",
      "    test overall loss:        1.0225280225276947\n",
      "    test cross_ent loss:      0.7044537961483002\n",
      "    cluster loss:             74.76267051696777\n",
      "    separation loss:          0.7159480154514313\n",
      "    avg separation loss:      4.49013090133667\n",
      "    l1_addon loss:            102.47370910644531\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.031577110290527344\n",
      "    test time:                0.010007858276367188\n",
      "    epoch time:               0.04218935966491699\n",
      "    joint lr:                 0.006538042877406532\n",
      "epoch:  84 (JOINT) - Libras\n",
      "    test acc:                 78.33%\n",
      "    train overall loss:       0.8012531995773315\n",
      "    train cross_ent loss:     0.4831858326991399\n",
      "    test overall loss:        1.0522624254226685\n",
      "    test cross_ent loss:      0.734175831079483\n",
      "    cluster loss:             74.76136016845703\n",
      "    separation loss:          0.7167134881019592\n",
      "    avg separation loss:      4.138848304748535\n",
      "    l1_addon loss:            102.88671112060547\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.030755996704101562\n",
      "    test time:                0.0045239925384521484\n",
      "    epoch time:               0.035909175872802734\n",
      "    joint lr:                 0.008598216598176611\n",
      "epoch:  85 (JOINT) - Libras\n",
      "    test acc:                 78.33%\n",
      "    train overall loss:       0.9087856213251749\n",
      "    train cross_ent loss:     0.590695858001709\n",
      "    test overall loss:        1.185454547405243\n",
      "    test cross_ent loss:      0.8673962950706482\n",
      "    cluster loss:             74.81962013244629\n",
      "    separation loss:          0.7991145253181458\n",
      "    avg separation loss:      4.337625741958618\n",
      "    l1_addon loss:            101.93991088867188\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.03491473197937012\n",
      "    test time:                0.010757207870483398\n",
      "    epoch time:               0.046372413635253906\n",
      "    joint lr:                 0.010616543040243577\n",
      "epoch:  86 (JOINT) - Libras\n",
      "    test acc:                 78.33%\n",
      "    train overall loss:       0.9590157965819041\n",
      "    train cross_ent loss:     0.6409322718779246\n",
      "    test overall loss:        1.2400320768356323\n",
      "    test cross_ent loss:      0.9219397902488708\n",
      "    cluster loss:             74.79724311828613\n",
      "    separation loss:          0.7315353453159332\n",
      "    avg separation loss:      4.234765291213989\n",
      "    l1_addon loss:            103.07456970214844\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.030784130096435547\n",
      "    test time:                0.009893178939819336\n",
      "    epoch time:               0.041352033615112305\n",
      "    joint lr:                 0.012593653131809358\n",
      "epoch:  87 (JOINT) - Libras\n",
      "    test acc:                 76.67%\n",
      "    train overall loss:       0.9467882215976715\n",
      "    train cross_ent loss:     0.6287509004275004\n",
      "    test overall loss:        1.3160706162452698\n",
      "    test cross_ent loss:      0.9980522990226746\n",
      "    cluster loss:             74.85408782958984\n",
      "    separation loss:          0.840325117111206\n",
      "    avg separation loss:      4.23945164680481\n",
      "    l1_addon loss:            100.60978698730469\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.03168201446533203\n",
      "    test time:                0.010047435760498047\n",
      "    epoch time:               0.042340993881225586\n",
      "    joint lr:                 0.014530169367239798\n",
      "epoch:  88 (JOINT) - Libras\n",
      "    test acc:                 63.89%\n",
      "    train overall loss:       1.0511435866355896\n",
      "    train cross_ent loss:     0.7330888112386068\n",
      "    test overall loss:        1.6319758892059326\n",
      "    test cross_ent loss:      1.3139245510101318\n",
      "    cluster loss:             74.93209648132324\n",
      "    separation loss:          1.0149263441562653\n",
      "    avg separation loss:      4.369618892669678\n",
      "    l1_addon loss:            101.70779418945312\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.028949975967407227\n",
      "    test time:                0.010058879852294922\n",
      "    epoch time:               0.03962850570678711\n",
      "    joint lr:                 0.01642670591264845\n",
      "epoch:  89 (JOINT) - Libras\n",
      "    test acc:                 61.67%\n",
      "    train overall loss:       1.0874444842338562\n",
      "    train cross_ent loss:     0.7693915367126465\n",
      "    test overall loss:        1.7909618020057678\n",
      "    test cross_ent loss:      1.4728909134864807\n",
      "    cluster loss:             74.93857955932617\n",
      "    separation loss:          0.9420373439788818\n",
      "    avg separation loss:      3.9271146059036255\n",
      "    l1_addon loss:            102.36053466796875\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.031771183013916016\n",
      "    test time:                0.01009511947631836\n",
      "    epoch time:               0.04248642921447754\n",
      "    joint lr:                 0.018283868710212207\n",
      "epoch:  90 (JOINT) - Libras\n",
      "    test acc:                 58.89%\n",
      "    train overall loss:       1.1970244844754536\n",
      "    train cross_ent loss:     0.878981371720632\n",
      "    test overall loss:        1.757946789264679\n",
      "    test cross_ent loss:      1.439911425113678\n",
      "    cluster loss:             74.96912384033203\n",
      "    separation loss:          0.8651730120182037\n",
      "    avg separation loss:      3.6232253313064575\n",
      "    l1_addon loss:            101.17670440673828\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.030763626098632812\n",
      "    test time:                0.010025501251220703\n",
      "    epoch time:               0.04141998291015625\n",
      "    joint lr:                 0.020102255581233422\n",
      "epoch:  91 (JOINT) - Libras\n",
      "    test acc:                 32.78%\n",
      "    train overall loss:       1.0882976055145264\n",
      "    train cross_ent loss:     0.7702459295590719\n",
      "    test overall loss:        2.4494904279708862\n",
      "    test cross_ent loss:      2.13143527507782\n",
      "    cluster loss:             75.33615303039551\n",
      "    separation loss:          1.3985341787338257\n",
      "    avg separation loss:      5.5901267528533936\n",
      "    l1_addon loss:            101.83319091796875\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.031759023666381836\n",
      "    test time:                0.00777435302734375\n",
      "    epoch time:               0.04014325141906738\n",
      "    joint lr:                 0.018912121374150048\n",
      "epoch:  92 (JOINT) - Libras\n",
      "    test acc:                 46.11%\n",
      "    train overall loss:       1.1054445306460063\n",
      "    train cross_ent loss:     0.7873849471410116\n",
      "    test overall loss:        2.1132840514183044\n",
      "    test cross_ent loss:      1.7952260375022888\n",
      "    cluster loss:             75.04998207092285\n",
      "    separation loss:          0.8257373571395874\n",
      "    avg separation loss:      4.559410810470581\n",
      "    l1_addon loss:            101.93325805664062\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.032004594802856445\n",
      "    test time:                0.010814189910888672\n",
      "    epoch time:               0.043506622314453125\n",
      "    joint lr:                 0.017743789625650205\n",
      "epoch:  93 (JOINT) - Libras\n",
      "    test acc:                 50.00%\n",
      "    train overall loss:       1.0432806611061096\n",
      "    train cross_ent loss:     0.7252166867256165\n",
      "    test overall loss:        1.9482667446136475\n",
      "    test cross_ent loss:      1.630211055278778\n",
      "    cluster loss:             75.00061225891113\n",
      "    separation loss:          0.9963591396808624\n",
      "    avg separation loss:      4.628558158874512\n",
      "    l1_addon loss:            101.85529327392578\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.030891895294189453\n",
      "    test time:                0.004502058029174805\n",
      "    epoch time:               0.03605246543884277\n",
      "    joint lr:                 0.01659694329998293\n",
      "epoch:  94 (JOINT) - Libras\n",
      "    test acc:                 50.56%\n",
      "    train overall loss:       1.1067063609759014\n",
      "    train cross_ent loss:     0.7886252005894979\n",
      "    test overall loss:        1.9386272430419922\n",
      "    test cross_ent loss:      1.6205796003341675\n",
      "    cluster loss:             75.00919723510742\n",
      "    separation loss:          0.8576319515705109\n",
      "    avg separation loss:      3.772945284843445\n",
      "    l1_addon loss:            101.58515167236328\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.0349276065826416\n",
      "    test time:                0.010738372802734375\n",
      "    epoch time:               0.046373844146728516\n",
      "    joint lr:                 0.01547126952186645\n",
      "epoch:  95 (JOINT) - Libras\n",
      "    test acc:                 62.78%\n",
      "    train overall loss:       1.1721557875474293\n",
      "    train cross_ent loss:     0.8540831406911215\n",
      "    test overall loss:        1.6432967782020569\n",
      "    test cross_ent loss:      1.3251803517341614\n",
      "    cluster loss:             74.92878150939941\n",
      "    separation loss:          0.9314010739326477\n",
      "    avg separation loss:      4.541894912719727\n",
      "    l1_addon loss:            103.87982940673828\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.031511545181274414\n",
      "    test time:                0.01089334487915039\n",
      "    epoch time:               0.043107032775878906\n",
      "    joint lr:                 0.014366459524982304\n",
      "epoch:  96 (JOINT) - Libras\n",
      "    test acc:                 67.78%\n",
      "    train overall loss:       1.002302924791972\n",
      "    train cross_ent loss:     0.6842069874207178\n",
      "    test overall loss:        1.570196270942688\n",
      "    test cross_ent loss:      1.252098798751831\n",
      "    cluster loss:             74.8650016784668\n",
      "    separation loss:          0.7162860631942749\n",
      "    avg separation loss:      3.914780855178833\n",
      "    l1_addon loss:            103.24578857421875\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.034970760345458984\n",
      "    test time:                0.013648748397827148\n",
      "    epoch time:               0.04929018020629883\n",
      "    joint lr:                 0.013282208601083652\n",
      "epoch:  97 (JOINT) - Libras\n",
      "    test acc:                 76.67%\n",
      "    train overall loss:       0.8933809796969095\n",
      "    train cross_ent loss:     0.5752845456202825\n",
      "    test overall loss:        1.2451874017715454\n",
      "    test cross_ent loss:      0.9271078109741211\n",
      "    cluster loss:             74.80034446716309\n",
      "    separation loss:          0.8097765147686005\n",
      "    avg separation loss:      4.094592809677124\n",
      "    l1_addon loss:            102.65289306640625\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.0349578857421875\n",
      "    test time:                0.010784626007080078\n",
      "    epoch time:               0.04645419120788574\n",
      "    joint lr:                 0.012218216049710476\n",
      "epoch:  98 (JOINT) - Libras\n",
      "    test acc:                 70.00%\n",
      "    train overall loss:       0.8497535387674967\n",
      "    train cross_ent loss:     0.5316541890303293\n",
      "    test overall loss:        1.4320971369743347\n",
      "    test cross_ent loss:      1.113973319530487\n",
      "    cluster loss:             74.82653999328613\n",
      "    separation loss:          0.6986908316612244\n",
      "    avg separation loss:      3.7954410314559937\n",
      "    l1_addon loss:            104.12480163574219\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.026407718658447266\n",
      "    test time:                0.004068851470947266\n",
      "    epoch time:               0.031063079833984375\n",
      "    joint lr:                 0.011174185128504639\n",
      "epoch:  99 (JOINT) - Libras\n",
      "    test acc:                 83.33%\n",
      "    train overall loss:       0.8453983167807261\n",
      "    train cross_ent loss:     0.5272922317186991\n",
      "    test overall loss:        0.9783892035484314\n",
      "    test cross_ent loss:      0.6602997481822968\n",
      "    cluster loss:             74.78461456298828\n",
      "    separation loss:          0.7042034566402435\n",
      "    avg separation loss:      3.8457000255584717\n",
      "    l1_addon loss:            102.98133850097656\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.026590585708618164\n",
      "    test time:                0.003975391387939453\n",
      "    epoch time:               0.03114604949951172\n",
      "    joint lr:                 0.010149823004117963\n",
      "epoch: 100 (JOINT) - Libras\n",
      "    test acc:                 82.78%\n",
      "    train overall loss:       0.8686939477920532\n",
      "    train cross_ent loss:     0.5505853494008383\n",
      "    test overall loss:        1.0511501133441925\n",
      "    test cross_ent loss:      0.7330343723297119\n",
      "    cluster loss:             74.78203201293945\n",
      "    separation loss:          0.6338321268558502\n",
      "    avg separation loss:      3.531739592552185\n",
      "    l1_addon loss:            103.85676574707031\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.02642035484313965\n",
      "    test time:                0.004090547561645508\n",
      "    epoch time:               0.031102418899536133\n",
      "    joint lr:                 0.009144840703706159\n",
      "epoch: 101 (JOINT) - Libras\n",
      "    test acc:                 75.56%\n",
      "    train overall loss:       0.7115327616532644\n",
      "    train cross_ent loss:     0.39343131085236865\n",
      "    test overall loss:        1.2069186568260193\n",
      "    test cross_ent loss:      0.8888239860534668\n",
      "    cluster loss:             74.80673789978027\n",
      "    separation loss:          0.6799313127994537\n",
      "    avg separation loss:      3.7210981845855713\n",
      "    l1_addon loss:            103.15721130371094\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.027418136596679688\n",
      "    test time:                0.003971099853515625\n",
      "    epoch time:               0.03195619583129883\n",
      "    joint lr:                 0.008158953067002189\n",
      "epoch: 102 (JOINT) - Libras\n",
      "    test acc:                 82.78%\n",
      "    train overall loss:       0.7293973962465922\n",
      "    train cross_ent loss:     0.4112914154926936\n",
      "    test overall loss:        1.0925323367118835\n",
      "    test cross_ent loss:      0.7744131088256836\n",
      "    cluster loss:             74.77621841430664\n",
      "    separation loss:          0.6300360858440399\n",
      "    avg separation loss:      3.4096771478652954\n",
      "    l1_addon loss:            103.97526550292969\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.026743650436401367\n",
      "    test time:                0.003973960876464844\n",
      "    epoch time:               0.031255245208740234\n",
      "    joint lr:                 0.0071918786989619305\n",
      "epoch: 103 (JOINT) - Libras\n",
      "    test acc:                 83.33%\n",
      "    train overall loss:       0.7137565116087595\n",
      "    train cross_ent loss:     0.3956408550341924\n",
      "    test overall loss:        1.0235776901245117\n",
      "    test cross_ent loss:      0.705485612154007\n",
      "    cluster loss:             74.76358413696289\n",
      "    separation loss:          0.641480028629303\n",
      "    avg separation loss:      3.4858168363571167\n",
      "    l1_addon loss:            103.0694808959961\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.02761554718017578\n",
      "    test time:                0.0040073394775390625\n",
      "    epoch time:               0.032175540924072266\n",
      "    joint lr:                 0.006243339922975775\n",
      "epoch: 104 (JOINT) - Libras\n",
      "    test acc:                 83.33%\n",
      "    train overall loss:       0.6639320453008016\n",
      "    train cross_ent loss:     0.3458387603362401\n",
      "    test overall loss:        0.9922777414321899\n",
      "    test cross_ent loss:      0.6741627752780914\n",
      "    cluster loss:             74.74611854553223\n",
      "    separation loss:          0.5811177790164948\n",
      "    avg separation loss:      3.3615827560424805\n",
      "    l1_addon loss:            103.83216857910156\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.0267331600189209\n",
      "    test time:                0.004060268402099609\n",
      "    epoch time:               0.03138542175292969\n",
      "    joint lr:                 0.005313062734639446\n",
      "epoch: 105 (JOINT) - Libras\n",
      "    test acc:                 86.11%\n",
      "    train overall loss:       0.6175529857476553\n",
      "    train cross_ent loss:     0.29943138857682544\n",
      "    test overall loss:        0.8576966524124146\n",
      "    test cross_ent loss:      0.5395818948745728\n",
      "    cluster loss:             74.74489784240723\n",
      "    separation loss:          0.5455439239740372\n",
      "    avg separation loss:      3.343185305595398\n",
      "    l1_addon loss:            103.82542419433594\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.02919459342956543\n",
      "    test time:                0.003964900970458984\n",
      "    epoch time:               0.03369498252868652\n",
      "    joint lr:                 0.004400776756077547\n",
      "epoch: 106 (JOINT) - Libras\n",
      "    test acc:                 87.22%\n",
      "    train overall loss:       0.5594432304302851\n",
      "    train cross_ent loss:     0.24133671323458353\n",
      "    test overall loss:        0.8645309209823608\n",
      "    test cross_ent loss:      0.5464305877685547\n",
      "    cluster loss:             74.74590110778809\n",
      "    separation loss:          0.5815350115299225\n",
      "    avg separation loss:      3.2088165283203125\n",
      "    l1_addon loss:            103.34207153320312\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.029259443283081055\n",
      "    test time:                0.004227876663208008\n",
      "    epoch time:               0.034301042556762695\n",
      "    joint lr:                 0.0035062151908134102\n",
      "epoch: 107 (JOINT) - Libras\n",
      "    test acc:                 87.22%\n",
      "    train overall loss:       0.5474054465691248\n",
      "    train cross_ent loss:     0.22930640975634256\n",
      "    test overall loss:        0.8651476502418518\n",
      "    test cross_ent loss:      0.5470443367958069\n",
      "    cluster loss:             74.73988914489746\n",
      "    separation loss:          0.5506010502576828\n",
      "    avg separation loss:      3.125761866569519\n",
      "    l1_addon loss:            103.44393157958984\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.029543161392211914\n",
      "    test time:                0.003981590270996094\n",
      "    epoch time:               0.03406882286071777\n",
      "    joint lr:                 0.0026291147791789593\n",
      "epoch: 108 (JOINT) - Libras\n",
      "    test acc:                 85.00%\n",
      "    train overall loss:       0.5653670827547709\n",
      "    train cross_ent loss:     0.24726330861449242\n",
      "    test overall loss:        0.8295482397079468\n",
      "    test cross_ent loss:      0.5114419460296631\n",
      "    cluster loss:             74.72665596008301\n",
      "    separation loss:          0.5310169011354446\n",
      "    avg separation loss:      3.104044795036316\n",
      "    l1_addon loss:            103.54081726074219\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.028537750244140625\n",
      "    test time:                0.003996133804321289\n",
      "    epoch time:               0.03307008743286133\n",
      "    joint lr:                 0.001769215754258106\n",
      "epoch: 109 (JOINT) - Libras\n",
      "    test acc:                 86.67%\n",
      "    train overall loss:       0.5267225454250971\n",
      "    train cross_ent loss:     0.2086183006564776\n",
      "    test overall loss:        0.8016951680183411\n",
      "    test cross_ent loss:      0.48359666764736176\n",
      "    cluster loss:             74.72087097167969\n",
      "    separation loss:          0.523473471403122\n",
      "    avg separation loss:      3.1071141958236694\n",
      "    l1_addon loss:            103.28254699707031\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.027889490127563477\n",
      "    test time:                0.003963947296142578\n",
      "    epoch time:               0.03241419792175293\n",
      "    joint lr:                 0.0009262617983577627\n",
      "epoch: 110 (JOINT) - Libras\n",
      "    test acc:                 87.22%\n",
      "    train overall loss:       0.5710267821947733\n",
      "    train cross_ent loss:     0.2529303195575873\n",
      "    test overall loss:        0.79208043217659\n",
      "    test cross_ent loss:      0.4739862233400345\n",
      "    cluster loss:             74.7226333618164\n",
      "    separation loss:          0.5187835693359375\n",
      "    avg separation loss:      3.109866499900818\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.028594255447387695\n",
      "    test time:                0.003977060317993164\n",
      "    epoch time:               0.03311419486999512\n",
      "    joint lr:                 0.0001\n",
      "epoch: 110 (PUSH) - Libras\n",
      "    test acc:                 80.56%\n",
      "    train overall loss:       0.5710267821947733\n",
      "    train cross_ent loss:     0.2529303195575873\n",
      "    test overall loss:        0.8625351786613464\n",
      "    test cross_ent loss:      0.5444409251213074\n",
      "    cluster loss:             74.71639633178711\n",
      "    separation loss:          0.5263721197843552\n",
      "    avg separation loss:      3.1679913997650146\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  315.0\n",
      "    train time:               0.028594255447387695\n",
      "    test time:                0.003995180130004883\n",
      "    epoch time:               0.06612920761108398\n",
      "epoch: 110 (1/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 80.00%\n",
      "    train overall loss:       0.588198592265447\n",
      "    train cross_ent loss:     0.27008916189273197\n",
      "    test overall loss:        0.8550176024436951\n",
      "    test cross_ent loss:      0.5369046330451965\n",
      "    cluster loss:             74.7164134979248\n",
      "    separation loss:          0.529035285115242\n",
      "    avg separation loss:      3.1909594535827637\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  315.018798828125\n",
      "    train time:               0.01246023178100586\n",
      "    test time:                0.004019498825073242\n",
      "    epoch time:               0.016956090927124023\n",
      "    last layer lr:            0.0007599999999999978\n",
      "epoch: 110 (2/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 80.00%\n",
      "    train overall loss:       0.6650434831778208\n",
      "    train cross_ent loss:     0.34697052588065463\n",
      "    test overall loss:        0.8486132323741913\n",
      "    test cross_ent loss:      0.5305754244327545\n",
      "    cluster loss:             74.71630859375\n",
      "    separation loss:          0.5287504643201828\n",
      "    avg separation loss:      3.198095679283142\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  314.943603515625\n",
      "    train time:               0.012320995330810547\n",
      "    test time:                0.003988981246948242\n",
      "    epoch time:               0.016765832901000977\n",
      "    last layer lr:            0.0014200000000000013\n",
      "epoch: 110 (3/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 80.00%\n",
      "    train overall loss:       0.5919515738884608\n",
      "    train cross_ent loss:     0.27388275414705276\n",
      "    test overall loss:        0.8385952115058899\n",
      "    test cross_ent loss:      0.5204952359199524\n",
      "    cluster loss:             74.71645736694336\n",
      "    separation loss:          0.5296973437070847\n",
      "    avg separation loss:      3.20439875125885\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  315.0057373046875\n",
      "    train time:               0.012314558029174805\n",
      "    test time:                0.004010915756225586\n",
      "    epoch time:               0.016780614852905273\n",
      "    last layer lr:            0.0020799999999999985\n",
      "epoch: 110 (4/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 80.56%\n",
      "    train overall loss:       0.5828650643428167\n",
      "    train cross_ent loss:     0.26471620549758273\n",
      "    test overall loss:        0.825590968132019\n",
      "    test cross_ent loss:      0.5073927491903305\n",
      "    cluster loss:             74.71581840515137\n",
      "    separation loss:          0.5296514183282852\n",
      "    avg separation loss:      3.218936562538147\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  315.10400390625\n",
      "    train time:               0.01229238510131836\n",
      "    test time:                0.004027128219604492\n",
      "    epoch time:               0.016774654388427734\n",
      "    last layer lr:            0.0027400000000000024\n",
      "epoch: 110 (5/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 81.11%\n",
      "    train overall loss:       0.5955724368492762\n",
      "    train cross_ent loss:     0.2774480606118838\n",
      "    test overall loss:        0.8121393918991089\n",
      "    test cross_ent loss:      0.4941478967666626\n",
      "    cluster loss:             74.71602249145508\n",
      "    separation loss:          0.5308187156915665\n",
      "    avg separation loss:      3.2206268310546875\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  314.89727783203125\n",
      "    train time:               0.012280702590942383\n",
      "    test time:                0.0040111541748046875\n",
      "    epoch time:               0.016746997833251953\n",
      "    last layer lr:            0.0034\n",
      "epoch: 110 (6/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 81.67%\n",
      "    train overall loss:       0.5918307850758234\n",
      "    train cross_ent loss:     0.273967223862807\n",
      "    test overall loss:        0.7963143289089203\n",
      "    test cross_ent loss:      0.4786510616540909\n",
      "    cluster loss:             74.71652603149414\n",
      "    separation loss:          0.5345426797866821\n",
      "    avg separation loss:      3.2160192728042603\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  314.5690612792969\n",
      "    train time:               0.01230478286743164\n",
      "    test time:                0.004041433334350586\n",
      "    epoch time:               0.016798973083496094\n",
      "    last layer lr:            0.004059999999999998\n",
      "epoch: 110 (7/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 83.89%\n",
      "    train overall loss:       0.5737821807463964\n",
      "    train cross_ent loss:     0.25634491940339404\n",
      "    test overall loss:        0.7873491644859314\n",
      "    test cross_ent loss:      0.4703119397163391\n",
      "    cluster loss:             74.71636962890625\n",
      "    separation loss:          0.5339803099632263\n",
      "    avg separation loss:      3.2163764238357544\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  313.94305419921875\n",
      "    train time:               0.012670278549194336\n",
      "    test time:                0.003978252410888672\n",
      "    epoch time:               0.017101526260375977\n",
      "    last layer lr:            0.004720000000000002\n",
      "epoch: 110 (8/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 82.22%\n",
      "    train overall loss:       0.5777570108572642\n",
      "    train cross_ent loss:     0.2610854109128316\n",
      "    test overall loss:        0.7866684794425964\n",
      "    test cross_ent loss:      0.4705958068370819\n",
      "    cluster loss:             74.71673774719238\n",
      "    separation loss:          0.5339842289686203\n",
      "    avg separation loss:      3.2172484397888184\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  312.97845458984375\n",
      "    train time:               0.012328147888183594\n",
      "    test time:                0.003988981246948242\n",
      "    epoch time:               0.016774415969848633\n",
      "    last layer lr:            0.005379999999999999\n",
      "epoch: 110 (9/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 82.78%\n",
      "    train overall loss:       0.5616458257039388\n",
      "    train cross_ent loss:     0.24609258770942688\n",
      "    test overall loss:        0.7759954631328583\n",
      "    test cross_ent loss:      0.4613567143678665\n",
      "    cluster loss:             74.7170639038086\n",
      "    separation loss:          0.5336912423372269\n",
      "    avg separation loss:      3.204249858856201\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  311.5445556640625\n",
      "    train time:               0.012308359146118164\n",
      "    test time:                0.0043103694915771484\n",
      "    epoch time:               0.017072439193725586\n",
      "    last layer lr:            0.006040000000000003\n",
      "epoch: 110 (10/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 83.33%\n",
      "    train overall loss:       0.5731705178817114\n",
      "    train cross_ent loss:     0.2595414159198602\n",
      "    test overall loss:        0.767682284116745\n",
      "    test cross_ent loss:      0.45537184178829193\n",
      "    cluster loss:             74.71593475341797\n",
      "    separation loss:          0.5289013534784317\n",
      "    avg separation loss:      3.2082059383392334\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  309.21624755859375\n",
      "    train time:               0.012321949005126953\n",
      "    test time:                0.003981351852416992\n",
      "    epoch time:               0.016756772994995117\n",
      "    last layer lr:            0.0067\n",
      "epoch: 110 (11/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 83.33%\n",
      "    train overall loss:       0.5334772268931071\n",
      "    train cross_ent loss:     0.2221272699534893\n",
      "    test overall loss:        0.753099113702774\n",
      "    test cross_ent loss:      0.44305868446826935\n",
      "    cluster loss:             74.71536827087402\n",
      "    separation loss:          0.5290018767118454\n",
      "    avg separation loss:      3.219978451728821\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  306.9461975097656\n",
      "    train time:               0.012293100357055664\n",
      "    test time:                0.0039975643157958984\n",
      "    epoch time:               0.016745805740356445\n",
      "    last layer lr:            0.0073599999999999985\n",
      "epoch: 110 (12/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 83.89%\n",
      "    train overall loss:       0.5297105213006338\n",
      "    train cross_ent loss:     0.22079937905073166\n",
      "    test overall loss:        0.7427980303764343\n",
      "    test cross_ent loss:      0.4353981614112854\n",
      "    cluster loss:             74.71540451049805\n",
      "    separation loss:          0.5277718752622604\n",
      "    avg separation loss:      3.2073107957839966\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  304.3056640625\n",
      "    train time:               0.012318134307861328\n",
      "    test time:                0.003960609436035156\n",
      "    epoch time:               0.01673102378845215\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 110 (13/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 87.78%\n",
      "    train overall loss:       0.5437943935394287\n",
      "    train cross_ent loss:     0.23731854682167372\n",
      "    test overall loss:        0.7230896353721619\n",
      "    test cross_ent loss:      0.41794392466545105\n",
      "    cluster loss:             74.71605110168457\n",
      "    separation loss:          0.529442697763443\n",
      "    avg separation loss:      3.1982533931732178\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  302.0515441894531\n",
      "    train time:               0.012296438217163086\n",
      "    test time:                0.003993034362792969\n",
      "    epoch time:               0.01674485206604004\n",
      "    last layer lr:            0.008679999999999998\n",
      "epoch: 110 (14/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 86.11%\n",
      "    train overall loss:       0.5180714974800745\n",
      "    train cross_ent loss:     0.21390673021475473\n",
      "    test overall loss:        0.7138905227184296\n",
      "    test cross_ent loss:      0.4112696349620819\n",
      "    cluster loss:             74.71606254577637\n",
      "    separation loss:          0.5309687405824661\n",
      "    avg separation loss:      3.2017632722854614\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  299.52667236328125\n",
      "    train time:               0.012329816818237305\n",
      "    test time:                0.00396728515625\n",
      "    epoch time:               0.0167539119720459\n",
      "    last layer lr:            0.009340000000000003\n",
      "epoch: 110 (15/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 85.00%\n",
      "    train overall loss:       0.48635752499103546\n",
      "    train cross_ent loss:     0.18500805894533792\n",
      "    test overall loss:        0.7039767205715179\n",
      "    test cross_ent loss:      0.4046866148710251\n",
      "    cluster loss:             74.71622848510742\n",
      "    separation loss:          0.5318106859922409\n",
      "    avg separation loss:      3.198644280433655\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  296.1958923339844\n",
      "    train time:               0.012290000915527344\n",
      "    test time:                0.004021406173706055\n",
      "    epoch time:               0.01676344871520996\n",
      "    last layer lr:            0.01\n",
      "epoch: 110 (16/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 87.22%\n",
      "    train overall loss:       0.4874296635389328\n",
      "    train cross_ent loss:     0.1900314303735892\n",
      "    test overall loss:        0.7010048925876617\n",
      "    test cross_ent loss:      0.4061451852321625\n",
      "    cluster loss:             74.71553802490234\n",
      "    separation loss:          0.529080718755722\n",
      "    avg separation loss:      3.205284595489502\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  291.7655029296875\n",
      "    train time:               0.01230168342590332\n",
      "    test time:                0.003949403762817383\n",
      "    epoch time:               0.01670360565185547\n",
      "    last layer lr:            0.009604000000000001\n",
      "epoch: 110 (17/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 87.22%\n",
      "    train overall loss:       0.4985502560933431\n",
      "    train cross_ent loss:     0.20564808075626692\n",
      "    test overall loss:        0.690231204032898\n",
      "    test cross_ent loss:      0.3998536914587021\n",
      "    cluster loss:             74.71628952026367\n",
      "    separation loss:          0.5324532389640808\n",
      "    avg separation loss:      3.203912615776062\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  287.2833251953125\n",
      "    train time:               0.012303590774536133\n",
      "    test time:                0.004058837890625\n",
      "    epoch time:               0.01681661605834961\n",
      "    last layer lr:            0.009208\n",
      "epoch: 110 (18/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 85.56%\n",
      "    train overall loss:       0.4651918311913808\n",
      "    train cross_ent loss:     0.17633585631847382\n",
      "    test overall loss:        0.6891580820083618\n",
      "    test cross_ent loss:      0.4026825428009033\n",
      "    cluster loss:             74.71573829650879\n",
      "    separation loss:          0.5295652896165848\n",
      "    avg separation loss:      3.2070086002349854\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  283.3813171386719\n",
      "    train time:               0.01230311393737793\n",
      "    test time:                0.0039806365966796875\n",
      "    epoch time:               0.016747236251831055\n",
      "    last layer lr:            0.008812\n",
      "epoch: 110 (19/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 87.22%\n",
      "    train overall loss:       0.4560866604248683\n",
      "    train cross_ent loss:     0.17145443459351858\n",
      "    test overall loss:        0.6798975169658661\n",
      "    test cross_ent loss:      0.39778365194797516\n",
      "    cluster loss:             74.71645736694336\n",
      "    separation loss:          0.5312945991754532\n",
      "    avg separation loss:      3.215024471282959\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  279.0196533203125\n",
      "    train time:               0.012305021286010742\n",
      "    test time:                0.003961324691772461\n",
      "    epoch time:               0.016724348068237305\n",
      "    last layer lr:            0.008415999999999998\n",
      "epoch: 110 (20/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 87.22%\n",
      "    train overall loss:       0.4606921970844269\n",
      "    train cross_ent loss:     0.1801814946035544\n",
      "    test overall loss:        0.6691435873508453\n",
      "    test cross_ent loss:      0.39085914194583893\n",
      "    cluster loss:             74.7160415649414\n",
      "    separation loss:          0.5307027250528336\n",
      "    avg separation loss:      3.2077442407608032\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  275.19024658203125\n",
      "    train time:               0.012308359146118164\n",
      "    test time:                0.003965616226196289\n",
      "    epoch time:               0.016729116439819336\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 110 (21/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 89.44%\n",
      "    train overall loss:       0.4677085876464844\n",
      "    train cross_ent loss:     0.19110078116257986\n",
      "    test overall loss:        0.6566539108753204\n",
      "    test cross_ent loss:      0.3822818696498871\n",
      "    cluster loss:             74.71613502502441\n",
      "    separation loss:          0.5310196131467819\n",
      "    avg separation loss:      3.209372043609619\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  271.27783203125\n",
      "    train time:               0.012306928634643555\n",
      "    test time:                0.004000425338745117\n",
      "    epoch time:               0.016761064529418945\n",
      "    last layer lr:            0.007624000000000002\n",
      "epoch: 110 (22/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 90.00%\n",
      "    train overall loss:       0.4528394788503647\n",
      "    train cross_ent loss:     0.17988375201821327\n",
      "    test overall loss:        0.6462799906730652\n",
      "    test cross_ent loss:      0.3753115236759186\n",
      "    cluster loss:             74.71597671508789\n",
      "    separation loss:          0.5302320718765259\n",
      "    avg separation loss:      3.199652671813965\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  267.8742370605469\n",
      "    train time:               0.012313127517700195\n",
      "    test time:                0.003996610641479492\n",
      "    epoch time:               0.0167694091796875\n",
      "    last layer lr:            0.007228000000000001\n",
      "epoch: 110 (23/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 91.67%\n",
      "    train overall loss:       0.4288920114437739\n",
      "    train cross_ent loss:     0.15929552291830382\n",
      "    test overall loss:        0.6405520141124725\n",
      "    test cross_ent loss:      0.3729752004146576\n",
      "    cluster loss:             74.71584129333496\n",
      "    separation loss:          0.5293445438146591\n",
      "    avg separation loss:      3.204274296760559\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  264.48260498046875\n",
      "    train time:               0.012293577194213867\n",
      "    test time:                0.0040013790130615234\n",
      "    epoch time:               0.016777753829956055\n",
      "    last layer lr:            0.006832000000000001\n",
      "epoch: 110 (24/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 90.56%\n",
      "    train overall loss:       0.4369347443183263\n",
      "    train cross_ent loss:     0.1704814719657103\n",
      "    test overall loss:        0.6408691108226776\n",
      "    test cross_ent loss:      0.37636950612068176\n",
      "    cluster loss:             74.71514320373535\n",
      "    separation loss:          0.5271026790142059\n",
      "    avg separation loss:      3.1994773149490356\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  261.4053955078125\n",
      "    train time:               0.012306690216064453\n",
      "    test time:                0.003968715667724609\n",
      "    epoch time:               0.016726255416870117\n",
      "    last layer lr:            0.006436\n",
      "epoch: 110 (25/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 89.44%\n",
      "    train overall loss:       0.4289675752321879\n",
      "    train cross_ent loss:     0.16588279604911804\n",
      "    test overall loss:        0.6382751166820526\n",
      "    test cross_ent loss:      0.377228245139122\n",
      "    cluster loss:             74.71522521972656\n",
      "    separation loss:          0.5275605916976929\n",
      "    avg separation loss:      3.205539107322693\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  257.9526672363281\n",
      "    train time:               0.012300252914428711\n",
      "    test time:                0.003954410552978516\n",
      "    epoch time:               0.016708850860595703\n",
      "    last layer lr:            0.00604\n",
      "epoch: 110 (26/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 90.00%\n",
      "    train overall loss:       0.4251434604326884\n",
      "    train cross_ent loss:     0.16543599466482797\n",
      "    test overall loss:        0.6349905431270599\n",
      "    test cross_ent loss:      0.3770829737186432\n",
      "    cluster loss:             74.71584510803223\n",
      "    separation loss:          0.5300104916095734\n",
      "    avg separation loss:      3.2058968544006348\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  254.81336975097656\n",
      "    train time:               0.012318849563598633\n",
      "    test time:                0.003980875015258789\n",
      "    epoch time:               0.01675558090209961\n",
      "    last layer lr:            0.005644000000000002\n",
      "epoch: 110 (27/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 91.11%\n",
      "    train overall loss:       0.4478925367196401\n",
      "    train cross_ent loss:     0.19132756193478903\n",
      "    test overall loss:        0.6227099895477295\n",
      "    test cross_ent loss:      0.36792242527008057\n",
      "    cluster loss:             74.71692848205566\n",
      "    separation loss:          0.5334421992301941\n",
      "    avg separation loss:      3.2031813859939575\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  251.69334411621094\n",
      "    train time:               0.012279272079467773\n",
      "    test time:                0.0039708614349365234\n",
      "    epoch time:               0.016700029373168945\n",
      "    last layer lr:            0.005248\n",
      "epoch: 110 (28/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 91.67%\n",
      "    train overall loss:       0.4301511247952779\n",
      "    train cross_ent loss:     0.17635391528407732\n",
      "    test overall loss:        0.6146707534790039\n",
      "    test cross_ent loss:      0.3623346537351608\n",
      "    cluster loss:             74.71597290039062\n",
      "    separation loss:          0.53236423432827\n",
      "    avg separation loss:      3.2116910219192505\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  249.24191284179688\n",
      "    train time:               0.012644052505493164\n",
      "    test time:                0.004106044769287109\n",
      "    epoch time:               0.017230510711669922\n",
      "    last layer lr:            0.004852000000000001\n",
      "epoch: 110 (29/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 91.11%\n",
      "    train overall loss:       0.40700991451740265\n",
      "    train cross_ent loss:     0.15569842234253883\n",
      "    test overall loss:        0.6179352104663849\n",
      "    test cross_ent loss:      0.3680383414030075\n",
      "    cluster loss:             74.71579360961914\n",
      "    separation loss:          0.530627965927124\n",
      "    avg separation loss:      3.2140581607818604\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  246.80264282226562\n",
      "    train time:               0.012354135513305664\n",
      "    test time:                0.003997087478637695\n",
      "    epoch time:               0.016805410385131836\n",
      "    last layer lr:            0.004455999999999999\n",
      "epoch: 110 (30/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 90.56%\n",
      "    train overall loss:       0.41005082428455353\n",
      "    train cross_ent loss:     0.1611488697429498\n",
      "    test overall loss:        0.6137854754924774\n",
      "    test cross_ent loss:      0.36624716222286224\n",
      "    cluster loss:             74.71579360961914\n",
      "    separation loss:          0.5311245620250702\n",
      "    avg separation loss:      3.2174930572509766\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  244.44412231445312\n",
      "    train time:               0.012307405471801758\n",
      "    test time:                0.003998756408691406\n",
      "    epoch time:               0.016760587692260742\n",
      "    last layer lr:            0.004060000000000001\n",
      "epoch: 110 (31/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 90.56%\n",
      "    train overall loss:       0.3735014349222183\n",
      "    train cross_ent loss:     0.12685452277461687\n",
      "    test overall loss:        0.6103473603725433\n",
      "    test cross_ent loss:      0.36498525738716125\n",
      "    cluster loss:             74.71588706970215\n",
      "    separation loss:          0.5306372940540314\n",
      "    avg separation loss:      3.2096753120422363\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  242.2678985595703\n",
      "    train time:               0.012295246124267578\n",
      "    test time:                0.003994464874267578\n",
      "    epoch time:               0.016745805740356445\n",
      "    last layer lr:            0.0036640000000000015\n",
      "epoch: 110 (32/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 90.56%\n",
      "    train overall loss:       0.4125947058200836\n",
      "    train cross_ent loss:     0.1681492862602075\n",
      "    test overall loss:        0.6038078963756561\n",
      "    test cross_ent loss:      0.36062397062778473\n",
      "    cluster loss:             74.71632385253906\n",
      "    separation loss:          0.5299168825149536\n",
      "    avg separation loss:      3.201220989227295\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  240.08973693847656\n",
      "    train time:               0.012484550476074219\n",
      "    test time:                0.010001182556152344\n",
      "    epoch time:               0.023008108139038086\n",
      "    last layer lr:            0.0032679999999999996\n",
      "epoch: 110 (33/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 88.89%\n",
      "    train overall loss:       0.4094659934441249\n",
      "    train cross_ent loss:     0.1671101109435161\n",
      "    test overall loss:        0.6059573888778687\n",
      "    test cross_ent loss:      0.3646371364593506\n",
      "    cluster loss:             74.71526336669922\n",
      "    separation loss:          0.5279135853052139\n",
      "    avg separation loss:      3.2148114442825317\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  238.22601318359375\n",
      "    train time:               0.016806840896606445\n",
      "    test time:                0.010725021362304688\n",
      "    epoch time:               0.028110027313232422\n",
      "    last layer lr:            0.002872000000000001\n",
      "epoch: 110 (34/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 91.11%\n",
      "    train overall loss:       0.4196622371673584\n",
      "    train cross_ent loss:     0.17892317535976568\n",
      "    test overall loss:        0.5969827771186829\n",
      "    test cross_ent loss:      0.3570985347032547\n",
      "    cluster loss:             74.71611595153809\n",
      "    separation loss:          0.5307925939559937\n",
      "    avg separation loss:      3.2065335512161255\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  236.79002380371094\n",
      "    train time:               0.016816139221191406\n",
      "    test time:                0.01073145866394043\n",
      "    epoch time:               0.028131723403930664\n",
      "    last layer lr:            0.0024759999999999986\n",
      "epoch: 110 (35/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 91.11%\n",
      "    train overall loss:       0.3879856616258621\n",
      "    train cross_ent loss:     0.1485940838853518\n",
      "    test overall loss:        0.5949429273605347\n",
      "    test cross_ent loss:      0.3563181459903717\n",
      "    cluster loss:             74.71579360961914\n",
      "    separation loss:          0.5295157730579376\n",
      "    avg separation loss:      3.2027649879455566\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  235.53057861328125\n",
      "    train time:               0.015751123428344727\n",
      "    test time:                0.010575532913208008\n",
      "    epoch time:               0.026915550231933594\n",
      "    last layer lr:            0.0020800000000000003\n",
      "epoch: 110 (36/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 90.56%\n",
      "    train overall loss:       0.37546313802401227\n",
      "    train cross_ent loss:     0.13739717130859694\n",
      "    test overall loss:        0.5922812223434448\n",
      "    test cross_ent loss:      0.35492826998233795\n",
      "    cluster loss:             74.71611976623535\n",
      "    separation loss:          0.5303646624088287\n",
      "    avg separation loss:      3.206509828567505\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  234.2587432861328\n",
      "    train time:               0.016877174377441406\n",
      "    test time:                0.010761022567749023\n",
      "    epoch time:               0.028223752975463867\n",
      "    last layer lr:            0.0016840000000000017\n",
      "epoch: 110 (37/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 91.11%\n",
      "    train overall loss:       0.3720463812351227\n",
      "    train cross_ent loss:     0.13500765586892763\n",
      "    test overall loss:        0.5890983641147614\n",
      "    test cross_ent loss:      0.35257136821746826\n",
      "    cluster loss:             74.71663856506348\n",
      "    separation loss:          0.5331419259309769\n",
      "    avg separation loss:      3.2107152938842773\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  233.4327850341797\n",
      "    train time:               0.015990257263183594\n",
      "    test time:                0.010796070098876953\n",
      "    epoch time:               0.02734851837158203\n",
      "    last layer lr:            0.0012879999999999994\n",
      "epoch: 110 (38/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 91.11%\n",
      "    train overall loss:       0.38926183183987934\n",
      "    train cross_ent loss:     0.15307487299044928\n",
      "    test overall loss:        0.5873357951641083\n",
      "    test cross_ent loss:      0.35163848102092743\n",
      "    cluster loss:             74.71685600280762\n",
      "    separation loss:          0.5315143167972565\n",
      "    avg separation loss:      3.2091360092163086\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  232.60308837890625\n",
      "    train time:               0.016839981079101562\n",
      "    test time:                0.010716676712036133\n",
      "    epoch time:               0.028154373168945312\n",
      "    last layer lr:            0.0008920000000000009\n",
      "epoch: 110 (39/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 91.11%\n",
      "    train overall loss:       0.3828064352273941\n",
      "    train cross_ent loss:     0.14734701439738274\n",
      "    test overall loss:        0.5857070684432983\n",
      "    test cross_ent loss:      0.3505980670452118\n",
      "    cluster loss:             74.71625137329102\n",
      "    separation loss:          0.5317477881908417\n",
      "    avg separation loss:      3.2108248472213745\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  232.01480102539062\n",
      "    train time:               0.016770362854003906\n",
      "    test time:                0.010842323303222656\n",
      "    epoch time:               0.028222322463989258\n",
      "    last layer lr:            0.0004959999999999986\n",
      "epoch: 110 (40/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 91.11%\n",
      "    train overall loss:       0.3953272153933843\n",
      "    train cross_ent loss:     0.1603457232316335\n",
      "    test overall loss:        0.5898089706897736\n",
      "    test cross_ent loss:      0.35500775277614594\n",
      "    cluster loss:             74.7154655456543\n",
      "    separation loss:          0.5302002280950546\n",
      "    avg separation loss:      3.212339401245117\n",
      "    l1_addon loss:            103.14080810546875\n",
      "    l1 loss:                  231.70701599121094\n",
      "    train time:               0.016913414001464844\n",
      "    test time:                0.008080005645751953\n",
      "    epoch time:               0.025561094284057617\n",
      "    last layer lr:            0.0001\n",
      "epoch: 111 (JOINT) - Libras\n",
      "    test acc:                 91.11%\n",
      "    train overall loss:       0.38439778983592987\n",
      "    train cross_ent loss:     0.14959675073623657\n",
      "    test overall loss:        0.5859042704105377\n",
      "    test cross_ent loss:      0.3511035293340683\n",
      "    cluster loss:             74.71627426147461\n",
      "    separation loss:          0.5319597125053406\n",
      "    avg separation loss:      3.2062777280807495\n",
      "    l1_addon loss:            103.12445068359375\n",
      "    l1 loss:                  231.70701599121094\n",
      "    train time:               0.0353851318359375\n",
      "    test time:                0.0077397823333740234\n",
      "    epoch time:               0.04384016990661621\n",
      "    joint lr:                 0.0017196383771408863\n",
      "epoch: 112 (JOINT) - Libras\n",
      "    test acc:                 92.22%\n",
      "    train overall loss:       0.4252109080553055\n",
      "    train cross_ent loss:     0.19041344026724497\n",
      "    test overall loss:        0.5799136161804199\n",
      "    test cross_ent loss:      0.3451191931962967\n",
      "    cluster loss:             74.72273254394531\n",
      "    separation loss:          0.5351174473762512\n",
      "    avg separation loss:      3.2508527040481567\n",
      "    l1_addon loss:            102.91275024414062\n",
      "    l1 loss:                  231.70701599121094\n",
      "    train time:               0.032927513122558594\n",
      "    test time:                0.010774850845336914\n",
      "    epoch time:               0.04440903663635254\n",
      "    joint lr:                 0.0033068839867389757\n",
      "epoch: 113 (JOINT) - Libras\n",
      "    test acc:                 89.44%\n",
      "    train overall loss:       0.3791644622882207\n",
      "    train cross_ent loss:     0.14436950410405794\n",
      "    test overall loss:        0.6265221536159515\n",
      "    test cross_ent loss:      0.3917262852191925\n",
      "    cluster loss:             74.73812484741211\n",
      "    separation loss:          0.5487584620714188\n",
      "    avg separation loss:      3.2639882564544678\n",
      "    l1_addon loss:            102.96089935302734\n",
      "    l1 loss:                  231.70701599121094\n",
      "    train time:               0.03300213813781738\n",
      "    test time:                0.0059626102447509766\n",
      "    epoch time:               0.03963518142700195\n",
      "    joint lr:                 0.0048622227203073696\n",
      "epoch: 114 (JOINT) - Libras\n",
      "    test acc:                 90.00%\n",
      "    train overall loss:       0.3697253465652466\n",
      "    train cross_ent loss:     0.13493132342894873\n",
      "    test overall loss:        0.6022754311561584\n",
      "    test cross_ent loss:      0.3674835115671158\n",
      "    cluster loss:             74.72766494750977\n",
      "    separation loss:          0.5100214630365372\n",
      "    avg separation loss:      3.2521281242370605\n",
      "    l1_addon loss:            102.8301773071289\n",
      "    l1 loss:                  231.70701599121094\n",
      "    train time:               0.0353085994720459\n",
      "    test time:                0.008672237396240234\n",
      "    epoch time:               0.04469609260559082\n",
      "    joint lr:                 0.00638613399080572\n",
      "epoch: 115 (JOINT) - Libras\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       0.42455704510211945\n",
      "    train cross_ent loss:     0.18976114938656488\n",
      "    test overall loss:        0.6724360883235931\n",
      "    test cross_ent loss:      0.4376322627067566\n",
      "    cluster loss:             74.73115921020508\n",
      "    separation loss:          0.48981034755706787\n",
      "    avg separation loss:      3.082609176635742\n",
      "    l1_addon loss:            103.22695922851562\n",
      "    l1 loss:                  231.70701599121094\n",
      "    train time:               0.03514671325683594\n",
      "    test time:                0.010982513427734375\n",
      "    epoch time:               0.046848297119140625\n",
      "    joint lr:                 0.007879090813622073\n",
      "epoch: 116 (JOINT) - Libras\n",
      "    test acc:                 90.56%\n",
      "    train overall loss:       0.40661455194155377\n",
      "    train cross_ent loss:     0.17182473093271255\n",
      "    test overall loss:        0.7383528351783752\n",
      "    test cross_ent loss:      0.5035886764526367\n",
      "    cluster loss:             74.78737831115723\n",
      "    separation loss:          0.6426895260810852\n",
      "    avg separation loss:      3.139589786529541\n",
      "    l1_addon loss:            101.90328216552734\n",
      "    l1 loss:                  231.70701599121094\n",
      "    train time:               0.032922983169555664\n",
      "    test time:                0.010892868041992188\n",
      "    epoch time:               0.04453873634338379\n",
      "    joint lr:                 0.009341559886583039\n",
      "epoch: 117 (JOINT) - Libras\n",
      "    test acc:                 89.44%\n",
      "    train overall loss:       0.40245411296685535\n",
      "    train cross_ent loss:     0.16768207401037216\n",
      "    test overall loss:        0.7818938493728638\n",
      "    test cross_ent loss:      0.547089233994484\n",
      "    cluster loss:             74.75605201721191\n",
      "    separation loss:          0.5733117163181305\n",
      "    avg separation loss:      3.1741485595703125\n",
      "    l1_addon loss:            103.25302124023438\n",
      "    l1 loss:                  231.70701599121094\n",
      "    train time:               0.03307032585144043\n",
      "    test time:                0.009669065475463867\n",
      "    epoch time:               0.04336071014404297\n",
      "    joint lr:                 0.010774001669003403\n",
      "epoch: 118 (JOINT) - Libras\n",
      "    test acc:                 86.67%\n",
      "    train overall loss:       0.4425550848245621\n",
      "    train cross_ent loss:     0.2077543195337057\n",
      "    test overall loss:        0.9064356684684753\n",
      "    test cross_ent loss:      0.6716741919517517\n",
      "    cluster loss:             74.79449844360352\n",
      "    separation loss:          0.6085905432701111\n",
      "    avg separation loss:      3.1757843494415283\n",
      "    l1_addon loss:            101.8138427734375\n",
      "    l1 loss:                  231.70701599121094\n",
      "    train time:               0.03561568260192871\n",
      "    test time:                0.010923624038696289\n",
      "    epoch time:               0.04726600646972656\n",
      "    joint lr:                 0.012176870459786701\n",
      "epoch: 119 (JOINT) - Libras\n",
      "    test acc:                 81.67%\n",
      "    train overall loss:       0.5011020749807358\n",
      "    train cross_ent loss:     0.2663397217790286\n",
      "    test overall loss:        0.9357489347457886\n",
      "    test cross_ent loss:      0.7009387016296387\n",
      "    cluster loss:             74.79876518249512\n",
      "    separation loss:          0.6204666197299957\n",
      "    avg separation loss:      3.2185442447662354\n",
      "    l1_addon loss:            103.43952941894531\n",
      "    l1 loss:                  231.70701599121094\n",
      "    train time:               0.03565835952758789\n",
      "    test time:                0.005286216735839844\n",
      "    epoch time:               0.04167437553405762\n",
      "    joint lr:                 0.013550614474587434\n",
      "epoch: 120 (JOINT) - Libras\n",
      "    test acc:                 84.44%\n",
      "    train overall loss:       0.5675533215204874\n",
      "    train cross_ent loss:     0.3327586178978284\n",
      "    test overall loss:        0.989411860704422\n",
      "    test cross_ent loss:      0.7546805143356323\n",
      "    cluster loss:             74.81372833251953\n",
      "    separation loss:          0.630683571100235\n",
      "    avg separation loss:      3.029083013534546\n",
      "    l1_addon loss:            100.81149291992188\n",
      "    l1 loss:                  231.70701599121094\n",
      "    train time:               0.032922983169555664\n",
      "    test time:                0.010978221893310547\n",
      "    epoch time:               0.0446162223815918\n",
      "    joint lr:                 0.014895675922046181\n",
      "epoch: 121 (JOINT) - Libras\n",
      "    test acc:                 83.89%\n",
      "    train overall loss:       0.5785569796959559\n",
      "    train cross_ent loss:     0.3437895526488622\n",
      "    test overall loss:        0.8111987709999084\n",
      "    test cross_ent loss:      0.5763824731111526\n",
      "    cluster loss:             74.78607940673828\n",
      "    separation loss:          0.5428085327148438\n",
      "    avg separation loss:      2.996200919151306\n",
      "    l1_addon loss:            103.64321899414062\n",
      "    l1 loss:                  231.70701599121094\n",
      "    train time:               0.03275465965270996\n",
      "    test time:                0.009956598281860352\n",
      "    epoch time:               0.04340481758117676\n",
      "    joint lr:                 0.014015333204684437\n",
      "epoch: 122 (JOINT) - Libras\n",
      "    test acc:                 78.33%\n",
      "    train overall loss:       0.5538284430901209\n",
      "    train cross_ent loss:     0.31904816379149753\n",
      "    test overall loss:        1.1891404688358307\n",
      "    test cross_ent loss:      0.9543673098087311\n",
      "    cluster loss:             74.82783699035645\n",
      "    separation loss:          0.6524634659290314\n",
      "    avg separation loss:      3.1123013496398926\n",
      "    l1_addon loss:            102.2047119140625\n",
      "    l1 loss:                  231.70701599121094\n",
      "    train time:               0.03522896766662598\n",
      "    test time:                0.010809898376464844\n",
      "    epoch time:               0.04676961898803711\n",
      "    joint lr:                 0.01315111777407772\n",
      "epoch: 123 (JOINT) - Libras\n",
      "    test acc:                 71.67%\n",
      "    train overall loss:       0.5666769196589788\n",
      "    train cross_ent loss:     0.33186207960049313\n",
      "    test overall loss:        1.1622645854949951\n",
      "    test cross_ent loss:      0.9274489283561707\n",
      "    cluster loss:             74.82821273803711\n",
      "    separation loss:          0.6390621960163116\n",
      "    avg separation loss:      2.935868740081787\n",
      "    l1_addon loss:            103.61911010742188\n",
      "    l1 loss:                  231.70701599121094\n",
      "    train time:               0.03517436981201172\n",
      "    test time:                0.0052356719970703125\n",
      "    epoch time:               0.041132450103759766\n",
      "    joint lr:                 0.012302795118762673\n",
      "epoch: 124 (JOINT) - Libras\n",
      "    test acc:                 86.11%\n",
      "    train overall loss:       0.4760570526123047\n",
      "    train cross_ent loss:     0.24125066151221594\n",
      "    test overall loss:        0.8038534224033356\n",
      "    test cross_ent loss:      0.569034144282341\n",
      "    cluster loss:             74.77062606811523\n",
      "    separation loss:          0.569931373000145\n",
      "    avg separation loss:      3.1703187227249146\n",
      "    l1_addon loss:            103.74129486083984\n",
      "    l1 loss:                  231.70701599121094\n",
      "    train time:               0.033075809478759766\n",
      "    test time:                0.010826587677001953\n",
      "    epoch time:               0.04458141326904297\n",
      "    joint lr:                 0.011470133804776505\n",
      "epoch: 125 (JOINT) - Libras\n",
      "    test acc:                 82.78%\n",
      "    train overall loss:       0.45262130598227185\n",
      "    train cross_ent loss:     0.21779673049847284\n",
      "    test overall loss:        0.8387877941131592\n",
      "    test cross_ent loss:      0.6039707660675049\n",
      "    cluster loss:             74.77324485778809\n",
      "    separation loss:          0.5103617608547211\n",
      "    avg separation loss:      3.074575662612915\n",
      "    l1_addon loss:            103.66545867919922\n",
      "    l1 loss:                  231.70701599121094\n",
      "    train time:               0.03230643272399902\n",
      "    test time:                0.010476112365722656\n",
      "    epoch time:               0.04350090026855469\n",
      "    joint lr:                 0.010652905437558197\n",
      "epoch: 126 (JOINT) - Libras\n",
      "    test acc:                 85.56%\n",
      "    train overall loss:       0.3935372829437256\n",
      "    train cross_ent loss:     0.15872214237848917\n",
      "    test overall loss:        0.7556687295436859\n",
      "    test cross_ent loss:      0.5208697766065598\n",
      "    cluster loss:             74.74795150756836\n",
      "    separation loss:          0.493837833404541\n",
      "    avg separation loss:      2.8398534059524536\n",
      "    l1_addon loss:            103.0653076171875\n",
      "    l1 loss:                  231.70701599121094\n",
      "    train time:               0.03514242172241211\n",
      "    test time:                0.0077970027923583984\n",
      "    epoch time:               0.04361844062805176\n",
      "    joint lr:                 0.009850884624303774\n",
      "epoch: 127 (JOINT) - Libras\n",
      "    test acc:                 90.00%\n",
      "    train overall loss:       0.37696978946526843\n",
      "    train cross_ent loss:     0.1421683356165886\n",
      "    test overall loss:        0.6419477760791779\n",
      "    test cross_ent loss:      0.4071384519338608\n",
      "    cluster loss:             74.73597145080566\n",
      "    separation loss:          0.4633066803216934\n",
      "    avg separation loss:      2.9249051809310913\n",
      "    l1_addon loss:            103.41056060791016\n",
      "    l1 loss:                  231.70701599121094\n",
      "    train time:               0.03521323204040527\n",
      "    test time:                0.010865926742553711\n",
      "    epoch time:               0.0467982292175293\n",
      "    joint lr:                 0.00906384893677068\n",
      "epoch: 128 (JOINT) - Libras\n",
      "    test acc:                 89.44%\n",
      "    train overall loss:       0.4165668835242589\n",
      "    train cross_ent loss:     0.18174867952863374\n",
      "    test overall loss:        0.6997871398925781\n",
      "    test cross_ent loss:      0.46497417986392975\n",
      "    cluster loss:             74.75586318969727\n",
      "    separation loss:          0.5262388437986374\n",
      "    avg separation loss:      2.9871050119400024\n",
      "    l1_addon loss:            103.53117370605469\n",
      "    l1 loss:                  231.70701599121094\n",
      "    train time:               0.03515005111694336\n",
      "    test time:                0.010936260223388672\n",
      "    epoch time:               0.04680490493774414\n",
      "    joint lr:                 0.00829157887452582\n",
      "epoch: 129 (JOINT) - Libras\n",
      "    test acc:                 83.89%\n",
      "    train overall loss:       0.37552479406197864\n",
      "    train cross_ent loss:     0.14072768141825995\n",
      "    test overall loss:        0.7490251958370209\n",
      "    test cross_ent loss:      0.5142245590686798\n",
      "    cluster loss:             74.74237251281738\n",
      "    separation loss:          0.5040571391582489\n",
      "    avg separation loss:      2.9897652864456177\n",
      "    l1_addon loss:            103.1199722290039\n",
      "    l1 loss:                  231.70701599121094\n",
      "    train time:               0.029310941696166992\n",
      "    test time:                0.004859447479248047\n",
      "    epoch time:               0.03483724594116211\n",
      "    joint lr:                 0.007533857828632187\n",
      "epoch: 130 (JOINT) - Libras\n",
      "    test acc:                 87.22%\n",
      "    train overall loss:       0.4250116248925527\n",
      "    train cross_ent loss:     0.19019747401277223\n",
      "    test overall loss:        0.711984246969223\n",
      "    test cross_ent loss:      0.477169007062912\n",
      "    cluster loss:             74.73429870605469\n",
      "    separation loss:          0.49384309351444244\n",
      "    avg separation loss:      3.037579655647278\n",
      "    l1_addon loss:            103.60602569580078\n",
      "    l1 loss:                  231.70701599121094\n",
      "    train time:               0.026484966278076172\n",
      "    test time:                0.004015684127807617\n",
      "    epoch time:               0.031070232391357422\n",
      "    joint lr:                 0.00679047204576897\n",
      "epoch: 131 (JOINT) - Libras\n",
      "    test acc:                 91.11%\n",
      "    train overall loss:       0.3429456651210785\n",
      "    train cross_ent loss:     0.10814589137832324\n",
      "    test overall loss:        0.6099753677845001\n",
      "    test cross_ent loss:      0.3751857280731201\n",
      "    cluster loss:             74.73574638366699\n",
      "    separation loss:          0.464917853474617\n",
      "    avg separation loss:      2.7950072288513184\n",
      "    l1_addon loss:            102.75537109375\n",
      "    l1 loss:                  231.70701599121094\n",
      "    train time:               0.0267333984375\n",
      "    test time:                0.004191398620605469\n",
      "    epoch time:               0.03152728080749512\n",
      "    joint lr:                 0.006061210592780146\n",
      "epoch: 132 (JOINT) - Libras\n",
      "    test acc:                 92.78%\n",
      "    train overall loss:       0.36155372361342114\n",
      "    train cross_ent loss:     0.1267540045082569\n",
      "    test overall loss:        0.5418319702148438\n",
      "    test cross_ent loss:      0.3070170283317566\n",
      "    cluster loss:             74.72233581542969\n",
      "    separation loss:          0.45489318668842316\n",
      "    avg separation loss:      2.695647716522217\n",
      "    l1_addon loss:            103.59767150878906\n",
      "    l1 loss:                  231.70701599121094\n",
      "    train time:               0.026385068893432617\n",
      "    test time:                0.005296468734741211\n",
      "    epoch time:               0.0322566032409668\n",
      "    joint lr:                 0.005345865321646531\n",
      "epoch: 133 (JOINT) - Libras\n",
      "    test acc:                 92.22%\n",
      "    train overall loss:       0.34297987818717957\n",
      "    train cross_ent loss:     0.10816412108639877\n",
      "    test overall loss:        0.5571307837963104\n",
      "    test cross_ent loss:      0.32232312858104706\n",
      "    cluster loss:             74.72362899780273\n",
      "    separation loss:          0.4401080757379532\n",
      "    avg separation loss:      2.68351411819458\n",
      "    l1_addon loss:            103.35478210449219\n",
      "    l1 loss:                  231.70701599121094\n",
      "    train time:               0.026587724685668945\n",
      "    test time:                0.003981828689575195\n",
      "    epoch time:               0.031162023544311523\n",
      "    joint lr:                 0.00464423083487631\n",
      "epoch: 134 (JOINT) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.34309182067712146\n",
      "    train cross_ent loss:     0.10829268395900726\n",
      "    test overall loss:        0.5453535914421082\n",
      "    test cross_ent loss:      0.31056323647499084\n",
      "    cluster loss:             74.72050666809082\n",
      "    separation loss:          0.4337853342294693\n",
      "    avg separation loss:      2.715850830078125\n",
      "    l1_addon loss:            102.77764892578125\n",
      "    l1 loss:                  231.70701599121094\n",
      "    train time:               0.02638840675354004\n",
      "    test time:                0.00407719612121582\n",
      "    epoch time:               0.031061172485351562\n",
      "    joint lr:                 0.003956104451309328\n",
      "epoch: 135 (JOINT) - Libras\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.3329000324010849\n",
      "    train cross_ent loss:     0.09810560817519824\n",
      "    test overall loss:        0.5235331356525421\n",
      "    test cross_ent loss:      0.2887327969074249\n",
      "    cluster loss:             74.71510124206543\n",
      "    separation loss:          0.43816205859184265\n",
      "    avg separation loss:      2.683406949043274\n",
      "    l1_addon loss:            103.11054229736328\n",
      "    l1 loss:                  231.70701599121094\n",
      "    train time:               0.026369810104370117\n",
      "    test time:                0.004014730453491211\n",
      "    epoch time:               0.030956268310546875\n",
      "    joint lr:                 0.0032812861723301896\n",
      "epoch: 136 (JOINT) - Libras\n",
      "    test acc:                 94.44%\n",
      "    train overall loss:       0.30709738035996753\n",
      "    train cross_ent loss:     0.07229554653167725\n",
      "    test overall loss:        0.5087845325469971\n",
      "    test cross_ent loss:      0.2739808112382889\n",
      "    cluster loss:             74.7103500366211\n",
      "    separation loss:          0.4258327931165695\n",
      "    avg separation loss:      2.612159013748169\n",
      "    l1_addon loss:            103.22358703613281\n",
      "    l1 loss:                  231.70701599121094\n",
      "    train time:               0.026493549346923828\n",
      "    test time:                0.0040051937103271484\n",
      "    epoch time:               0.031083106994628906\n",
      "    joint lr:                 0.0026195786484855114\n",
      "epoch: 137 (JOINT) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.3103020091851552\n",
      "    train cross_ent loss:     0.07549666489164035\n",
      "    test overall loss:        0.5413632094860077\n",
      "    test cross_ent loss:      0.30655810236930847\n",
      "    cluster loss:             74.71321868896484\n",
      "    separation loss:          0.42634958028793335\n",
      "    avg separation loss:      2.6388790607452393\n",
      "    l1_addon loss:            103.26930236816406\n",
      "    l1 loss:                  231.70701599121094\n",
      "    train time:               0.0264737606048584\n",
      "    test time:                0.004081249237060547\n",
      "    epoch time:               0.031153202056884766\n",
      "    joint lr:                 0.0019707871465004943\n",
      "epoch: 138 (JOINT) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.31227357188860577\n",
      "    train cross_ent loss:     0.07746972764531772\n",
      "    test overall loss:        0.5362415611743927\n",
      "    test cross_ent loss:      0.30144253373146057\n",
      "    cluster loss:             74.71147727966309\n",
      "    separation loss:          0.42400412261486053\n",
      "    avg separation loss:      2.628543734550476\n",
      "    l1_addon loss:            103.06678771972656\n",
      "    l1 loss:                  231.70701599121094\n",
      "    train time:               0.026272058486938477\n",
      "    test time:                0.0040531158447265625\n",
      "    epoch time:               0.03091907501220703\n",
      "    joint lr:                 0.0013347195166903292\n",
      "epoch: 139 (JOINT) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.2963043600320816\n",
      "    train cross_ent loss:     0.06150984205305576\n",
      "    test overall loss:        0.5197385400533676\n",
      "    test cross_ent loss:      0.28494893014431\n",
      "    cluster loss:             74.70895767211914\n",
      "    separation loss:          0.4173612892627716\n",
      "    avg separation loss:      2.621216058731079\n",
      "    l1_addon loss:            102.75309753417969\n",
      "    l1 loss:                  231.70701599121094\n",
      "    train time:               0.02620077133178711\n",
      "    test time:                0.004067897796630859\n",
      "    epoch time:               0.030863046646118164\n",
      "    joint lr:                 0.0007111861607617089\n",
      "epoch: 140 (JOINT) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.3107977981368701\n",
      "    train cross_ent loss:     0.07600899211441477\n",
      "    test overall loss:        0.513994038105011\n",
      "    test cross_ent loss:      0.2792052924633026\n",
      "    cluster loss:             74.71010971069336\n",
      "    separation loss:          0.4155827909708023\n",
      "    avg separation loss:      2.620651125907898\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  231.70701599121094\n",
      "    train time:               0.02619314193725586\n",
      "    test time:                0.00403594970703125\n",
      "    epoch time:               0.030822038650512695\n",
      "    joint lr:                 0.0001\n",
      "epoch: 140 (PUSH) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.3107977981368701\n",
      "    train cross_ent loss:     0.07600899211441477\n",
      "    test overall loss:        0.5294997692108154\n",
      "    test cross_ent loss:      0.29471099376678467\n",
      "    cluster loss:             74.7089958190918\n",
      "    separation loss:          0.43735843896865845\n",
      "    avg separation loss:      2.6072945594787598\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  231.70701599121094\n",
      "    train time:               0.02619314193725586\n",
      "    test time:                0.004168033599853516\n",
      "    epoch time:               0.07125639915466309\n",
      "epoch: 140 (1/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.3208347906668981\n",
      "    train cross_ent loss:     0.08607251942157745\n",
      "    test overall loss:        0.5329586267471313\n",
      "    test cross_ent loss:      0.29823610186576843\n",
      "    cluster loss:             74.70768165588379\n",
      "    separation loss:          0.4364156126976013\n",
      "    avg separation loss:      2.6121790409088135\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  231.64077758789062\n",
      "    train time:               0.012738704681396484\n",
      "    test time:                0.007548093795776367\n",
      "    epoch time:               0.020762205123901367\n",
      "    last layer lr:            0.0007599999999999978\n",
      "epoch: 140 (2/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.3480158398548762\n",
      "    train cross_ent loss:     0.1135213989764452\n",
      "    test overall loss:        0.5345684885978699\n",
      "    test cross_ent loss:      0.3003844916820526\n",
      "    cluster loss:             74.70747566223145\n",
      "    separation loss:          0.4358430653810501\n",
      "    avg separation loss:      2.6126898527145386\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  231.10226440429688\n",
      "    train time:               0.013282537460327148\n",
      "    test time:                0.004084587097167969\n",
      "    epoch time:               0.0178987979888916\n",
      "    last layer lr:            0.0014199999999999955\n",
      "epoch: 140 (3/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.3570343405008316\n",
      "    train cross_ent loss:     0.12328489683568478\n",
      "    test overall loss:        0.5362374782562256\n",
      "    test cross_ent loss:      0.30304911732673645\n",
      "    cluster loss:             74.7069320678711\n",
      "    separation loss:          0.43465882539749146\n",
      "    avg separation loss:      2.6143068075180054\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  230.10659790039062\n",
      "    train time:               0.013609647750854492\n",
      "    test time:                0.004097700119018555\n",
      "    epoch time:               0.018242359161376953\n",
      "    last layer lr:            0.0020800000000000046\n",
      "epoch: 140 (4/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.313678299387296\n",
      "    train cross_ent loss:     0.08091820466021697\n",
      "    test overall loss:        0.5318349003791809\n",
      "    test cross_ent loss:      0.29975035786628723\n",
      "    cluster loss:             74.70694160461426\n",
      "    separation loss:          0.4364471435546875\n",
      "    avg separation loss:      2.614816427230835\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  229.00277709960938\n",
      "    train time:               0.012707233428955078\n",
      "    test time:                0.004076480865478516\n",
      "    epoch time:               0.01727581024169922\n",
      "    last layer lr:            0.0027400000000000024\n",
      "epoch: 140 (5/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.3334490954875946\n",
      "    train cross_ent loss:     0.1020596952488025\n",
      "    test overall loss:        0.5252161622047424\n",
      "    test cross_ent loss:      0.2948681712150574\n",
      "    cluster loss:             74.70744323730469\n",
      "    separation loss:          0.438017800450325\n",
      "    avg separation loss:      2.613769292831421\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  227.26622009277344\n",
      "    train time:               0.012435197830200195\n",
      "    test time:                0.0040361881256103516\n",
      "    epoch time:               0.016972780227661133\n",
      "    last layer lr:            0.0034\n",
      "epoch: 140 (6/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 92.78%\n",
      "    train overall loss:       0.31976662079493207\n",
      "    train cross_ent loss:     0.09051264015336831\n",
      "    test overall loss:        0.522889256477356\n",
      "    test cross_ent loss:      0.2951524555683136\n",
      "    cluster loss:             74.7078742980957\n",
      "    separation loss:          0.43872614204883575\n",
      "    avg separation loss:      2.6084152460098267\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  224.655029296875\n",
      "    train time:               0.01236104965209961\n",
      "    test time:                0.003989696502685547\n",
      "    epoch time:               0.01680922508239746\n",
      "    last layer lr:            0.004059999999999998\n",
      "epoch: 140 (7/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 92.78%\n",
      "    train overall loss:       0.3035718897978465\n",
      "    train cross_ent loss:     0.07711344212293625\n",
      "    test overall loss:        0.5224719941616058\n",
      "    test cross_ent loss:      0.29780635237693787\n",
      "    cluster loss:             74.70753288269043\n",
      "    separation loss:          0.4375937730073929\n",
      "    avg separation loss:      2.609702706336975\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  221.58389282226562\n",
      "    train time:               0.012341976165771484\n",
      "    test time:                0.00397801399230957\n",
      "    epoch time:               0.016775131225585938\n",
      "    last layer lr:            0.004719999999999996\n",
      "epoch: 140 (8/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.30271440744400024\n",
      "    train cross_ent loss:     0.07963385246694088\n",
      "    test overall loss:        0.5235916376113892\n",
      "    test cross_ent loss:      0.30264195799827576\n",
      "    cluster loss:             74.70759963989258\n",
      "    separation loss:          0.4377909451723099\n",
      "    avg separation loss:      2.6077513694763184\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  217.86793518066406\n",
      "    train time:               0.012371540069580078\n",
      "    test time:                0.0039899349212646484\n",
      "    epoch time:               0.0168154239654541\n",
      "    last layer lr:            0.0053800000000000054\n",
      "epoch: 140 (9/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.3109194238980611\n",
      "    train cross_ent loss:     0.09150806193550427\n",
      "    test overall loss:        0.5241758525371552\n",
      "    test cross_ent loss:      0.30701611936092377\n",
      "    cluster loss:             74.70757675170898\n",
      "    separation loss:          0.4377756863832474\n",
      "    avg separation loss:      2.606624960899353\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  214.07797241210938\n",
      "    train time:               0.012370586395263672\n",
      "    test time:                0.003987312316894531\n",
      "    epoch time:               0.016816139221191406\n",
      "    last layer lr:            0.006040000000000003\n",
      "epoch: 140 (10/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.31038900713125867\n",
      "    train cross_ent loss:     0.0950695772965749\n",
      "    test overall loss:        0.5269317328929901\n",
      "    test cross_ent loss:      0.3141578286886215\n",
      "    cluster loss:             74.7069206237793\n",
      "    separation loss:          0.43613384664058685\n",
      "    avg separation loss:      2.610033392906189\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  209.69216918945312\n",
      "    train time:               0.012326240539550781\n",
      "    test time:                0.003953695297241211\n",
      "    epoch time:               0.01673293113708496\n",
      "    last layer lr:            0.0067\n",
      "epoch: 140 (11/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.28074685484170914\n",
      "    train cross_ent loss:     0.07006238587200642\n",
      "    test overall loss:        0.5205072164535522\n",
      "    test cross_ent loss:      0.3126750588417053\n",
      "    cluster loss:             74.70718574523926\n",
      "    separation loss:          0.43711480498313904\n",
      "    avg separation loss:      2.609561562538147\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  204.75042724609375\n",
      "    train time:               0.012314081192016602\n",
      "    test time:                0.0047435760498046875\n",
      "    epoch time:               0.017534732818603516\n",
      "    last layer lr:            0.0073599999999999985\n",
      "epoch: 140 (12/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.28181420763333637\n",
      "    train cross_ent loss:     0.0760482211286823\n",
      "    test overall loss:        0.5188743323087692\n",
      "    test cross_ent loss:      0.31609609723091125\n",
      "    cluster loss:             74.70734977722168\n",
      "    separation loss:          0.4370903968811035\n",
      "    avg separation loss:      2.6099276542663574\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  199.69647216796875\n",
      "    train time:               0.012324094772338867\n",
      "    test time:                0.004383087158203125\n",
      "    epoch time:               0.01717662811279297\n",
      "    last layer lr:            0.008019999999999994\n",
      "epoch: 140 (13/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.27393142133951187\n",
      "    train cross_ent loss:     0.0733784381300211\n",
      "    test overall loss:        0.5081812292337418\n",
      "    test cross_ent loss:      0.310795322060585\n",
      "    cluster loss:             74.70740127563477\n",
      "    separation loss:          0.43704478442668915\n",
      "    avg separation loss:      2.609312653541565\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  194.3041534423828\n",
      "    train time:               0.012300968170166016\n",
      "    test time:                0.004454612731933594\n",
      "    epoch time:               0.017224788665771484\n",
      "    last layer lr:            0.008680000000000005\n",
      "epoch: 140 (14/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.27820071081320447\n",
      "    train cross_ent loss:     0.08355252693096797\n",
      "    test overall loss:        0.497110515832901\n",
      "    test cross_ent loss:      0.30605658888816833\n",
      "    cluster loss:             74.70741081237793\n",
      "    separation loss:          0.43815021216869354\n",
      "    avg separation loss:      2.611536383628845\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  187.97216796875\n",
      "    train time:               0.01243901252746582\n",
      "    test time:                0.004379749298095703\n",
      "    epoch time:               0.01730203628540039\n",
      "    last layer lr:            0.009340000000000003\n",
      "epoch: 140 (15/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 92.78%\n",
      "    train overall loss:       0.27796674768129986\n",
      "    train cross_ent loss:     0.08921011661489804\n",
      "    test overall loss:        0.497087687253952\n",
      "    test cross_ent loss:      0.31159086525440216\n",
      "    cluster loss:             74.70711898803711\n",
      "    separation loss:          0.43729180097579956\n",
      "    avg separation loss:      2.613282799720764\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  182.41506958007812\n",
      "    train time:               0.012306928634643555\n",
      "    test time:                0.0043866634368896484\n",
      "    epoch time:               0.0171816349029541\n",
      "    last layer lr:            0.01\n",
      "epoch: 140 (16/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 92.78%\n",
      "    train overall loss:       0.26469293236732483\n",
      "    train cross_ent loss:     0.08153445397814114\n",
      "    test overall loss:        0.4884722828865051\n",
      "    test cross_ent loss:      0.3089752644300461\n",
      "    cluster loss:             74.70755004882812\n",
      "    separation loss:          0.43874596059322357\n",
      "    avg separation loss:      2.6109026670455933\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  176.41526794433594\n",
      "    train time:               0.012323617935180664\n",
      "    test time:                0.0043833255767822266\n",
      "    epoch time:               0.017171859741210938\n",
      "    last layer lr:            0.009604000000000001\n",
      "epoch: 140 (17/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 92.78%\n",
      "    train overall loss:       0.24853515625\n",
      "    train cross_ent loss:     0.07158789597451687\n",
      "    test overall loss:        0.488913357257843\n",
      "    test cross_ent loss:      0.31566321849823\n",
      "    cluster loss:             74.70708847045898\n",
      "    separation loss:          0.43687406182289124\n",
      "    avg separation loss:      2.6152422428131104\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  170.16839599609375\n",
      "    train time:               0.012346506118774414\n",
      "    test time:                0.0043909549713134766\n",
      "    epoch time:               0.017208337783813477\n",
      "    last layer lr:            0.009208000000000003\n",
      "epoch: 140 (18/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 92.22%\n",
      "    train overall loss:       0.2557867293556531\n",
      "    train cross_ent loss:     0.08526543031136195\n",
      "    test overall loss:        0.4835561215877533\n",
      "    test cross_ent loss:      0.316535621881485\n",
      "    cluster loss:             74.70740509033203\n",
      "    separation loss:          0.4378553628921509\n",
      "    avg separation loss:      2.616958975791931\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  163.93875122070312\n",
      "    train time:               0.01281881332397461\n",
      "    test time:                0.004426479339599609\n",
      "    epoch time:               0.018118858337402344\n",
      "    last layer lr:            0.008811999999999997\n",
      "epoch: 140 (19/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.25925344973802567\n",
      "    train cross_ent loss:     0.09435744397342205\n",
      "    test overall loss:        0.4746338427066803\n",
      "    test cross_ent loss:      0.31260043382644653\n",
      "    cluster loss:             74.7074203491211\n",
      "    separation loss:          0.4378277361392975\n",
      "    avg separation loss:      2.6193853616714478\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  158.95167541503906\n",
      "    train time:               0.01265859603881836\n",
      "    test time:                0.004439353942871094\n",
      "    epoch time:               0.017596960067749023\n",
      "    last layer lr:            0.008415999999999998\n",
      "epoch: 140 (20/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.22834970305363336\n",
      "    train cross_ent loss:     0.06838906370103359\n",
      "    test overall loss:        0.4725852608680725\n",
      "    test cross_ent loss:      0.3154299259185791\n",
      "    cluster loss:             74.70718574523926\n",
      "    separation loss:          0.43747560679912567\n",
      "    avg separation loss:      2.6142176389694214\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  154.0736083984375\n",
      "    train time:               0.013406991958618164\n",
      "    test time:                0.0045168399810791016\n",
      "    epoch time:               0.018441438674926758\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 140 (21/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.2232507343093554\n",
      "    train cross_ent loss:     0.06817647255957127\n",
      "    test overall loss:        0.46888354420661926\n",
      "    test cross_ent loss:      0.3166865259408951\n",
      "    cluster loss:             74.70711135864258\n",
      "    separation loss:          0.4373372495174408\n",
      "    avg separation loss:      2.614317536354065\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  149.11526489257812\n",
      "    train time:               0.012455463409423828\n",
      "    test time:                0.004433155059814453\n",
      "    epoch time:               0.017405271530151367\n",
      "    last layer lr:            0.007624000000000002\n",
      "epoch: 140 (22/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 92.22%\n",
      "    train overall loss:       0.23178043216466904\n",
      "    train cross_ent loss:     0.08159212581813335\n",
      "    test overall loss:        0.46652013063430786\n",
      "    test cross_ent loss:      0.318901926279068\n",
      "    cluster loss:             74.70683097839355\n",
      "    separation loss:          0.43567878007888794\n",
      "    avg separation loss:      2.619120240211487\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  144.5364532470703\n",
      "    train time:               0.013669490814208984\n",
      "    test time:                0.004655361175537109\n",
      "    epoch time:               0.018848180770874023\n",
      "    last layer lr:            0.0072280000000000035\n",
      "epoch: 140 (23/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 92.78%\n",
      "    train overall loss:       0.22759073972702026\n",
      "    train cross_ent loss:     0.08169935426364343\n",
      "    test overall loss:        0.46171337366104126\n",
      "    test cross_ent loss:      0.3180431127548218\n",
      "    cluster loss:             74.70698928833008\n",
      "    separation loss:          0.4366273880004883\n",
      "    avg separation loss:      2.613544225692749\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  140.58851623535156\n",
      "    train time:               0.014271259307861328\n",
      "    test time:                0.011604785919189453\n",
      "    epoch time:               0.026447534561157227\n",
      "    last layer lr:            0.006831999999999998\n",
      "epoch: 140 (24/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.22414096941550574\n",
      "    train cross_ent loss:     0.08189336024224758\n",
      "    test overall loss:        0.44865676760673523\n",
      "    test cross_ent loss:      0.30841100215911865\n",
      "    cluster loss:             74.70731735229492\n",
      "    separation loss:          0.43682999908924103\n",
      "    avg separation loss:      2.6041640043258667\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  137.16400146484375\n",
      "    train time:               0.014453411102294922\n",
      "    test time:                0.01025080680847168\n",
      "    epoch time:               0.025250911712646484\n",
      "    last layer lr:            0.006436\n",
      "epoch: 140 (25/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 92.78%\n",
      "    train overall loss:       0.22776018579800925\n",
      "    train cross_ent loss:     0.0890114326030016\n",
      "    test overall loss:        0.4431074857711792\n",
      "    test cross_ent loss:      0.3063524067401886\n",
      "    cluster loss:             74.70733833312988\n",
      "    separation loss:          0.4373798072338104\n",
      "    avg separation loss:      2.607839584350586\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  133.67333984375\n",
      "    train time:               0.013794183731079102\n",
      "    test time:                0.004427433013916016\n",
      "    epoch time:               0.02049732208251953\n",
      "    last layer lr:            0.00604\n",
      "epoch: 140 (26/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.2063103417555491\n",
      "    train cross_ent loss:     0.0707888479034106\n",
      "    test overall loss:        0.4473688006401062\n",
      "    test cross_ent loss:      0.3135623633861542\n",
      "    cluster loss:             74.70707511901855\n",
      "    separation loss:          0.4369919002056122\n",
      "    avg separation loss:      2.6142632961273193\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  130.7246856689453\n",
      "    train time:               0.017165422439575195\n",
      "    test time:                0.010769367218017578\n",
      "    epoch time:               0.02853083610534668\n",
      "    last layer lr:            0.005644000000000002\n",
      "epoch: 140 (27/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.20799769957860312\n",
      "    train cross_ent loss:     0.07543302762011687\n",
      "    test overall loss:        0.44848689436912537\n",
      "    test cross_ent loss:      0.3177378475666046\n",
      "    cluster loss:             74.70697021484375\n",
      "    separation loss:          0.43630100786685944\n",
      "    avg separation loss:      2.6098644733428955\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  127.66728973388672\n",
      "    train time:               0.017499685287475586\n",
      "    test time:                0.01076507568359375\n",
      "    epoch time:               0.02887272834777832\n",
      "    last layer lr:            0.005248000000000003\n",
      "epoch: 140 (28/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.2136977712313334\n",
      "    train cross_ent loss:     0.0841901870444417\n",
      "    test overall loss:        0.4465675801038742\n",
      "    test cross_ent loss:      0.31868894398212433\n",
      "    cluster loss:             74.70702171325684\n",
      "    separation loss:          0.43555858731269836\n",
      "    avg separation loss:      2.6074390411376953\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  124.79688262939453\n",
      "    train time:               0.016294479370117188\n",
      "    test time:                0.0040438175201416016\n",
      "    epoch time:               0.020825862884521484\n",
      "    last layer lr:            0.004851999999999998\n",
      "epoch: 140 (29/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.19834406673908234\n",
      "    train cross_ent loss:     0.07144842576235533\n",
      "    test overall loss:        0.44128653407096863\n",
      "    test cross_ent loss:      0.3157944083213806\n",
      "    cluster loss:             74.70697212219238\n",
      "    separation loss:          0.43659499287605286\n",
      "    avg separation loss:      2.61354923248291\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  122.41036987304688\n",
      "    train time:               0.017218351364135742\n",
      "    test time:                0.010773420333862305\n",
      "    epoch time:               0.028589725494384766\n",
      "    last layer lr:            0.004455999999999999\n",
      "epoch: 140 (30/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.20294204105933508\n",
      "    train cross_ent loss:     0.07853868665794532\n",
      "    test overall loss:        0.43851716816425323\n",
      "    test cross_ent loss:      0.3155429810285568\n",
      "    cluster loss:             74.70730018615723\n",
      "    separation loss:          0.4378226399421692\n",
      "    avg separation loss:      2.608072519302368\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  119.89244079589844\n",
      "    train time:               0.017153501510620117\n",
      "    test time:                0.010898351669311523\n",
      "    epoch time:               0.028654813766479492\n",
      "    last layer lr:            0.004060000000000001\n",
      "epoch: 140 (31/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.2311772977312406\n",
      "    train cross_ent loss:     0.10902813449501991\n",
      "    test overall loss:        0.4300222843885422\n",
      "    test cross_ent loss:      0.3090294152498245\n",
      "    cluster loss:             74.70818328857422\n",
      "    separation loss:          0.44024913012981415\n",
      "    avg separation loss:      2.601621389389038\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  117.91111755371094\n",
      "    train time:               0.017293691635131836\n",
      "    test time:                0.0042345523834228516\n",
      "    epoch time:               0.02203536033630371\n",
      "    last layer lr:            0.0036640000000000015\n",
      "epoch: 140 (32/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.20961531500021616\n",
      "    train cross_ent loss:     0.08930231196184953\n",
      "    test overall loss:        0.43087929487228394\n",
      "    test cross_ent loss:      0.31153394281864166\n",
      "    cluster loss:             74.70768737792969\n",
      "    separation loss:          0.4385908544063568\n",
      "    avg separation loss:      2.601208209991455\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  116.26361083984375\n",
      "    train time:               0.017509937286376953\n",
      "    test time:                0.010784149169921875\n",
      "    epoch time:               0.02889084815979004\n",
      "    last layer lr:            0.003268000000000003\n",
      "epoch: 140 (33/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 92.78%\n",
      "    train overall loss:       0.19142911583185196\n",
      "    train cross_ent loss:     0.072747309692204\n",
      "    test overall loss:        0.4313957840204239\n",
      "    test cross_ent loss:      0.3135973960161209\n",
      "    cluster loss:             74.70730018615723\n",
      "    separation loss:          0.43719057738780975\n",
      "    avg separation loss:      2.6065536737442017\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  114.71664428710938\n",
      "    train time:               0.017276763916015625\n",
      "    test time:                0.010765314102172852\n",
      "    epoch time:               0.028644323348999023\n",
      "    last layer lr:            0.002871999999999997\n",
      "epoch: 140 (34/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.19444778064886728\n",
      "    train cross_ent loss:     0.07713682018220425\n",
      "    test overall loss:        0.4339466691017151\n",
      "    test cross_ent loss:      0.317422553896904\n",
      "    cluster loss:             74.70722579956055\n",
      "    separation loss:          0.43747560679912567\n",
      "    avg separation loss:      2.608912467956543\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  113.44236755371094\n",
      "    train time:               0.016359329223632812\n",
      "    test time:                0.003997087478637695\n",
      "    epoch time:               0.02084493637084961\n",
      "    last layer lr:            0.0024759999999999986\n",
      "epoch: 140 (35/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.18781751145919165\n",
      "    train cross_ent loss:     0.07176211414237817\n",
      "    test overall loss:        0.4291864186525345\n",
      "    test cross_ent loss:      0.313824787735939\n",
      "    cluster loss:             74.70717430114746\n",
      "    separation loss:          0.43727707862854004\n",
      "    avg separation loss:      2.6069129705429077\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  112.27989196777344\n",
      "    train time:               0.01712656021118164\n",
      "    test time:                0.010820865631103516\n",
      "    epoch time:               0.02854132652282715\n",
      "    last layer lr:            0.0020800000000000003\n",
      "epoch: 140 (36/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.18439472218354544\n",
      "    train cross_ent loss:     0.06948587360481422\n",
      "    test overall loss:        0.43134187161922455\n",
      "    test cross_ent loss:      0.3170553594827652\n",
      "    cluster loss:             74.70694351196289\n",
      "    separation loss:          0.43583883345127106\n",
      "    avg separation loss:      2.6131584644317627\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  111.20477294921875\n",
      "    train time:               0.017327070236206055\n",
      "    test time:                0.010832548141479492\n",
      "    epoch time:               0.028767108917236328\n",
      "    last layer lr:            0.0016840000000000017\n",
      "epoch: 140 (37/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 92.78%\n",
      "    train overall loss:       0.19048951317866644\n",
      "    train cross_ent loss:     0.07653517896930377\n",
      "    test overall loss:        0.43199317157268524\n",
      "    test cross_ent loss:      0.3185652941465378\n",
      "    cluster loss:             74.7068920135498\n",
      "    separation loss:          0.43498043715953827\n",
      "    avg separation loss:      2.6161712408065796\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  110.34612274169922\n",
      "    train time:               0.0193328857421875\n",
      "    test time:                0.012202739715576172\n",
      "    epoch time:               0.03222370147705078\n",
      "    last layer lr:            0.001288000000000003\n",
      "epoch: 140 (38/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 92.78%\n",
      "    train overall loss:       0.17701870451370874\n",
      "    train cross_ent loss:     0.06394072684148948\n",
      "    test overall loss:        0.4293261170387268\n",
      "    test cross_ent loss:      0.31670306622982025\n",
      "    cluster loss:             74.70701217651367\n",
      "    separation loss:          0.43478988111019135\n",
      "    avg separation loss:      2.6152257919311523\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  109.54130554199219\n",
      "    train time:               0.023360729217529297\n",
      "    test time:                0.004820346832275391\n",
      "    epoch time:               0.028845548629760742\n",
      "    last layer lr:            0.0008919999999999973\n",
      "epoch: 140 (39/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.17488405853509903\n",
      "    train cross_ent loss:     0.06249018758535385\n",
      "    test overall loss:        0.4251655042171478\n",
      "    test cross_ent loss:      0.31308333575725555\n",
      "    cluster loss:             74.70711898803711\n",
      "    separation loss:          0.4359724372625351\n",
      "    avg separation loss:      2.618767499923706\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  109.00042724609375\n",
      "    train time:               0.023160457611083984\n",
      "    test time:                0.012645959854125977\n",
      "    epoch time:               0.03658485412597656\n",
      "    last layer lr:            0.0004959999999999986\n",
      "epoch: 140 (40/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 92.78%\n",
      "    train overall loss:       0.20183569192886353\n",
      "    train cross_ent loss:     0.08988139778375626\n",
      "    test overall loss:        0.4254826605319977\n",
      "    test cross_ent loss:      0.31370018422603607\n",
      "    cluster loss:             74.70687866210938\n",
      "    separation loss:          0.43585018813610077\n",
      "    avg separation loss:      2.620963215827942\n",
      "    l1_addon loss:            102.72441864013672\n",
      "    l1 loss:                  108.70072937011719\n",
      "    train time:               0.023154020309448242\n",
      "    test time:                0.012664556503295898\n",
      "    epoch time:               0.03660464286804199\n",
      "    last layer lr:            0.0001\n",
      "epoch: 141 (JOINT) - Libras\n",
      "    test acc:                 92.78%\n",
      "    train overall loss:       0.18483233948548636\n",
      "    train cross_ent loss:     0.07304975452522437\n",
      "    test overall loss:        0.4240681529045105\n",
      "    test cross_ent loss:      0.312285378575325\n",
      "    cluster loss:             74.70732688903809\n",
      "    separation loss:          0.43579068779945374\n",
      "    avg separation loss:      2.6236648559570312\n",
      "    l1_addon loss:            102.73477935791016\n",
      "    l1 loss:                  108.70072937011719\n",
      "    train time:               0.04213070869445801\n",
      "    test time:                0.012748479843139648\n",
      "    epoch time:               0.05583381652832031\n",
      "    joint lr:                 0.001298047112325102\n",
      "epoch: 142 (JOINT) - Libras\n",
      "    test acc:                 92.22%\n",
      "    train overall loss:       0.1727112407485644\n",
      "    train cross_ent loss:     0.060926644752422966\n",
      "    test overall loss:        0.4148600399494171\n",
      "    test cross_ent loss:      0.3030732274055481\n",
      "    cluster loss:             74.70734596252441\n",
      "    separation loss:          0.428027018904686\n",
      "    avg separation loss:      2.615821957588196\n",
      "    l1_addon loss:            102.86936950683594\n",
      "    l1 loss:                  108.70072937011719\n",
      "    train time:               0.0411074161529541\n",
      "    test time:                0.012856483459472656\n",
      "    epoch time:               0.05490517616271973\n",
      "    joint lr:                 0.002472133282403701\n",
      "epoch: 143 (JOINT) - Libras\n",
      "    test acc:                 92.78%\n",
      "    train overall loss:       0.18024953454732895\n",
      "    train cross_ent loss:     0.06846313364803791\n",
      "    test overall loss:        0.4158772826194763\n",
      "    test cross_ent loss:      0.3040924519300461\n",
      "    cluster loss:             74.70674705505371\n",
      "    separation loss:          0.4222651273012161\n",
      "    avg separation loss:      2.6013338565826416\n",
      "    l1_addon loss:            102.80320739746094\n",
      "    l1 loss:                  108.70072937011719\n",
      "    train time:               0.04290437698364258\n",
      "    test time:                0.012794256210327148\n",
      "    epoch time:               0.05661320686340332\n",
      "    joint lr:                 0.0036226179243694966\n",
      "epoch: 144 (JOINT) - Libras\n",
      "    test acc:                 92.78%\n",
      "    train overall loss:       0.1704672450820605\n",
      "    train cross_ent loss:     0.0586810347934564\n",
      "    test overall loss:        0.4094913899898529\n",
      "    test cross_ent loss:      0.2977028340101242\n",
      "    cluster loss:             74.7074031829834\n",
      "    separation loss:          0.4094482511281967\n",
      "    avg separation loss:      2.5517011880874634\n",
      "    l1_addon loss:            102.92727661132812\n",
      "    l1 loss:                  108.70072937011719\n",
      "    train time:               0.03443431854248047\n",
      "    test time:                0.01044607162475586\n",
      "    epoch time:               0.04567694664001465\n",
      "    joint lr:                 0.004749855660167736\n",
      "epoch: 145 (JOINT) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.17104019969701767\n",
      "    train cross_ent loss:     0.059254059568047523\n",
      "    test overall loss:        0.4105352461338043\n",
      "    test cross_ent loss:      0.29875269532203674\n",
      "    cluster loss:             74.7089958190918\n",
      "    separation loss:          0.4047531187534332\n",
      "    avg separation loss:      2.5048779249191284\n",
      "    l1_addon loss:            102.72734069824219\n",
      "    l1 loss:                  108.70072937011719\n",
      "    train time:               0.036569833755493164\n",
      "    test time:                0.010895490646362305\n",
      "    epoch time:               0.04821491241455078\n",
      "    joint lr:                 0.005854196379457574\n",
      "epoch: 146 (JOINT) - Libras\n",
      "    test acc:                 91.11%\n",
      "    train overall loss:       0.15742323299249014\n",
      "    train cross_ent loss:     0.04563928581774235\n",
      "    test overall loss:        0.4216584265232086\n",
      "    test cross_ent loss:      0.3098730891942978\n",
      "    cluster loss:             74.70537376403809\n",
      "    separation loss:          0.39914484322071075\n",
      "    avg separation loss:      2.5449506044387817\n",
      "    l1_addon loss:            102.81988525390625\n",
      "    l1 loss:                  108.70072937011719\n",
      "    train time:               0.035559892654418945\n",
      "    test time:                0.010983705520629883\n",
      "    epoch time:               0.04726266860961914\n",
      "    joint lr:                 0.006935985298795627\n",
      "epoch: 147 (JOINT) - Libras\n",
      "    test acc:                 92.78%\n",
      "    train overall loss:       0.19447005291779837\n",
      "    train cross_ent loss:     0.08268464698145787\n",
      "    test overall loss:        0.44540661573410034\n",
      "    test cross_ent loss:      0.33363012969493866\n",
      "    cluster loss:             74.71219253540039\n",
      "    separation loss:          0.3988318592309952\n",
      "    avg separation loss:      2.4682836532592773\n",
      "    l1_addon loss:            102.52518463134766\n",
      "    l1 loss:                  108.70072937011719\n",
      "    train time:               0.03400111198425293\n",
      "    test time:                0.010883569717407227\n",
      "    epoch time:               0.04564714431762695\n",
      "    joint lr:                 0.007995563020108943\n",
      "epoch: 148 (JOINT) - Libras\n",
      "    test acc:                 87.78%\n",
      "    train overall loss:       0.2544076020518939\n",
      "    train cross_ent loss:     0.14264288110037646\n",
      "    test overall loss:        0.4968256205320358\n",
      "    test cross_ent loss:      0.38504432141780853\n",
      "    cluster loss:             74.73179626464844\n",
      "    separation loss:          0.42625971138477325\n",
      "    avg separation loss:      2.5692909955978394\n",
      "    l1_addon loss:            102.68550109863281\n",
      "    l1 loss:                  108.70072937011719\n",
      "    train time:               0.03456425666809082\n",
      "    test time:                0.010897636413574219\n",
      "    epoch time:               0.046202659606933594\n",
      "    joint lr:                 0.009033265588466115\n",
      "epoch: 149 (JOINT) - Libras\n",
      "    test acc:                 76.11%\n",
      "    train overall loss:       0.30423718442519504\n",
      "    train cross_ent loss:     0.19245518743991852\n",
      "    test overall loss:        0.906571090221405\n",
      "    test cross_ent loss:      0.7948167622089386\n",
      "    cluster loss:             74.81100845336914\n",
      "    separation loss:          0.4873701483011246\n",
      "    avg separation loss:      2.8636815547943115\n",
      "    l1_addon loss:            101.7863540649414\n",
      "    l1 loss:                  108.70072937011719\n",
      "    train time:               0.029531002044677734\n",
      "    test time:                0.0075414180755615234\n",
      "    epoch time:               0.037930965423583984\n",
      "    joint lr:                 0.010049424549154131\n",
      "epoch: 150 (JOINT) - Libras\n",
      "    test acc:                 85.56%\n",
      "    train overall loss:       0.3307238345344861\n",
      "    train cross_ent loss:     0.21895362685124078\n",
      "    test overall loss:        0.7318345308303833\n",
      "    test cross_ent loss:      0.6200518012046814\n",
      "    cluster loss:             74.7706527709961\n",
      "    separation loss:          0.4949640929698944\n",
      "    avg separation loss:      2.7214417457580566\n",
      "    l1_addon loss:            102.73280334472656\n",
      "    l1 loss:                  108.70072937011719\n",
      "    train time:               0.029480457305908203\n",
      "    test time:                0.004137277603149414\n",
      "    epoch time:               0.03447604179382324\n",
      "    joint lr:                 0.011044367004069541\n",
      "epoch: 151 (JOINT) - Libras\n",
      "    test acc:                 81.11%\n",
      "    train overall loss:       0.365602341790994\n",
      "    train cross_ent loss:     0.25383321692546207\n",
      "    test overall loss:        0.7564834952354431\n",
      "    test cross_ent loss:      0.6447027921676636\n",
      "    cluster loss:             74.77900123596191\n",
      "    separation loss:          0.48044316470623016\n",
      "    avg separation loss:      2.75197970867157\n",
      "    l1_addon loss:            102.6645736694336\n",
      "    l1 loss:                  108.70072937011719\n",
      "    train time:               0.028853893280029297\n",
      "    test time:                0.004087924957275391\n",
      "    epoch time:               0.03386521339416504\n",
      "    joint lr:                 0.010393177167327405\n",
      "epoch: 152 (JOINT) - Libras\n",
      "    test acc:                 91.11%\n",
      "    train overall loss:       0.43464914957682294\n",
      "    train cross_ent loss:     0.32288004209597904\n",
      "    test overall loss:        0.6439079940319061\n",
      "    test cross_ent loss:      0.5321528166532516\n",
      "    cluster loss:             74.76265335083008\n",
      "    separation loss:          0.528928816318512\n",
      "    avg separation loss:      2.7394901514053345\n",
      "    l1_addon loss:            101.8155517578125\n",
      "    l1 loss:                  108.70072937011719\n",
      "    train time:               0.029204130172729492\n",
      "    test time:                0.004121303558349609\n",
      "    epoch time:               0.034180402755737305\n",
      "    joint lr:                 0.009753916690619703\n",
      "epoch: 153 (JOINT) - Libras\n",
      "    test acc:                 91.11%\n",
      "    train overall loss:       0.3515690639615059\n",
      "    train cross_ent loss:     0.23981126646200815\n",
      "    test overall loss:        0.6190232038497925\n",
      "    test cross_ent loss:      0.5072817802429199\n",
      "    cluster loss:             74.76836585998535\n",
      "    separation loss:          0.5200707465410233\n",
      "    avg separation loss:      2.6976089477539062\n",
      "    l1_addon loss:            101.3555908203125\n",
      "    l1 loss:                  108.70072937011719\n",
      "    train time:               0.02956843376159668\n",
      "    test time:                0.004071712493896484\n",
      "    epoch time:               0.03454899787902832\n",
      "    joint lr:                 0.009126412105729424\n",
      "epoch: 154 (JOINT) - Libras\n",
      "    test acc:                 83.33%\n",
      "    train overall loss:       0.29913124442100525\n",
      "    train cross_ent loss:     0.18738391622900963\n",
      "    test overall loss:        0.6754816770553589\n",
      "    test cross_ent loss:      0.5637167245149612\n",
      "    cluster loss:             74.76775360107422\n",
      "    separation loss:          0.46662378311157227\n",
      "    avg separation loss:      2.7977705001831055\n",
      "    l1_addon loss:            102.14047241210938\n",
      "    l1 loss:                  108.70072937011719\n",
      "    train time:               0.02924799919128418\n",
      "    test time:                0.0040132999420166016\n",
      "    epoch time:               0.03381061553955078\n",
      "    joint lr:                 0.008510492220867888\n",
      "epoch: 155 (JOINT) - Libras\n",
      "    test acc:                 91.11%\n",
      "    train overall loss:       0.3125188301006953\n",
      "    train cross_ent loss:     0.2007517802218596\n",
      "    test overall loss:        0.5279682725667953\n",
      "    test cross_ent loss:      0.41620534658432007\n",
      "    cluster loss:             74.75442504882812\n",
      "    separation loss:          0.4980950504541397\n",
      "    avg separation loss:      2.7870243787765503\n",
      "    l1_addon loss:            102.07379150390625\n",
      "    l1 loss:                  108.70072937011719\n",
      "    train time:               0.029448986053466797\n",
      "    test time:                0.004509449005126953\n",
      "    epoch time:               0.03483223915100098\n",
      "    joint lr:                 0.00790598809249301\n",
      "epoch: 156 (JOINT) - Libras\n",
      "    test acc:                 86.11%\n",
      "    train overall loss:       0.3164639100432396\n",
      "    train cross_ent loss:     0.2046994318564733\n",
      "    test overall loss:        0.6568897664546967\n",
      "    test cross_ent loss:      0.54513218998909\n",
      "    cluster loss:             74.7591609954834\n",
      "    separation loss:          0.5498586297035217\n",
      "    avg separation loss:      3.042368173599243\n",
      "    l1_addon loss:            101.89361572265625\n",
      "    l1 loss:                  108.70072937011719\n",
      "    train time:               0.029429197311401367\n",
      "    test time:                0.004521846771240234\n",
      "    epoch time:               0.03481721878051758\n",
      "    joint lr:                 0.007312732997463544\n",
      "epoch: 157 (JOINT) - Libras\n",
      "    test acc:                 91.11%\n",
      "    train overall loss:       0.25796352078517276\n",
      "    train cross_ent loss:     0.146207415809234\n",
      "    test overall loss:        0.5549958050251007\n",
      "    test cross_ent loss:      0.4432417005300522\n",
      "    cluster loss:             74.74556159973145\n",
      "    separation loss:          0.4951792508363724\n",
      "    avg separation loss:      2.7280019521713257\n",
      "    l1_addon loss:            101.77975463867188\n",
      "    l1 loss:                  108.70072937011719\n",
      "    train time:               0.029373645782470703\n",
      "    test time:                0.004508256912231445\n",
      "    epoch time:               0.034470319747924805\n",
      "    joint lr:                 0.006730562405525418\n",
      "epoch: 158 (JOINT) - Libras\n",
      "    test acc:                 91.67%\n",
      "    train overall loss:       0.23959291726350784\n",
      "    train cross_ent loss:     0.1278328038752079\n",
      "    test overall loss:        0.505800873041153\n",
      "    test cross_ent loss:      0.3940281271934509\n",
      "    cluster loss:             74.73721504211426\n",
      "    separation loss:          0.4383199214935303\n",
      "    avg separation loss:      2.799023747444153\n",
      "    l1_addon loss:            102.40093994140625\n",
      "    l1 loss:                  108.70072937011719\n",
      "    train time:               0.0296022891998291\n",
      "    test time:                0.004319429397583008\n",
      "    epoch time:               0.03464627265930176\n",
      "    joint lr:                 0.006159313952126306\n",
      "epoch: 159 (JOINT) - Libras\n",
      "    test acc:                 94.44%\n",
      "    train overall loss:       0.2136324942111969\n",
      "    train cross_ent loss:     0.10185968627532323\n",
      "    test overall loss:        0.3938819169998169\n",
      "    test cross_ent loss:      0.2821214348077774\n",
      "    cluster loss:             74.72367095947266\n",
      "    separation loss:          0.4430479407310486\n",
      "    avg separation loss:      2.6211507320404053\n",
      "    l1_addon loss:            101.99176788330078\n",
      "    l1 loss:                  108.70072937011719\n",
      "    train time:               0.027725696563720703\n",
      "    test time:                0.004109382629394531\n",
      "    epoch time:               0.03248953819274902\n",
      "    joint lr:                 0.005598827411554625\n",
      "epoch: 160 (JOINT) - Libras\n",
      "    test acc:                 92.78%\n",
      "    train overall loss:       0.21260432650645575\n",
      "    train cross_ent loss:     0.10085607320070267\n",
      "    test overall loss:        0.43576234579086304\n",
      "    test cross_ent loss:      0.3240215629339218\n",
      "    cluster loss:             74.72246170043945\n",
      "    separation loss:          0.4348676949739456\n",
      "    avg separation loss:      2.4982982873916626\n",
      "    l1_addon loss:            101.33486938476562\n",
      "    l1 loss:                  108.70072937011719\n",
      "    train time:               0.026560544967651367\n",
      "    test time:                0.00444483757019043\n",
      "    epoch time:               0.0316159725189209\n",
      "    joint lr:                 0.005048944670399165\n",
      "epoch: 161 (JOINT) - Libras\n",
      "    test acc:                 92.78%\n",
      "    train overall loss:       0.18799545615911484\n",
      "    train cross_ent loss:     0.07625465436528127\n",
      "    test overall loss:        0.3778848648071289\n",
      "    test cross_ent loss:      0.26614099740982056\n",
      "    cluster loss:             74.71662902832031\n",
      "    separation loss:          0.4031490832567215\n",
      "    avg separation loss:      2.4844470024108887\n",
      "    l1_addon loss:            101.43756103515625\n",
      "    l1 loss:                  108.70072937011719\n",
      "    train time:               0.026441335678100586\n",
      "    test time:                0.004407644271850586\n",
      "    epoch time:               0.031436920166015625\n",
      "    joint lr:                 0.004509509701325646\n",
      "epoch: 162 (JOINT) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.16998635977506638\n",
      "    train cross_ent loss:     0.05823763832449913\n",
      "    test overall loss:        0.3769736886024475\n",
      "    test cross_ent loss:      0.2652202174067497\n",
      "    cluster loss:             74.71655464172363\n",
      "    separation loss:          0.4074905514717102\n",
      "    avg separation loss:      2.561710238456726\n",
      "    l1_addon loss:            101.75819396972656\n",
      "    l1 loss:                  108.70072937011719\n",
      "    train time:               0.025708913803100586\n",
      "    test time:                0.004370927810668945\n",
      "    epoch time:               0.030654430389404297\n",
      "    joint lr:                 0.00398036853716657\n",
      "epoch: 163 (JOINT) - Libras\n",
      "    test acc:                 94.44%\n",
      "    train overall loss:       0.15472851445277533\n",
      "    train cross_ent loss:     0.042975531270106636\n",
      "    test overall loss:        0.38113851845264435\n",
      "    test cross_ent loss:      0.26938746124505997\n",
      "    cluster loss:             74.71023368835449\n",
      "    separation loss:          0.4019867032766342\n",
      "    avg separation loss:      2.5520946979522705\n",
      "    l1_addon loss:            101.67794799804688\n",
      "    l1 loss:                  108.70072937011719\n",
      "    train time:               0.024451255798339844\n",
      "    test time:                0.004433870315551758\n",
      "    epoch time:               0.029456377029418945\n",
      "    joint lr:                 0.0034613692453205423\n",
      "epoch: 164 (JOINT) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.15559841940800348\n",
      "    train cross_ent loss:     0.043849290969471134\n",
      "    test overall loss:        0.38653191924095154\n",
      "    test cross_ent loss:      0.27478542923927307\n",
      "    cluster loss:             74.70858001708984\n",
      "    separation loss:          0.39514702558517456\n",
      "    avg separation loss:      2.5034371614456177\n",
      "    l1_addon loss:            101.52595520019531\n",
      "    l1 loss:                  108.70072937011719\n",
      "    train time:               0.02659296989440918\n",
      "    test time:                0.004423618316650391\n",
      "    epoch time:               0.03159785270690918\n",
      "    joint lr:                 0.002952361902457719\n",
      "epoch: 165 (JOINT) - Libras\n",
      "    test acc:                 94.44%\n",
      "    train overall loss:       0.15231343855460486\n",
      "    train cross_ent loss:     0.0405689412727952\n",
      "    test overall loss:        0.3734707236289978\n",
      "    test cross_ent loss:      0.261729434132576\n",
      "    cluster loss:             74.70912170410156\n",
      "    separation loss:          0.3926510363817215\n",
      "    avg separation loss:      2.479108214378357\n",
      "    l1_addon loss:            101.35198974609375\n",
      "    l1 loss:                  108.70072937011719\n",
      "    train time:               0.02643585205078125\n",
      "    test time:                0.004380941390991211\n",
      "    epoch time:               0.031412601470947266\n",
      "    joint lr:                 0.0024531985695276076\n",
      "epoch: 166 (JOINT) - Libras\n",
      "    test acc:                 94.44%\n",
      "    train overall loss:       0.1537910575668017\n",
      "    train cross_ent loss:     0.04205045228203138\n",
      "    test overall loss:        0.3603804111480713\n",
      "    test cross_ent loss:      0.24864088743925095\n",
      "    cluster loss:             74.70672607421875\n",
      "    separation loss:          0.38841401040554047\n",
      "    avg separation loss:      2.4820992946624756\n",
      "    l1_addon loss:            101.29338073730469\n",
      "    l1 loss:                  108.70072937011719\n",
      "    train time:               0.025694608688354492\n",
      "    test time:                0.004505157470703125\n",
      "    epoch time:               0.0307924747467041\n",
      "    joint lr:                 0.001963733267065865\n",
      "epoch: 167 (JOINT) - Libras\n",
      "    test acc:                 94.44%\n",
      "    train overall loss:       0.14721355711420378\n",
      "    train cross_ent loss:     0.03547417574251691\n",
      "    test overall loss:        0.3557697832584381\n",
      "    test cross_ent loss:      0.2440299689769745\n",
      "    cluster loss:             74.70542335510254\n",
      "    separation loss:          0.3900305926799774\n",
      "    avg separation loss:      2.4956817626953125\n",
      "    l1_addon loss:            101.30305480957031\n",
      "    l1 loss:                  108.70072937011719\n",
      "    train time:               0.028937578201293945\n",
      "    test time:                0.004331350326538086\n",
      "    epoch time:               0.03406572341918945\n",
      "    joint lr:                 0.001483821950796405\n",
      "epoch: 168 (JOINT) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.17062749216953912\n",
      "    train cross_ent loss:     0.058888327019910015\n",
      "    test overall loss:        0.361267626285553\n",
      "    test cross_ent loss:      0.2495298683643341\n",
      "    cluster loss:             74.70575332641602\n",
      "    separation loss:          0.38369515538215637\n",
      "    avg separation loss:      2.467510461807251\n",
      "    l1_addon loss:            101.23309326171875\n",
      "    l1 loss:                  108.70072937011719\n",
      "    train time:               0.02926921844482422\n",
      "    test time:                0.00466156005859375\n",
      "    epoch time:               0.034784793853759766\n",
      "    joint lr:                 0.0010133224875256274\n",
      "epoch: 169 (JOINT) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.14565074319640794\n",
      "    train cross_ent loss:     0.03391317014272014\n",
      "    test overall loss:        0.36611229181289673\n",
      "    test cross_ent loss:      0.25437483191490173\n",
      "    cluster loss:             74.70533180236816\n",
      "    separation loss:          0.37991368770599365\n",
      "    avg separation loss:      2.4615161418914795\n",
      "    l1_addon loss:            101.22483825683594\n",
      "    l1 loss:                  108.70072937011719\n",
      "    train time:               0.029573917388916016\n",
      "    test time:                0.004332065582275391\n",
      "    epoch time:               0.03443646430969238\n",
      "    joint lr:                 0.0005520946313251855\n",
      "epoch: 170 (JOINT) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.15194373205304146\n",
      "    train cross_ent loss:     0.040206094117214285\n",
      "    test overall loss:        0.36469054222106934\n",
      "    test cross_ent loss:      0.25295284390449524\n",
      "    cluster loss:             74.70508575439453\n",
      "    separation loss:          0.3797885477542877\n",
      "    avg separation loss:      2.4686044454574585\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  108.70072937011719\n",
      "    train time:               0.029068946838378906\n",
      "    test time:                0.004399538040161133\n",
      "    epoch time:               0.03402829170227051\n",
      "    joint lr:                 0.0001\n",
      "epoch: 170 (PUSH) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.15194373205304146\n",
      "    train cross_ent loss:     0.040206094117214285\n",
      "    test overall loss:        0.39089369773864746\n",
      "    test cross_ent loss:      0.27915599942207336\n",
      "    cluster loss:             74.70512390136719\n",
      "    separation loss:          0.3782896250486374\n",
      "    avg separation loss:      2.4780057668685913\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  108.70072937011719\n",
      "    train time:               0.029068946838378906\n",
      "    test time:                0.004340410232543945\n",
      "    epoch time:               0.06561398506164551\n",
      "epoch: 170 (1/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.15885893752177557\n",
      "    train cross_ent loss:     0.04714353444675604\n",
      "    test overall loss:        0.3900304287672043\n",
      "    test cross_ent loss:      0.2783481925725937\n",
      "    cluster loss:             74.70494842529297\n",
      "    separation loss:          0.3798448443412781\n",
      "    avg separation loss:      2.4808353185653687\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  108.64529418945312\n",
      "    train time:               0.011742591857910156\n",
      "    test time:                0.004304647445678711\n",
      "    epoch time:               0.01649022102355957\n",
      "    last layer lr:            0.0007599999999999978\n",
      "epoch: 170 (2/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.1669420301914215\n",
      "    train cross_ent loss:     0.0554064487417539\n",
      "    test overall loss:        0.3897254317998886\n",
      "    test cross_ent loss:      0.2784152776002884\n",
      "    cluster loss:             74.70480728149414\n",
      "    separation loss:          0.37866465747356415\n",
      "    avg separation loss:      2.4847556352615356\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  108.27320861816406\n",
      "    train time:               0.011931180953979492\n",
      "    test time:                0.0044100284576416016\n",
      "    epoch time:               0.016785860061645508\n",
      "    last layer lr:            0.0014199999999999955\n",
      "epoch: 170 (3/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.16765033453702927\n",
      "    train cross_ent loss:     0.056650454799334206\n",
      "    test overall loss:        0.38570232689380646\n",
      "    test cross_ent loss:      0.27516041696071625\n",
      "    cluster loss:             74.70499420166016\n",
      "    separation loss:          0.37994199991226196\n",
      "    avg separation loss:      2.4835060834884644\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  107.50495910644531\n",
      "    train time:               0.013563156127929688\n",
      "    test time:                0.009905338287353516\n",
      "    epoch time:               0.023993968963623047\n",
      "    last layer lr:            0.0020800000000000046\n",
      "epoch: 170 (4/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.18533231814702353\n",
      "    train cross_ent loss:     0.07525498792529106\n",
      "    test overall loss:        0.37783314287662506\n",
      "    test cross_ent loss:      0.26840196549892426\n",
      "    cluster loss:             74.7049503326416\n",
      "    separation loss:          0.3807039111852646\n",
      "    avg separation loss:      2.486082911491394\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  106.39421844482422\n",
      "    train time:               0.013655424118041992\n",
      "    test time:                0.010260343551635742\n",
      "    epoch time:               0.02444314956665039\n",
      "    last layer lr:            0.0027400000000000024\n",
      "epoch: 170 (5/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.16075594599048296\n",
      "    train cross_ent loss:     0.05185377458110452\n",
      "    test overall loss:        0.37473537027835846\n",
      "    test cross_ent loss:      0.26663364470005035\n",
      "    cluster loss:             74.70485877990723\n",
      "    separation loss:          0.38090838491916656\n",
      "    avg separation loss:      2.4820361137390137\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  105.06476593017578\n",
      "    train time:               0.016828536987304688\n",
      "    test time:                0.011620283126831055\n",
      "    epoch time:               0.029027462005615234\n",
      "    last layer lr:            0.0034\n",
      "epoch: 170 (6/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.18792958557605743\n",
      "    train cross_ent loss:     0.0805188212543726\n",
      "    test overall loss:        0.36808574199676514\n",
      "    test cross_ent loss:      0.2615574523806572\n",
      "    cluster loss:             74.70523262023926\n",
      "    separation loss:          0.3814595639705658\n",
      "    avg separation loss:      2.4791934490203857\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  103.49134063720703\n",
      "    train time:               0.014049768447875977\n",
      "    test time:                0.010742902755737305\n",
      "    epoch time:               0.02533864974975586\n",
      "    last layer lr:            0.004059999999999998\n",
      "epoch: 170 (7/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.17297914127508798\n",
      "    train cross_ent loss:     0.06717368463675182\n",
      "    test overall loss:        0.3611505329608917\n",
      "    test cross_ent loss:      0.2563399374485016\n",
      "    cluster loss:             74.70523262023926\n",
      "    separation loss:          0.38280537724494934\n",
      "    avg separation loss:      2.4803149700164795\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  101.77365112304688\n",
      "    train time:               0.015645503997802734\n",
      "    test time:                0.004657268524169922\n",
      "    epoch time:               0.02083110809326172\n",
      "    last layer lr:            0.004719999999999996\n",
      "epoch: 170 (8/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.15916965901851654\n",
      "    train cross_ent loss:     0.05493529327213764\n",
      "    test overall loss:        0.35964618623256683\n",
      "    test cross_ent loss:      0.2564524784684181\n",
      "    cluster loss:             74.7051010131836\n",
      "    separation loss:          0.3821794390678406\n",
      "    avg separation loss:      2.476202130317688\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  100.15675354003906\n",
      "    train time:               0.013639211654663086\n",
      "    test time:                0.010032415390014648\n",
      "    epoch time:               0.024196147918701172\n",
      "    last layer lr:            0.0053800000000000054\n",
      "epoch: 170 (9/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 95.00%\n",
      "    train overall loss:       0.15079916020234427\n",
      "    train cross_ent loss:     0.04859724889198939\n",
      "    test overall loss:        0.36026889085769653\n",
      "    test cross_ent loss:      0.2595246210694313\n",
      "    cluster loss:             74.70488739013672\n",
      "    separation loss:          0.38005711138248444\n",
      "    avg separation loss:      2.480600953102112\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  97.70732879638672\n",
      "    train time:               0.013025045394897461\n",
      "    test time:                0.009971380233764648\n",
      "    epoch time:               0.02350640296936035\n",
      "    last layer lr:            0.006040000000000003\n",
      "epoch: 170 (10/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 94.44%\n",
      "    train overall loss:       0.16282041495045027\n",
      "    train cross_ent loss:     0.06321311152229707\n",
      "    test overall loss:        0.3585270047187805\n",
      "    test cross_ent loss:      0.26052096486091614\n",
      "    cluster loss:             74.70476913452148\n",
      "    separation loss:          0.3803661912679672\n",
      "    avg separation loss:      2.4838892221450806\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  94.96908569335938\n",
      "    train time:               0.013737201690673828\n",
      "    test time:                0.01000666618347168\n",
      "    epoch time:               0.024276018142700195\n",
      "    last layer lr:            0.0067\n",
      "epoch: 170 (11/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 94.44%\n",
      "    train overall loss:       0.15595348676045737\n",
      "    train cross_ent loss:     0.059400102434058986\n",
      "    test overall loss:        0.3503081947565079\n",
      "    test cross_ent loss:      0.2556966170668602\n",
      "    cluster loss:             74.70487785339355\n",
      "    separation loss:          0.3811182677745819\n",
      "    avg separation loss:      2.482531189918518\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  91.57463836669922\n",
      "    train time:               0.013739585876464844\n",
      "    test time:                0.009959220886230469\n",
      "    epoch time:               0.02421283721923828\n",
      "    last layer lr:            0.0073599999999999985\n",
      "epoch: 170 (12/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 94.44%\n",
      "    train overall loss:       0.15765532727042833\n",
      "    train cross_ent loss:     0.06416303695489962\n",
      "    test overall loss:        0.34687456488609314\n",
      "    test cross_ent loss:      0.2551470994949341\n",
      "    cluster loss:             74.7048225402832\n",
      "    separation loss:          0.3813093453645706\n",
      "    avg separation loss:      2.483001232147217\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  88.69050598144531\n",
      "    train time:               0.012755632400512695\n",
      "    test time:                0.009629011154174805\n",
      "    epoch time:               0.022899627685546875\n",
      "    last layer lr:            0.008019999999999994\n",
      "epoch: 170 (13/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 94.44%\n",
      "    train overall loss:       0.15695216755072275\n",
      "    train cross_ent loss:     0.06673526888092358\n",
      "    test overall loss:        0.3458087146282196\n",
      "    test cross_ent loss:      0.25761812925338745\n",
      "    cluster loss:             74.70503997802734\n",
      "    separation loss:          0.38019004464149475\n",
      "    avg separation loss:      2.482734441757202\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  85.15364074707031\n",
      "    train time:               0.013864278793334961\n",
      "    test time:                0.010027647018432617\n",
      "    epoch time:               0.024410486221313477\n",
      "    last layer lr:            0.008680000000000005\n",
      "epoch: 170 (14/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.1470941404501597\n",
      "    train cross_ent loss:     0.060318054941793285\n",
      "    test overall loss:        0.34318411350250244\n",
      "    test cross_ent loss:      0.2583354711532593\n",
      "    cluster loss:             74.70509719848633\n",
      "    separation loss:          0.3801039159297943\n",
      "    avg separation loss:      2.4760502576828003\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  81.81169128417969\n",
      "    train time:               0.013777017593383789\n",
      "    test time:                0.01000070571899414\n",
      "    epoch time:               0.02430558204650879\n",
      "    last layer lr:            0.009340000000000003\n",
      "epoch: 170 (15/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.1526325804491838\n",
      "    train cross_ent loss:     0.06854682508856058\n",
      "    test overall loss:        0.3432695269584656\n",
      "    test cross_ent loss:      0.26045435667037964\n",
      "    cluster loss:             74.70450019836426\n",
      "    separation loss:          0.38206295669078827\n",
      "    avg separation loss:      2.4815268516540527\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  79.77821350097656\n",
      "    train time:               0.012555599212646484\n",
      "    test time:                0.009447336196899414\n",
      "    epoch time:               0.022507190704345703\n",
      "    last layer lr:            0.01\n",
      "epoch: 170 (16/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.139049602051576\n",
      "    train cross_ent loss:     0.057757927725712456\n",
      "    test overall loss:        0.3395627588033676\n",
      "    test cross_ent loss:      0.26037873327732086\n",
      "    cluster loss:             74.70481872558594\n",
      "    separation loss:          0.3827633410692215\n",
      "    avg separation loss:      2.486094832420349\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  76.1470718383789\n",
      "    train time:               0.014028549194335938\n",
      "    test time:                0.010095596313476562\n",
      "    epoch time:               0.02466416358947754\n",
      "    last layer lr:            0.009604000000000001\n",
      "epoch: 170 (17/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 94.44%\n",
      "    train overall loss:       0.1392237382630507\n",
      "    train cross_ent loss:     0.061483170837163925\n",
      "    test overall loss:        0.33467520773410797\n",
      "    test cross_ent loss:      0.25882817804813385\n",
      "    cluster loss:             74.70506477355957\n",
      "    separation loss:          0.38231219351291656\n",
      "    avg separation loss:      2.4801868200302124\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  72.81008911132812\n",
      "    train time:               0.013747692108154297\n",
      "    test time:                0.010054588317871094\n",
      "    epoch time:               0.024313926696777344\n",
      "    last layer lr:            0.009208000000000003\n",
      "epoch: 170 (18/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.1263199063638846\n",
      "    train cross_ent loss:     0.05150074232369661\n",
      "    test overall loss:        0.33345894515514374\n",
      "    test cross_ent loss:      0.2600705698132515\n",
      "    cluster loss:             74.70501518249512\n",
      "    separation loss:          0.381644532084465\n",
      "    avg separation loss:      2.479046940803528\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  70.3514175415039\n",
      "    train time:               0.01253199577331543\n",
      "    test time:                0.009485721588134766\n",
      "    epoch time:               0.02251291275024414\n",
      "    last layer lr:            0.008811999999999997\n",
      "epoch: 170 (19/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.11632367720206578\n",
      "    train cross_ent loss:     0.04419040524711212\n",
      "    test overall loss:        0.3329377770423889\n",
      "    test cross_ent loss:      0.26266247034072876\n",
      "    cluster loss:             74.70507431030273\n",
      "    separation loss:          0.38084158301353455\n",
      "    avg separation loss:      2.479759454727173\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  67.23835754394531\n",
      "    train time:               0.01395726203918457\n",
      "    test time:                0.010603189468383789\n",
      "    epoch time:               0.02509140968322754\n",
      "    last layer lr:            0.008415999999999998\n",
      "epoch: 170 (20/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.11900657167037328\n",
      "    train cross_ent loss:     0.050127658837785326\n",
      "    test overall loss:        0.3372102677822113\n",
      "    test cross_ent loss:      0.27013784646987915\n",
      "    cluster loss:             74.70529174804688\n",
      "    separation loss:          0.38069815933704376\n",
      "    avg separation loss:      2.47647488117218\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  64.03547668457031\n",
      "    train time:               0.014124155044555664\n",
      "    test time:                0.010410308837890625\n",
      "    epoch time:               0.025067806243896484\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 170 (21/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.12285214165846507\n",
      "    train cross_ent loss:     0.05684725598742565\n",
      "    test overall loss:        0.3353833258152008\n",
      "    test cross_ent loss:      0.27069519460201263\n",
      "    cluster loss:             74.70496559143066\n",
      "    separation loss:          0.3809577226638794\n",
      "    avg separation loss:      2.4830729961395264\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  61.65118408203125\n",
      "    train time:               0.013180732727050781\n",
      "    test time:                0.010146141052246094\n",
      "    epoch time:               0.023847579956054688\n",
      "    last layer lr:            0.007624000000000002\n",
      "epoch: 170 (22/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.11174143354098003\n",
      "    train cross_ent loss:     0.0480795685822765\n",
      "    test overall loss:        0.3299196660518646\n",
      "    test cross_ent loss:      0.26767128705978394\n",
      "    cluster loss:             74.70490837097168\n",
      "    separation loss:          0.38183271884918213\n",
      "    avg separation loss:      2.4830278158187866\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  59.21141815185547\n",
      "    train time:               0.013885021209716797\n",
      "    test time:                0.009978055953979492\n",
      "    epoch time:               0.024381160736083984\n",
      "    last layer lr:            0.0072280000000000035\n",
      "epoch: 170 (23/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.12238908062378566\n",
      "    train cross_ent loss:     0.06098276159415642\n",
      "    test overall loss:        0.3304622173309326\n",
      "    test cross_ent loss:      0.27000191807746887\n",
      "    cluster loss:             74.70498847961426\n",
      "    separation loss:          0.3808644711971283\n",
      "    avg separation loss:      2.481387138366699\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  57.42333984375\n",
      "    train time:               0.014370918273925781\n",
      "    test time:                0.010364770889282227\n",
      "    epoch time:               0.025275468826293945\n",
      "    last layer lr:            0.006831999999999998\n",
      "epoch: 170 (24/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.11318119739492734\n",
      "    train cross_ent loss:     0.05305736744776368\n",
      "    test overall loss:        0.32999274134635925\n",
      "    test cross_ent loss:      0.27063682675361633\n",
      "    cluster loss:             74.70496940612793\n",
      "    separation loss:          0.38125069439411163\n",
      "    avg separation loss:      2.4867106676101685\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  56.31897735595703\n",
      "    train time:               0.017179250717163086\n",
      "    test time:                0.010776042938232422\n",
      "    epoch time:               0.028560876846313477\n",
      "    last layer lr:            0.006436\n",
      "epoch: 170 (25/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.11154650524258614\n",
      "    train cross_ent loss:     0.05288740216443936\n",
      "    test overall loss:        0.3275758624076843\n",
      "    test cross_ent loss:      0.269803911447525\n",
      "    cluster loss:             74.70494079589844\n",
      "    separation loss:          0.3813403695821762\n",
      "    avg separation loss:      2.483260154724121\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  54.7349967956543\n",
      "    train time:               0.013886213302612305\n",
      "    test time:                0.01069188117980957\n",
      "    epoch time:               0.02516484260559082\n",
      "    last layer lr:            0.00604\n",
      "epoch: 170 (26/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.10874854028224945\n",
      "    train cross_ent loss:     0.05153730108092228\n",
      "    test overall loss:        0.32077768445014954\n",
      "    test cross_ent loss:      0.2643674314022064\n",
      "    cluster loss:             74.70504379272461\n",
      "    separation loss:          0.3802359700202942\n",
      "    avg separation loss:      2.4796128273010254\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  53.37331008911133\n",
      "    train time:               0.013953924179077148\n",
      "    test time:                0.004663944244384766\n",
      "    epoch time:               0.019144773483276367\n",
      "    last layer lr:            0.005644000000000002\n",
      "epoch: 170 (27/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.09941750640670459\n",
      "    train cross_ent loss:     0.043596125207841396\n",
      "    test overall loss:        0.32093529403209686\n",
      "    test cross_ent loss:      0.26597900688648224\n",
      "    cluster loss:             74.7049503326416\n",
      "    separation loss:          0.38036584854125977\n",
      "    avg separation loss:      2.483294367790222\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  51.919334411621094\n",
      "    train time:               0.013794183731079102\n",
      "    test time:                0.010093927383422852\n",
      "    epoch time:               0.024410009384155273\n",
      "    last layer lr:            0.005248000000000003\n",
      "epoch: 170 (28/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.10841992124915123\n",
      "    train cross_ent loss:     0.054057435132563114\n",
      "    test overall loss:        0.32057246565818787\n",
      "    test cross_ent loss:      0.26704660058021545\n",
      "    cluster loss:             74.7050609588623\n",
      "    separation loss:          0.3797431141138077\n",
      "    avg separation loss:      2.4792094230651855\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  50.488929748535156\n",
      "    train time:               0.013706684112548828\n",
      "    test time:                0.010065317153930664\n",
      "    epoch time:               0.024300336837768555\n",
      "    last layer lr:            0.004851999999999998\n",
      "epoch: 170 (29/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.10123892625172932\n",
      "    train cross_ent loss:     0.04814346072574457\n",
      "    test overall loss:        0.32249675691127777\n",
      "    test cross_ent loss:      0.2700635641813278\n",
      "    cluster loss:             74.70529174804688\n",
      "    separation loss:          0.3796781897544861\n",
      "    avg separation loss:      2.4794617891311646\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  49.39623260498047\n",
      "    train time:               0.012553691864013672\n",
      "    test time:                0.00440526008605957\n",
      "    epoch time:               0.017436981201171875\n",
      "    last layer lr:            0.004455999999999999\n",
      "epoch: 170 (30/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 94.44%\n",
      "    train overall loss:       0.10529020552833875\n",
      "    train cross_ent loss:     0.053329652175307274\n",
      "    test overall loss:        0.3175711929798126\n",
      "    test cross_ent loss:      0.26622551679611206\n",
      "    cluster loss:             74.7049617767334\n",
      "    separation loss:          0.3812182992696762\n",
      "    avg separation loss:      2.4839924573898315\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  48.308712005615234\n",
      "    train time:               0.012445449829101562\n",
      "    test time:                0.004433870315551758\n",
      "    epoch time:               0.017353057861328125\n",
      "    last layer lr:            0.004060000000000001\n",
      "epoch: 170 (31/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 94.44%\n",
      "    train overall loss:       0.09394961719711621\n",
      "    train cross_ent loss:     0.042919013959666096\n",
      "    test overall loss:        0.3142803758382797\n",
      "    test cross_ent loss:      0.2637080103158951\n",
      "    cluster loss:             74.70494079589844\n",
      "    separation loss:          0.38204634189605713\n",
      "    avg separation loss:      2.479860544204712\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  47.53541564941406\n",
      "    train time:               0.012341022491455078\n",
      "    test time:                0.0044329166412353516\n",
      "    epoch time:               0.017239809036254883\n",
      "    last layer lr:            0.0036640000000000015\n",
      "epoch: 170 (32/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 94.44%\n",
      "    train overall loss:       0.11634176224470139\n",
      "    train cross_ent loss:     0.06596269365400076\n",
      "    test overall loss:        0.3103198707103729\n",
      "    test cross_ent loss:      0.26027631759643555\n",
      "    cluster loss:             74.70478820800781\n",
      "    separation loss:          0.3823338896036148\n",
      "    avg separation loss:      2.486634612083435\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  47.006591796875\n",
      "    train time:               0.01235055923461914\n",
      "    test time:                0.00439763069152832\n",
      "    epoch time:               0.017219066619873047\n",
      "    last layer lr:            0.003268000000000003\n",
      "epoch: 170 (33/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.1001051515340805\n",
      "    train cross_ent loss:     0.05031976600488027\n",
      "    test overall loss:        0.3124232292175293\n",
      "    test cross_ent loss:      0.2630380690097809\n",
      "    cluster loss:             74.7048568725586\n",
      "    separation loss:          0.3820175379514694\n",
      "    avg separation loss:      2.49120557308197\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  46.34820556640625\n",
      "    train time:               0.012437820434570312\n",
      "    test time:                0.004396915435791016\n",
      "    epoch time:               0.017325878143310547\n",
      "    last layer lr:            0.002871999999999997\n",
      "epoch: 170 (34/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.10219121227661769\n",
      "    train cross_ent loss:     0.05306129530072212\n",
      "    test overall loss:        0.3109798729419708\n",
      "    test cross_ent loss:      0.26225489377975464\n",
      "    cluster loss:             74.70488929748535\n",
      "    separation loss:          0.38161079585552216\n",
      "    avg separation loss:      2.4866011142730713\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  45.688026428222656\n",
      "    train time:               0.012357711791992188\n",
      "    test time:                0.004357814788818359\n",
      "    epoch time:               0.01718616485595703\n",
      "    last layer lr:            0.0024759999999999986\n",
      "epoch: 170 (35/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.09621876602371533\n",
      "    train cross_ent loss:     0.04776740912348032\n",
      "    test overall loss:        0.31128764152526855\n",
      "    test cross_ent loss:      0.26318788528442383\n",
      "    cluster loss:             74.70460891723633\n",
      "    separation loss:          0.38107267022132874\n",
      "    avg separation loss:      2.4890143871307373\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  45.06279754638672\n",
      "    train time:               0.012382984161376953\n",
      "    test time:                0.0044002532958984375\n",
      "    epoch time:               0.01725149154663086\n",
      "    last layer lr:            0.0020800000000000003\n",
      "epoch: 170 (36/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.09590198347965877\n",
      "    train cross_ent loss:     0.04800814731667439\n",
      "    test overall loss:        0.3111700564622879\n",
      "    test cross_ent loss:      0.2635412961244583\n",
      "    cluster loss:             74.7045841217041\n",
      "    separation loss:          0.38140445947647095\n",
      "    avg separation loss:      2.490109920501709\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  44.59180450439453\n",
      "    train time:               0.012387990951538086\n",
      "    test time:                0.00441288948059082\n",
      "    epoch time:               0.017271995544433594\n",
      "    last layer lr:            0.0016840000000000017\n",
      "epoch: 170 (37/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.0935869999229908\n",
      "    train cross_ent loss:     0.046120344971617065\n",
      "    test overall loss:        0.30952349305152893\n",
      "    test cross_ent loss:      0.2622895985841751\n",
      "    cluster loss:             74.70488357543945\n",
      "    separation loss:          0.38145193457603455\n",
      "    avg separation loss:      2.489370822906494\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  44.19694519042969\n",
      "    train time:               0.01287531852722168\n",
      "    test time:                0.004419088363647461\n",
      "    epoch time:               0.0177915096282959\n",
      "    last layer lr:            0.001288000000000003\n",
      "epoch: 170 (38/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.08939765890439351\n",
      "    train cross_ent loss:     0.04231812090923389\n",
      "    test overall loss:        0.31081923842430115\n",
      "    test cross_ent loss:      0.26394641399383545\n",
      "    cluster loss:             74.70485305786133\n",
      "    separation loss:          0.3809448331594467\n",
      "    avg separation loss:      2.485013246536255\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  43.835880279541016\n",
      "    train time:               0.01238703727722168\n",
      "    test time:                0.004395723342895508\n",
      "    epoch time:               0.017258405685424805\n",
      "    last layer lr:            0.0008919999999999973\n",
      "epoch: 170 (39/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.12338536232709885\n",
      "    train cross_ent loss:     0.07657864006857078\n",
      "    test overall loss:        0.31046658754348755\n",
      "    test cross_ent loss:      0.2637218236923218\n",
      "    cluster loss:             74.70547485351562\n",
      "    separation loss:          0.37914039194583893\n",
      "    avg separation loss:      2.473370313644409\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  43.707828521728516\n",
      "    train time:               0.012392282485961914\n",
      "    test time:                0.00439763069152832\n",
      "    epoch time:               0.017261028289794922\n",
      "    last layer lr:            0.0004959999999999986\n",
      "epoch: 170 (40/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.1055583544075489\n",
      "    train cross_ent loss:     0.05880220979452133\n",
      "    test overall loss:        0.30659712851047516\n",
      "    test cross_ent loss:      0.25986114889383316\n",
      "    cluster loss:             74.70532608032227\n",
      "    separation loss:          0.3816235214471817\n",
      "    avg separation loss:      2.4743484258651733\n",
      "    l1_addon loss:            101.2314224243164\n",
      "    l1 loss:                  43.69902801513672\n",
      "    train time:               0.012105941772460938\n",
      "    test time:                0.0044269561767578125\n",
      "    epoch time:               0.017005443572998047\n",
      "    last layer lr:            0.0001\n",
      "epoch: 171 (JOINT) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.10470093786716461\n",
      "    train cross_ent loss:     0.0579649256542325\n",
      "    test overall loss:        0.30473823845386505\n",
      "    test cross_ent loss:      0.2580021992325783\n",
      "    cluster loss:             74.70496368408203\n",
      "    separation loss:          0.3827226459980011\n",
      "    avg separation loss:      2.4800381660461426\n",
      "    l1_addon loss:            101.23324584960938\n",
      "    l1 loss:                  43.69902801513672\n",
      "    train time:               0.03010725975036621\n",
      "    test time:                0.004320383071899414\n",
      "    epoch time:               0.03498053550720215\n",
      "    joint lr:                 0.0009861958963236286\n",
      "epoch: 172 (JOINT) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.09710685163736343\n",
      "    train cross_ent loss:     0.050370672096808754\n",
      "    test overall loss:        0.2998887002468109\n",
      "    test cross_ent loss:      0.2531515285372734\n",
      "    cluster loss:             74.7049331665039\n",
      "    separation loss:          0.3788403123617172\n",
      "    avg separation loss:      2.4768550395965576\n",
      "    l1_addon loss:            101.27098083496094\n",
      "    l1 loss:                  43.69902801513672\n",
      "    train time:               0.029727935791015625\n",
      "    test time:                0.004509687423706055\n",
      "    epoch time:               0.03479814529418945\n",
      "    joint lr:                 0.001854667874720785\n",
      "epoch: 173 (JOINT) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.09230548143386841\n",
      "    train cross_ent loss:     0.04556738771498203\n",
      "    test overall loss:        0.2984355688095093\n",
      "    test cross_ent loss:      0.2516969069838524\n",
      "    cluster loss:             74.70393371582031\n",
      "    separation loss:          0.374382883310318\n",
      "    avg separation loss:      2.4617258310317993\n",
      "    l1_addon loss:            101.32077026367188\n",
      "    l1 loss:                  43.69902801513672\n",
      "    train time:               0.029571533203125\n",
      "    test time:                0.004391670227050781\n",
      "    epoch time:               0.03454113006591797\n",
      "    joint lr:                 0.0027056817939603655\n",
      "epoch: 174 (JOINT) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.10221542914708455\n",
      "    train cross_ent loss:     0.05547619859377543\n",
      "    test overall loss:        0.30885618925094604\n",
      "    test cross_ent loss:      0.2621166706085205\n",
      "    cluster loss:             74.70216369628906\n",
      "    separation loss:          0.37017722427845\n",
      "    avg separation loss:      2.4596139192581177\n",
      "    l1_addon loss:            101.34957885742188\n",
      "    l1 loss:                  43.69902801513672\n",
      "    train time:               0.029417037963867188\n",
      "    test time:                0.004513263702392578\n",
      "    epoch time:               0.0347895622253418\n",
      "    joint lr:                 0.003539499968027705\n",
      "epoch: 175 (JOINT) - Libras\n",
      "    test acc:                 94.44%\n",
      "    train overall loss:       0.08313828520476818\n",
      "    train cross_ent loss:     0.036396979819983244\n",
      "    test overall loss:        0.3256818503141403\n",
      "    test cross_ent loss:      0.2789374738931656\n",
      "    cluster loss:             74.70437622070312\n",
      "    separation loss:          0.3737472742795944\n",
      "    avg separation loss:      2.4642245769500732\n",
      "    l1_addon loss:            101.511474609375\n",
      "    l1 loss:                  43.69902801513672\n",
      "    train time:               0.029938697814941406\n",
      "    test time:                0.004517316818237305\n",
      "    epoch time:               0.03534865379333496\n",
      "    joint lr:                 0.00435638121043428\n",
      "epoch: 176 (JOINT) - Libras\n",
      "    test acc:                 92.78%\n",
      "    train overall loss:       0.08778577173749606\n",
      "    train cross_ent loss:     0.04104201619823774\n",
      "    test overall loss:        0.31546375155448914\n",
      "    test cross_ent loss:      0.26872551441192627\n",
      "    cluster loss:             74.7031364440918\n",
      "    separation loss:          0.3703031837940216\n",
      "    avg separation loss:      2.4370179176330566\n",
      "    l1_addon loss:            101.30664825439453\n",
      "    l1 loss:                  43.69902801513672\n",
      "    train time:               0.02989959716796875\n",
      "    test time:                0.004382133483886719\n",
      "    epoch time:               0.034850358963012695\n",
      "    joint lr:                 0.00515658087799592\n",
      "epoch: 177 (JOINT) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.09287586311499278\n",
      "    train cross_ent loss:     0.04614094148079554\n",
      "    test overall loss:        0.3222424387931824\n",
      "    test cross_ent loss:      0.27550145983695984\n",
      "    cluster loss:             74.70661926269531\n",
      "    separation loss:          0.36435818672180176\n",
      "    avg separation loss:      2.3718600273132324\n",
      "    l1_addon loss:            101.39881896972656\n",
      "    l1 loss:                  43.69902801513672\n",
      "    train time:               0.028139352798461914\n",
      "    test time:                0.004469394683837891\n",
      "    epoch time:               0.03346419334411621\n",
      "    joint lr:                 0.005940350914085284\n",
      "epoch: 178 (JOINT) - Libras\n",
      "    test acc:                 94.44%\n",
      "    train overall loss:       0.0962921753525734\n",
      "    train cross_ent loss:     0.04954255931079388\n",
      "    test overall loss:        0.32507629692554474\n",
      "    test cross_ent loss:      0.2783329039812088\n",
      "    cluster loss:             74.7078800201416\n",
      "    separation loss:          0.3640469163656235\n",
      "    avg separation loss:      2.3423584699630737\n",
      "    l1_addon loss:            101.47859191894531\n",
      "    l1 loss:                  43.69902801513672\n",
      "    train time:               0.029484033584594727\n",
      "    test time:                0.004339933395385742\n",
      "    epoch time:               0.03437042236328125\n",
      "    joint lr:                 0.00670793989136506\n",
      "epoch: 179 (JOINT) - Libras\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       0.14339210589726767\n",
      "    train cross_ent loss:     0.09666717983782291\n",
      "    test overall loss:        0.4799116551876068\n",
      "    test cross_ent loss:      0.4331946074962616\n",
      "    cluster loss:             74.72527313232422\n",
      "    separation loss:          0.4091057777404785\n",
      "    avg separation loss:      2.440883755683899\n",
      "    l1_addon loss:            100.599853515625\n",
      "    l1 loss:                  43.69902801513672\n",
      "    train time:               0.029155254364013672\n",
      "    test time:                0.0043299198150634766\n",
      "    epoch time:               0.03401637077331543\n",
      "    joint lr:                 0.007459593054007833\n",
      "epoch: 180 (JOINT) - Libras\n",
      "    test acc:                 92.78%\n",
      "    train overall loss:       0.13183412700891495\n",
      "    train cross_ent loss:     0.08510945675273736\n",
      "    test overall loss:        0.389962375164032\n",
      "    test cross_ent loss:      0.34321313351392746\n",
      "    cluster loss:             74.73058700561523\n",
      "    separation loss:          0.4221806973218918\n",
      "    avg separation loss:      2.5475720167160034\n",
      "    l1_addon loss:            101.67361450195312\n",
      "    l1 loss:                  43.69902801513672\n",
      "    train time:               0.029668331146240234\n",
      "    test time:                0.004420042037963867\n",
      "    epoch time:               0.03465604782104492\n",
      "    joint lr:                 0.008195552359408614\n",
      "epoch: 181 (JOINT) - Libras\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       0.16172676036755243\n",
      "    train cross_ent loss:     0.1149735761185487\n",
      "    test overall loss:        0.4900749921798706\n",
      "    test cross_ent loss:      0.44335174560546875\n",
      "    cluster loss:             74.72683143615723\n",
      "    separation loss:          0.4279264807701111\n",
      "    avg separation loss:      2.387350916862488\n",
      "    l1_addon loss:            100.80657958984375\n",
      "    l1 loss:                  43.69902801513672\n",
      "    train time:               0.02896595001220703\n",
      "    test time:                0.004533052444458008\n",
      "    epoch time:               0.03435850143432617\n",
      "    joint lr:                 0.007713866994023813\n",
      "epoch: 182 (JOINT) - Libras\n",
      "    test acc:                 78.89%\n",
      "    train overall loss:       0.19298948471744856\n",
      "    train cross_ent loss:     0.14627788898845515\n",
      "    test overall loss:        0.7636030912399292\n",
      "    test cross_ent loss:      0.7168719172477722\n",
      "    cluster loss:             74.7531509399414\n",
      "    separation loss:          0.47817468643188477\n",
      "    avg separation loss:      2.791204333305359\n",
      "    l1_addon loss:            101.07075500488281\n",
      "    l1 loss:                  43.69902801513672\n",
      "    train time:               0.02946758270263672\n",
      "    test time:                0.0045320987701416016\n",
      "    epoch time:               0.03484797477722168\n",
      "    joint lr:                 0.007241005780710745\n",
      "epoch: 183 (JOINT) - Libras\n",
      "    test acc:                 91.11%\n",
      "    train overall loss:       0.19424348448713621\n",
      "    train cross_ent loss:     0.14750496918956438\n",
      "    test overall loss:        0.4169493317604065\n",
      "    test cross_ent loss:      0.37022846937179565\n",
      "    cluster loss:             74.72528076171875\n",
      "    separation loss:          0.4243374466896057\n",
      "    avg separation loss:      2.487515091896057\n",
      "    l1_addon loss:            100.72746276855469\n",
      "    l1 loss:                  43.69902801513672\n",
      "    train time:               0.029341936111450195\n",
      "    test time:                0.0043849945068359375\n",
      "    epoch time:               0.034273624420166016\n",
      "    joint lr:                 0.006776840404964548\n",
      "epoch: 184 (JOINT) - Libras\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       0.2175356149673462\n",
      "    train cross_ent loss:     0.17082064847151437\n",
      "    test overall loss:        0.4628486931324005\n",
      "    test cross_ent loss:      0.41611239314079285\n",
      "    cluster loss:             74.72961616516113\n",
      "    separation loss:          0.4487803131341934\n",
      "    avg separation loss:      2.4771779775619507\n",
      "    l1_addon loss:            101.24217987060547\n",
      "    l1 loss:                  43.69902801513672\n",
      "    train time:               0.03165149688720703\n",
      "    test time:                0.015059471130371094\n",
      "    epoch time:               0.047367095947265625\n",
      "    joint lr:                 0.006321244236155204\n",
      "epoch: 185 (JOINT) - Libras\n",
      "    test acc:                 88.33%\n",
      "    train overall loss:       0.1983922744790713\n",
      "    train cross_ent loss:     0.15165074542164803\n",
      "    test overall loss:        0.5396039634943008\n",
      "    test cross_ent loss:      0.4928828775882721\n",
      "    cluster loss:             74.74955749511719\n",
      "    separation loss:          0.4716062694787979\n",
      "    avg separation loss:      2.509835362434387\n",
      "    l1_addon loss:            100.73526763916016\n",
      "    l1 loss:                  43.69902801513672\n",
      "    train time:               0.032240867614746094\n",
      "    test time:                0.010125398635864258\n",
      "    epoch time:               0.04303097724914551\n",
      "    joint lr:                 0.00587409230668155\n",
      "epoch: 186 (JOINT) - Libras\n",
      "    test acc:                 90.56%\n",
      "    train overall loss:       0.15516205628712973\n",
      "    train cross_ent loss:     0.1084481639166673\n",
      "    test overall loss:        0.45251117646694183\n",
      "    test cross_ent loss:      0.405788317322731\n",
      "    cluster loss:             74.74573516845703\n",
      "    separation loss:          0.47257810831069946\n",
      "    avg separation loss:      2.4982516765594482\n",
      "    l1_addon loss:            100.79483032226562\n",
      "    l1 loss:                  43.69902801513672\n",
      "    train time:               0.03140401840209961\n",
      "    test time:                0.010030269622802734\n",
      "    epoch time:               0.04207801818847656\n",
      "    joint lr:                 0.0054352612913737535\n",
      "epoch: 187 (JOINT) - Libras\n",
      "    test acc:                 85.56%\n",
      "    train overall loss:       0.1323446730772654\n",
      "    train cross_ent loss:     0.08561376171807449\n",
      "    test overall loss:        0.48917895555496216\n",
      "    test cross_ent loss:      0.4424498677253723\n",
      "    cluster loss:             74.72697830200195\n",
      "    separation loss:          0.4228475093841553\n",
      "    avg separation loss:      2.5278260707855225\n",
      "    l1_addon loss:            101.00157928466797\n",
      "    l1 loss:                  43.69902801513672\n",
      "    train time:               0.030260801315307617\n",
      "    test time:                0.010035991668701172\n",
      "    epoch time:               0.040909528732299805\n",
      "    joint lr:                 0.005004629487141445\n",
      "epoch: 188 (JOINT) - Libras\n",
      "    test acc:                 92.78%\n",
      "    train overall loss:       0.1029341071844101\n",
      "    train cross_ent loss:     0.056210871785879135\n",
      "    test overall loss:        0.39323006570339203\n",
      "    test cross_ent loss:      0.34651054441928864\n",
      "    cluster loss:             74.71462059020996\n",
      "    separation loss:          0.4062433987855911\n",
      "    avg separation loss:      2.4507529735565186\n",
      "    l1_addon loss:            100.68336486816406\n",
      "    l1 loss:                  43.69902801513672\n",
      "    train time:               0.029346942901611328\n",
      "    test time:                0.010057687759399414\n",
      "    epoch time:               0.04006052017211914\n",
      "    joint lr:                 0.004582076792864645\n",
      "epoch: 189 (JOINT) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.09711976225177447\n",
      "    train cross_ent loss:     0.05039392318576574\n",
      "    test overall loss:        0.34642720222473145\n",
      "    test cross_ent loss:      0.2996922731399536\n",
      "    cluster loss:             74.7122859954834\n",
      "    separation loss:          0.4320090562105179\n",
      "    avg separation loss:      2.5419641733169556\n",
      "    l1_addon loss:            101.19708251953125\n",
      "    l1 loss:                  43.69902801513672\n",
      "    train time:               0.03052806854248047\n",
      "    test time:                0.01034855842590332\n",
      "    epoch time:               0.041528940200805664\n",
      "    joint lr:                 0.004167484689524657\n",
      "epoch: 190 (JOINT) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.0901413622001807\n",
      "    train cross_ent loss:     0.0434046204512318\n",
      "    test overall loss:        0.3150542676448822\n",
      "    test cross_ent loss:      0.26831671595573425\n",
      "    cluster loss:             74.71028709411621\n",
      "    separation loss:          0.4016311764717102\n",
      "    avg separation loss:      2.468829870223999\n",
      "    l1_addon loss:            101.28394317626953\n",
      "    l1 loss:                  43.69902801513672\n",
      "    train time:               0.03026866912841797\n",
      "    test time:                0.010118961334228516\n",
      "    epoch time:               0.041030168533325195\n",
      "    joint lr:                 0.003760736220572192\n",
      "epoch: 191 (JOINT) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.09272206326325734\n",
      "    train cross_ent loss:     0.04598630592226982\n",
      "    test overall loss:        0.31656451523303986\n",
      "    test cross_ent loss:      0.26983390748500824\n",
      "    cluster loss:             74.70947647094727\n",
      "    separation loss:          0.38263584673404694\n",
      "    avg separation loss:      2.3915399312973022\n",
      "    l1_addon loss:            101.0528793334961\n",
      "    l1 loss:                  43.69902801513672\n",
      "    train time:               0.031086444854736328\n",
      "    test time:                0.009738683700561523\n",
      "    epoch time:               0.041491031646728516\n",
      "    joint lr:                 0.0033617159725298235\n",
      "epoch: 192 (JOINT) - Libras\n",
      "    test acc:                 92.22%\n",
      "    train overall loss:       0.0778302326798439\n",
      "    train cross_ent loss:     0.03110301603252689\n",
      "    test overall loss:        0.3249536156654358\n",
      "    test cross_ent loss:      0.27822911739349365\n",
      "    cluster loss:             74.70777893066406\n",
      "    separation loss:          0.3813240975141525\n",
      "    avg separation loss:      2.3782788515090942\n",
      "    l1_addon loss:            100.84938049316406\n",
      "    l1 loss:                  43.69902801513672\n",
      "    train time:               0.030370235443115234\n",
      "    test time:                0.0044248104095458984\n",
      "    epoch time:               0.035373687744140625\n",
      "    joint lr:                 0.002970310055826246\n",
      "epoch: 193 (JOINT) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.07147094048559666\n",
      "    train cross_ent loss:     0.02474512020125985\n",
      "    test overall loss:        0.31489212810993195\n",
      "    test cross_ent loss:      0.2681641951203346\n",
      "    cluster loss:             74.7044563293457\n",
      "    separation loss:          0.38324975967407227\n",
      "    avg separation loss:      2.3753591775894165\n",
      "    l1_addon loss:            100.96340942382812\n",
      "    l1 loss:                  43.69902801513672\n",
      "    train time:               0.03316354751586914\n",
      "    test time:                0.0044097900390625\n",
      "    epoch time:               0.03816986083984375\n",
      "    joint lr:                 0.0025864060858594865\n",
      "epoch: 194 (JOINT) - Libras\n",
      "    test acc:                 92.78%\n",
      "    train overall loss:       0.07482893951237202\n",
      "    train cross_ent loss:     0.028100036084651947\n",
      "    test overall loss:        0.3145992010831833\n",
      "    test cross_ent loss:      0.2678689509630203\n",
      "    cluster loss:             74.7027759552002\n",
      "    separation loss:          0.38174134492874146\n",
      "    avg separation loss:      2.3691415786743164\n",
      "    l1_addon loss:            101.04109954833984\n",
      "    l1 loss:                  43.69902801513672\n",
      "    train time:               0.03396105766296387\n",
      "    test time:                0.00950932502746582\n",
      "    epoch time:               0.04409527778625488\n",
      "    joint lr:                 0.00220989316428648\n",
      "epoch: 195 (JOINT) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.07359111184875171\n",
      "    train cross_ent loss:     0.026860297735159595\n",
      "    test overall loss:        0.30977731943130493\n",
      "    test cross_ent loss:      0.2630464434623718\n",
      "    cluster loss:             74.7027702331543\n",
      "    separation loss:          0.3811289519071579\n",
      "    avg separation loss:      2.354199171066284\n",
      "    l1_addon loss:            101.06149291992188\n",
      "    l1 loss:                  43.69902801513672\n",
      "    train time:               0.03177976608276367\n",
      "    test time:                0.010282039642333984\n",
      "    epoch time:               0.0428624153137207\n",
      "    joint lr:                 0.0018406618605363474\n",
      "epoch: 196 (JOINT) - Libras\n",
      "    test acc:                 93.89%\n",
      "    train overall loss:       0.083496135349075\n",
      "    train cross_ent loss:     0.03676540466646353\n",
      "    test overall loss:        0.31097956001758575\n",
      "    test cross_ent loss:      0.264249786734581\n",
      "    cluster loss:             74.70290565490723\n",
      "    separation loss:          0.37710487842559814\n",
      "    avg separation loss:      2.3304587602615356\n",
      "    l1_addon loss:            101.02481079101562\n",
      "    l1 loss:                  43.69902801513672\n",
      "    train time:               0.0328974723815918\n",
      "    test time:                0.010696649551391602\n",
      "    epoch time:               0.04430890083312988\n",
      "    joint lr:                 0.001478604193544789\n",
      "epoch: 197 (JOINT) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.07865159772336483\n",
      "    train cross_ent loss:     0.031921288619438805\n",
      "    test overall loss:        0.3185749053955078\n",
      "    test cross_ent loss:      0.271843820810318\n",
      "    cluster loss:             74.7017936706543\n",
      "    separation loss:          0.37358467280864716\n",
      "    avg separation loss:      2.3427505493164062\n",
      "    l1_addon loss:            101.06851196289062\n",
      "    l1 loss:                  43.69902801513672\n",
      "    train time:               0.031572580337524414\n",
      "    test time:                0.010817766189575195\n",
      "    epoch time:               0.04309535026550293\n",
      "    joint lr:                 0.0011236136137069992\n",
      "epoch: 198 (JOINT) - Libras\n",
      "    test acc:                 93.33%\n",
      "    train overall loss:       0.08465812789897124\n",
      "    train cross_ent loss:     0.03792743214095632\n",
      "    test overall loss:        0.3175000101327896\n",
      "    test cross_ent loss:      0.2707696035504341\n",
      "    cluster loss:             74.70167350769043\n",
      "    separation loss:          0.371134951710701\n",
      "    avg separation loss:      2.347920060157776\n",
      "    l1_addon loss:            101.04611206054688\n",
      "    l1 loss:                  43.69902801513672\n",
      "    train time:               0.03279876708984375\n",
      "    test time:                0.01076960563659668\n",
      "    epoch time:               0.0442657470703125\n",
      "    joint lr:                 0.0007755849850466195\n",
      "epoch: 199 (JOINT) - Libras\n",
      "    test acc:                 92.78%\n",
      "    train overall loss:       0.07476233194271724\n",
      "    train cross_ent loss:     0.02803246397525072\n",
      "    test overall loss:        0.3133833408355713\n",
      "    test cross_ent loss:      0.2666541337966919\n",
      "    cluster loss:             74.70163345336914\n",
      "    separation loss:          0.3713628202676773\n",
      "    avg separation loss:      2.34433376789093\n",
      "    l1_addon loss:            101.00637817382812\n",
      "    l1 loss:                  43.69902801513672\n",
      "    train time:               0.033621788024902344\n",
      "    test time:                0.010812997817993164\n",
      "    epoch time:               0.04510307312011719\n",
      "    joint lr:                 0.0004344145675980766\n",
      "epoch: 200 (JOINT) - Libras\n",
      "    test acc:                 92.22%\n",
      "    train overall loss:       0.07009613824387391\n",
      "    train cross_ent loss:     0.02336716279387474\n",
      "    test overall loss:        0.3124435842037201\n",
      "    test cross_ent loss:      0.2657148540019989\n",
      "    cluster loss:             74.70172119140625\n",
      "    separation loss:          0.36989323794841766\n",
      "    avg separation loss:      2.347548246383667\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  43.69902801513672\n",
      "    train time:               0.03762316703796387\n",
      "    test time:                0.010973453521728516\n",
      "    epoch time:               0.04942178726196289\n",
      "    joint lr:                 0.0001\n",
      "epoch: 200 (PUSH) - Libras\n",
      "    test acc:                 92.78%\n",
      "    train overall loss:       0.07009613824387391\n",
      "    train cross_ent loss:     0.02336716279387474\n",
      "    test overall loss:        0.33805300295352936\n",
      "    test cross_ent loss:      0.29132427275180817\n",
      "    cluster loss:             74.7009162902832\n",
      "    separation loss:          0.3667138069868088\n",
      "    avg separation loss:      2.3717808723449707\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  43.69902801513672\n",
      "    train time:               0.03762316703796387\n",
      "    test time:                0.004052877426147461\n",
      "    epoch time:               0.08005523681640625\n",
      "epoch: 200 (1/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 92.78%\n",
      "    train overall loss:       0.09878986080487569\n",
      "    train cross_ent loss:     0.05207531557728847\n",
      "    test overall loss:        0.3421657830476761\n",
      "    test cross_ent loss:      0.2954736202955246\n",
      "    cluster loss:             74.70054817199707\n",
      "    separation loss:          0.3667014390230179\n",
      "    avg separation loss:      2.381060481071472\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  43.6624641418457\n",
      "    train time:               0.013303518295288086\n",
      "    test time:                0.0040493011474609375\n",
      "    epoch time:               0.01782703399658203\n",
      "    last layer lr:            0.0007600000000000095\n",
      "epoch: 200 (2/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 92.22%\n",
      "    train overall loss:       0.09110175569852193\n",
      "    train cross_ent loss:     0.044511434311668076\n",
      "    test overall loss:        0.3445686399936676\n",
      "    test cross_ent loss:      0.29809054732322693\n",
      "    cluster loss:             74.70058059692383\n",
      "    separation loss:          0.36680588126182556\n",
      "    avg separation loss:      2.3864049911499023\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  43.448394775390625\n",
      "    train time:               0.01329350471496582\n",
      "    test time:                0.004022121429443359\n",
      "    epoch time:               0.01778268814086914\n",
      "    last layer lr:            0.0014199999999999955\n",
      "epoch: 200 (3/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 92.22%\n",
      "    train overall loss:       0.08664196729660034\n",
      "    train cross_ent loss:     0.04024152737110853\n",
      "    test overall loss:        0.3417492210865021\n",
      "    test cross_ent loss:      0.2955095171928406\n",
      "    cluster loss:             74.7009105682373\n",
      "    separation loss:          0.36823272705078125\n",
      "    avg separation loss:      2.3847399950027466\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  43.209999084472656\n",
      "    train time:               0.01329493522644043\n",
      "    test time:                0.0039937496185302734\n",
      "    epoch time:               0.01776909828186035\n",
      "    last layer lr:            0.0020800000000000046\n",
      "epoch: 200 (4/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 92.78%\n",
      "    train overall loss:       0.09196837494770686\n",
      "    train cross_ent loss:     0.045916932014127575\n",
      "    test overall loss:        0.3403502255678177\n",
      "    test cross_ent loss:      0.29457150399684906\n",
      "    cluster loss:             74.70062255859375\n",
      "    separation loss:          0.366751953959465\n",
      "    avg separation loss:      2.3816479444503784\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  42.74900817871094\n",
      "    train time:               0.013233661651611328\n",
      "    test time:                0.004027605056762695\n",
      "    epoch time:               0.017728090286254883\n",
      "    last layer lr:            0.0027399999999999907\n",
      "epoch: 200 (5/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 92.22%\n",
      "    train overall loss:       0.0999252771337827\n",
      "    train cross_ent loss:     0.05432408209890127\n",
      "    test overall loss:        0.33631518483161926\n",
      "    test cross_ent loss:      0.29090118408203125\n",
      "    cluster loss:             74.70068168640137\n",
      "    separation loss:          0.36831191182136536\n",
      "    avg separation loss:      2.3730756044387817\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  42.3842887878418\n",
      "    train time:               0.01329350471496582\n",
      "    test time:                0.004022359848022461\n",
      "    epoch time:               0.017797231674194336\n",
      "    last layer lr:            0.0034\n",
      "epoch: 200 (6/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 92.22%\n",
      "    train overall loss:       0.09046881025036176\n",
      "    train cross_ent loss:     0.04512664768844843\n",
      "    test overall loss:        0.32837915420532227\n",
      "    test cross_ent loss:      0.2832081615924835\n",
      "    cluster loss:             74.7007999420166\n",
      "    separation loss:          0.3694039285182953\n",
      "    avg separation loss:      2.3773082494735718\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  42.141273498535156\n",
      "    train time:               0.01331019401550293\n",
      "    test time:                0.003992795944213867\n",
      "    epoch time:               0.01774311065673828\n",
      "    last layer lr:            0.00406000000000001\n",
      "epoch: 200 (7/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 91.67%\n",
      "    train overall loss:       0.09367406989137332\n",
      "    train cross_ent loss:     0.04874918206284443\n",
      "    test overall loss:        0.32759803533554077\n",
      "    test cross_ent loss:      0.28310228884220123\n",
      "    cluster loss:             74.7005615234375\n",
      "    separation loss:          0.368601992726326\n",
      "    avg separation loss:      2.373672366142273\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  41.466041564941406\n",
      "    train time:               0.013733386993408203\n",
      "    test time:                0.003954887390136719\n",
      "    epoch time:               0.0181429386138916\n",
      "    last layer lr:            0.004719999999999996\n",
      "epoch: 200 (8/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 92.22%\n",
      "    train overall loss:       0.0899040475487709\n",
      "    train cross_ent loss:     0.04566253783802191\n",
      "    test overall loss:        0.32660165429115295\n",
      "    test cross_ent loss:      0.2827467620372772\n",
      "    cluster loss:             74.7007827758789\n",
      "    separation loss:          0.3690492510795593\n",
      "    avg separation loss:      2.378988742828369\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  40.82518005371094\n",
      "    train time:               0.013885021209716797\n",
      "    test time:                0.003978729248046875\n",
      "    epoch time:               0.018332242965698242\n",
      "    last layer lr:            0.0053800000000000054\n",
      "epoch: 200 (9/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 92.22%\n",
      "    train overall loss:       0.09178085252642632\n",
      "    train cross_ent loss:     0.04809943648676077\n",
      "    test overall loss:        0.32789504528045654\n",
      "    test cross_ent loss:      0.28458555042743683\n",
      "    cluster loss:             74.70049095153809\n",
      "    separation loss:          0.37015075981616974\n",
      "    avg separation loss:      2.3799835443496704\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  40.279788970947266\n",
      "    train time:               0.01376652717590332\n",
      "    test time:                0.004027366638183594\n",
      "    epoch time:               0.018265247344970703\n",
      "    last layer lr:            0.0060399999999999916\n",
      "epoch: 200 (10/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 91.11%\n",
      "    train overall loss:       0.08121424292524655\n",
      "    train cross_ent loss:     0.03821533856292566\n",
      "    test overall loss:        0.32982781529426575\n",
      "    test cross_ent loss:      0.28725722432136536\n",
      "    cluster loss:             74.7004222869873\n",
      "    separation loss:          0.366191104054451\n",
      "    avg separation loss:      2.3795472383499146\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  39.54088592529297\n",
      "    train time:               0.014098882675170898\n",
      "    test time:                0.004028797149658203\n",
      "    epoch time:               0.018617630004882812\n",
      "    last layer lr:            0.0067\n",
      "epoch: 200 (11/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 92.22%\n",
      "    train overall loss:       0.09845237930615743\n",
      "    train cross_ent loss:     0.05611383604506651\n",
      "    test overall loss:        0.33118684589862823\n",
      "    test cross_ent loss:      0.28947754204273224\n",
      "    cluster loss:             74.70038795471191\n",
      "    separation loss:          0.36665159463882446\n",
      "    avg separation loss:      2.382427453994751\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  38.679588317871094\n",
      "    train time:               0.013650655746459961\n",
      "    test time:                0.003977537155151367\n",
      "    epoch time:               0.018094539642333984\n",
      "    last layer lr:            0.007360000000000011\n",
      "epoch: 200 (12/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 92.78%\n",
      "    train overall loss:       0.08296665673454602\n",
      "    train cross_ent loss:     0.04174938735862573\n",
      "    test overall loss:        0.32806429266929626\n",
      "    test cross_ent loss:      0.28745728731155396\n",
      "    cluster loss:             74.70040130615234\n",
      "    separation loss:          0.3673402667045593\n",
      "    avg separation loss:      2.3796708583831787\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  37.577308654785156\n",
      "    train time:               0.013912200927734375\n",
      "    test time:                0.00397944450378418\n",
      "    epoch time:               0.01835346221923828\n",
      "    last layer lr:            0.008019999999999994\n",
      "epoch: 200 (13/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 91.67%\n",
      "    train overall loss:       0.11279611413677533\n",
      "    train cross_ent loss:     0.07267547585070133\n",
      "    test overall loss:        0.32516855001449585\n",
      "    test cross_ent loss:      0.2855798304080963\n",
      "    cluster loss:             74.70054817199707\n",
      "    separation loss:          0.36697065830230713\n",
      "    avg separation loss:      2.3818193674087524\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  36.55902862548828\n",
      "    train time:               0.013826847076416016\n",
      "    test time:                0.004941463470458984\n",
      "    epoch time:               0.019231319427490234\n",
      "    last layer lr:            0.008680000000000005\n",
      "epoch: 200 (14/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 91.67%\n",
      "    train overall loss:       0.08406307982901733\n",
      "    train cross_ent loss:     0.04435529590894779\n",
      "    test overall loss:        0.32844752073287964\n",
      "    test cross_ent loss:      0.28916245698928833\n",
      "    cluster loss:             74.70071029663086\n",
      "    separation loss:          0.3682561218738556\n",
      "    avg separation loss:      2.379684329032898\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  36.25535202026367\n",
      "    train time:               0.013785600662231445\n",
      "    test time:                0.004018306732177734\n",
      "    epoch time:               0.018269777297973633\n",
      "    last layer lr:            0.00933999999999999\n",
      "epoch: 200 (15/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 92.22%\n",
      "    train overall loss:       0.07870530275007089\n",
      "    train cross_ent loss:     0.039836022071540356\n",
      "    test overall loss:        0.327057421207428\n",
      "    test cross_ent loss:      0.2890665531158447\n",
      "    cluster loss:             74.70091247558594\n",
      "    separation loss:          0.3692740648984909\n",
      "    avg separation loss:      2.381914973258972\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  34.961177825927734\n",
      "    train time:               0.013611078262329102\n",
      "    test time:                0.004008769989013672\n",
      "    epoch time:               0.018082380294799805\n",
      "    last layer lr:            0.01\n",
      "epoch: 200 (16/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 91.67%\n",
      "    train overall loss:       0.07458036144574483\n",
      "    train cross_ent loss:     0.037031970297296844\n",
      "    test overall loss:        0.3254196494817734\n",
      "    test cross_ent loss:      0.2884944826364517\n",
      "    cluster loss:             74.70067405700684\n",
      "    separation loss:          0.36716529726982117\n",
      "    avg separation loss:      2.3811320066452026\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  33.89546585083008\n",
      "    train time:               0.013064861297607422\n",
      "    test time:                0.003983736038208008\n",
      "    epoch time:               0.017511606216430664\n",
      "    last layer lr:            0.009603999999999994\n",
      "epoch: 200 (17/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 92.22%\n",
      "    train overall loss:       0.07420345954596996\n",
      "    train cross_ent loss:     0.038107615585128464\n",
      "    test overall loss:        0.320761501789093\n",
      "    test cross_ent loss:      0.28560832142829895\n",
      "    cluster loss:             74.70061111450195\n",
      "    separation loss:          0.36711646616458893\n",
      "    avg separation loss:      2.3831883668899536\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  32.12347412109375\n",
      "    train time:               0.013357877731323242\n",
      "    test time:                0.0040395259857177734\n",
      "    epoch time:               0.017861127853393555\n",
      "    last layer lr:            0.009208000000000003\n",
      "epoch: 200 (18/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 91.67%\n",
      "    train overall loss:       0.07684958229462306\n",
      "    train cross_ent loss:     0.042269934900105\n",
      "    test overall loss:        0.3200356811285019\n",
      "    test cross_ent loss:      0.2860981971025467\n",
      "    cluster loss:             74.70067596435547\n",
      "    separation loss:          0.366263672709465\n",
      "    avg separation loss:      2.383044958114624\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  30.907777786254883\n",
      "    train time:               0.013421773910522461\n",
      "    test time:                0.0041348934173583984\n",
      "    epoch time:               0.017994403839111328\n",
      "    last layer lr:            0.008811999999999997\n",
      "epoch: 200 (19/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 92.22%\n",
      "    train overall loss:       0.0753411166369915\n",
      "    train cross_ent loss:     0.04166877300788959\n",
      "    test overall loss:        0.3157688081264496\n",
      "    test cross_ent loss:      0.28250157833099365\n",
      "    cluster loss:             74.70070266723633\n",
      "    separation loss:          0.3668828308582306\n",
      "    avg separation loss:      2.3838350772857666\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  30.237518310546875\n",
      "    train time:               0.01404881477355957\n",
      "    test time:                0.003977537155151367\n",
      "    epoch time:               0.01849532127380371\n",
      "    last layer lr:            0.008416000000000005\n",
      "epoch: 200 (20/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 91.67%\n",
      "    train overall loss:       0.0654992579172055\n",
      "    train cross_ent loss:     0.032653828927626215\n",
      "    test overall loss:        0.31566107273101807\n",
      "    test cross_ent loss:      0.28346121311187744\n",
      "    cluster loss:             74.70117378234863\n",
      "    separation loss:          0.36638201773166656\n",
      "    avg separation loss:      2.387068510055542\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  29.17014503479004\n",
      "    train time:               0.013716697692871094\n",
      "    test time:                0.003980398178100586\n",
      "    epoch time:               0.018161773681640625\n",
      "    last layer lr:            0.008020000000000001\n",
      "epoch: 200 (21/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 91.67%\n",
      "    train overall loss:       0.07804569477836291\n",
      "    train cross_ent loss:     0.04632700886577368\n",
      "    test overall loss:        0.3109331578016281\n",
      "    test cross_ent loss:      0.2797391563653946\n",
      "    cluster loss:             74.70088386535645\n",
      "    separation loss:          0.369031623005867\n",
      "    avg separation loss:      2.3834314346313477\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  28.164283752441406\n",
      "    train time:               0.01373147964477539\n",
      "    test time:                0.003966331481933594\n",
      "    epoch time:               0.018161296844482422\n",
      "    last layer lr:            0.007623999999999995\n",
      "epoch: 200 (22/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 91.67%\n",
      "    train overall loss:       0.07543124879399936\n",
      "    train cross_ent loss:     0.04417185283576449\n",
      "    test overall loss:        0.30692535638809204\n",
      "    test cross_ent loss:      0.2756594121456146\n",
      "    cluster loss:             74.70112800598145\n",
      "    separation loss:          0.3687896877527237\n",
      "    avg separation loss:      2.386718988418579\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  28.236251831054688\n",
      "    train time:               0.013415098190307617\n",
      "    test time:                0.003985166549682617\n",
      "    epoch time:               0.017885684967041016\n",
      "    last layer lr:            0.0072280000000000035\n",
      "epoch: 200 (23/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 92.22%\n",
      "    train overall loss:       0.07055755083759625\n",
      "    train cross_ent loss:     0.03961265770097574\n",
      "    test overall loss:        0.31187722086906433\n",
      "    test cross_ent loss:      0.2813800573348999\n",
      "    cluster loss:             74.70118141174316\n",
      "    separation loss:          0.3692016750574112\n",
      "    avg separation loss:      2.389167904853821\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  27.467453002929688\n",
      "    train time:               0.013234138488769531\n",
      "    test time:                0.003995418548583984\n",
      "    epoch time:               0.017711400985717773\n",
      "    last layer lr:            0.006831999999999998\n",
      "epoch: 200 (24/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 91.67%\n",
      "    train overall loss:       0.07883283371726672\n",
      "    train cross_ent loss:     0.048407758275667824\n",
      "    test overall loss:        0.3160153329372406\n",
      "    test cross_ent loss:      0.285842627286911\n",
      "    cluster loss:             74.70096969604492\n",
      "    separation loss:          0.3691665828227997\n",
      "    avg separation loss:      2.383467197418213\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  27.142995834350586\n",
      "    train time:               0.012279748916625977\n",
      "    test time:                0.0038983821868896484\n",
      "    epoch time:               0.01660895347595215\n",
      "    last layer lr:            0.006436000000000007\n",
      "epoch: 200 (25/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 91.67%\n",
      "    train overall loss:       0.06652628071606159\n",
      "    train cross_ent loss:     0.036466420628130436\n",
      "    test overall loss:        0.319727823138237\n",
      "    test cross_ent loss:      0.29005812108516693\n",
      "    cluster loss:             74.7009048461914\n",
      "    separation loss:          0.3681766241788864\n",
      "    avg separation loss:      2.3791511058807373\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  26.639984130859375\n",
      "    train time:               0.012837648391723633\n",
      "    test time:                0.003982067108154297\n",
      "    epoch time:               0.01727914810180664\n",
      "    last layer lr:            0.00604\n",
      "epoch: 200 (26/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 91.11%\n",
      "    train overall loss:       0.06205258394281069\n",
      "    train cross_ent loss:     0.03280949251105388\n",
      "    test overall loss:        0.3201720863580704\n",
      "    test cross_ent loss:      0.29136110842227936\n",
      "    cluster loss:             74.70050239562988\n",
      "    separation loss:          0.36586305499076843\n",
      "    avg separation loss:      2.3831965923309326\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  25.781259536743164\n",
      "    train time:               0.016829490661621094\n",
      "    test time:                0.010659217834472656\n",
      "    epoch time:               0.028073787689208984\n",
      "    last layer lr:            0.0056439999999999945\n",
      "epoch: 200 (27/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 91.67%\n",
      "    train overall loss:       0.06174719085295995\n",
      "    train cross_ent loss:     0.033192168921232224\n",
      "    test overall loss:        0.3175661414861679\n",
      "    test cross_ent loss:      0.2893431931734085\n",
      "    cluster loss:             74.70042419433594\n",
      "    separation loss:          0.36628417670726776\n",
      "    avg separation loss:      2.3813958168029785\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  25.193239212036133\n",
      "    train time:               0.016879796981811523\n",
      "    test time:                0.01085042953491211\n",
      "    epoch time:               0.028318405151367188\n",
      "    last layer lr:            0.005248000000000003\n",
      "epoch: 200 (28/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 91.11%\n",
      "    train overall loss:       0.0692926241705815\n",
      "    train cross_ent loss:     0.04121321470787128\n",
      "    test overall loss:        0.31360821425914764\n",
      "    test cross_ent loss:      0.285784974694252\n",
      "    cluster loss:             74.70043563842773\n",
      "    separation loss:          0.36706002056598663\n",
      "    avg separation loss:      2.3824011087417603\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  24.79352378845215\n",
      "    train time:               0.01719355583190918\n",
      "    test time:                0.010854482650756836\n",
      "    epoch time:               0.028632164001464844\n",
      "    last layer lr:            0.004851999999999998\n",
      "epoch: 200 (29/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 91.11%\n",
      "    train overall loss:       0.06147701603670915\n",
      "    train cross_ent loss:     0.03380150937785705\n",
      "    test overall loss:        0.3156261146068573\n",
      "    test cross_ent loss:      0.2882592976093292\n",
      "    cluster loss:             74.70046997070312\n",
      "    separation loss:          0.36785973608493805\n",
      "    avg separation loss:      2.3860198259353638\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  24.33709716796875\n",
      "    train time:               0.016957759857177734\n",
      "    test time:                0.010756254196166992\n",
      "    epoch time:               0.028315305709838867\n",
      "    last layer lr:            0.004456000000000006\n",
      "epoch: 200 (30/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 91.67%\n",
      "    train overall loss:       0.06808805527786414\n",
      "    train cross_ent loss:     0.0409496968301634\n",
      "    test overall loss:        0.31380921602249146\n",
      "    test cross_ent loss:      0.2868698239326477\n",
      "    cluster loss:             74.70031547546387\n",
      "    separation loss:          0.36750471591949463\n",
      "    avg separation loss:      2.3752514123916626\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  23.90967559814453\n",
      "    train time:               0.016983509063720703\n",
      "    test time:                0.01073455810546875\n",
      "    epoch time:               0.028301715850830078\n",
      "    last layer lr:            0.004060000000000001\n",
      "epoch: 200 (31/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 91.67%\n",
      "    train overall loss:       0.06518872889379661\n",
      "    train cross_ent loss:     0.038369446682433285\n",
      "    test overall loss:        0.31374381482601166\n",
      "    test cross_ent loss:      0.2871103733778\n",
      "    cluster loss:             74.70048522949219\n",
      "    separation loss:          0.36987389624118805\n",
      "    avg separation loss:      2.3809508085250854\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  23.603740692138672\n",
      "    train time:               0.01714920997619629\n",
      "    test time:                0.010762691497802734\n",
      "    epoch time:               0.02850174903869629\n",
      "    last layer lr:            0.0036639999999999945\n",
      "epoch: 200 (32/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 91.67%\n",
      "    train overall loss:       0.06549572013318539\n",
      "    train cross_ent loss:     0.038996721152216196\n",
      "    test overall loss:        0.31307731568813324\n",
      "    test cross_ent loss:      0.28674568235874176\n",
      "    cluster loss:             74.70094108581543\n",
      "    separation loss:          0.3688517212867737\n",
      "    avg separation loss:      2.3871448040008545\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  23.30191421508789\n",
      "    train time:               0.016922473907470703\n",
      "    test time:                0.010774850845336914\n",
      "    epoch time:               0.028283119201660156\n",
      "    last layer lr:            0.003268000000000003\n",
      "epoch: 200 (33/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 91.67%\n",
      "    train overall loss:       0.06461676520605882\n",
      "    train cross_ent loss:     0.03830923823018869\n",
      "    test overall loss:        0.3137771487236023\n",
      "    test cross_ent loss:      0.2875863015651703\n",
      "    cluster loss:             74.70075416564941\n",
      "    separation loss:          0.36811184883117676\n",
      "    avg separation loss:      2.3858784437179565\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  23.161155700683594\n",
      "    train time:               0.016589641571044922\n",
      "    test time:                0.010800361633300781\n",
      "    epoch time:               0.02797985076904297\n",
      "    last layer lr:            0.002871999999999997\n",
      "epoch: 200 (34/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 91.67%\n",
      "    train overall loss:       0.05929719532529513\n",
      "    train cross_ent loss:     0.0331566723374029\n",
      "    test overall loss:        0.31380072236061096\n",
      "    test cross_ent loss:      0.28777819871902466\n",
      "    cluster loss:             74.70086479187012\n",
      "    separation loss:          0.3676237463951111\n",
      "    avg separation loss:      2.386823058128357\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  22.992830276489258\n",
      "    train time:               0.01624464988708496\n",
      "    test time:                0.010864734649658203\n",
      "    epoch time:               0.02768397331237793\n",
      "    last layer lr:            0.0024760000000000055\n",
      "epoch: 200 (35/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 91.67%\n",
      "    train overall loss:       0.06327423391242822\n",
      "    train cross_ent loss:     0.037272271079321705\n",
      "    test overall loss:        0.3163440078496933\n",
      "    test cross_ent loss:      0.2903914302587509\n",
      "    cluster loss:             74.70091247558594\n",
      "    separation loss:          0.3672593832015991\n",
      "    avg separation loss:      2.3906749486923218\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  22.92288589477539\n",
      "    train time:               0.015241384506225586\n",
      "    test time:                0.010798931121826172\n",
      "    epoch time:               0.026605606079101562\n",
      "    last layer lr:            0.0020800000000000003\n",
      "epoch: 200 (36/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 91.11%\n",
      "    train overall loss:       0.061512876922885575\n",
      "    train cross_ent loss:     0.035608734004199505\n",
      "    test overall loss:        0.3162623345851898\n",
      "    test cross_ent loss:      0.2904757559299469\n",
      "    cluster loss:             74.70074844360352\n",
      "    separation loss:          0.3680018186569214\n",
      "    avg separation loss:      2.383660674095154\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  22.75687026977539\n",
      "    train time:               0.013908147811889648\n",
      "    test time:                0.010756969451904297\n",
      "    epoch time:               0.025236845016479492\n",
      "    last layer lr:            0.0016839999999999945\n",
      "epoch: 200 (37/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 91.67%\n",
      "    train overall loss:       0.07210363199313481\n",
      "    train cross_ent loss:     0.04643175688882669\n",
      "    test overall loss:        0.3138637840747833\n",
      "    test cross_ent loss:      0.2882879972457886\n",
      "    cluster loss:             74.7010269165039\n",
      "    separation loss:          0.36921098828315735\n",
      "    avg separation loss:      2.387895345687866\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  22.546072006225586\n",
      "    train time:               0.014851808547973633\n",
      "    test time:                0.010547637939453125\n",
      "    epoch time:               0.026004791259765625\n",
      "    last layer lr:            0.001288000000000003\n",
      "epoch: 200 (38/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 91.67%\n",
      "    train overall loss:       0.0586065948009491\n",
      "    train cross_ent loss:     0.03303227464978894\n",
      "    test overall loss:        0.3124277591705322\n",
      "    test cross_ent loss:      0.2869102358818054\n",
      "    cluster loss:             74.70091819763184\n",
      "    separation loss:          0.369869664311409\n",
      "    avg separation loss:      2.3805580139160156\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  22.48781967163086\n",
      "    train time:               0.013580560684204102\n",
      "    test time:                0.009996652603149414\n",
      "    epoch time:               0.024135351181030273\n",
      "    last layer lr:            0.0008919999999999973\n",
      "epoch: 200 (39/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 91.67%\n",
      "    train overall loss:       0.06424086603025596\n",
      "    train cross_ent loss:     0.03878377083068093\n",
      "    test overall loss:        0.31058989465236664\n",
      "    test cross_ent loss:      0.28520335257053375\n",
      "    cluster loss:             74.70096778869629\n",
      "    separation loss:          0.37119175493717194\n",
      "    avg separation loss:      2.3832427263259888\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  22.356834411621094\n",
      "    train time:               0.01415705680847168\n",
      "    test time:                0.009767293930053711\n",
      "    epoch time:               0.024428367614746094\n",
      "    last layer lr:            0.0004960000000000057\n",
      "epoch: 200 (40/40) (LAST_LAYER) - Libras\n",
      "    test acc:                 91.11%\n",
      "    train overall loss:       0.06596911326050758\n",
      "    train cross_ent loss:     0.040598799319316946\n",
      "    test overall loss:        0.31143325567245483\n",
      "    test cross_ent loss:      0.28609445691108704\n",
      "    cluster loss:             74.70073127746582\n",
      "    separation loss:          0.37037812173366547\n",
      "    avg separation loss:      2.3779371976852417\n",
      "    l1_addon loss:            100.98992919921875\n",
      "    l1 loss:                  22.309091567993164\n",
      "    train time:               0.016300678253173828\n",
      "    test time:                0.004452705383300781\n",
      "    epoch time:               0.021262645721435547\n",
      "    last layer lr:            0.0001\n",
      "Finished training in 21.25 seconds\n",
      "Last epoch test accu: 91.11%\n",
      "Done in 200 epochs, 27.57s\n"
     ]
    }
   ],
   "source": [
    "experiment_name = \"LibrasTestExperiment\"\n",
    "curr_experiment_dir = experiment_setup(experiment_name)\n",
    "log, logclose = create_logger(curr_experiment_dir / \"log.txt\", display=True)\n",
    "\n",
    "try:\n",
    "    params = {\n",
    "        \"protos_per_class\": protos_per_class,\n",
    "        \"proto_features\": proto_features,\n",
    "        \"proto_len_latent\": proto_len,\n",
    "        \"features_lr\": features_lr,\n",
    "        \"num_classes\": ds_info.num_classes,\n",
    "        \"protos_per_class\": protos_per_class,\n",
    "        \"coeffs\": coeffs._asdict(),\n",
    "        \"num_warm_epochs\": num_warm_epochs,\n",
    "        \"push_start_epoch\": push_start_epoch,\n",
    "        \"num_last_layer_epochs\": num_last_layer_epochs,\n",
    "        \"epochs\": epochs,\n",
    "    }\n",
    "    with open(curr_experiment_dir / \"params.json\", \"w\") as f:\n",
    "        json.dump(params, f, indent=4)\n",
    "\n",
    "    log(\n",
    "        f\"Training for {dataset.name}, proto len {proto_len}, features_lr {features_lr}, protos per class {protos_per_class}, l1_addon {coeffs.l1_addon}\",\n",
    "        flush=True,\n",
    "        display=True\n",
    "    )\n",
    "    log(f'Params: {json.dumps(params, indent=4)}')\n",
    "    \n",
    "    whole_training_start = time.time()\n",
    "\n",
    "    log(f'Training encoder', flush=True, display=True)\n",
    "    autoencoder = PermutingConvAutoencoder(num_features=ds_info.features, latent_features=proto_features, reception_percent=reception, padding='same')\n",
    "    train_loader = torch.utils.data.DataLoader(dataset.train, batch_size=train_batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset.val if dataset.val else dataset.test, batch_size=test_batch_size)\n",
    "    train_autoencoder(autoencoder, train_loader, test_loader, device=device, log=log)\n",
    "    encoder = autoencoder.encoder\n",
    "\n",
    "    log(f'Training ProtoTSNet', flush=True, display=True)\n",
    "    trainer = train_prototsnet(\n",
    "        dataset,\n",
    "        curr_experiment_dir,\n",
    "        device,\n",
    "        encoder,\n",
    "        features_lr,\n",
    "        coeffs,\n",
    "        protos_per_class,\n",
    "        proto_features,\n",
    "        proto_len,\n",
    "        train_batch_size,\n",
    "        test_batch_size,\n",
    "        num_epochs=epochs,\n",
    "        num_warm_epochs=num_warm_epochs,\n",
    "        push_start_epoch=push_start_epoch,\n",
    "        push_epochs=push_epochs,\n",
    "        ds_info=ds_info,\n",
    "        num_last_layer_epochs=num_last_layer_epochs,\n",
    "        custom_checkpointers=[\n",
    "            get_verbose_logger(dataset.name),\n",
    "        ],\n",
    "        log=log,\n",
    "    )\n",
    "\n",
    "    accu_test = trainer.latest_stat(\"accu_test\")\n",
    "    log(f'Last epoch test accu: {accu_test*100:.2f}%', display=True)\n",
    "    with open(curr_experiment_dir / \"test_accu.json\", \"w\") as f:\n",
    "        json.dump({\"value\": accu_test}, f, indent=4)\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(dataset.test, batch_size=test_batch_size)\n",
    "    ptsnet = trainer.ptsnet\n",
    "    confusion_matrix = torch.zeros(ptsnet.num_classes, ptsnet.num_classes)\n",
    "    for i, (image, label) in enumerate(test_loader):\n",
    "        output, _ = ptsnet(image.to(device))\n",
    "        confusion_matrix += multiclass_confusion_matrix(output.to('cpu'), label, num_classes=output.shape[1])\n",
    "    np.savetxt(curr_experiment_dir / 'confusion_matrix.txt', confusion_matrix.numpy(), fmt='%4d')\n",
    "\n",
    "    whole_training_end = time.time()\n",
    "    log(f\"Done in {trainer.curr_epoch - 1} epochs, {whole_training_end - whole_training_start:.2f}s\", display=True)\n",
    "except Exception as e:\n",
    "    log(f\"Exception ocurred for {dataset.name}: {e}\", display=True)\n",
    "    tb_str = traceback.format_tb(e.__traceback__)\n",
    "    log('\\n'.join(tb_str), display=True)\n",
    "    raise\n",
    "finally:\n",
    "    logclose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch kernel",
   "language": "python",
   "name": "pytorch"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
